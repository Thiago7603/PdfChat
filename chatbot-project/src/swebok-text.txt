

EDITOR
Hironori Washizaki 
Waseda University, IEEE Computer Society 2024 
President-Elect, 2025 President
Guide to the 
Software 
Engineering 
Body of 
Knowledge
v4.0

A PROJECT OF THE IEEE COMPUTER SOCIETY
Guide to the 
Software 
Engineering 
Body of 
Knowledge
v4.0



EDITOR
Hironori Washizaki, Waseda University
(IEEE Computer Society 2024 President-Elect, 2025 President)
Guide to the 
Software 
Engineering 
Body of 
Knowledge
v4.0

iv   SWEBOK
®
 GUIDE V4.0
Copyright and Reprint Permissions. Educational or personal use of this material is permitted 
without fee provided such copies 1) are not made for profit or in lieu of purchasing copies for 
classes,  and  that  this  notice  and  a  full  citation  to  the  original  work  appear  on  the  first  page  
of  the  copy  and  2)  do  not  imply  IEEE  endorsement  of  any  third-party  products  or  services.  
Permission  to  reprint/republish  this  material  for  commercial,  advertising  or  promotional  
purposes or for creating new collective works for resale or redistribution must be obtained from 
IEEE by writing to the IEEE Intellectual Property Rights Office, 445 Hoes Lane, Piscataway, 
NJ 08854-4141 or pubs-permissions@ieee.org. 
Reference to any specific commercial products, process, or service does not imply endorsement by 
IEEE. Products, services, and company names mentioned in this document may be the trademarks 
of their respective owners. Mention in this document does not constitute an endorsement. The 
views and opinions expressed in this work do not necessarily reflect those of IEEE. 
IEEE  makes  this  document  available  on  an  “as  is”  basis  and  makes  no  warranty,  express  or  
implied, as to the accuracy, capability, efficiency merchantability, or functioning of this document. 
In no event will IEEE be liable for any general, consequential, indirect, incidental, exemplary, or 
special damages, even if IEEE has been advised of the possibility of such damages.
Copyright © 2014–2024 IEEE. All rights reserved.
Digital  copies  of  SWEBOK  Guide  V4.0  may  be  downloaded  free  of  charge  for  personal  and  
academic use via www.swebok.org.
IEEE COMPUTER SOCIETY STAFF FOR THIS PUBLICATION
Melissa A. Russell, Executive Director
Eric Berkowitz, Director of Membership
Michelle Phon, Professional Education & Certification Program Coordinator  
Jennie Zhu-Mai, Creative Design Manager
IEEE Computer Society Products and Services. The world-renowned IEEE Computer Society 
publishes,  promotes,  and  distributes  a  wide  variety  of  authoritative  computer  science  and  
engineering journals, magazines, conference proceedings, and professional education products. 
Visit the Computer Society at www.computer.org for more information.

v 
Table   of  
Contents
Foreword xxv  
Foreword to the 2014 Edition  xxvi
Foreword to the 2004 Edition xxvii
Editor                                                                                                              xxix
Knowledge Area Editors xxix
Contributing Editors xxx
Steering Group xxxi
Knowledge Area Editors of Previous SWEBOK Versions xxxi
Review Team xxxiii
Acknowledgements                                                                                       xxxiv
IEEE Computer Society Presidents xxxiv
Professional and Educational Activities Board, 2024 Membership xxxiv
Motions Regarding the Approval of SWEBOK Guide V4.0 xxxv
Motions Regarding the Approval of SWEBOK Guide V3.0 xxxv
Motions Regarding the Approval of SWEBOK Guide 2004 Version xxxvi
Introduction to the Guide xxxvii
CHAPTER 01 
Software Requirements 1-1
Introduction                                                                                                      1-1
1. Software Requirements Fundamentals 1-2
1.1. Definition of a Software Requirement  1-2
1.2. Categories of Software Requirements 1-3
1.3. Software Product Requirements and Software  
Project Requirements 1-3
1.4. Functional Requirements 1-4
1.5. Nonfunctional Requirements  1-4
1.6. Technology Constraints 1-4
1.7. Quality of Service Constraints 1-4
1.8. Why Categorize Requirements This Way? 1-5
1.9. System Requirements and Software Requirements 1-5
1.10.   Derived Requirements 1-6
1.11.   Software Requirements Activities 1-6
2. Requirements Elicitation 1-6
2.1. Requirements Sources 1-6
2.2. Common Requirements Elicitation Techniques  1-7
3. Requirements Analysis 1-8
3.1. Basic Requirements Analysis  1-8
3.2. Economics of Quality of Service Constraints 1-8
3.3. Formal Analysis  1-9

vi   SWEBOK
®
 GUIDE V4.0
3.4. Addressing Conflict in Requirements 1-10
4. Requirements Specification 1-10
4.1. Unstructured Natural Language Requirements Specification 1-11
4.2. Structured Natural Language Requirements Specification 1-12
4.3. Acceptance Criteria-Based Requirements Specification 1-12
4.4. Model-Based Requirements Specification 1-14
4.5. Additional Attributes of Requirement 1-14
4.6. Incremental and Comprehensive Requirements Specification 1-15
5. Requirements Validation 1-15
5.1. Requirements Reviews 1-15
5.2. Simulation and Execution 1-16
5.3. Prototyping                                                                                                            1-16
6. Requirements Management Activities 1-16
6.1. Requirements Scrubbing 1-16
6.2. Requirements Change Control  1-17
6.3. Scope Matching 1-17
7.   Practical Considerations 1-17
7.1. Iterative Nature of the Requirements Process  1-17
7. 2 . Requirements Prioritization 1-17
7. 3. Requirements Tracing  1-18
7.4 . Requirements Stability and Volatility 1-19
7. 5. Measuring Requirements 1-19
7. 6 . Requirements Process Quality and Improvement  1-19
8. Software Requirements Tools 1-20
8.1. Requirements Management Tools  1-20
8.2. Requirements Modeling Tools 1-20
8.3. Functional Test Case Generation Tools 1-20
Matrix of Topics vs. Reference Material 1-21
Further Readings 1-22
References                                                                                                                                1-23
CHAPTER 02 
Software Architecture 2-1
Introduction                                                                                                                              2-1
1. Software Architecture Fundamentals 2-1
1.1. The Senses of “Architecture” 2-1
1.2. Stakeholders and Concerns 2-3
1.3. Uses of Architecture 2-4
2. Software Architecture Description 2-4
2.1. Architecture Views and Viewpoints 2-5
2.2. Architecture Patterns, Styles and Reference Architectures 2-6
2.3. Architecture Description Languages and Architecture Frameworks 2-7
2.4. Architecture as Significant Decisions 2-7
3. Software Architecture Process 2-8
3.1. Architecture in Context 2-8
3.1.1. Relation of Architecture to Design 2-9

TABLE OF CONTENTS   vii
3.2. Architectural Design 2-9
3.2.1. 
A
rchitecture Analysis 
2
-9
3.2.2.
 Architecture Synthesis 2-9
3.2.3.
 A
rchitecture Evaluation
 2-
10
3.3.
 Architecture Practices, Methods, and Tactics 2-10
3.4. Architecting in the Large 2-10
4.Software Architecture Evaluation2-10
4.1.
 G
oodness in Architecture 
2
-10
4.2.
 Reasoning about Architectures 2-11
4.3.
 A
rchitecture Reviews 
2
-11
4.4.
 A
rchitecture Metrics 
2
-11
Matrix of Topics vs. Reference Material
 
2
-12
Further Readings
 2-
13
References2-14
CHAPTER 03 
Software Design 3-1
Introduction3-1
1.Software Design Fundamentals3-2
1.1. Design Thinking 3-2
1.2. Context of Software Design 3-2
1.3. K
ey Issues in Software Design 
3
-3
1.4. Software Design Principles 3-3
2.Software Design Processes3-5
2.1. High-Level Design 3-6
2.2. Detailed Design 3-6
3.Software Design Qualities3-6
3.1. Concurrency3-6
3.2. Control and Event Handling 3-6
3.3.
 Data Persistence 3-7
3.4. Distribution of Components 3-7
3.5. E
rrors and Exception Handling, Fault Tolerance 
3
-7
3.6.
 I
ntegration and Interoperability 
3
-7
3.7. Assurance, Security, and Safety 3-7
3.8. V
ariability3-7
4.
R
ecording Software Designs
3
-7
4.1. Model-Based Design 3-8
4.2. Structural Design Descriptions 3-8
4.3. Behavioral Design Descriptions 3-9
4.4.
 D
esign Patterns and Styles 
3
-10
4.5.
 S
pecialized and Domain-Specific Languages
 3
-10
4.6.
 
D
esign Rationale 
3
-11
5.
S
oftware Design Strategies and Methods
3
-11
5.1.
 G
eneral Strategies
 3
-11
5.2.
 F
unction-Oriented (or Structured) Design 
3
-11
5.3.
 D
ata-Centered Design 
3
-11

viii   SWEBOK
®
 GUIDE V4.0
5.4. Object-Oriented Design 3-11
5.5. User-Centered Design 3-12
5.6. Component-Based Design (CBD) 3-12
5.7. Event-Driven Design 3-12
5.8. Aspect-Oriented Design (AOD) 3-12
5.9. Constraint-Based Design 3-12
5.10.   Domain-Driven Design 3-13
5.11.   Other Methods 3-13
6. Software Design Quality Analysis and Evaluation 3-13
6.1. Design Reviews and Audits 3-13
6.2. Quality Attributes 3-13
6.3. Quality Analysis and Evaluation Techniques 3-13
6.4. Measures and Metrics 3-14
6.5. Verification, Validation, and Certification 3-14
Matrix of Topics vs. Reference Material 3-14
Further Readings 3-16
References                                                                                                                                3-16
CHAPTER 04 
Software Construction 4-1
Introduction                                                                                                                              4-1
1. Software Construction Fundamentals 4-2
1.1. Minimizing Complexity 4-2
1.2. Anticipating and Embracing Change 4-2
1.3. Constructing for Verification 4-4
1.4. Reusing Assets  4-4
1.5. Applying Standards in Construction  4-4
2. Managing Construction 4-4
2.1. Construction in Life Cycle Models 4-4
2.2. Construction Planning  4-5
2.3. Construction Measurement  4-5
2.4. Managing Dependencies  4-5
3. Practical Considerations                                                                                                    4-6
3.1. Construction Design 4-6
3.2. Construction Languages  4-6
3.3. Cod ing  4 -7
3.4. Construction Testing  4-7
3.5. Reuse in Construction  4-7
3.6. Construction Quality  4-8
3.7. Integration                                                                                                               4-9
3.8. Cross-Platform Development and Migration  4-9
4. Construction Technologies 4-10
4.1. API Design and Use  4-10
4.2. Object-Oriented Runtime Issues  4-10
4.3. Parameterization, Templates, and Generics  4-10
4.4. Assertions, Design by Contract, and Defensive Programming  4-10
4.5. Error Handling, Exception Handling, and Fault Tolerance  4-11

TABLE OF CONTENTS   ix
4.6. Executable Models  4-11
4 .7. State-Based and Table-Driven Construction Techniques  4-11
4.8. Runtime Configuration and Internationalization 4-12
4.9. Grammar-Based Input Processing 4-12
4.10.   Concurrency Primitives  4-12
4.11.   Middleware                                                                                                           4-12
4.12.   Construction Methods for Distributed and Cloud-Based Software 4-13
4.13.   Constructing Heterogeneous Systems 4-13
4.14.   Performance Analysis and Tuning 4-13
4.15.   Platform Standards 4-13
4.16.   Test-First Programming 4-14
4 .17.   Feedback Loop for Construction 4-14
5. Software Construction Tools 4-14
5.1. Development Environments  4-14
5.2. Visual Programming and Low-Code/Zero-Code Platforms 4-14
5.3. Unit Testing Tools 4-15
5.4. Profiling, Performance Analysis, and Slicing Tools  4-15
Matrix of Topics vs. Reference Material 4-15
Further Readings 4-18
References                                                                                                                                4-18                                                                                                                                
CHAPTER 05 
Software Testing 5-1
Introduction                                                                                                                               5-1
1. Software Testing Fundamentals 5-3
1.1. Faults vs. Failures 5-3
1.2. Key Issues 5-4
1.2.1. Test Case Creation  5-4
1.2.2. Test Selection and Adequacy Criteria 5-4
1.2.3.  Prioritization/Minimization  5-4
1.2.4. Purpose of Testing 5-4
1.2.5. Assessment and Certification  5-4
1.2.6. Testing for Quality Assurance/Improvement  5-4
1.2.7. The Oracle Problem  5-4
1.2.8. Theoretical and Practical Limitations  5-5
1.2.9. The Problem of Infeasible Paths  5-5
1.2.10. Testability  5-5
1.2.11. Test Execution and Automation 5-5
1.2.12. Scalability  5-5
1.2.13. Test  Effectiveness 5-5
1.2.14. Controllability, Replication, and Generalization 5-5
1.2.15. Off-Line vs. Online Testing 5-6
1.3. Relationship of Testing to Other Activities 5-6
2. Test Levels 5-6
2.1. The Target of the Test  5-6
2.1.1.  Unit Testing  5-6
2.1.2. Integration Testing  5-7

x   SWEBOK
®
 GUIDE V4.0
2.1.3. System Testing 5-7
2.1.4.  Acceptance Testing  5-7
2.2. Objectives of Testing  5-7
2.2.1. Conformance Testing 5-7
2.2.2.  Compliance Testing 5-8
2.2.3. Installation Testing  5-8
2.2.4. Alpha and Beta Testing  5-8
2.2.5.  Regression Testing  5-8
2.2.6. Prioritization Testing  5-8
2.2.7. Non-functional Testing  5-8
2.2.8. Security Testing 5-9
2.2.9. Privacy Testing  5-9
2.2.10. Interface and Application Program Interface (API) Testing 5-10
2.2.11. Configuration Testing  5-10
2.2.12. Usability and Human-Computer Interaction Testing 5-10
3. Test Techniques  5-10
3.1. Specification-Based Techniques 5-10
3.1.1. Equivalence Partitioning 5-11
3.1.2. Boundary-Value Analysis 5-11
3.1.3. Syntax Testing 5-11
3.1.4. Combinatorial Test Techniques  5-11
3.1.5. Decision Table 5-11
3.1.6. Cause-Effect Graphing 5-11
3.1.7. State Transition Testing  5-12
3.1.8. Scenario-Based Testing  5-12
3.1.9. Random Testing 5-12
3.1.10. Ev idence-Based  5-12
3.1.11. Forcing Exception  5-12
3.2. Structure-Based Test Techniques 5-13
3.2.1. Control Flow Testing 5-13
3.2.2. Data Flow Testing  5-13
3.2.3. Reference Models for Structure-Based Test Techniques  5-13
3.3. Experience-Based Techniques 5-13
3.3.1.  Error Guessing 5-13
3.3.2.  Exploratory Testing 5-13
3.3.3. Further Experience-Based Techniques  5-14
3.4. Fault-Based and Mutation Techniques  5-14
3.5. Usage-Based Techniques  5-15
3.5.1. Operational Profile  5-15
3.5.2. User Observation Heuristics 5-15
3.6. Techniques Based on the Nature of the Application 5-15
3.7. Selecting and Combining Techniques  5-16
3.7.1. Combining Functional and Structural 5-16
3.7.2. Deterministic vs. Random  5-16
3.8. Techniques Based on Derived Knowledge  5-16
4. Test-Related Measures 5-16
4.1. Evaluation of the SUT  5-17
4.1.1. SUT Measurements that Aid in Planning and Designing Tests  5-17

TABLE OF CONTENTS   xi
4.1.2. Fault Types, Classification and Statistics 5-17
4.1.3. Fault Density  5-17
4.1.4. Life Test, Reliability Evaluation  5-17
4.1.5. Reliability Growth Models  5-17
4.2. Evaluation of the Tests Performed  5-18
4.2.1. Fault Injection 5-18
4.2.2. Mutation Score  5-18
4.2.3. Comparison and Relative Effectiveness of Different Techniques  5-18
5. Test Process  5-18
5.1. Practical Considerations  5-19
5.1.1. Attitudes/Egoless Programming  5-19
5.1.2. Test Guides and Organizational Process  5-19
5.1.3. Test Management and Dynamic Test Processes 5-19
5.1.4. Test Documentation 5-19
5.1.5. Test Team  5-20
5.1.6. Test Process Measures  5-20
5.1.7.  Test Monitoring and Control  5-20
5.1.8. Test Completion 5-20
5.1.9. Test Reusability 5-21
5.2. Test Sub-Processes and Activities 5-21
5.2.1. Test Planning Process  5-21
5.2.2. Test Design and Implementation 5-21
5.2.3. Test Environment Set-up and Maintenance  5-21
5.2.4. Controlled Experiments and Test Execution  5-22
5.2.5. Test Incident Reporting 5-22
5.3. Sta ffing  5-22
6. Software Testing in the Development Processes and the Application Domains 5-23
6.1. Testing Inside Software Development Processes  5-23
6.1.1. Testing in Traditional Processes  5-23
6.1.2. Testing in Line with Shift-Left Movement 5-23
6.2. Testing in the Application Domains 5-24
7.   Testing of and Testing Through Emerging Technologies  5-26
7.1. Testing of Emerging Technologies 5-26
7. 2 . Testing Through Emerging Technologies 5-27
8. Software Testing Tools  5-29
8.1. Testing Tool Support and Selection 5-29
8.2. Categories of Tools  5-29
Matrix of Topics vs. Reference Material 5-31
References                                                                                                                                5-34
CHAPTER 06 
Software Engineering Operations 6-1
Introduction                                                                                                                              6-1
1. Software Engineering Operations Fundamentals 6-3
1.1. Definition of Software Engineering Operations 6-3
1.2. Software Engineering Operations Processes 6-4

xii   SWEBOK
®
 GUIDE V4.0
1.3. Software Installation  6-5
1.4. Scripting and Automating 6-5
1.5. Effective Testing and Troubleshooting 6-5
1.6. Performance, Reliability and Load Balancing 6-6
2. Software Engineering Operations Planning 6-6
2.1. Operations Plan and Supplier Management 6-6
2.1.1. Operations Plan 6-6
2.1.2. Supplier Management 6-7
2.2. Development and Operational Environments 6-7
2.3. Software Availability, Continuity, and Service Levels 6-8
2.4. Software Capacity Management 6-8
2.5. Software Backup, Disaster Recovery, and Failover 6-8
2.6. Software and Data Safety, Security, Integrity, Protection, and Controls 6-9
3. Software Engineering Operations Delivery 6-9
3.1. Operational Testing, Verification, and Acceptance 6-9
3.2. Deployment/Release Engineering 6-10
3.3. Rollback and Data Migration 6-10
3.4. Change Management 6-11
3.5. Problem Management 6-11
4. Software Engineering Operations Control 6-11
4.1. Incident Management 6-11
4.2. Monitor, Measure, Track, and Review 6-11
4.3. Operations Support 6-12
4.4. Operations Service Reporting 6-12
5. Practical Considerations 6-12
5.1. Incident and Problem Prevention 6-12
5.2. Operational Risk Management 6-12
5.3. Automating Software Engineering Operations 6-12
5.4. Software Engineering Operations for Small Organizations 6-13
6. Software Engineering Operations Tools 6-13
6.1. Containers and Virtualization 6-13
6.2. Deployment                                                                                                           6-13
6.3. Automated Test 6-14
6.4. Monitoring and Telemetry 6-14
Matrix of Topics vs. Reference Material 6-14
References  6-15
CHAPTER 07 
Software Maintenance 7-1
Introduction                                                                                                                               7-1
1. Software Maintenance Fundamentals 7-2
1.1. Definitions and Terminology 7-2
1.2. Nature of Software Maintenance 7-2
1.3. Need for Software Maintenance 7-3
1.4. Majority of Maintenance Costs 7-3
1.5. Evolution of Software 7-3

TABLE OF CONTENTS   xiii
1.6. Categories of Software Maintenance 7-4
2. Key Issues in Software Maintenance 7-5
2.1. Technical Issues 7-5
2.1.1   Limited Understanding                                                                                 7-5
2.1.2   Testing                                                                                                           7-5
2.1.3 Impact Analysis                                                                                             7-6
2.1.4   Maintainability                                                                                             7-6
2.2. Management Issues 7-7
2.2.1. Alignment with Organizational Objectives                                                 7-7
2.2.2. Staffing                                                                                                          7-7
2.2.3. Process                                                                                                           7-8
2.2.4. Supplier Management                                                                                   7-8
2.2.5.  Organizational Aspects of Maintenance 7-8
2.3. Software Maintenance Costs  7-9
2.3.1.  Technical Debt Cost Estimation 7-9
2.3.2.  Maintenance Cost Estimation                                                                      7-9
2.4. Software Maintenance Measurement 7-10
3. Software Maintenance Processes 7-11
3.1. Software Maintenance Processes 7-11
3.2. Software Maintenance Activities and Tasks 7-11
3.2.1. Supporting and Monitoring Activities 7-12
3.2.2. Planning Activities 7-12
3.2.3. Configuration Management 7-13
3.2.4. Software Quality 7-13
4. Software Maintenance Techniques 7-13
4.1. Program Comprehension 7-13
4.2. Software Reengineering 7-13
4.3. Reverse Engineering 7-14
4.4. Continuous Integration, Delivery, Testing, and Deployment 7-14
4.5. Visualizing Maintenance 7-15
5. Software Maintenance Tools 7-15
Matrix of Topics vs. Reference Material 7-16
Further Readings 7-17
References  7-17
CHAPTER 08 
Software Configuration Management 8-1
Introduction                                                                                                                              8-1
1. Management of the SCM Process                                                                                      8-2
1.1. Organizational Context for SCM                                                                            8-2
1.2. Constraints and Guidance for the SCM Process                                                     8-3
1.3. Planning for SCM                                                                                                     8-3
1.3.1. SCM Organization and Responsibilities 8-4
1.3.2. SCM Resources and Schedules 8-4
1.3.3. Tool Selection and Implementation 8-4
1.3.4. Vendor/Subcontractor Control 8-5

xiv   SWEBOK
®
 GUIDE V4.0
1.3.5. Interface Control 8-5
1.4. SCM Plan                                                                                                                  8-5
1.5. Monitoring of Software Configuration Management                                             8-5
1.5.1 SCM Measures and Measurement                                                                8-6
1.5.2 In-Process Audits of SCM                                                                            8-6
2. Software Configuration Identification                                                                               8-6
2.1. Identifying Items to Be Controlled                                                                          8-6
2.1.1 Software Configuration                                                                                 8-6
2.1.2 Software Configuration Item                                                                        8-6
2.2. Configuration Item Identifiers and Attributes 8-7
2.3. Baseline Identification                                                                                               8-7
2.4. Baseline Attributes                                                                                                    8-7
2.5. Relationships Scheme Definition                                                                             8-7
2.6. Software Libraries                                                                                                    8-8
3. Software Configuration Change Control                                                                           8-9
3.1. Requesting, Evaluating, and Approving Software Changes                                  8-9
3.1.1 Software Configuration Control Board 8-10
3.1.2 Software Change Request Process 8-10
3.1.3 Software Change Request Forms Definition 8-10
3.2. Implementing Software Changes                                                                           8-10
3.3. Deviations and Waivers                                                                                           8 -11
4. Software Configuration Status Accounting                                                                     8-11
4.1. Software Configuration Status Information                                                          8 -11
4.2. Software Configuration Status Reporting                                                              8 -11
5. Software Configuration Auditing                                                                                     8-12
5.1. Software Functional Configuration Audit                                                             8-12
5.2. Software Physical Configuration Audit  8-12
5.3. In-Process Audits of a Software Baseline                                                              8-12
6. Software Release Management and Delivery                                                                   8-13
6.1. Software Building                                                                                                   8-13
6.2. Software Release Management                                                                              8-13
7.   Software Configuration Management To o l s                                                                     8-14
Matrix of Topics vs. Reference Material 8-15
Further Readings                                                                                                                      8-16
References                                                                                                                                  8-17
CHAPTER 09
Software Engineering Management 9-1
Introduction                                                                                                                              9-1
1. Initiation and Scope Definition 9-6
1.1. Determination and Negotiation of Requirements 9-6
1.2. Feasibility Analysis 9-6
1.3. Process for the Review and Revision of Requirements 9-7
2. Software Project Planning 9-7
2.1. Process Planning 9-8
2.2. Determine Deliverables 9-8

TABLE OF CONTENTS   xv
2.3. Effort, Schedule, and Cost Estimation 9-8
2.4. Resource Allocation 9-9
2.5. R
isk Management 
9
-9
2.6. Quality Management 9-9
2 .7. P
lan Management 
9
-10
3.
S
oftware Project Execution
9
-11
3.1. Implementation of Plans 9-11
3.2. Software Acquisition and Supplier Contract Management 9-11
3.3. I
mplementation of Measurement Process 
9
-12
3.4. Monitor Process 9-12
3.5. C
ontrol Process 
9-12
3.
6.
 Re
porting
9
-13
4.
S
oftware Review and Evaluation
9
-13
4.1.
 D
etermining Satisfaction of Requirements 
9
-13
4.2. 
R
eviewing and Evaluating Performance 
9
-13
5.
C
losure9-13
5.1.
 Determining Closure 9-13
5.2.
 C
losure Activities 
9-
14
6.
S
oftware Engineering Measurement
9
-14
6.1.
 E
stablish and Sustain Measurement Commitment 
9
-14
6.2. 
P
lan the Measurement Process 
9
-15
6.3.
 P
erform the Measurement Process 
9
-15
6.4.
 E
valuate Measurement 
9
-16
7.
Software Engineering Management Tools9-16
Matrix of Topics vs. Reference Material
9
-17
Further Readings
9
-18
References
9-18
CHAPTER 10 
Software Engineering Process 10-1
Introduction10-1
1.Software Engineering Process Fundamentals10-1
1.1.
 I
ntroduction 
1
0-1
1.2.
 Software Engineering Process Definition 10-3
2.Life Cycles10-3
2.1.
 L
ife Cycle Definition, Process Categories, and Terminology 
1
0-3
2.2.
 Rationale for Life Cycles 10-4
2.3. The Concepts of Process Models and Life Cycle Models 10-5
2.4.
 S
ome Paradigms for Development Life Cycle Models 
1
0-5
2.5.
 Development Life Cycle Models and Their Engineering Dimension 10-6
2.6.
 
Th
e Management of SLCPs 
1
0-7
2 .7.
 S
oftware Engineering Process Management 
1
0-8
2.8.
 S
oftware Life Cycle Adaptation 
1
0-8
2.9. P
ractical Considerations
 1
0-8
2.10.
 Software Process Infrastructure, Tools, Methods 10-9
2.11. S
oftware Engineering Process Monitoring and  

xvi   SWEBOK
®
 GUIDE V4.0
its Relationship with the Software Product 10-9
3. Software Process Assessment and Improvement 10-9
3.1. Overview of Software Process Assessment and Improvement 10-9
3.2. Goal-Question-Metric (GQM) 10-10
3.3. Framework-Based Methods 10-10
3.4. Process Assessment and Improvement in Agile 10-10
Matrix of Topics vs. Reference Material 10-10
References                                                                                                                              10-11
CHAPTER 11 
Software Engineering Models and Methods 11-1
Introduction                                                                                                                             11-1
1. Mo del i ng                                                                                                                           11-1
1.1. Modeling Principles 11-2
1.2. Properties and Expression of Models  11-3
1.3. Syntax, Semantics, and Pragmatics  11-3
1.4. Preconditions, Postconditions, and Invariants  11-4
2. Types of Models 11-4
2.1. Structural Modeling 11-5
2.2. Behavioral Modeling 11-5
3. Analysis of Models 11-5
3.1. Analyzing for Completeness  11-6
3.2. Analyzing for Consistency  11-6
3.3. Analyzing for Correctness  11-6
3.4. Analyzing for Traceability  11.6
3.5. Analyzing for Interaction  11-6
4. Software Engineering Methods 11-7
4.1. Heuristic Methods  11-7
4.2. Formal Methods  11-8
4.3. Prototyping Methods  11-9
4.4. Agile Methods 11-10
Matrix of Topics vs. Reference Material 11-11
References                                                                                                                              11-12
CHAPTER 12
Software Quality 12-1
Introduction                                                                                                                            12-1
1. Software Quality Fundamentals 12-3
1.1. Software Engineering Culture and Ethics 12-3
1.2. Value and Costs of Quality 12-4
1.3. Standards, Models, and Certifications 12-4
1.4. Software Dependability and Integrity Levels 12-5
1.4.1   Dependability   12-5
1.4.2. Integrity Levels of Software 12-6

TABLE OF CONTENTS   xvii
2. Software Quality Management Process 12-6
2.1. Software Quality Improvement  12-7
2.2. Plan Quality Management 12-7
2.3. Evaluate Quality Management 12-8
2.3.1 Software Quality Measurement 12-8
2.4. Perform Corrective and Preventive Actions  12-9
2.4.1. Defect Characterization  12-9
3. Software Quality Assurance Process 12-10
3.1. Prepare for Quality Assurance  12-10
3.2. Perform Process Assurance  12-10
3.3. Perform Product Assurance 12-11
3.4. V&V and Testing 12-12
3.4.1 Static Analysis Techniques 12-13
3.4.2. Dynamic Analysis Techniques 12-13
3.4.3. Formal Analysis Techniques 12-13
3.4.4. Software Quality Control and Testing 12-13
3.4.5. Technical Reviews and Audits 12-14
4. Software Quality Tools 12-15
Matrix of Topics vs. Reference Material 12-15
Further Readings 12-16
References                                                                                                                              12-17
CHAPTER 13
Software Security 13-1
Introduction                                                                                                                            13-1
1. Software Security Fundamentals 13-1
1.1. Software Security 13-1
1.2. Information Security 13-1
1.3. Cybersecurity  13-2
2. Security Management and Organization  13-2
2.1. Capability Maturity Model  13-2
2.2. Information Security Management System 13-2
2.3. Agile Practice for Software Security 13-3
3. Software Security Engineering and Processes 13-3
3.1. Security Engineering and Secure Development Life Cycle (SDLC)  13-3
3.2. Common Criteria for Information Technology Security Evaluation  13-3
4. Security Engineering for Software Systems 13-3
4.1. Security Requirements  13-3
4.2. Security Design 13-4
4.3. Security Patterns 13-4
4.4. Construction for Security  13-4
4.5. Security Testing  13-5
4.6. Vulnerability Management  13-5
5. Software Security Tools 13-5
5.1. Security Vulnerability Checking Tools  13-5
5.2. Penetration Testing Tools 13-6

xviii   SWEBOK
®
 GUIDE V4.0
6. Domain-Specific Software Security 13-6
6.1. Security for Container and Cloud 13-6
6.2. Security for IoT Software 13-6
6.3. Security for Machine Learning-Based Application 13-6
Matrix of Topics vs. Reference Material 13-7
Further Readings 13-8
References                                                                                                                               13-8
CHAPTER 14
Software Engineering Professional Practice 14-1
Introduction                                                                                                                             14-1
1. Professionalism                                                                                                                 14-2
1.1. Accreditation, Certification and Qualification, and Licensing 14-2
1.1.1. Accreditation 14-2
1.1.2. Certification and Qualification 14-3
1.1.3. Licensing 14-3
1.2. Codes of Ethics and Professional Conduct 14-3
1.3. Nature and Role of Professional Societies 14-4
1.4. Nature and Role of Software Engineering Standards  14-4
1.5. Economic Impact of Software  14-5
1.6. Employment Contracts  14-5
1.7. Legal Issues 14-6
1.7.1.  Standards  14-6
1.7.2.  Trademarks  14-6
1.7.3.  Patents  14-6
1.7.4.  Copyrights  14-6
1.7.5. Trade Secrets 14-6
1.7.6. Professional Liability 14-7
1.7.7. Legal Requirements 14-7
1.7.8. Trade Compliance 14-7
1.7.9.  Cybercrime  14-7
1.7.10. Data  Privacy 14-8
1.8. Documentation                                                                                                      14-8
1.9. Trade-Off Analysis 14-9
2. Group Dynamics and Psychology 14-9
2.1. Dynamics of Working in Teams/Groups  14-9
2.2. Individual Cognition 14-10
2.3. Dealing with Problem Complexity 14-10
2.4. Interacting with Stakeholders 14-10
2.5. Dealing with Uncertainty and Ambiguity 14-11
2.6. Dealing with Equity, Diversity, and Inclusivity 14-11
3. Communication Skills 14-11
3.1. Reading, Understanding, and Summarizing 14-12
3.2. Wr it i ng                                                                                                                 14 -1 2
3.3. Team and Group Communication 14-12
3.4. Presentation Skills 14-12

TABLE OF CONTENTS   xix
Matrix of Topics vs. Reference Material 14-13
Fur ther Readings 14-14
References                                                                                                                              14-14
CHAPTER 15
Software Engineering Economics 15-1
Introduction                                                                                                                             15-1
1. Software Engineering Economics Fundamentals 15-3
1.1. Proposals                                                                                                                15-3
1.2. Cash Flow 15-3
1.3. Time-Value of Money 15-3
1.4. Equivalence                                                                                                           15-4
1.5. Bases for Comparison 15-4
1.6. Alternatives                                                                                                           15-4
1.7. Intangible Assets 15-4
1.8. Business Model 15-5
2. The Engineering Decision-Making Process 15-5
2.1. Process Overview 15-5
2.2. Understand the Real Problem 15-5
2.3. Identify All Reasonable Technically Feasible Solutions 15-6
2.4. Define the Selection Criteria 15-6
2.5. Evaluate Each Alternative Against the Selection Criteria 15-6
2.6. Select the Preferred Alternative 15-6
2 .7. Monitor the Performance of the Selected Alternative 15-7
3. For-Profit Decision-Making 15-7
3.1. Minimum Acceptable Rate of Return 15-7
3.2. Economic Life 15-7
3.3. Planning Horizon 15-8
3.4. Replacement Decisions 15-8
3.5. Retirement Decisions 15-9
3.6. Advanced For-Profit Decision Considerations 15-9
4. Nonprofit Decision-Making 15-9
4.1. Benefit-Cost Analysis 15-9
4.2. Cost-Effectiveness Analysis 15-9
5. Present Economy Decision-Making 15-9
5.1. Break-Even Analysis 15-9
5.2. Optimization Analysis 15-9
6. Multiple-Attribute Decision-Making 15-10
6.1. Compensatory Techniques 15-10
6.2. Non-Compensatory Techniques 15-10
7.   Identifying and Characterizing Intangible Assets 15-10
7.1. Identify Processes and Define Business Goals 15-10
7. 2 . Identify Intangible Assets Linked with Business Goal 15-11
7. 3. Identify Software Products That Support Intangible Assets 15-11
7.4 . Define and Measure Indicators 15-11
7. 5. Intangible Asset Characterization 15-11

xx   SWEBOK
®
 GUIDE V4.0
7. 6 . Link Specific Intangible Assets with the Business Model 15-13
7.7. D ec ision-M a k i ng                                                                                                 15-13
8. Estimation                                                                                                                      15-13
8.1. Expert Judgment 15-14
8.2. Analogy                                                                                                               15-15
8.3. Decomposition                                                                                                     15-15
8.4. Parametric                                                                                                            15-15
8.5. Multiple Estimates 15-15
9. Practical Considerations 15-16
9.1. Business Case 15-16
9.2. Multiple-Currency Analysis  15-16
9.3. Systems Thinking 15-16
10.  Related Concepts  15-16
10.1.   Accounting                                                                                                           15-16
10.2.   Cost and Costing 15-16
10.3.   F i na nce                                                                                                                 15-17
10.4.   Controlling                                                                                                          15-17
10.5.   Efficiency and Effectiveness 15-17
10.6.   Productivity                                                                                                         15-18
10 .7.   Product or Service 15-18
10.8.   Project                                                                                                                  15-18
10.9.   Program                                                                                                               15-18
10.10. Portfolio                                                                                                               15-18
10.11. Product Life Cycle 15-19
10.12. Project Life Cycle 15-19
10.13. Price and Pricing 15-19
10.14. Prioritization                                                                                                        15-19
Matrix of Topics vs. Reference Material 15-20
Further Readings 15-22
References                                                                                                                              15-22
CHAPTER 16
Computing Foundations 16-1
Introduction                                                                                                                            16-2
1. Basic Concepts of a System or Solution 16-2
2. Computer Architecture and Organization 16-3
2.1. Computer Architecture 16-3
2.2. Types of Computer Architectures 16-3
2.2.1. Von Neumann Architecture 16-3
2.2.2. Harvard Architecture 16-4
2.2.3. Instruction Set Architecture 16-4
2.2.4. Flynn’s Architecture or Taxonomy 16-5
2.2.5. System Architecture 16-5
2.3. Microarchitecture or Computer Organization 16-5
2.3.1.  Arithmetic Logic Unit  16-5
2.3.2. Memory Unit 16-6

TABLE OF CONTENTS   xxi
2.3.3.  Input/Output Devices                                                                                16-6
2.3.4. Control Unit 16-6
3. Data Structures and Algorithms 16-6
3.1. Types of Data Structures 16-6
3.2. Operations on Data Structures 16-7
3.3. Algorithms and Attributes of Algorithms 16-7
3.4. Algorithm Complexity 16-8
3.5. Measurement of Complexity 16-8
3.6. Designing Algorithms 16-8
3.7. Sorting Techniques 16-9
3.8. Searching Techniques 16-10
3.9. Hashing                                                                                                                16-10
4. Programming Fundamentals and Languages 16-10
4.1. Programming Language Types 16-10
4.2. Programming Syntax, Semantics, Type Systems 16-11
4.3. Subprograms and Coroutines 16-11
4.4. Object-Oriented Programming  16-12
4.5. Distributed Programming and Parallel Programming 16-13
4.6. Debugging                                                                                                           16-13
4 .7. Standards and Guidelines 16-13
5. Operating Systems 16-15
5.1. Processor Management 16-15
5.2. Memory Management 16-16
5.3. Device Management 16-16
5.4. Information Management 16-16
5.5. Network Management 16-16
6. Database Management 16-17
6.1. Schema                                                                                                                 16-17
6.2. Data Models and Storage Models 16-17
6.3. Database Management Systems  16-18
6.4. Relational Database Management Systems and Normalization 16-18
6.5. Structured Query Language  16-19
6.6. Data Mining and Data Warehousing 16-19
6 .7. Database Backup and Recovery 16-20
7.   Computer Networks and Communications 16-20
7.1. Types of Computer Networks 16-20
7. 2 . Layered Architectures of Networks 16-21
7. 3. Open Systems Interconnection Model 16-21
7.4 . Encapsulation and Decapsulation 16-22
7. 5. Application Layer Protocols 16-22
7. 6 . Design Techniques for Reliable and Efficient Network 16-22
7.7. Internet Protocol Suite 16-23
7.8. Wireless and Mobile Networks 16-23
7.9. Security and Vulnerabilities 16-23
8. User and Developer Human Factors 16-24
8.1. User Human Factors 16-24
8.2. Developer Human Factors 16-24
9. Artificial Intelligence and Machine Learning 16-25

xxii   SWEBOK
®
 GUIDE V4.0
9.1. Reasoning                                                                                                            16-25
9.2. Lea rning                                                                                                              16-26
9.3. Models                                                                                                                 16-26
9.4. Perception and Problem-Solving 16-27
9.5. Natural Language Processing 16-27
9.6. AI and Software Engineering 16-27
Matrix of Topics vs. Reference Material 16-28
References                                                                                                                              16-32
CHAPTER 17
Mathematical Foundations 17-1
Introduction                                                                                                                             17-1
1. Basic Logic 17-1
1.1. Propositional Logic 17-1
1.2. Predicate Logic 17-3
2. Proof Techniques                                                                                                              17-3
2.1. Direct Proof 17-4
2.2. Proof by Contradiction 17-4
2.3. Proof by Induction 17-4
2.4. Proof by Example 17-5
3. Set, Relation, Function 17-5
3.1. Set Operations 17-6
3.2. Properties of Sets 17-6
3.3. Relation and Function 17-7
4. Graph and Tree 17-8
4.1. Graph                                                                                                                     17-8
4.2. Tre e                                                                                                                       17-10
5. Finite-State Machine                                                                                                      17-12
6. Grammar   17-13
6.1. Language Recognition  17-14
7.   Number Theory   17-14
7.1. Types of Numbers 17-15
7. 2 . Divisibility                                                                                                           17-15
7. 3. Prime Number 17-15
7.4 . Greatest Common Divisor 17-16
8. Basics of Counting                                                                                                          17-16
9. Discrete Probability                                                                                                        17-17
10.  Numerical Precision, Accuracy, and Error 17-18
11.  Algebraic Structures                                                                                                       17-19
11.1.   Group                                                                                                                   17-19
11.2.   R ing                                                                                                                      17-2 0
12. Engineering Calculus 17-21
13.  New Advancements 17-21
13.1.   Computational Neurosciences 17-21
13.2.  Genomics                                                                                                             17-21
Matrix of Topics vs. Reference Material 17-22
References                                                                                                                              17-22

TABLE OF CONTENTS   xxiii
CHAPTER 18
Engineering Foundations 18-1
Introduction                                                                                                                             18-1
1. The Engineering Process 18-1
2. Engineering Design 18-2
2.1. Engineering Design in Engineering Education 18-2
2.2. Design as a Problem-Solving Activity 18-3
3. Abstraction and Encapsulation 18-3
3.1. Levels of Abstraction  18-4
3.2. Encapsulation                                                                                                        18-4
3.3. Hierarchy                                                                                                               18-4
3.4. Alternate Abstractions 18-4
4. Empirical Methods and Experimental Techniques  18-4
4.1. Designed Experiment 18-5
4.2. Observational Study 18-5
4.3. Retrospective Study 18-5
5. Statistical Analysis  18-5
5.1. Unit of Analysis (Sampling Units), Population, and Sample 18-5
5.2. Correlation and Regression 18-8
6. Modeling, Simulation, and Prototyping 18-8
6.1. Modeling                                                                                                               18-8
6.2. Simulation  18-9
6.3. Prototyping                                                                                                            18-9
7.   Measurement                                                                                                                  18-10
7.1. Levels (Scales) of Measurement 18-10
7. 2 . Implications of Measurement Theory for Programming Languages 18-12
7. 3. Direct and Derived Measures 18-13
7.4 . Reliability and Validity 18-14
7. 5. Assessing Reliability 18-14
7. 6 . Goal-Question-Metric Paradigm: Why Measure? 18-15
8. Standards                                                                                                                        18-15
9. Root Cause Analysis 18-16
9.1. Root Cause Analysis Techniques 18-16
9.2. Root Cause–Based Improvement 18-17
10.  Industry 4.0 and Software Engineering 18-17
Matrix of Topics vs. Reference Material 18-18
Further Readings 18-19
References                                                                                                                              18-20
APPENDIX A
Knowledge Area Description Specifications A-1
Introduction                                                                                                                              A-1
The Swebok Guide is a Foundational Document for the IEEE Computer Society  
Suite of Software Engineering Products A-1

xxiv   SWEBOK
®
 GUIDE V4.0
Baseline and Change Control A-1
Criteria and Requirements for the Breakdown of Topics Within a Knowledge Area A-2
Criteria and Requirements for Describing Topics A-2
Criteria and Requirements for Reference Material A-2
Common Structure A-4
What Do We Mean by “Generally Recognized Knowledge”? A-4
Length of KA Description A-5
Important Related Documents A-5
Other Detailed Guidelines A-6
Editing  A-6
Release of Copyright A-6
References                                                                                                                                A-6
APPENDIX B
IEEE and ISO/IEC Standards Supporting the Software 
Engineering Body of Knowledge (SWEBOK) B-1
1. O ver v ie w                                                                                                                            B-1
1.1. The SWEBOK and standards B-1
1.2. Types of Standards B-2
1.3. Sources of Software Engineering Standards B-2
2. The software engineering standards landscape B-3
3. Life cycle process standards B-4
4. Extensions and specialized applications of ISO/IEC/IEEE 12207 B-5
4.1. Explanations of concepts and several processes B-5
4.2. More specialized extensions B-8
4.3. SoS standards B-9
5. Single Process Standards B-9
6. Standards for product line, methods, and tools B-9
7.   Process assessment standards B-10
8. Professional Skills and Knowledge Standards B-11
9. Selected Software Engineering Standards B-11
APPENDIX C
Consolidated Reference List C-1
Consolidated Reference List C-1

FOREWOR D 
The Guide to the Software Engineering Body of Knowledge (SWEBOK Guide), published by the 
IEEE Computer Society (IEEE CS), represents the current state of generally accepted, con-
sensus-based  knowledge  emanating  from  the  interplay  between  software  engineering  theory  
and practice. Its objectives include the provision of guidance for learners, researchers, and prac-
titioners to identify and share a common understanding of “generally accepted knowledge” in 
software engineering, defining the boundary between software engineering and related disci-
plines, and providing a foundation for certifications and educational curricula.
The origins of the Guide go back to the early 2000s. Much like the software engineering dis-
cipline, the Guide has continued to evolve over the last 20 years to reflect society’s industrial, 
educational, social, technical, and technological changes. Publication of the 2014 version of the 
Guide (SWEBOK Guide V3) was a significant milestone in establishing software engineering as 
a recognized engineering discipline. 
The  goal  of  developing  this  update  (SWEBOK  Guide  V4)  to  the  Guide  is  to  improve  the  
Guide’s  currency,  readability,  consistency,  and  usability.  The  Guide  consists  of  18  knowledge  
areas (KAs) followed by several appendixes. A KA is an identified area of software engineering 
defined by its knowledge requirements and described in terms of its component processes, prac-
tices, inputs, outputs, tools, and techniques. Three appendixes provide, respectively, the speci-
fications for the KA descriptions, an annotated set of relevant standards for each KA, and a list 
of references cited in the Guide. 
All KAs have been updated to reflect changes in software engineering since the publication 
of Guide V3, including modern development practices, new techniques, and the advancement 
of  standards.  One  significant  change  is  that  Agile  and  DevOps  have  been  incorporated  into  
almost all KAs because these models have been widely accepted since the previous publication 
of  the  Guide.  Agile  models  typically  involve  frequent  demonstrations  of  working  software  to  
a customer in short, iterative cycles. Agile practices exist across KAs. Furthermore, emerging 
platforms and technologies, including artificial intelligence (AI), machine learning (ML), and 
the internet of things (IoT), have been incorporated into the foundation KAs.
To reflect areas that are becoming particularly important in modern software engineering, 
the following KAs have been added: the Software Architecture KA, Software Security KA, 
and Software Engineering Operations KA.
This Guide, written under the auspices of the Professional and Educational Activities Board 
of the IEEE Computer Society, represents the next step in the evolution of the software engi-
neering profession.
Steve McConnell
Chief Executive Officer, Construx Software
Hironori Washizaki
President-Elect 2024, President 2025, IEEE Computer Society
  xxv

xxvi   SWEBOK
®
 GUIDE V4.0
FOREWORD TO THE 2014 EDITION
Every  profession  is  based  on  a  body  of  knowledge,  although  that  knowledge  is  not  always  
defined in a concise manner. In cases where no formality exists, the body of knowledge is “gen-
erally recognized” by practitioners and may be codified in a variety of ways for a variety of dif-
ferent uses. But in many cases, a guide to a body of knowledge is formally documented, usually 
in a form that permits it to be used for such purposes as development and accreditation of aca-
demic and training programs, certification of specialists, or professional licensing. Generally, 
a professional society or similar body maintains stewardship of the formal definition of a body 
of knowledge.
During the past forty-five years, software engineering has evolved from a conference catch-
phrase  into  an  engineering  profession,  characterized  by  1)  a  professional  society,  2)  standards  
that specify generally accepted professional practices, 3) a code of ethics, 4) conference proceed-
ings, 5) textbooks, 6) curriculum guidelines and curricula, 7) accreditation criteria and accred-
ited degree programs, 8) certification and licensing, and 9) this Guide to the Body of Knowledge.
In  this  Guide to the Software Engineering Body of Knowledge,  the  IEEE  Computer  Society  
presents  a  revised  and  updated  version  of  the  body  of  knowledge  formerly  documented  as  
SWEBOK 2004; this revised and updated version is denoted SWEBOK Guide V3. This work is 
in partial fulfillment of the Society’s responsibility to promote the advancement of both theory 
and practice for the profession of software engineering.
It should be noted that this Guide does not present the entire body of knowledge for soft-
ware engineering but rather serves as a guide to the body of knowledge that has been devel-
oped over more than four decades. The software engineering body of knowledge is constantly 
evolving. Nevertheless, this Guide constitutes a valuable characterization of the software engi-
neering profession.
In 1958, John Tukey, the world-renowned statistician, coined the term software. The term 
software engineering was used in the title of a NATO conference held in Germany in 1968. The 
IEEE Computer Society first published its Transactions on Software Engineering in 1972, and 
a committee for developing software engineering standards was established within the IEEE 
Computer Society in 1976.
In  1990,  planning  was  begun  for  an  international  standard  to  provide  an  overall  view  of  
software engineering. The standard was completed in 1995 with designation ISO/IEC 12207 
and given the title of Standard for Software Life Cycle Processes. The IEEE version of 12207 
was  published  in  1996  and  provided  a  major  foundation  for  the  body  of  knowledge  captured  
in SWEBOK 2004. The current version of 12207 is designated as ISO/IEC 12207:2008 and 
IEEE 12207-2008; it provides the basis for this SWEBOK Guide V3. 
This Guide to the Software Engineering Body of Knowledge is presented to you, the reader, as a 
mechanism for acquiring the knowledge you need in your lifelong career development as a soft-
ware engineering professional.
Dick Fairley, Chair 
Software and Systems Engineering Committee
IEEE Computer Society
Don Shafer, Vice President
Professional Activities Board IEEE Computer Society

FOREWORD TO THE 2004 EDITION
In this Guide, the IEEE Computer Society establishes for the first time a baseline for the body 
of knowledge for the field of software engineering, and the work partially fulfills the Society’s 
responsibility to promote the advancement of both theory and practice in this field. In so doing, 
the Society has been guided by the experience of disciplines with longer histories but was not 
bound either by their problems or their solutions.
It  should  be  noted  that  the  Guide  does  not  purport  to  define  the  body  of  knowledge  but  
rather to serve as a compendium and guide to the body of knowledge that has been developing 
and evolving over the past four decades. Furthermore, this body of knowledge is not static. The 
Guide  must,  necessarily,  develop  and  evolve  as  software  engineering  matures.  It  nevertheless  
constitutes a valuable element of the software engineering infrastructure.
In  1958,  John  Tukey,  the  world-renowned  statistician,  coined  the  term  software.  The  term  
software  engineering  was  used  in  the  title  of  a  NATO  conference  held  in  Germany  in  1968.  
The  IEEE  Computer  Society  first  published  its  Transactions on Software Engineering in  1972. 
The committee established within the IEEE Computer Society for developing software engi-
neering standards was founded in 1976.
The first holistic view of software engineering to emerge from the IEEE Computer Society 
resulted  from  an  effort  led  by  Fletcher  Buckley  to  develop  IEEE  standard  730  for  software  
quality assurance, which was completed in 1979. The purpose of IEEE Std. 730 was to provide 
uniform,  minimum  acceptable  requirements  for  preparation  and  content  of  software  quality  
assurance  plans.  This  standard  was  influential  in  completing  the  developing  standards  in  the  
following topics: configuration management, software testing, software requirements, software 
design, and software verification and validation.
During the period 1981–1985, the IEEE Computer Society held a series of workshops con-
cerning  the  application  of  software  engineering  standards.  These  workshops  involved  practi-
tioners sharing their experiences with existing standards. The workshops also held sessions on 
planning for future standards, including one involving measures and metrics for software engi-
neering  products  and  processes.  The  planning  also  resulted  in  IEEE  Std.  1002,  Taxonomy of 
Software Engineering Standards  (1986),  which  provided  a  new,  holistic  view  of  software  engi-
neering. The standard describes the form and content of a software engineering standards tax-
onomy.  It  explains  the  various  types  of  software  engineering  standards,  their  functional  and  
external relationships, and the role of various functions participating in the software life cycle.
In 1990, planning for an international standard with an overall view was begun. The plan-
ning focused on reconciling the software process views from IEEE Std. 1074 and the revised 
US DoD standard 2167A. The revision was eventually published as DoD Std. 498. The inter-
national standard was completed in 1995 with designation, ISO/IEC 12207, and given the title 
of Standard for Software Life Cycle Processes.  Std.  ISO/  IEC  12207  provided  a  major  point  of  
departure for the body of knowledge captured in this book.
It was the IEEE Computer Society Board of Governors’ approval of the motion put forward 
in May 1993 by Fletcher Buckley which resulted in the writing of this book. The Association 
for Computing Machinery (ACM) Council approved a related motion in August 1993. The two 
motions led to a joint committee under the leadership of Mario Barbacci and Stuart Zweben 
who  served  as  cochairs.  The  mission  statement  of  the  joint  committee  was  “To  establish  the  
appropriate set(s) of criteria and norms for professional practice of software engineering upon 
which industrial decisions, professional certification, and educational curricula can be based.” 
The steering committee organized task forces in the following areas: 
  xxvii

xxviii   SWEBOK
®
 GUIDE V4.0
1. Define Required Body of Knowledge and Recommended Practices.
2. Define Ethics and Professional Standards.
3. Define Educational Curricula for undergraduate, graduate, and continuing education.
This  book  supplies  the  first  component:  required  body  of  knowledge  and  recommended  
practices.
The code of ethics and professional practice for software engineering was completed in 1998 
and approved by both the ACM Council and the IEEE Computer Society Board of Governors. 
It has been adopted by numerous corporations and other organizations and is included in sev-
eral recent textbooks.
The  educational  curriculum  for  undergraduates  is  being  completed  by  a  joint  effort  of  the  
IEEE Computer Society and the ACM and is expected to be completed in 2004.
Every  profession  is  based  on  a  body  of  knowledge  and  recommended  practices,  although  
they are not always defined in a precise manner. In many cases, these are formally documented, 
usually in a form that permits them to be used for such purposes as accreditation of academic 
programs, development of education and training programs, certification of specialists, or pro-
fessional licensing. Generally, a professional society or related body maintains custody of such 
a formal definition. In cases where no such formality exists, the body of knowledge and recom-
mended practices are “generally recognized” by practitioners and may be codified in a variety 
of ways for different uses.
It is hoped that readers will find this book useful in guiding them toward the knowledge and 
resources they need in their lifelong career development as software engineering professionals.
The book is dedicated to Fletcher Buckley in recognition of his commitment to promoting 
software engineering as a professional discipline and his excellence as a software engineering 
practitioner in radar applications. 
Leonard L. Tripp, IEEE Fellow 2003
Chair, Professional Practices Committee, IEEE 
Computer Society (2001–2003)
Chair, Joint IEEE Computer Society and ACM 
Steering Committee for the Establishment of 
Software Engineering as a Profession (1998–1999)
Chair, Software Engineering Standards  Committee, 
IEEE Computer Society (1992–1998)

EDITOR
Hironori Washizaki, Waseda University / National Institute of Informatics / eXmotion / 
University of Human Environments, Japan, washizaki@waseda.jp
KNOWLEDGE AREA EDITORS
Software Requirements
Steve Tockey, Construx Software, USA.
Software Architecture
Rich Hilliard, USA.
Software Design
Rich Hilliard, USA.
Software Construction
Xin Peng, Software School, Fudan University, China.
Steve Schwarm, Synopsys - Black Duck Software, USA.
Software Testing
Eda Marchetti, ISTI-CNR, Italy.
Said Daoudagh, ISTI-CNR, Italy.
Software Engineering Operations
Francis Bordeleau, École de technologie supérieure (ÉTS), Canada.
Alain April, École de technologie supérieure (ÉTS), Canada.
Software Maintenance
Ali Ouni, École de technologie supérieure (ÉTS), Canada
Alain April, École de technologie supérieure (ÉTS), Canada
Peter Leather, Exceptional Performance, UK.
Software Configuration Management
Maria Isabel Sánchez Segura, Universidad Carlos III de Madrid, Spain. 
Bob Aiello, CM Best Practices, USA.
Software Engineering Management
Kenneth E. Nidiffer, George Mason University, USA.
Software Engineering Process
Juan Garbajosa, Universidad Politécnica de Madrid, Spain.
Software Engineering Models and Methods
Hironori Washizaki, Waseda University, Japan.
Akinori Ihara, Wakayama University, Japan.
Shinpei Ogata, Shinshu University, Japan.
  xxix

xxx   SWEBOK
®
 GUIDE V4.0
Software Quality
Alain April, École de technologie supérieure (ÉTS), Canada.
Steve Tockey, Construx Software, USA. 
Steve Schwarm, Synopsys - Black Duck Software, USA.
Software Security
Nobukazu Yoshioka, Waseda University, Japan.
Seiji Munetoh, IBM Research, Japan.
Software Engineering Professional Practice
Katsuhisa Shintani, Waseda University, Japan.
Eiji Hayashiguchi, Waseda University, Japan.
Software Engineering Economics
Maria Isabel Sánchez Segura, Universidad Carlos III de Madrid, Spain.
Steve Tockey, Construx Software, USA.
Computing Foundations
Yatheendranath TJ, DhiiHii Labs Private Limited, India.
Mathematical Foundations
Yatheendranath TJ, DhiiHii Labs Private Limited, India.
Steve Tockey, Construx Software, USA.
Engineering Foundations
Yatheendranath TJ, DhiiHii Labs Private Limited, India.
Steve Tockey, Construx Software, USA.
Appendix A: Knowledge Area Description Specifications
Juan Garbajosa, Universidad Politécnica de Madrid, Spain. 
Hironori Washizaki, Waseda University, Japan.
Appendix B: IEEE and ISO/IEC Standards Supporting SWEBOK
Annette Reilly, USA.
Appendix C: Consolidated Reference List
Hironori Washizaki, Waseda University, Japan.
CONTRIBUTING EDITORS
The following persons contributed to editing the SWEBOK Guide V4:
Michelle Phon
Eric Berkowitz

STEERING GROUP
The following experts served on the SWEBOK Guide V4 Steering Group that guided the initial 
architecture of the Guide at the beginning of the project:
Hironori Washizaki
Yatheendranath TJ
Rich Hilliard
Kenneth Nidiffer
Pete Brink
V.S. Mani
Hari Prasad Devarapalli
Annette Reilly
Narendra S Chowdhury
Dharanipragada Janakiram
Juan Garbajosa
Maria Isabel Sánchez Segura
Peter Leather
Andy Chen
Steve Schwarm
KNOWLEDGE AREA EDITORS OF PREVIOUS SWEBOK VERSIONS
The following persons served as Knowledge Area Editors for either the Trial version published 
in 2001, the 2004 version, and/or the 2014 version (SWEBOK V3). The affiliations listed are as 
they belonged to when each person served as a knowledge area editor.
Software Requirements
Peter Sawyer, Computing Department, Lancaster University, UK
Gerald Kotonya, Computing Department, Lancaster University, UK
Software Design
Guy Tremblay, Département d ’ informatique, UQAM, Canada
Yanchun Sun, School of Electronics Engineering and Computer Science, Peking University, China
Software Construction
Steve McConnell, Construx Software, USA
Terry Bollinger, the MITRE Corporation, USA
Philippe Gabrini, Département d ’ informatique, UQAM, Canada
Louis Martin, Département d ’ informatique, UQAM, Canada
Xin Peng, Software School, Fudan University, China
Software Testing
Antonia Bertolino, ISTI-CNR, Italy
Eda Marchetti, ISTI-CNR, Italy
Software Maintenance
Thomas M. Pigoski, Techsoft Inc., USA
Alain April, École de technologie supérieure, Canada
Mira Kajko-Mattsson, School of Information and Communication Technology,  KTH Royal 
Institute of Technology
Software Configuration Management
John A. Scott, Lawrence Livermore National Laboratory, USA David Nisse, USA
Roger Champagne, École de technologie supérieure (ÉTS), Canada
Alain April, École de technologie supérieure (ÉTS), Canada
  xxxi

xxxii   SWEBOK
®
 GUIDE V4.0
Software Engineering Management
Dennis Frailey, Raytheon Company, USA
Stephen G. MacDonell, Auckland University of Technology, New Zealand
Andrew R. Gray, University of Otago, New Zealand 
James McDonald, Department of Computer Science and Software Engineering, Monmouth 
University, USA
Software Engineering Process
Khaled El Emam, served while at the Canadian National Research Council, Canada
Annette Reilly, Lockheed Martin Information Systems & Global Solutions, USA
Richard E. Fairley, Software and Systems Engineering Associates (S2EA), USA
Software Engineering Tools and Methods
David Carrington, School of Information Technology and Electrical Engineering,  
The University of Queensland, Australia
Michael F. Siok, Lockheed Martin Aeronautics Company, USA
Software Quality
Alain April, École de technologie supérieure, Canada
Dolores Wallace, retired from the National Institute of Standards and Technology, USA 
Larry Reeker, NIST, USA
J. David Blaine, USA
Durba Biswas, Tata Consultancy Services, India
Software Engineering Professional Practice
Aura Sheffield, USA
Hengming Zou, Shanghai Jiao Tong University, China
Software Engineering Economics
Christof Ebert, Vector Consulting Services, Germany
Computing Foundations
Hengming Zou, Shanghai Jiao Tong University, China
Mathematical Foundations
Nabendu Chaki, University of Calcutta, India
Engineering Foundations
Amitava Bandyopadhayay, Indian Statistical Institute, India 
Mary Jane Willshire, Software and Systems Engineering Associates (S2EA), USA
Appendix B: IEEE and ISO/IEC Standards Supporting SWEBOK 
James W. Moore, USA
References Editor
Marc Bouisset, Département d ’ informatique, UQAM 

REVIEW TEAM
The  people  listed  below  participated  in  the  public  review  process  of  SWEBOK  Guide  V4. 
Membership of the IEEE Computer Society was not a requirement to participate in this review 
process, and membership information was not requested from reviewers. Over 1300 individual 
comments were collected and duly adjudicated.
Aakashjit Bhattacharya
Adil Aliyev
Alaa Mahjoub
Alberto Córdoba Izaguirre
Ang Boon Chong
Antonio Navarro
Arjun Remadevi Somanathan
Atilla Elci
Beatri Beltrán Martínez
Biswaranjan Senapati
Brandon Thorin Klein
Brian Kirkpatrick
Ca rol Woody
ChandraSR K
Christof Ebert
Claude Laporte
Clive Boughton
Dale Dzielski
Daniel Medeiros Rocha
David Budgen
David Mack Endres
Dmytro Lenda
Duncan Hall
Ed Zuk
Eka Arriyanti
Elena Williams
Emmanuelle Wintergerst
Ernesto Cuadros-Vargas
Fabrício Laguna
Fabricio Lantieri
Fedor Dzerzhinskiy
Fernando Pinciroli
Francisco Valdés-Souto
Gabriel Tamura
Gavin Howard
Gopal T V
Graham Lee
Hector Teran
Helmut Neukirchen
Hernan Guarda
Hiroyuki Sato
Hossein Saiedian
Ian Hirst
Irina Marudina
Jack McKenzie
Jack Pope
James C Davis
James Purtilo
Jason Adcock
Javier Gonzalez Huerta
Joanna Isabelle Olszewska
Joanna Leng
Joao Marcelo Borovina Josko
Jon D Hagar
Jonathan Oliver
Joshua Cook
Juris Borzovs
Karol Szkudlarek
Kiyoshi Endo
Kiyoshi Honda
Konstantinos Domdouzis
Kun Hsiang Wu
Lolita Narag
Magesh Kasthuri
Maher Ben Abdessalem
Manu Mitra
Marc Blumberg
Marcia Ito
Maria-Isabel Sanchez-Segura
Martin Kropp
Masahiko Ishikawa
Matteo Große-Kampmann
Micheal Tuape
Mirna Muñoz
Mohammad Samarah
Muthu Ramachandran
Myneni Madhu Bala
Nancy Mead
Nandakumar Ramanathan
Nauman Ahmad
Nenad Medvidović
Nicolae Giurescu
Norha Villegas
Omar
Oscar A. Schivo
Pankaj Kamthan
Paola Britos
Peter Schoo
Phillip A. Laplante
Pieter Botman
Piotr Karocki
Prashant Verma
Qusay F. Hassan
Radoslav Rakovic
Ravindra Joshi
Ren-Her Hwang
Robert Lemay
Rodrigo Martins Pagliares
Rupesh Sreeraman
Samuel J. Crawford
Saurabh Kumar
Shailendra Suryawanshi
Shelly Sachdeva
Sheydi Anel Zamudio López
Sravan Kumar Reddy 
Kamidi Raja
Stefan Malich
Stefano Pietroiusti
  xxxiii

xxxiv   SWEBOK
®
 GUIDE V4.0
Steffen Becker
Steve France
Sudheer Kumar 
Reddy Gowrigari
Susanne Müller
Sushil Birla
Syed Mohamed Thameem 
Nizamudeen
T V Gopal
Takehisa Okazaki
Tarig Ahmed Khalid
Tateki Sano
Te t s u   N a g a t a
Thomas M. Prinz
Tim Bond
Trent Leopold
Tyler Thomas Procko
Vivek Dave
Vivienne Bičak
Walter Green
Weihan Goh
Weijia Yang
William Uemura
Yarlagadda Padma Sai
Ya s u k o Ok a z a k i
Yuseon Yu
Zheng Wang
ACKNOWLEDGEMENTS 
Funding for the development of SWEBOK Guide V4 has been provided by the IEEE Computer 
Society. The editors and coeditors appreciate the important work performed by the KA editors 
and the contributing editors, as well as by the members of the Steering Group. The editorial 
team must also acknowledge the indispensable contribution of reviewers. 
Finally,  there  are  surely  other  people  who  have  contributed  to  this  Guide,  either  directly  or  
indirectly,  whose  names  we  have  inadvertently  omitted.  To  those  people,  we  offer  our  tacit  
appreciation and apologize for having omitted explicit recognition. 
IEEE COMPUTER SOCIETY PRESIDENTS
Leila De Floriani, 2020 President
Forrest Shull, 2021 President
William “Bill” Gropp, 2022 President
Nita Patel, 2023 President
Jyotika Athavale, 2024 President
Hironori Washizaki, 2025 President
PROFESSIONAL AND EDUCATIONAL ACTIVITIES BOARD,  
2024 MEMBERSHIP
Cyril Onwubiko, Chair
Deborah Silver
Hironori Washizaki
Rajendra Raj
Ernesto Cuadros-Vargas
Sao-Jie Chen
Akinori Ihara
Kiyoshi Honda
Andrew Seely
Megha Ben
Kwabena Boateng
Eric Berkowitz
Michelle Phon

TABLE OF CONTENTS   xxxv
MOTIONS REGARDING THE APPROVAL OF SWEBOK GUIDE V4.0
The  following  motion  was  unanimously  adopted  by  the  Professional  and  Educational  
Activities Board of the IEEE Computer Society in September 2024: 
The Professional Activities Board of the IEEE Computer Society finds that the Guide to the Software 
Engineering Body of Knowledge Version 4.0 has been successfully completed; and endorses the Guide 
to the Software Engineering Body of Knowledge Version 4.0 and commends it to the IEEE Computer 
Society Board of Governors for their approval.
The following motion was adopted by the IEEE Computer Society Board of Governors in 
October 2024:
MOVED,  that  the  Board  of  Governors  of  the  IEEE  Computer  Society  approves  Version  4.0  of  the  
Guide to the Software Engineering Body of Knowledge and authorizes the Chair of the Professional 
Activities Board to proceed with printing.
MOTIONS REGARDING THE APPROVAL OF SWEBOK GUIDE V3.0
The SWEBOK Guide V3.0 was submitted to ballot by verified IEEE Computer Society mem-
bers in November 2013 with the following question: “Do you approve this manuscript of the 
SWEBOK  Guide  V3.0  to  move  forward  to  formatting  and  publication?”  The  results  of  this  
ballot were 259 Yes votes and 5 No votes.
The following motion was unanimously adopted by the Professional Activities Board of the 
IEEE Computer Society in December 2013: 
The Professional Activities Board of the IEEE Computer Society finds that the Guide to the Software 
Engineering Body of Knowledge Version 3.0 has been successfully completed; and endorses the Guide 
to the Software Engineering Body of Knowledge Version 3.0 and commends it to the IEEE Computer 
Society Board of Governors for their approval.
The following motion was adopted by the IEEE Computer Society Board of Governors in 
December 2013:
MOVED,  that  the  Board  of  Governors  of  the  IEEE  Computer  Society  approves  Version  3.0  of  the  
Guide to the Software Engineering Body of Knowledge and authorizes the Chair of the Professional 
Activities Board to proceed with printing.
Please also note that The SWEBOK Guide V3.0 was submitted by the IEEE Computer Society to 
ISO/IEC without any change and was recognized as Technical Report ISO/IEC TR 19759:2015.

xxxvi   SWEBOK
®
 GUIDE V4.0
MOTIONS REGARDING THE APPROVAL OF SWEBOK GUIDE 2004 VERSION
The  following  motion  was  unanimously  adopted  by  the  Industrial  Advisory  Board  of  the  
SWEBOK Guide project in February 2004:
The  Industrial  Advisory  Board  finds  that  the  Software  Engineering  Body  of  Knowledge  project  
initiated in 1998 has been successfully completed; and endorses the 2004 Version of the Guide to the 
SWEBOK and commends it to the IEEE Computer Society Board of Governors for their approval.
The following motion was adopted by the IEEE Computer Society Board of Governors in 
February 2004:
MOVED,  that  the  Board  of  Governors  of  the  IEEE  Computer  Society  approves  the  2004  Edition  
of  the  Guide  to  the  Software  Engineering  Body  of  Knowledge  and  authorizes  the  Chair  of  the  
Professional Practices Committee to proceed with printing.
Please also note that the 2004 edition of the Guide to the Software Engineering Body of Knowledge 
was submitted by the IEEE Computer Society to ISO/IEC without any change and was recog-
nized as Technical Report ISO/IEC TR 19759:2005.

xxxvii 
Introduction to the Guide
ACRONYMS
KAKnowledge Area
SWEBOKSoftware Engineering Body 
of Knowledge
Publication  of  the  2014  version  of  the  Guide 
to  the  Software  Engineering  Body  of  Knowledge  
(SWEBOK Guide V3) was a major milestone in 
establishing  software  engineering  as  a  recog-
nized engineering discipline. The goal of devel-
oping this update (Version 4) to the SWEBOK 
Guide is to improve the Guide’s currency, read-
ability,  consistency  and  usability.  The  content  
of  the  Guide  consists  of  18  knowledge  areas  
(KAs) followed by several appendixes. A KA is 
an identified area of software engineering and 
is  described  in  terms  of  its  generally  accepted  
knowledge,  such  as  its  component  processes,  
practices,   inputs,   outputs,   tools   and   tech-
niques. Three appendixes provide, respectively, 
the  specifications  for  the  KA  descriptions,  an  
annotated  set  of  relevant  standards  for  each  
KA, and a list of references cited in the Guide. 
All   KAs   have   been   updated   to   reflect   
changes  in  software  engineering  since  the  
publication of the Guide V3, including modern 
development  practices,  new  techniques,  and  
the  advancement  of  standards.  One  signifi-
cant  change  is  that  Agile  and  DevOps  have  
been incorporated into almost all KAs because 
these models have been widely accepted since 
the  previous  publication  of  the  Guide.  Agile  
models  typically  involve  frequent  demonstra-
tions  of  working  software  to  a  customer  in  
short,  iterative  cycles.  Agile  practices  exist  
across   KAs.   Furthermore,   emerging   plat-
forms  and  technologies,  including  artificial  
1  http://pascal.computer.org/sev_display/index.action.
intelligence (AI), machine learning (ML) and 
the internet of things (IoT), have been incor-
porated into the foundation KAs.
To  reflect  areas  that  are  becoming  partic-
ularly  important  in  modern  software  engi-
neering, the following KAs have been added: 
the   Software   Architecture   KA,   Software   
Security   KA   and   Software   Engineering   
Operations KA.
This Guide,  written  under  the  auspices  of  
the  Professional  and  Educational  Activities  
Board  of  the  IEEE  Computer  Society,  rep-
resents a next step in the evolution of the soft-
ware engineering profession.
1. What Is Software Engineering?
ISO/IEC/IEEE    Systems    and    Software    
Engineering     Vocabulary     (SEVOCAB)1     
defines  software  as  “computer  programs,  pro-
cedures  and  possibly  associated  documenta-
tion and data pertaining to the operation of a 
computer  system”.
1
  And  software  engineering  
is  defined  as  “the  application  of  a  systematic,  
disciplined, quantifiable approach to the devel-
opment,  operation,  and  maintenance  of  soft-
ware;  that  is,  the  application  of  engineering  
to  software”  [1].  Historically,  software  engi-
neering  has  been  defined  in  various  ways,  
such  as  “the  practical  application  of  scientific  
knowledge  to  the  design  and  construction  of  
computer  programs  and  the  associated  docu-
mentation  required  to  develop,  operate,  and  
maintain them” [2] and “the technological and 
managerial  discipline  concerned  with  system-
atic  production  and  maintenance  of  software  
products  that  are  developed  and  modified  on  
time and within cost estimates” [3]. Although 

xxxviii   SWEBOK
®
 GUIDE V4.0
these definitions differ in detail, they have an 
essential commonality in that they both deal 
with software development and maintenance. 
Furthermore,   the   application   of   scientific   
knowledge (mentioned in the first definition) 
can be described as a technological discipline 
(a  phrase  used  in  the  second  definition).  As  
“scientific”  implies  a  systematic  and  quan-
tifiable  approach,  the  initial  definition  also  
expresses an idea common in past definitions 
of the discipline.
Software  engineering  occupies  a  position  
between the mathematical and physical disci-
plines of computer science and technology on 
the one hand and the work of applying those 
findings  to  solve  the  problems  of  particular  
application domains on the other [3]. Science 
is about discovering new things. On the other 
hand,   engineering   is   about   applying   that   
knowledge  to  solve  real-world  problems  with  
limited   resources   cost-effectively.   As   such,   
the engineering discipline of a given scientific 
field  requires  skills  and  knowledge  about  rel-
evant “practice.” Further, as engineering con-
cerns   cost-effective   solutions   to   real-world   
problems,  all  engineering  disciplines  involve  
engineering  economics,  which  is  the  analysis  
of  theoretically  possible  solutions  to  identify  
the  most  cost-effective  one.  In  essence,  this  
Guide distills the relevant theory of computer 
science  and  engineering  into  the  three  foun-
dation  KAs,  while  the  remaining  KAs  cat-
alog  the  practice  and  engineering  economics  
of software engineering.
Software   engineering   techniques   can   be   
viewed as specializations of techniques of more 
general  disciplines,  such  as  project  manage-
ment,  systems  engineering  and  quality  man-
agement  [3].  Furthermore,  a  software  project  
must   implement   requirements   imposed   by   
cross-cutting disciplines such as dependability 
and  safety.  Software  engineering  and  com-
puter  science  are  related  but  distinct  in  the  
same way chemical engineering and chemistry 
are  related  but  distinct.  Scientific  disciplines,  
such as computer science and chemistry, aim to 
extend  human  knowledge.  Effective  require-
ments  elicitation  techniques,  design  princi-
ples  like  cohesion  and  coupling,  appropriate  
branch-merge  strategies,  conducting  a  proper  
peer  review,  and  assessing  the  cost  of  quality  
are  a  few  examples  of  critical  software  engi-
neering practices that are of little or no concern 
to  computer  science.  In  engineering,  science  
and  practice  are  applied  to  generate  poten-
tial  solutions  to  the  real-world  problem,  and  
engineering  economics  is  used  to  identify  the  
most  cost-effective  one.  In  the  same  way  that  
it  would  not  make  sense  to  send  a  chemist  to  
solve  a  chemical  engineering  problem,  it  does  
not make sense to send a computer scientist to 
solve a software engineering problem.
In  addition  to  computer  science,  software  
engineering  is  related  to  several  other  disci-
plines  and  professional  areas,  such  as  indus-
trial  engineering,  dependability  engineering,  
and safety and security engineering. 
2. What Are the Objectives of the  
SWEBOK Guide?
The Guide  should  not  be  confused  with  the  
body of knowledge itself, which exists in the 
published  literature.  The  Guide’s  purpose  is  
to  describe  the  generally  accepted  portion  of  
the body of knowledge, organize that portion, 
and provide topical access to it. 
The SWEBOK  Guide  was  established  with  
the following five objectives:
1. To promote a consistent view of software 
engineering worldwide
2. To specify the scope and clarify the place 
of  software  engineering  with  respect  to  
other  disciplines,  such  as  computer  sci-
ence,   project   management,   computer   
engineering and mathematics
3. To  characterize  the  contents  of  the  soft-
ware engineering discipline
4. To provide topical access to the Software 
Engineering Body of Knowledge
5. To  provide  a  foundation  for  curriculum  
development and for individual certifica-
tion and licensing materials
The  first  objective,  to  promote  a  consis-
tent worldwide view of software engineering, 
was supported by a development process that 

INTRODUCTION TO THE GUIDE   xxxix
engaged  about  130+  reviewers  from  various  
countries.  More  information  regarding  the  
development  process  can  be  found  at  www.
swebok.org.  Professional  and  learned  soci-
eties  and  public  agencies  involved  in  soft-
ware   engineering   were   contacted,   made   
aware of this project to update the SWEBOK 
Guide, and invited to participate in the review 
process.   Associate   editors   were   recruited   
from  America,  Asia,  Europe,  and  Oceania.  
Presentations on the project were made at var-
ious international venues.
The  second  objective,  to  specify  the  scope  
of  software  engineering,  underlies  the  fun-
damental organization of the Guide. Material 
that  falls  within  this  discipline  is  organized  
into the 18 KAs listed in Table I.1. Each KA 
is  treated  as  a  chapter  in  this  Guide.  Among  
them, Chapters 1-15 are regarded as the soft-
ware engineering KAs, while Chapters 16-18 
address foundation KAs.
TABLE I.1. THE 18 SWEBOK KAS
1.   Software Requirements
2. Software Architecture
3. Software Design
4. Software Construction
5.    Software Testing
6. Software Engineering Operations
7.    Software Maintenance
8. Software Configuration Management
9.      Software Engineering Management
10.  Software Engineering Process
11.  Software Engineering Models 
and Methods
12. Software Quality
13. Software Security
14.  Software Engineering 
Professional Practice
15.  Software Engineering Economics
16.  Computing Foundations 
17.  Mathematical Foundations
18.  Engineering Foundations
In  specifying  the  scope  of  the  discipline,  
it  is  also  important  to  identify  disciplines  
that  intersect  with  software  engineering.  To  
this  end,  the  SWEBOK  V4  Guide  continues  
to  recognize  eleven  related  disciplines,  listed  
in  Table  I.2.  Software  engineers  should,  of  
course,  be  knowledgeable  about  these  dis-
ciplines  (and  KA  descriptions  in  this  Guide 
might refer to them). However, characterizing 
the knowledge of related disciplines is not an 
objective of the SWEBOK Guide.
TABLE I.2. RELATED DISCIPLINES
Business Analysis
Computer Engineering
Computer Science
Cybersecurity 
Data Science
General Management
Information Systems and Technology
Mathematics
Project Management
Quality Management
Systems Engineering
The relevant elements of computer science, 
mathematics,   and   engineering   foundations   
are presented in the Computing Foundations 
KA,    Mathematical  Foundations  KA,  and  
Engineering  Foundations  KA  of  the  Guide 
(Chapters 16, 17 and 18).
HIERARCHICAL ORGANIZATION
The organization of the KA chapters supports 
the  third  project  objective  —  to  characterize  
the  contents  of  software  engineering.  The  
detailed  specifications  provided  by  the  proj-
ect’s  editorial  team  to  the  associate  editors  
regarding the contents of the KA descriptions 
can be found in Appendix A.
The Guide  uses  a  hierarchical  organiza-
tional structure to decompose each KA into 
a set of topics with recognizable labels. Each 

xl   SWEBOK
®
 GUIDE V4.0
KA  provides  a  two-  or  three-level  break-
down,  which  provides  a  reasonable  way  to  
find  topics  of  interest.  The  Guide  treats  the  
selected  topics  in  a  way  that  is  compatible  
with  major  schools  of  thought  and  sepa-
rates  the  topics  into  subtopics  that  are  gen-
erally  found  in  industry  and  in  software  
engineering  literature  and  standards.  The  
breakdowns  are  not  designed  for  particular  
application domains, business uses, manage-
ment philosophies, development methods and 
so forth. Each topic description is meant only 
to  give  the  reader  a  general  understanding  
of the topic and to enable the reader to find 
reference  material.  The  body  of  knowledge  
is  found  in  the  reference  materials,  not  in  
the Guide.
Software plays a core role in various appli-
cation  and  technological  domains,  such  as  
automotive,  legal,  health  care,  and  finance.  
Differences in application domains and busi-
ness  models  (e.g.,  custom  applications,  and  
open  source  applications)  and  system  types  
(e.g., enterprise and cloud systems, embedded 
and  IoT  systems,  and  AI/ML-based  sys-
tems)   may   influence   what   practices   are   
adopted.  Major  special  techniques  and  prac-
tices   specific   to   certain   system   types   are   
also  discussed  in  some  KAs,  especially  the  
Software  Requirements  KA,  the  Software  
Testing  KA,  the  Software  Quality  KA,  the  
Software  Security  KA  and  the  Computing  
Foundations KA.
REFERENCE MATERIAL AND 
MATRIX
To  provide  topical  access  to  the  knowledge  
—  the  fourth  project  objective  —  the  Guide 
identifies  authoritative  reference  material  for  
each  KA.  In  addition,  Appendix  C  provides  
a  Consolidated  Reference  List  for  the  entire  
Guide.  Each  KA  includes  relevant  references  
from the Consolidated Reference List as well 
as a matrix connecting the reference materials 
to the topics covered. 
2 A Guide to the Project Management Body of Knowledge, 7th ed., Project Management Institute, 2021, www.pmi.org. 
Please note that the Guide does not attempt 
to  be  comprehensive  in  its  citations.  Much  
suitable  and  excellent  material  is  not  refer-
enced. However, the material included in the 
Consolidated Reference List provides further 
information about the topics described.
DEP TH OF TREATMENT
To  achieve  the  Guide’s  fifth  objective  —  to  
provide  a  foundation  for  curriculum  devel-
opment,  certification  and  licensing  —  the  
criterion of generally accepted knowledge has 
been applied. This is distinct from advanced 
and research knowledge (on the grounds of 
maturity)  and  from  specialized  knowledge  
(on  the  grounds  of  generality  of  applica-
tion).  The  equivalent  term  generally  recog-
nized  comes  from  the  Project  Management  
Institute:
2
 
“Generally  recognized  means  the  knowl-
edge and practices described are applicable to 
most  projects  most  of  the  time,  and  there  is  
consensus about their value and usefulness.”
However,  the  terms  generally  accepted  and 
generally recognized do not imply that the desig-
nated knowledge should be uniformly applied 
to all software engineering endeavors — each 
project’s needs determine what knowledge to 
apply, and how. However, competent, capable 
software  engineers  should  be  equipped  with  
this   knowledge   for   potential   application.   
Therefore,  appropriate  selection  of  generally  
accepted knowledge should be included in the 
study  material  for  the  software  engineering  
professional certification and licensing exam-
inations that graduates take after gaining four 
years of work experience.  
STRUCTURE OF THE KA 
DESCRIP TIONS
Each chapter provides a description of one of 
the  KAs.  These  descriptions  are  structured  
as follows. 

INTRODUCTION TO THE GUIDE   xli
The  introduction  briefly  defines  the  KA  
and  presents  an  overview  of  its  scope  and  its  
relationship with other KAs.
The breakdown of topics in each KA consti-
tutes the core of the KA description, showing 
the  decomposition  of  the  KA  into  subareas,  
topics  and  subtopics.  For  each  topic  or  sub-
topic, a short description is given, along with 
one or more references. 
These  reference  materials  were  selected  as  
the  best  available  presentation  of  knowledge  
related to the topic. A matrix links the topics 
to the reference materials. 
The last part of each KA description is the 
list  of  recommended  references  and  suggested  
further  reading.  Relevant  standards  for  each  
KA are presented in Appendix B of the Guide.
APPENDIX A. KA DESCRIP TION 
SPECIFICATIONS
Appendix   A   describes   the   specifications   
provided  by  the  editorial  team  to  the  asso-
ciate  editors  for  the  content,  recommended  
references,   format   and   style   of   the   KA   
descriptions.
APPENDIX B. IEEE AND ISO/IEC 
STANDARDS
Appendix B presents an annotated list of the 
relevant  standards,  mostly  from  the  IEEE  
and   the   ISO,   for   each   of   the   SWEBOK 
Guide’s K As.
APPENDIX C. CONSOLIDATED 
REFERENCE LIST
Appendix C contains the consolidated list of 
recommended  references  cited  in  the  KAs.  
These references are marked with an asterisk
(*) in the text. 
REFERENCES
[1]  ISO/IEC/IEEE, “ISO/IEC/IEEE 
24765:2017 Systems and Software 
Engineering — Vocabulary,” 
2nd ed. 2017.
[2] Barry W. Boehm, “Software 
Engineering,” IEEE Transactions on 
Computers, Vol. C-25, No. 12, 1976.
[3]  James W. Moore, “Software 
Engineering Standards: A User’s Road 
Map,” IEEE Computer Society, 1998.

1-1 
CHAPTER 01
Software Requirements
ACRONYMS
ATDDAcceptance Test Driven 
Development
BDDBehavior Driven 
Development
CIAConfidentia lit y, Integrit y, 
and Availability
FSMFunctional Size 
Measurement
INCOSEInternational Council on 
Systems Engineering
JADJoint Application 
Development
JRPJoint Requirements Planning
SMESubject Matter Expert
SysMLSystems Modeling Language
TDDTest Driven Development
UMLUnified Modeling Language
INTRODUCTION
Software requirements should be viewed from 
two  perspectives.  The  first  is  as  an  expres-
sion  of  the  needs  and  constraints  on  a  soft-
ware product or project that contribute to the 
solution  of  a  real-world  problem.  The  second  
is  that  of  the  activities  necessary  to  develop  
and maintain the requirements for a software 
product  and  for  the  project  that  constructs  
it.  Both  perspectives  are  presented  in  this  
knowledge area (KA).
If a team does a poor job of determining the 
requirements, the project, the product or both 
are  likely  to  suffer  from  added  costs,  delays,  
cancellations  and  defects.  One  reason  is  that  
each  software  product  requirement  generally  
leads  to  many  design  decisions.  Each  design  
decision  generally  leads  to  many  code-level  
decisions.  Each  decision  can  involve  several  
test decisions, as well. In other words, deter-
mining  the  requirements  correctly  is  high-
stakes  work.  If  not  detected  and  repaired  
early,  missing,  misinterpreted  and  incorrect  
requirements  can  induce  exponentially  cas-
cading rework to correct them.
Real-world    software    projects    tend    to    
suffer   from   two   primary   requirements-re-
lated problems:
1. incompleteness:     stakeholder     require-
ments, and necessary detail, exist that are 
not  revealed    and  communicated  to  the  
software engineers;
2. ambiguity:  requirements  are  communi-
cated  in  a  way  that  is  open  to  multiple  
interpretations,  with  only  one  possible  
interpretation being correct.
Beyond    the    obvious    short-term    role    
requirements  play  in  initial  software  con-
struction,  they  also  play  a  less  recognized  
but still important role in long-term mainte-
nance.  Upon  receiving  software  without  any  
supporting  documentation,  a  software  engi-
neer has several means to determine what that 
code  does,  such  as  execute  it,  step  through  
it  with  a  debugger,  hand-execute  it,  stati-
cally  analyze  it,  and  so  on.  The  challenge  is  
determining what that code is intended to do. 
What is generally referred to as a bug —  but  
is better called a defect — is simply an observ-
able  difference  between  what  the  software  is  
intended  to  do  and  what  it  does.  The  role  of  
requirements  documentation  throughout  the  
service  life  of  the  software  is  to  capture  and  

1-2   SWEBOK
®
 GUIDE V4.0
communicate  intent  for  software  engineers  
who  maintain  the  code  but  might  not  have  
been its original authors.
The  Software  Requirements  KA  concerns  
developing  software  requirements  and  man-
aging  those  requirements  over  the  software’s  
service   life.   This   KA   provides   an   under-
standing that software requirements:
•    are  not  necessarily  a  discrete  front-end  
activity of the software development life 
cycle  but  rather  a  process  initiated  at  a  
project’s  beginning  that  often  continues  
to  be  refined  throughout  the  software’s  
entire service life;
•    need  to  be  tailored  to  the  organization  
and project context.
The  term  requirements  engineering  is  often  
used  to  denote  the  systematic  handling  of  
requirements. For consistency, the term engi-
neering will not be used in this KA other than 
for software engineering per se. 
The  Software  Requirements  KA  is  most  
closely  related  to  the  Software  Architecture,  
Software   Design,   Software   Construction,   
Software Testing, and Software Maintenance 
KAs,  as  well  as  to  the  models  topic  in  the  
Software  Engineering  Models  and  Methods  
KA, in that there can be high value in speci-
fying requirements in model form.
This  KA  is  also  related  to  the  Software  
Life Cycles topic in the Software Engineering 
Process KA, in that this KA’s focus is on what 
and how  requirements  work  can  and  should  
be done, whereas the project’s life cycle deter-
mines when  that  work  is  done.  For  example,  
in a waterfall life cycle, all requirements work 
is  essentially  done  in  a  discrete  Requirements 
phase and is expected to be substantially com-
plete before any architecture, design and con-
struction  work  occurs  in  subsequent  phases.  
Under some iterative life cycles, initial, high-
level  requirements  work  is  done  during  an  
Inception  phase,  and  further  detailing  is  done  
during  one  or  more  Elaboration  phases.  In  an  
Agile  life  cycle,  requirements  work  is  done  
incrementally, just in time, as each additional 
element of functionality is constructed.
The whats  and  hows  of  software  require-
ments work on a project should be determined 
by the nature of the software constructed, not 
by the life cycle under which it is constructed. 
Insofar  as  requirements  documentation  cap-
tures and communicates the software’s intent, 
downstream  maintainers  should  not  be  able  
to discern the life cycle used in earlier devel-
opment   from   the   form   of   those   require-
ments alone.
This  KA  is  also  related,  but  somewhat  
less   so,   to   the   Software   Configuration   
Management,        Software        Engineering        
Management   and   Software   Quality   KAs.   
Software  CM  approaches  can  be  applied  to  
trace   and   manage   requirements;   software   
quality looks at how well formed the require-
ments are, and engineering management can 
use the status of requirements to evaluate the 
completion of the project.
BREAKDOWN OF TOPICS FOR 
SOF TWARE REQUIREMENTS
The   topic   breakdown   for   the   Software   
Requirements KA is shown in Figure 1.1.
1. Software Requirements Fundamentals
1.1.  Definition of a Software Requirement  
 [1*, c1pp5-6] [2*, c4p102]
Formally,   a   software   requirement   has   been   
defined as [28]:
•    a condition or capability needed by a user 
to solve a problem or achieve an objective;
•    a  condition  or  capability  that  must  be  
met  or  possessed  by  a  system  or  system  
component  to  satisfy  a  contract,  stan-
dard,   specification   or   other   formally   
imposed document;
•    a  documented  representation  or  capa-
bility as in (1) or (2) above.
This  formal  definition  is  extended  in  this  
KA to include expressions of a software proj-
ect’s needs and constraints.

SOFTWARE REQUIREMENTS   1-3
At  its  most  basic,  a  software  requirement  
is a property that must be exhibited to solve a 
real-world problem. It might aim to automate 
all  or  part  of  a  task  supporting  an  organiza-
tion’s business policies and processes, correct 
existing software’s shortcomings, or control a 
device — just a few of the many problems for 
which software solutions are possible. 
Business  policies  and  processes,  as  well  as  
device  functions,  are  often  very  complex.  By  
extension,  software  requirements  are  often  a  
complex  combination  of  requirements  from  
various  stakeholders  at  different  organiza-
tional  levels  who  are  involved  or  connected  
with some aspect of the environment in which 
the software will operate.
Clients, customers and users usually impose 
requirements.  However,  other  third  parties,  
like regulatory authorities and, in some cases, 
the software organization or the project itself, 
might also impose requirements. (See also [5, 
c1] [6, c1] [9, c4].)
1.2.  Categories of Software Requirements  
 [1*, c1pp7-12] [2*, s4.1]
Figure  1.2  shows  the  categories  of  software  
requirements  defined  in  this  KA  and  the  
relationships  among  those  categories.  (See  
also  [5,  c1]  [6,  c1]  [9,  c4].)  Each  category  is  
further described below.
1.3.  Software Product Requirements and 
Software Project Requirements  
 [1*, c1pp14-15]
Software   product   requirements  specify  the  
software’s  expected  form,  fit  or  function.  
Software  project  requirements  —  also  called  
process  requirements  or,  sometimes  business 
requirements—  constrain  the  project  that  
constructs  the  software.  Project  require-
ments often constrain cost, schedule and/or 
staffing but can also constrain other aspects 
of  a  software  project,  such  as  testing  envi-
ronments,  data  migration,  user  training,  
and maintenance. Software project require-
ments  can  be  captured  in  a  project  charter  
or  other  high-level  project  initiation  doc-
ument.   They   are   most   relevant   to   how   
the  project  is  managed  (see  the  Software  
Engineering   Management   KA)   or   what   
life  cycle  process  should  be  used  (see  the  
Software  Engineering  Process  KA).  This  
KA   does   not   discuss   software   project   
requirements further.
Software
Requirements
Software
Requirements
Fundamentals
Definition of a
Software
Requirement
Categories of
Software
Requirements
Software Product
Requirements and
Software Project
Requirements
Functional
Requirements
Nonfunctional
Requirements
Technology
Constraints
Quality of Service
Constraints
Why Categorize
Requirements is Way?
System Requirements
and Software Requirements
Derived
Requirements
Software Requirements
Activities
Requirements
Sources
Common
Requirements
Elicitation
Techniques
Basic
Requirements
Analysis
Economics of
Quality of Service
Constraints
Formal
Analysis
Addressing
Conflict in
Requirements
Unstructured
Natural
Language
Requirements
Specification
Structured
Natural
Language
Requirements
Specification
Acceptance
Criteria-based
Requirements
Specification
Model-Based
Requirements
Specification
Additional
Attributes of
Requirements
Incremental and
Comprehensive
Requirements
Specification
Requirements
Reviews
Simulation and
Execution
Prototyping
Requirements
Scrubbing
Requirements
Change
Control
Scope
Matching
Iterative Nature
of the
Requirements
Process
Requirements
Prioritization
Requirements
Tracing
Requirements
Stability and
Volatility
Measuring
Requirements
Requirements
Process Quality
and Improvement
Requirements
Elicitation
Requirements
Analysis
Requirements
Specification
Requirements
Validation
Requirements
Management
Activities
Practical
Considerations
Software
Requirements
Tools
Requirements
Management
Tools
Requirements
Modeling
Tools
Functional
Test Case
Generation
Tools
Figure 1.1. Breakdown of Topics for the Software Requirements KA

1-4   SWEBOK
®
 GUIDE V4.0
1.4.  Functional Requirements  
 [1*, c1p9] [2*, s4.1.1]
Functional   requirements   specify   observable   
behaviors  that  the  software  is  to  provide  —  
policies  to  be  enforced  and  processes  to  be  
carried out. Example policies in banking soft-
ware might be “an account shall always have 
at  least  one  customer  as  its  owner,”  and  “the  
balance of an account shall never be negative.” 
Example processes could specify the meanings 
of  depositing  money  into  an  account,  with-
drawing  money  from  an  account  and  trans-
ferring money from one account to another.
Even   highly   technical   (nonbusiness-ori-
ented) software, such as software that imple-
ments   the   transmission   control   protocol/
internet  protocol  (TCP/IP)  network  com-
munications  protocol,  has  policies  and  pro-
cesses: “a Port shall be able to exist with zero, 
one,  or  many  associated  Connections,  but  a  
Connection shall exist on exactly one associ-
ated Port,” “acceptable states of a Connection 
shall   be   ‘listen,’   ‘syn   sent,’   ‘established,’   
‘closing,’  .  .  .  ,”  and  “if  the  time-to-live  of  a  
Segment reaches zero, that Segment shall be 
deleted.” (See [5, c1] [6, c10] [9, c4].)
1.5.  Nonfunctional Requirements  
 [1*, c1pp10-11] [2*, s4.1.2]
Nonfunctional  requirements  in  some  way  con-
strain  the  technologies  to  be  used  in  the  
implementation:    What    computing    plat-
form(s)? What database engine(s)? How accu-
rate do results need to be? How quickly must 
results be presented? How many records of a 
certain  type  need  to  be  stored?  Some  non-
functional  requirements  might  relate  to  the  
operation of the software. (See the Operation 
and  Maintenance  KA.)  (See  also  [5,  c1]  [6,  
c11] [9, c4].)
The  nonfunctional  requirements  can  be  
further  divided  into  technology  constraints  
and  quality  of  service  constraints.  They  have  
essential   relationships   among   themselves,   
which  affect  them  positively  or  negatively  
and  require  that,  whenever  a  nonfunctional  
requirement  is  modified,  the  impact  it  may  
cause on others should be considered.
1.6.  Technology Constraints
These requirements mandate — or prohibit — 
use  of  specific,  named  automation  technolo-
gies  or  defined  infrastructures.  Examples  are  
requirements  to  use  specific  computing  plat-
forms  (e.g.,  Windows™,  MacOS™,  Android  
OS™,     iOS™),     programming     languages     
(e.g.,  Java,  C++,  C#,  Python),  compatibility  
with  specific  web  browsers  (e.g.,  Chrome™,  
Safari™, Edge™), given database engines (e.g., 
Oracle™, SQL Server™, MySQL™), and gen-
eral  technologies  (e.g.,  reduced  instruction  set  
computer   (RISC),   Relational   Database).   A   
requirement prohibiting use of pointers would 
be another example. (See also [9, c4].)
1.7.  Quality of Service Constraints
These  requirements  do  not  constrain  the  use  
of   specific,   named   technologies.   Instead,   
these specify acceptable performance levels an 
automated  solution  must  exhibit.  Examples  
are   response   time,   throughput,   accuracy,   
reliability  and  scalability.  ISO/IEC  25010:  
“System and software engineering – Systems 
and   software   Quality   Requirements   and   
Evaluation (SQuaRE) – System and software 
quality  models”  [27]  contains  a  large  list  of  
the kinds of quality characteristics that can be 
relevant for software. (See also [9, c4].) Safety 
Software
Requirements
Software Project
Requirements
Functional
Requirements
Nonfunctional
Requirements
Technology
Constraints
Quality of Service
Constraints
Software Product
Requirements
Figure 1.2. Categories of Software Requirements

SOFTWARE REQUIREMENTS   1-5
and security are also a particularly important 
topic  where  requirements  tend  to  be  over-
looked.  (See  the  Security  KA  for  details  on  
the  kinds  of  specific  security  requirements  
that should be considered.) (See also [2*, c13].)
1.8.  Why Categorize Requirements This Way?
Categorizing  requirements  this  way  is  useful  
for the following reasons:
•    requirements  in  one  category  tend  to  
come  from  different  sources  than  other  
categories;
•    elicitation      techniques      often      vary      
by source;
•    analysis techniques vary by category;
•    specification techniques vary by category;
•    validation authorities vary by category;
•    the different categories affect the resulting 
software in different ways.
In  addition,  organizing  the  requirements  
in  these  categories  is  beneficial  in  the  fol-
lowing ways:
•    complexity can be better managed because 
different  areas  can  be  addressed  sepa-
rately;  software  engineers  can  deal  with  
policy  and  process  complexities  without  
worrying  about  automation  technology  
issues  at  the  same  time  (and  vice  versa).  
One  large  problem  becomes  two  smaller  
ones.  This  is  classic  divide  and  conquer 
complexity management;
•    distinct  areas  of  expertise  can  be  iso-
lated;  stakeholders,  not  software  engi-
neers, are the experts in the policies and 
processes  to  be  automated.  Software  
engineers,   not   stakeholders,   are   the   
technology  experts.  When  a  business  
expert  is  given  interspersed  functional  
and   nonfunctional   requirements   for   
review  or  validation,  they  might  give  
up because they don’t understand — or 
even care about — the technology issues. 
The relevant requirements reviewer can 
focus on just the subset of requirements 
relevant to them.
The Perfect   Technology   Filter   originally   
described  in  [18,  c1-4]  but  also  explained  in  
[8] and [9, c4] helps separate functional from 
nonfunctional    requirements.    Simply    put,    
functional requirements are those that would 
still need to be stated even if a computer with 
infinite  speed,  unlimited  memory,  zero  cost,  
no failures, etc., existed on which to construct 
the   software.   All   other   software   product   
requirements  are  constraints  on  automation  
technologies and are therefore nonfunctional.
Large  systems  often  span  more  than  one  
subject matter area, or domain. As explained 
in  [9,  c6],  recursive  design  shows  how  non-
functional  requirements  in  a  parent  domain  
can become, or can induce, functional require-
ments in a child domain. For example, a non-
functional  requirement  about  user  security  
in  a  parent  banking  domain  can  become  or  
can induce functional requirements in a child 
security domain. Similarly, cross-cutting non-
functional  requirements  about  auditing  and  
transaction management in a parent banking 
domain   can   become   or   induce   functional   
requirements in a child auditing domain and a 
child transaction domain. Decomposing large 
systems into a set of related domains signifi-
cantly reduces complexity.
1.9.  System Requirements and Software 
Requirements
The    International    Council    on    Systems    
Engineering  (INCOSE)  defines  a  system  as  
“an  interacting  combination  of  elements  to  
accomplish a defined objective. These include 
hardware,  software,  firmware,  people,  infor-
mation,  techniques,  facilities,  services,  and  
other support elements” [24].
In some cases, it is either useful or manda-
tory to distinguish system requirements from 
software  requirements.  System  requirements  
apply  to  larger  systems  —  for  example,  an  
autonomous  vehicle.  Software  requirements  
apply  only  to  an  element  of  software  in  that  
larger  system.  Some  software  requirements  
may  be  derived  from  system  requirements.  
(See also [5, c1].) In other cases, the software is 
itself the system of interest, and hardware and 

1-6   SWEBOK
®
 GUIDE V4.0
support  system  are  regarded  as  the  platform  
or infrastructure, so that the system require-
ments are mostly software requirements.
1.10.   Derived Requirements
In  practice,  requirements  can  be  context-sensi-
tive and can depend on perspective. An external 
stakeholder  can  impose  a  scope  requirement,  
and this would be a requirement for the entire 
project  —  even  if  that  project  involves  hun-
dreds  of  software  engineers.  An  architect’s  
decision to use a pipes-and-filters architecture 
style would not be a requirement from the per-
spective  of  the  overall  project  stakeholders,  
but a design decision. But that same decision, 
when seen from the perspective of a sub-team 
responsible for constructing a particular filter, 
would be considered a requirement.
The  aerospace  industry  has  long  used  the  
term derived  requirement  to  mean  a  require-
ment  that  was  not  made  by  a  stakeholder  
external  to  the  overall  project  but  that  was  
imposed inside the larger development team. 
The  architect’s  pipes-and-filters  decision  fits  
this  definition.  That  choice  would  be  seen  as  
a  design  decision  from  the  point  of  view  of  
external stakeholders, but as a requirement for 
the sub-teams responsible for developing each 
filter. (See also [9, c4].)
1.11.   Software Requirements Activities  
 [1*, c1pp15-18] [2*, s4.2]
Figure  1.3  shows  the  requirements  develop-
ment and management activities.
Requirements  development,  as  a  whole,  
can be thought of as “reaching an agreement 
on  what  software  is  to  be  constructed.”  In  
contrast,  requirements  management  can  be  
considered “maintaining that agreement over 
time.” Each activity is presented in this KA. 
Requirements development activities are pre-
sented  as  separate  topics,  with  requirements  
management presented as a single topic. (See 
also [5, c1] [6, 2].)
2. Requirements Elicitation  
 [1*, c6-7] [2*, s4.3]
The goal of requirements elicitation is to sur-
face  candidate  requirements.  It  is  also  called  
requirements  capture, requirements  discovery  or  
requirements acquisition. As stated earlier, one 
problem  in  requirements  work  on  real-world  
software   projects   is   incompleteness.   This   
can  be  the  result  of  inadequate  elicitation.  
Although  there  is  no  guarantee  that  a  set  of  
requirements is complete, well-executed elic-
itation  helps  minimize  incompleteness.  (See  
also [5, c2-3] [6, c3-7].)
2.1.  Requirements Sources  
 [1*, c6] [2*, s4.3]
Requirements come — can be elicited — from 
many different sources. All potential require-
ments  sources  should  be  identified  and  eval-
uated.  A  stakeholder  can  be  defined  as  any  
person, group or organization that: 
•    is actively involved in the project;
•    is affected by the project’s outcome;
•    can influence the project’s outcome.
Typical  stakeholders  for  software  projects  
include but are not limited to the following:
•    clients — those who pay for the software 
to  be  constructed  (e.g.,  organizational  
management);
•    customers — those who decide whether a 
software product will be put into service;
•    users  —  those  who  interact  directly  or  
indirectly  with  the  software;  users  can  
Requirements
Requirements
Development
Elicitation
Analysis
Specification
Validation
Scrubbing
Change Control
Scope Matchin
g
Requirements
Management
Figure 1.3. Software Requirements Activities

SOFTWARE REQUIREMENTS   1-7
often  be  further  broken  down  into  dis-
tinct  user  classes  that  vary  in  frequency  
of use, tasks performed, skill and knowl-
edge level, privilege level, and so on;
•    subject matter experts (SMEs);
•    operations staff;
•    first-level product support staff;
•    relevant professional bodies;
•    regulatory agencies;
•    special interest groups;
•    people  who  can  be  negatively  affected  if  
the project is successful;
•    developers.
Stakeholder   classes   are   groups   of   stake-
holders  that  have  similar  perspectives  and  
needs. Working on a software project in terms 
of  stakeholder  classes  rather  than  with  indi-
vidual  stakeholders  can  produce  important,  
additional insight.
Many   projects   benefit   from   performing   
a  stakeholder  analysis  to  identify  as  many  
important stakeholder classes as possible. This 
reduces  the  possibility  that  the  requirements  
are  biased  toward  better-represented  stake-
holders  and  away  from  less  well-represented  
stakeholders.  The  stakeholder  analysis  can  
also  inform  negotiation  and  conflict  resolu-
tion when requirements from one stakeholder 
class conflict with requirements from another. 
(See also [5, c3] [6, c3].)
Requirements   are   not   limited   to   only   
coming   from   people.   Other,   non-person   
requirements sources can include:
•    documentation  such  as  requirements  for  
previous   versions,   mission   statements,   
concept of operations;
•    other systems;
•    larger business context including organi-
zational policies and processes;
•    computing environment.
2.2.  Common Requirements Elicitation 
Techniques  [1*, c7] [2*, s4.3]
A  wide  variety  of  techniques  can  be  used  to  
elicit  requirements  from  stakeholders.  Some  
techniques  work  better  with  certain  stake-
holder  classes  than  others.  Common  stake-
holder   elicitation   techniques   include   the   
following:
•    interviews;
•    meetings,           possibly           including           
brainstorming;
•    joint   application   development   ( JAD)   
[13],  joint  requirements  planning  (JRP)  
[14] and other facilitated workshops;
•    protocol analysis;
•    focus groups;
•    questionnaires and market surveys;
•    exploratory      prototyping,      including      
low-fidelity  and  high-fidelity  user  inter-
face prototyping [1*, c15];
•    user story mapping.
Elicitation can be difficult, and the software 
engineer needs to know that (for example) users 
might  have  difficulty  describing  their  tasks,  
leave  important  information  unstated  or  be  
unwilling  or  unable  to  cooperate.  Elicitation  
is  not  a  passive  activity.  Even  if  cooperative  
and  articulate  stakeholders  are  available,  the  
software  engineer  must  work  hard  to  elicit  
the right information. Many product require-
ments are tacit or can be found only in infor-
mation that has yet to be collected.
Requirements  can  also  be  elicited  from  
sources other than stakeholders. Such sources 
and techniques include the following:
•    previous versions of the system;
•    defect tracking database for previous ver-
sions of the system;
•    systems  that  interface  with  the  system  
under development;
•    competitive benchmarking;
•    literature search;
•    quality   function   deployment   (QFD)’s   
House of Quality [15];
•    observation, where the software engineer 
studies  the  work  and  the  environment  
where the work is being done;
•    apprenticing,  where  the  software  engi-
neer learns by doing the work;
•    usage scenario descriptions;

1-8   SWEBOK
®
 GUIDE V4.0
•    decomposition    (e.g.,    capabilities    into    
epics into features into stories);
•    task analysis [16];
•    design    thinking    (empathize,    define,    
ideate, prototype, test) [17];
•    ISO/IEC  25010:  “System  and  software  
engineering   –   Systems   and   software   
Quality   Requirements   and   Evaluation   
(SQuaRE) – System and software quality 
models” [27];
•    security requirements, as discussed in the 
Security KA;
•    applicable standards and regulations.
(See also [5, c3] [6, c4-7].)
3. Requirements Analysis [1*, c8-9]
Requirements  are  unlikely  to  be  elicited  in  
their final form. Further investigation is usu-
ally  needed  to  reveal  the  full,  true  require-
ments  suggested  by  the  originally  elicited  
information.   Requirements   analysis   helps   
software  developers  understand  the  meaning  
and  implications  of  candidate  requirements,  
both  individually  and  in  the  context  of  the  
overall set of requirements.
3.1.  Basic Requirements Analysis  
 [1*, c8-9]
The  following  list  of  desirable  properties  of  
requirements  can  guide  basic  requirements  
analysis.   The   software   engineer   seeks   to   
establish  any  of  these  properties  that  do  not  
hold yet. Each requirement should:
•    be     unambiguous     (interpretable     in     
only one way);
•    be   testable   (quantified),   meaning   that   
compliance   or   noncompliance   can   be   
clearly demonstrated;
•    be   binding,   meaning   that   clients   are   
willing  to  pay  for  it  and  unwilling  not  
to have it;
•    atomic, represent a single decision
•    represent true, actual stakeholder needs;
•    use stakeholder vocabulary;
•    be acceptable to all stakeholders.
The   overall   collection   of   requirements   
should be:
•    complete  — The requirements adequately 
address  boundary  conditions,  exception  
conditions and security needs;
•    concise — No extraneous content in the 
requirements
•    internally  consistent  —  No  requirement  
conflicts with any other;
•    externally  consistent  —  No  requirement  
conflicts with any source material;
•    feasible  —  A  viable,  cost-effective  solu-
tion can be created within cost, schedule, 
staffing, and other constraints.
In  some  cases,  an  elicited  statement  rep-
resents  a  solution  to  be  implemented  rather  
than  the  true  problem  to  be  solved.  This  
risks  implementing  a  suboptimal  solution.  
The 5-whys  technique  (e.g.,  [3*,  c4])  involves  
repeatedly  asking,  “Why  is  this  the  require-
ment?”  to  converge  on  the  true  problem.  
Repetition stops when the answer is, “If that 
isn’t done, then the stakeholder’s problem has 
not  been  solved.”  Often,  the  true  problem  is  
reached  in  two  or  three  cycles,  but  the  tech-
nique is called 5-whys to incentivize engineers 
to push it as far as possible.
3.2.  Economics of Quality of Service Constraints 
 [3*]
Quality  of  service  constraints  can  be  partic-
ularly  challenging.  This  is  generally  because  
engineers do not consider them from an eco-
nomic  perspective  [9,  c4].  Figure  1.4  illus-
trates  the  economic  perspective  of  a  typical  
quality of service constraint, such as capacity, 
throughput    and    reliability,    where    value    
increases with performance level. This curve is 
mirrored vertically for quality of service con-
straints whose value decreases as performance 
level increases (response time and mean time 
to repair would be examples).
  Over  the  relevant  range  of  performance  
levels, the stakeholders have a corresponding 
value if the system performs at that level. The 
value curve has two important points:

SOFTWARE REQUIREMENTS   1-9
1. Perfection  point  —  This  is  the  most  
favorable  level  of  performance,  beyond  
which there is no additional benefit. Even 
if the system can perform better than the 
perfection point, the customer cannot use 
that capacity. For example, a social media 
system that supports more members than 
the  world  population  would  have  this  
excess capacity.
2. Fail  point  —  This  is  the  least  favorable  
level of performance, beyond which there 
is  no  further  reduction  in  benefit.  For  
example,  the  social  media  system  might  
need   to   support   at   least   a   minimum   
market share to be viable as a platform.
A  quantified  requirement  point,  even  if  
stated  explicitly,  is  usually  arbitrary.  It  is  
often  based  on  what  a  client  feels  justified  
requesting,  given  what  they  are  paying  for  
the  software.  Even  if  the  software  engineers  
cannot construct a system that fully achieves 
the  stated  requirement  point,  the  software  
typically  still  has  value;  it  just  has  less  value  
than the client expected. Further, the ability 
to  exceed  the  requirement  point  can  signifi-
cantly increase value in some cases.
The  cost  to  achieve  a  given  performance  
level  is  usually  a  step  function.  First,  for  a  
given  investment  level,  there  is  some  max-
imum  achievable  performance  level.  Then,  
additional  investment  is  needed,  and  that  
further  investment  enables  performance  up  
to  a  new,  more  favorable  maximum.  Figure  
1.5  illustrates  the  most  cost-effective  perfor-
mance  level  —  the  performance  level  with  
the maximum positive difference between the 
value at that performance level and the cost to 
achieve it.
(See the Software Engineering Economics 
KA  or  [3*]  for  more  information  on  per-
forming economic analyses such as this.)
The software engineer should pay particular 
attention  to  positive  and  negative  relation-
ships  between  quality  of  service  constraints  
(e.g., Figure 14-1 in [1*, c14]). Some quality of 
service  constraints  are  mutually  supporting;  
improving  one’s  performance  level  will  auto-
matically  improve  the  other’s  performance  
level. For example, the more modifiable code 
is,  the  more  reliable  it  tends  to  be,  as  both  
modifiability  and  reliability  are,  to  a  degree,  
a  consequence  of  how  clean  the  code  is.  On  
the  other  hand,  the  higher  the  code’s  speed,  
the less modifiable it might be, because high 
speed is often achieved through optimizations 
that make the code more complex.
3.3.  Formal Analysis  
 [2*, s12.3.2-12.3.3]
Formal  analysis  has  shown  benefits  in  some  
application domains, particularly high-integ-
rity systems (e.g., [5, c6]). The formal expres-
sion of requirements depends on the use of a 
specification  language  with  formally  defined  
semantics.  Formality  has  two  benefits.  First,  
formal  requirements  are  precise  and  concise,  
Value
Level of Performance
Fail
Perfection
Figure 1.4. Value as a Function of Level of 
Performance
$
Value
Cost to
deliver
Most cost-effective
level of performance
Level of performance
Figure 1.5. Most Cost-Effective Level of 
Performance

1-10   SWEBOK
®
 GUIDE V4.0
which (in principle) will reduce the possibility 
for misinterpretation. Second, formal require-
ments   can   be   reasoned   over,   permitting   
desired properties of the specified software to 
be proved. This permits static validation that 
the  software  specified  by  the  requirements  
does  have  the  properties  (e.g.,  absence  of  
deadlock)  that  the  customer,  users  and  soft-
ware engineer expect it to have.
This  topic  is  related  to  Formal  Methods  
in  the  Software  Engineering  Models  and  
Methods KA.
3.4.  Addressing Conflict in Requirements
When a project has more — and more diverse 
— stakeholders, conflicts among the require-
ments   are   more   likely.   One   particularly   
important   aspect   of   requirements   analysis   
is  identifying  and  managing  such  conflicts  
(e.g., [6, c17]). Once conflicting requirements 
have  been  identified,  the  engineer  may  con-
sider  two  different  approaches  to  managing  
that  conflict  (and  possibly  other  approaches  
as  well)  and  determine  the  most  appropriate  
course of action.
One  approach  is  to  negotiate  a  resolution  
among  the  conflicting  stakeholders.  In  most  
cases,  it  is  unwise  for  the  software  engineer  
to  make  a  unilateral  decision,  so  it  becomes  
necessary to consult with the stakeholders to 
reach  a  consensus  resolution.  It  is  often  also  
important,  for  contractual  reasons,  that  such  
decisions be traceable back to the customer. A 
specific example is project scope management — 
namely, balancing what’s desired in the stated 
software product requirements with what can 
be  accomplished  given  the  project  require-
ments  of  cost,  schedule,  staffing  and  other  
project-level   constraints.   There   are   many   
useful sources for information on negotiation 
and conflict resolution [25].
Another approach is to apply product family 
development  (e.g.,  [20]).  This  involves  sepa-
rating  requirements  into  two  categories.  The  
first  category  contains  the  invariant  require-
ments.  These  are  requirements  that  all  stake-
holders agree on. The second category contains 
the variant requirements, where conflict exists. 
The  software  engineer  can  focus  on  under-
standing  the  range  of  variations  needed  to  
satisfy  all  stakeholders.  The  software  can  be  
designed using design to invariants to accom-
modate the invariant requirements and design 
for change to incorporate customization points 
to configure an instance of the system to best 
fit relevant stakeholders. In a simple example, 
some  users  of  a  weather  application  require  
temperatures   displayed   in   degrees   Celsius   
while others require degrees Fahrenheit.
4. Requirements Specification  
 [1*, c10-14, c20-26] [2*, s4.4, c5]
Requirements  specification  concerns  recording  
the requirements so they can be both remem-
bered    and    communicated.    Requirements    
specification  might  be  the  most  contentious  
topic  in  this  KA.  Debate  centers  on  ques-
tions such as:
•    should      requirements      be      written      
down at all?
•    if  requirements  are  written  down,  what  
form should they take?
•    if requirements are written down, should 
they also be maintained over time?
There  are  no  standard  answers  to  these  
questions; the answer to each can depend on 
factors such as the following:
•    the  software  engineer’s  familiarity  with  
the business domain;
•    precedent for this kind of software;
•    degree  of  risk  (e.g.,  probability,  severity)  
of incorrect requirements;
•    staff turnover anticipated during the ser-
vice life of the software;
•    geographic  distribution  of  the  develop-
ment team members;
•    stakeholder  involvement  over  the  course  
of the project;
•    whether the use of a third-party service, 
packaged solution or open source library 
is anticipated;
•    whether  any  design  or  construction  will  
be outsourced;

SOFTWARE REQUIREMENTS   1-11
•    the     degree     of     requirements-based     
testing expected;
•    effort needed to use a candidate specifica-
tion technique;
•    accuracy    needed    from    the    require-
ments-based estimates;
•    extent   of   requirements   tracing   neces-
sary, if any;
•    contractual  impositions  of  requirements  
specification content and format.
As  stated  in  this  KA’s  introduction,  the  
whats  and  hows  of  software  requirements  
work  on  a  project  should  be  determined  by  
the  nature  of  the  software  constructed,  not  
by the life cycle under which it is constructed. 
Downstream maintainers should not be able 
to discern the life cycle used in earlier devel-
opment from the form of those requirements 
alone. The chosen life cycle’s effect should be 
limited  to  the  completeness  of  the  require-
ments  at  any  point  in  the  project.  Under  a  
waterfall   life   cycle,   the   requirements   are   
expected to be completely specified at the end 
of  the  Requirements  phase.  Under  an  Agile  
life  cycle,  the  requirements  are  expected  to  
change, grow, or be eliminated continuously 
and not be complete until the project’s end.
Some organizations have a culture of docu-
menting requirements; some do not. Dynamic 
startup  projects  are  often  driven  by  a  strong  
product  vision  and  limited  resources;  their  
teams  might  view  requirements  documen-
tation  as  unnecessary  overhead.  But  as  these  
products  evolve  and  mature,  software  engi-
neers often recognize that they need to recover 
the requirements that motivated product fea-
tures in order to assess the impact of proposed 
changes. Hence, requirements documentation 
and  change  management  become  important  
to long-term success. A project’s approach to 
requirements in general, and to requirements 
specification  in  particular,  may  evolve  over  
the service life of that software.
The    most    basic    recommendation    for    
requirements  documentation  is  to  base  deci-
sions  on  an  audience analysis.  Who  are  the  
different  consumers  who  will  need  informa-
tion from a requirements specification? What 
information  will  they  need?  How  can  that  
information  be  packaged  and  presented  so  
that  each  consumer  can  get  the  information  
they need with the least effort?
There is a degree of overlap and dependency 
between requirements analysis and specifica-
tion.  Use  of  certain  requirements  specifica-
tion  techniques  —  particularly  model-based  
requirements   specifications   —   permit   and   
encourage  requirements  analysis  that  can  go  
beyond what has already been presented.
Documented software requirements should 
be  subject  to  the  same  configuration  man-
agement  practices  as  the  other  deliverables  
of  the  software  life  cycle  processes.  (See  the  
Configuration Management KA for a detailed 
discussion.)  In  addition,  when  practical,  the  
individual  requirements  are  also  subject  to  
configuration  management  and  traceability,  
which is generally supported by a requirements 
management  tool.  (See  Topic  8,  Software  
Requirements Tools.)
There   are   several   general   categories   of   
requirements  specification  techniques,  each  
of which is discussed below. The requirements 
specification  for  a  given  project  may  also  use  
various  techniques.  ISO/IEC/IEEE  29148  
[26],  as  well  as  [1*,  c10-14],  [5,  c4],  [6,  c16],  
and  many  others  offer  templates  for  require-
ments documentation.
4.1.  Unstructured Natural Language 
Requirements Specification 
  [1*, c11] [2*, s4.4.1]
Natural    language    requirements    specifications    
express requirements in common, ordinary lan-
guage.  Natural  language  requirements  specifi-
cations can be unstructured or structured.
A  typical  unstructured  natural  language  
requirements  specification  is  a  collection  of  
statements in natural language, such as, “The 
system shall . . . .” For example, business rules 
are  statements  that  define  or  constrain  some  
aspect of the structure or the behavior of the 
business  to  be  automated.  “A  student  cannot  
register  in  next  semester’s  courses  if  there  
remain any unpaid tuition fees” is an example 
of a business rule that serves as a requirement 

1-12   SWEBOK
®
 GUIDE V4.0
for a university’s course-registration software. 
Some  projects  can  publish  a  user  manual  as  
a    satisfactory    requirements    specification,    
although there are limits to how effective this 
can be. (See also [5, c4] [26].)
4.2.  Structured Natural Language Requirements 
Specification  [1*, c8] [2*, s4.4.2]
Structured natural language requirements 
specifications impose constraints on how the 
requirements  are  expressed;  the  goal  is  to  
increase precision and conciseness.
The   simplest   example   might   be   the   
actor-action format. The actor is the entity 
responsible for carrying out the action, and 
action  is  what  needs  to  happen.  A  trig-
gering  event  might  precede  the  actor,  and  
the action might be followed by an optional 
condition  or  qualification.  The  statement  
“When an order is shipped, the system shall 
create  an  Invoice  unless  the  Order  Terms  
are   ‘Prepaid’”   uses   actor-action   format.   
The  triggering  event  is  “When  an  order  is  
shipped.”  The  actor  is  “the  system.”  The  
action is “create an Invoice.” The condition/
qualification is “except the Order Terms are 
‘ Prepa id ’.” 
Another  example  is  a  use  case  specifica-
tion  template,  as  shown  in  Figure  1.6.  (See  
[11]  for  guidelines  on  writing  good  use  case  
specifications.)
The user story format, “As a <user> I want 
<capability> so that <benefit>” as well as deci-
sion  tables  are  other  examples.  (See  also  [5,  
c4] [6, c12, c16] [7, c2-5].)
4.3.  Acceptance Criteria-Based Requirements 
Specification
This  general  approach  includes  two  specific  
variants:  acceptance  test  driven    develop-
ment  (ATDD)  and  behavior  driven  develop-
ment (BDD).
ATDD  [2*,  s3.2.3,  s8.2]  is  a  part  of  the  
larger   test      driven   development   (TDD)   
approach.  (See  the  Software  Testing  KA.).  
The main idea of TDD is that test cases pre-
cede construction. Therefore, no new produc-
tion  code  is  written  and  no  existing  code  is  
modified  unless  at  least  one  test  case  fails,  
either at the unit test level or at the acceptance 
test level. The ATDD process has three steps:
1. A unit of functionality (e.g., a user story) 
is selected for implementation.
2. One  or  more  software  engineers,  one  or  
more  business  domain  experts,  and  pos-
sibly  one  or  more  QA/test  professionals  
meet — before any production design or 
Use case #66  Use case name: Reserve flight(s)
Triggering event(s)  Customer requests reservation(s) on flight(s)
Parameters  Passenger, itinerary, fare class, payment method(s)
Requires  Legal itinerary, fare class restrictions met
Guarantees  Seat(s) reserved for passenger on itinerary flight(s)
Normal course  Non-FF passenger, all domestic itinerary, Economy fare class, credit/debit card
Alternative course(s)  Is FF passenger: [None, Silver, Gold, Platinum, Elite]
 Itinerary: [all international, mixed domestic + international] 
 Fare class: [Basic economy, Premium Economy, Business, First] 
 Payment method: [Voucher, FF miles]
Exceptions  C/D card declined, voucher doesn’t exist, voucher expired, FF account doesn’t exist,
 insufficient miles in FF account
Figure 1.6. Example of Structured Natural Language Specification for a Single Use Case

SOFTWARE REQUIREMENTS   1-13
construction work is done — to agree on 
a set of test cases that must pass to show 
that  the  unit  of  functionality  has  been  
correctly implemented.
3. At least one of those acceptance test cases 
must  fail  on  the  existing  software.  The  
existence  of  at  least  one  failing  test  case  
gives  the  software  engineer(s)  permis-
sion to create or modify production code 
to pass all of the agreed-upon test cases. 
This step might require several iterations. 
The  code  may  also  be  refactored  during  
this step.
When all acceptance test cases have passed, 
and  presumably  all  unit  and  integration  test  
cases as well, then the unit of functionality is 
deemed to have been completely and correctly 
implemented.  The  ATDD  process  returns  to  
step  1,  where  a  new  unit  of  functionality  is  
selected, and the cycle repeats.
ATDD  might  seem  to  be  a  testing  tech-
nique  rather  than  a  requirements  specifica-
tion technique. On the other hand, a test case 
has  the  general  form  of  “When  given  input  
that  looks  like  X,  we  expect  the  software  to  
produce  results  that  look  like  Y.”  The  key  is  
the  underlined  phrase,  “we  expect  the  soft-
ware  to  produce.”  If  we  simply  modify  that  
phrase  to  say,  “the  software  shall  produce,”  
as  in  “When  given  input  that  looks  like  X,  
the  software  shall  produce  results  that  look  
like Y,” what first looked like a test case now 
looks  like  a  requirement.  Technically,  one  
acceptance  test  case  can  encompass  more  
than  one  single  requirement,  but  the  gen-
eral idea holds that the ATDD test cases are 
essentially  precise,  unambiguous  statements  
of requirements.
The  BDD  approach  [19]  is  slightly  more  
structured, and business domain experts typ-
ically  prefer  it  over  ATDD  because  it  is  less  
technical  in  appearance.  In  BDD,  the  unit  
of  functionality  is  described  as  a  user  story,  
in  a  form  such  as  this:  “As  a  <user>  I  want  
<capability>  so  that  <benefit>.”  This  leads  to  
the identification and specification of a set of 
“scenarios”  in  this  form:  “Given  <some  con-
text>  [and  <possibly  more  context>],  when  
<stimulus>  then  <outcome>  [and  <possibly  
more outcomes>].”
If the story is “As a bank customer, I want 
to  withdraw  cash  from  the  automated  teller  
machine  (ATM)  so  that  I  can  get  money  
without going to the bank,” one scenario could 
be that “the account has a sufficient balance.” 
This scenario could be detailed as “Given the 
account  balance  is  $500,  and  the  customer’s  
bank  card  is  valid,  and  the  automated  teller  
machine  contains  enough  money  in  its  cash  
box, when the Account Holder requests $100, 
then the ATM should dispense $100 and the 
account balance should be $400, and the cus-
tomer’s bank card should be returned.”
Another   scenario   could   be   that   “the   
account   has   an   insufficient   balance”   and   
could  be  detailed  as  “Given  the  account  bal-
ance  is  $50,  and  the  customer’s  bank  card  is  
valid, and the automated teller machine con-
tains  enough  money  in  its  cash  box,  when  
the  Account  Holder  requests  $100,  then  the  
ATM should not dispense any money, and the 
ATM  should  say  there  is  an  insufficient  bal-
ance,  the  balance  should  remain  at  $50,  and  
the customer’s bank card should be returned.”
The goal of BDD is to have a comprehensive 
set of scenarios for each unit of functionality. 
In the withdrawing cash situation, additional 
scenarios for “The Bank Customer’s bank card 
has  been  disabled”  and  “The  ATM  does  not  
contain enough money in its cash box” would 
be necessary.
The acceptance test cases are obvious from 
the BDD scenarios.
Acceptance    criteria-based    requirements    
specification  directly  addresses  the  require-
ments ambiguity problem. Natural languages 
are  inherently  ambiguous,  but  test  case  lan-
guage  is  not.  In  acceptance-based  criteria  
requirements  specification,  the  requirements  
are written using test case language, which is 
very precise. On the other hand, this does not 
inherently solve the incompleteness problem. 
However,  combining  ATDD  or  BDD  with  
appropriate   functional   test   coverage   cri-
teria,  such  as  Domain  Testing,  Boundary  
Value  Analysis  and  Pairwise  Testing  (see  
the  Software  Testing  KA),  can  reduce  the  

1-14   SWEBOK
®
 GUIDE V4.0
likelihood  of  requirements  incompleteness.  
(See also [9, c1, c12].)
4.4.  Model-Based Requirements Specification  
 [1*, c12] [2*, c5] [4*]
Another  approach  to  avoiding  the  inherent  
ambiguity of natural languages is to use mod-
eling  languages  such  as  selected  elements  of  
the  unified  modeling  language™  (UML)  or  
systems modeling language™ (SysML). Much 
like the blueprints used in building construc-
tion,  these  modeling  languages  can  be  used  
in  a  computing  technology-free  manner  to  
precisely   and   concisely   specify   functional   
requirements  [9,  c1-2].  This  topic  is  closely  
related  to  the  Software  Engineering  Models  
and Methods KA. Requirements models fall 
into two general categories:
1. Structural  models  for  specifying  poli-
cies to be enforced: These are logical class 
models  as  described  in,  for  example,  [9,  
c8]. They are also called conceptual data 
models,  logical  data  models  and  enti-
ty-relationship diagrams.
2. Behavioral  models  for  specifying  pro-
cesses  to  be  carried  out:  These  models  
include use case modeling as described in 
[9, c7], interaction diagrams as described 
in [9, c9] and state modeling as described 
in  [9,  c10].  Other  examples  are  UML  
activity  diagrams  and  data-flow  mod-
eling,  as  described  in  [1*,  c12-13],  [8],  
[10] a nd [18].
Model-based      requirements      specifica-
tions  vary  in  the  degree  of  model  formality.  
Consider the following: 
1. Agile  modeling  (see,  for  example,  [10])  
is  the  least  formal.  Agile  models  can  be  
little  more  than  rough  sketches  whose  
goal  is  to  communicate  important  infor-
mation  rather  than  demonstrate  proper  
use  of  modeling  notations.  In  this  type  
of modeling, the effect of the communi-
cation is considered more important than 
the form of the communication.
2. Semiformal  modeling,  for  example  [9,  
c6-12], provides a definition of the mod-
eling  language  semantics  ([9,  Appendix  
L]),  but  that  definition  has  not  been  
formally   proved   to   be   complete   and   
consistent.
3. Formal  modeling,  for  example,  Z,  the  
Vienna   development   method   (VDM),   
specification  and  description  language  
(SDL)  and  [5,  c7]  have  very  precisely  
defined  semantics  that  allow  specifica-
tions to be mechanically analyzed for the 
presence or absence of specific properties 
to  help  avoid  critical  reasoning  errors.  
The  term  correctness  by  construction  has  
been  used  for  development  in  this  con-
text. (See the Formal Methods section in 
the  Software  Engineering  Models  and  
Methods K A.)
Generally, the more formal a requirements 
model  is,  the  less  ambiguous  it  is,  so  soft-
ware  engineers  are  less  likely  to  misinterpret  
the  requirements.  More  formal  requirements  
models can also be:
•    more concise and compact;
•    easier   to   translate   into   code,   possibly   
mechanically;
•    used  as  a  basis  for  deriving  acceptance  
test cases.
One important message in [4*] is that while 
formal modeling languages are stronger than 
semiformal and Agile modeling, formal nota-
tions can burden both the model creator and 
human readers. Wing’s compromise is to use 
formally  defined  underpinnings  (e.g.,  in  Z)  
for surface syntaxes that are easier to read and 
write (e.g., UML statecharts).
4.5.  Additional Attributes of Requirements  
 [1*, c27pp462-463]
Over  and  above  the  basic  requirements  
statements already described, documenting 
additional attributes for some or all require-
ments  can  be  useful.  This  supplemental  
detail  can  help  software  engineers  better  

SOFTWARE REQUIREMENTS   1-15
interpret and manage the requirements [6, 
c16].  Possible  additional  attributes  include  
the following:
•    tag to support requirements tracing;
•    description  (additional  details  about  the  
requirement);
•    rationale    (why    the    requirement    is    
important);
•    source  (role  or  name  of  the  stakeholder  
who imposed this requirement);
•    use case or relevant triggering event;
•    type  (classification  or  category  of  the  
requirement  —  e.g.,  functional,  quality  
of service);
•    dependencies;
•    conflicts;
•    acceptance criteria;
•    priority (see Requirements Prioritization 
later in this KA);
•    stability (see Requirements Stability and 
Volatility later in this KA);
•    whether the requirement is common or a 
variant  for  product  family  development  
(e.g., [20]);
•    supporting materials;
•    the requirement’s change history.
Gilb’s   Planguage   (short   for   Planning   
Language) [7] recommends attributes such as 
scale,  meter,  minimum,  target,  outstanding,  
past, trend and record.
4.6.  Incremental and Comprehensive 
Requirements Specification
Projects   that   explicitly   document   require-
ments  take  one  of  two  approaches.  One  can  
be   called   incremental   specification.   In   this   
approach, a version of the requirements speci-
fication contains only the differences — addi-
tions,  modifications  and  deletions  —  from  
the  previous  version.  An  advantage  of  this  
approach  is  that  it  can  produce  a  smaller  
volume of written specifications.
The  other  approach  can  be  called  compre-
hensive  specification.  In  this  approach,  each  
version’s    requirements    specification    con-
tains all requirements, not just changes from 
the  previous  version.  An  advantage  of  this  
approach  is  that  a  reader  can  understand  all  
requirements in a single document instead of 
having to keep track of cumulative additions, 
modifications and deletions across a series of 
specifications.
Some   organizations   combine   these   two   
approaches,  producing  intermediate  releases  
(e.g., x.1, x.2 and x.3) that are specified incre-
mentally and major releases (e.g., 1.0, 2.0 and 
3.0)  that  are  specified  comprehensively.  The  
reader  never  needs  to  go  any  further  back  
than  the  requirements  specifications  for  the  
last  major  release  to  obtain  the  complete  set  
of specifications.
5. Requirements Validation  
 [1*, c17] [2*, s4.5]
Requirements    validation    concerns    gaining    
confidence  that  the  requirements  represent  
the  stakeholders’  true  needs  as  they  are  cur-
rently understood (and possibly documented). 
Key questions include the following:
•    do  these  represent  all  requirements  rele-
vant at this time?
•    are any stated requirements not represen-
tative of stakeholder needs?
•    are      these      requirements      appropri-
ately stated?
•    are   the   requirements   understandable,   
consistent and complete?
•    does   the   requirements   documentation   
conform to relevant standards?
Three methods for requirements validation 
tend  to  be  used:  requirements  reviews,  sim-
ulation  and  execution,  and  prototyping.  (See  
also [5, c5] [6, c17] [9, c12].)
5.1.  Requirements Reviews  
 [1*, c17pp332-342] [2*, c4p130]
The  most  common  way  to  validate  is  by  
reviewing or inspecting a requirements docu-
ment. One or more reviewers are asked to look 
for  errors,  omissions,  invalid  assumptions,  
lack  of  clarity  and  deviation  from  accepted  

1-16   SWEBOK
®
 GUIDE V4.0
practice.  Review  from  multiple  perspectives  
is preferred:
•    clients,  customers  and  users  check  that  
their wants and needs are completely and 
accurately represented;
•    other  software  engineers  with  expertise  
in  requirements  specification  check  that  
the  document  is  clear  and  conforms  to  
applicable standards;
•    software engineers who will do architec-
ture,  design  or  construction  of  the  soft-
ware   that   satisfies   these   requirements   
check  that  the  document  is  sufficient  to  
support their work.
Providing   checklists,   quality   criteria   or   
a  “definition  of  done”  to  the  reviewers  can  
guide them to focus on specific aspects of the 
requirements specification. (See Reviews and 
Audits in the Software Quality KA.)
5.2.  Simulation and Execution
Nontechnical stakeholders might not want to 
spend time reviewing a specification in detail. 
Some  specifications  can  be  subjected  to  sim-
ulation  or  actual  execution  in  place  of  or  in  
addition to human review. To the extent that 
the  requirements  are  formally  specified  (e.g.,  
in   a   model-based   specification),   software   
engineers  can  hand  interpret  that  specifica-
tion  and  “execute”  the  specification.  Given  
a  sufficient  set  of  demonstration  scenarios,  
stakeholders can be convinced that the spec-
ification  defines  their  policies  and  processes  
completely and accurately. (See [9, c12].)
5.3.  Prototyping  
 [1*, c17p342] [2*, c4p130]
If  the  requirements  specification  is  not  in  
a  form  that  allows  direct  simulation  or  exe-
cution,  an  alternative  is  to  have  a  software  
engineer  build  a  prototype  that  concretely  
demonstrates  some  important  dimension  of  
an  implementation.  This  demonstrates  the  
software  engineer’s  interpretation  of  those  
requirements.
Prototypes can help expose software engi-
neers’  assumptions  and,  where  needed,  give  
useful  feedback  on  why  they  are  wrong.  For  
example,  a  user  interface’s  dynamic  behavior  
might  be  better  understood  through  an  ani-
mated    prototype    than    through    textual    
description  or  graphical  models.  However,  a  
danger  of  prototyping  is  that  cosmetic  issues  
or  quality  problems  with  the  prototype  can  
distract the reviewers’ attention from the core 
underlying functionality. Prototypes can also 
be costly to develop. However, if a prototype 
helps  engineers  avoid  the  waste  caused  by  
trying  to  satisfy  erroneous  requirements,  its  
cost can be more easily justified.
6. Requirements Management Activities 
 [1*, c27-28] [2*, s4.6]
Requirements development, as a whole, can be 
thought of as “reaching an agreement on what 
software  is  to  be  constructed.”  (See  Figure  
1.3.)  In  contrast,  requirements  management  
can be thought of as “maintaining that agree-
ment over time.” This topic examines require-
ments management. (See also [5, c9].)
6.1.  Requirements Scrubbing
The  goal  of  requirements  scrubbing  [22,  c14,  
c32] is to find the smallest set of simply stated 
requirements that will meet stakeholder needs. 
Doing so will reduce the size and complexity of 
the  solution,  thus  minimizing  the  effort,  cost  
and schedule to deliver it. Requirements scrub-
bing involves eliminating requirements that:
•    are out of scope;
•    would  not  yield  an  adequate  return  on  
investment;
•    are not that important.
Another   important   part   of   the   process   
is   to   simplify   unnecessarily   complicated   
requirements.
In  waterfall  and  other  plan-based  life  cycles,  
requirements    scrubbing    can    be    coordi-
nated  with  requirements  reviews  for  valida-
tion;  scrubbing  should  occur  just  before  the  

SOFTWARE REQUIREMENTS   1-17
validation review. In Agile life cycles, scrub-
bing happens implicitly in iteration planning; 
only  the  highest-priority  requirements  are  
brought into a sprint (iteration).
6.2.  Requirements Change Control  
 [1*, c28] [2*, s4.6]
Change   control   is   central   to   managing   
requirements. This topic is closely linked to the 
Software  Configuration  Management  KA.  
(Refer to that chapter for more information.)
Projects using waterfall or other plan-based 
life  cycles  should  have  an  explicit  require-
ments change control process that includes:
•    a means to request changes to previously 
agreed-upon requirements;
•    an optional impact analysis stage to more 
thoroughly examine benefits and costs of 
a requested change;
•    a   responsible   person   or   group   who   
decides  to  accept,  reject,  or  defer  each  
requested change;
•    a means to notify all affected stakeholders 
of that decision;
•    a   means   to   track   accepted   changes   
to closure.
All stakeholders must understand and agree 
that  accepting  a  change  means  accepting  its  
impact  on  schedule,  resources  and/or  com-
mensurate  change  in  scope  elsewhere  in  the  
project. Ideally the change in scope should be 
objectively quantifiable, i.e., in terms of  func-
tional size  units.
In contrast, requirements change manage-
ment  happens  implicitly  in  Agile  life  cycles.  
In these life cycles, any request to change pre-
viously  agreed-upon  requirements  becomes  
just  another  item  on  the  product  backlog.  A  
request  will  only  become  “accepted”  when  it  
is prioritized highly enough to make it into an 
iteration (a sprint). (See also [5, c9] [22, c17].)
6.3.  Scope Matching
Scope  matching  [22,  c14]  involves  ensuring  
that  the  scope  of  requirements  to  architect,  
design  and  construct  does  not  exceed  any  
cost,  schedule  or  staffing  constraints  on  the  
project.  When  requirements  scope  exceeds  
the   cost,   schedule   or   staffing   constraints,   
then  either  that  scope  must  be  reduced  (pre-
sumably  by  removing  a  sufficient  number  of  
the   lowest-priority   requirements),   capacity   
must be increased (by extending the schedule 
or  increasing  the  budget  and/or  staffing),  or  
some appropriate combination thereof must be 
negotiated.  Where  possible,  scope  matching  
should  be  quantitative  instead  of  qualitative,  
i.e., in terms of functional size units.
In waterfall and other plan-based life cycles, 
scope   matching   can   be   coordinated   with   
requirements  validation;  the  scope  matching  
should occur just before the validation review. 
In Agile life cycles, as long as some variant of 
velocity-based sprint planning is done, then the 
only work allowed into a sprint/iteration will 
be  the  work  that  can  reasonably  be  expected  
to be completed during that sprint/iteration.
7. Practical Considerations
7.1.  Iterative Nature of the Requirements 
Process  [2*, s4.2]
Requirements  for  typical  software  not  only  
have   wide   breadth;   they   must   also   have   
significant   depth.   The   tension   created   by   
simultaneous  breadth-wise  and  depth-wise  
requirements   in   real-world   projects   often   
prompts teams to perform requirements activ-
ities  iteratively.  At  some  points,  elicitation  
and  analysis  favor  expanding  the  breadth  of  
requirements knowledge, while at other points, 
expanding the depth is called for. In practice, 
it is highly unlikely that all requirements work 
can be done in a single pass through the sub-
ject matter. (See also [6, c2, c9].)
7.2.  Requirements Prioritization  [1*, c16]
Prioritizing requirements is useful throughout 
a software project because it helps focus soft-
ware engineers on delivering the most valuable 
functionality  soonest.  It  also  helps  support  
intelligent     trade-off     decisions     involving     

1-18   SWEBOK
®
 GUIDE V4.0
conflict    resolution    and    scope    matching.    
Prioritized requirements also help in mainte-
nance  beyond  the  initial  development  project  
itself.  Defects  raised  against  higher-priority  
requirements   should   probably   be   repaired   
before    defects    raised    against    lower-pri-
ority ones.
A  variety  of  prioritization  schemes  are  
available. Answering a few key questions can 
help engineers choose the best approach. The 
first question is “What factors are relevant in 
determining  the  priority  of  one  requirement  
over another?” The following factors might be 
relevant to a project:
•    value;  desirability;  client,  customer  and  
user satisfaction;
•    undesirability;  client,  customer  and  user  
dissatisfaction (Kano model, below);
•    cost to deliver;
•    cost  to  maintain  over  the  software’s  ser-
vice life; 
•    technical risk of implementation;
•    risk  that  users  will  not  use  it  even  if  
implemented.
The Kano model, which underlies [6, c17], 
shows   that   considering   only   value,   desir-
ability  or  satisfaction  can  lead  to  erroneous  
priorities. A better understanding of priorities 
comes from considering how unhappy stake-
holders  would  be  if  that  requirement  were  
not  satisfied.  For  example,  consider  a  project  
to  develop  an  email  client.  Two  candidate  
requirements might relate to:
1. Having an effective spam filter
2. Handling attachments on emails
Prioritization  must  weigh  both  the  satis-
faction users will experience from having cer-
tain  features  and  the  dissatisfaction  they  will  
experience  if  they  lack  certain  features.  For  
example,  users  are  more  likely  to  be  happy  
with  an  effective  spam  filter  than  with  the  
ability  to  handle  attachments,  so  the  spam  
filter would be given a higher priority based on 
the satisfaction criterion. On the other hand, 
the  inability  to  handle  attachments  would  
make many users extremely unhappy — much 
more  so  than  not  having  an  effective  spam  
filter.  When  considering  happiness,  or  satis-
faction, from implementing features combined 
with unhappiness (or dissatisfaction) from not 
implementing   certain   features,   developers   
would  generally  give  handling  attachments  a  
higher priority than the effective spam filter.
The  second  key  question  is  “How  can  we  
convert  the  set  of  relevant  factors  into  an  
expression of priority?” The formula
Cost
Priority  =
(V alue 
*
 (1-Risk))
is just one example of an objective function  to  
do so. The choice of measurement schemes for 
the  relevant  factors  can  impose  constraints  
on the objective function. (See Measurement 
Theory in Computing Foundations).
Once  the  priority  of  the  requirements  has  
been  determined,  those  priorities  must  be  
specified in a way that can be communicated 
to all stakeholders. Several ways to do this are 
possible, including the following:
•    enumerated scale (e.g., must have, should 
have, nice to have);
•    numerical scale (e.g., 1 . . . 10);
•    Lists   that   sort   the   requirements   in   
decreasing priority order.
Effective requirement prioritization focuses 
on finding groups of requirements with sim-
ilar priorities rather than creating overly rig-
orous  measurement  scales  or  debating  small  
differences.
7.3.  Requirements Tracing  [1*, c29]
Requirements  tracing  can  serve  two  poten-
tially  useful  purposes.  One  is  to  serve  as  an  
accounting  exercise  that  documents  consis-
tency  between  pairs  of  related  project  work  
products.  An  important  question  might  be  
“For  each  identified  software  requirement,  
are there identified design elements intended 
to satisfy it?” If no identified design elements 
can  be  found,  then  either  that  requirement  
is not satisfied in that design or the design is 

SOFTWARE REQUIREMENTS   1-19
correct  and  one  or  more  stated  requirements  
can be deleted. Similarly, “For each identified 
design  element,  are  there  identified  require-
ments that cause it to exist?” If no identified 
requirements  can  be  found,  then  either  that  
design  element  is  unnecessary  or  the  stated  
requirements are incomplete.
The  other  purpose  is  to  assist  in  impact  
analysis  of  a  proposed  requirement  change.  
If  a  particular  system  requirement  were  to  
change, for example, that system requirement 
could be traced to its linked software require-
ments.  Not  all  linked  software  requirements  
would  need  to  change.  But  each  software  
requirement  that  would  be  affected  could  be  
traced  to  its  linked  design  elements.  Again,  
not  all  linked  design  elements  would  need  
to  change.  But  each  design  element  affected  
could   be   traced   to   the   linked   code.   The   
affected  software  requirements,  design  ele-
ments and code units could also be traced to 
their linked test cases for further impact anal-
ysis. This helps establish a “footprint” for the 
volume  of  work  needed  to  incorporate  that  
change to the system requirement.
Software  requirements  can  be  traced  back  
to   source   documentation   such   as   system   
requirements, standards documents and other 
relevant specifications. Software requirements 
can also be traced forward to design elements 
and  requirements-based  test  cases.  Finally,  
software requirements can also be traced for-
ward  to  sections  in  a  user  manual  describing  
the implemented functionality. (See also [23].)
7.4.  Requirements Stability and Volatility  
 [2*, s4.6]
Some  requirements  are  very  stable;  they  will  
probably never change over the software’s ser-
vice  life.  Some  requirements  are  less  stable;  
they  might  change  over  the  service  life  but  
might  not  change  during  the  development  
project.  For  example,  in  a  banking  applica-
tion,  requirements  for  functions  to  calculate  
and  credit  interest  to  customers’  accounts  
are  likely  to  be  more  stable  than  require-
ments  to  support  different  tax-free  accounts.  
The   former   reflects   a   banking   domain’s   
fundamental  feature  (that  accounts  can  earn  
interest).  At  the  same  time,  the  latter  may  
be  rendered  obsolete  by  a  change  in  govern-
ment  legislation.  Finally,  some  requirements  
can be very unstable; they can change during 
the  project  —  possibly  more  than  once.  It  is  
useful to assess the likelihood that a require-
ment will change in a given time. Identifying 
potentially  volatile  requirements  helps  the  
software engineer establish a design more tol-
erant of change, (e.g., [20]). (See also [9, c4].)
7.5.  Measuring Requirements 
  [1*, c19]
As a practical matter, it may be useful to have 
some  concept  of  the  volume  of  the  require-
ments   for   a   particular   software   product.   
This  number  is  useful  in  evaluating  the  size 
of  a  new  development  project  or  the  size  of  
a  change  in  requirements  and  in  estimating  
the cost of development or maintenance tasks 
(e.g., [9, c23]), or simply for use as the denom-
inator in other measurements. Functional size 
measurement (FSM) is a technique for evalu-
ating the size of a body of functional require-
ments.  Story  points  can  also  be  considered  a  
measure of requirements size. 
Additional  information  on  size  measure-
ment  and  standards  can  be  found  in  the  
Software Engineering Process KA. 
Many  quality  indicators  have  been  devel-
oped that can be used to relate the quality of 
software  requirements  specification  to  other  
project  variables  such  as  cost,  acceptance,  
performance,   schedule   and   reproducibility.   
Quality   indicators   for   individual   software   
requirements  and  a  requirements  specifica-
tion document as a whole can be derived from 
the  desirable  properties  discussed  in  Section  
3.1,   Basic   Requirements   Analysis,   earlier   
in this KA.
7.6.  Requirements Process Quality and 
Improvement  [1*, c31]
This topic concerns assessing the quality and 
improvement of the requirements process. Its 
purpose  is  to  emphasize  the  key  role  of  the  

1-20   SWEBOK
®
 GUIDE V4.0
requirements  process  in  a  software  product’s  
cost and timeliness and in customer satisfac-
tion. Furthermore, it helps align the require-
ments  process  with  quality  standards  and  
process improvement models for software and 
systems. Process quality and improvement are 
closely  related  to  both  the  Software  Quality  
KA  and  Software  Engineering  Process  KA,  
comprising the following:
•    requirements process coverage by process 
improvement standards and models;
•    requirements    process    measures    and    
benchmarking;
•    improvement            planning            and            
implementation;
•    security/CIA  (confidentiality,  integrity,  
and  availability)  improvement/planning  
and implementation.
8. Software Requirements Tools [1*, c30]
Tools  that  help  software  engineers  deal  with  
software requirements fall broadly into three 
categories:  requirements  management  tools,  
requirements  modeling  tools  and  functional  
test case generation tools, as discussed below.
8.1.  Requirements Management Tools  
 [1*, c30pp506-510]
Requirements management tools support var-
ious activities, including storing requirements 
attributes,  tracing,  document  generation  and  
change  control.  Indeed,  tracing  and  change  
control  might  only  be  practical  when  sup-
ported by a tool. Because requirements man-
agement is fundamental to good requirements 
practice,  many  organizations  have  invested  
in  tools.  However,  many  more  manage  their  
requirements  in  more  ad  hoc  and  generally  
less satisfactory ways (e.g., spreadsheets). (See 
also [5, c8].)
8.2.  Requirements Modeling Tools  
 [1*, c30p506] [2*, s12.3.3]
At a minimum, a requirements modeling tools 
support   visually   creating,   modifying   and   
publishing  model-based  requirements  speci-
fications. Some tools extend that by also pro-
viding static analysis (e.g., syntax correctness, 
completeness  and  consistency).  Formal  anal-
ysis requires tool support to be practicable for 
anything other than trivial systems, and tools 
generally  fall  into  two  categories:  theorem  
provers  or  model  checkers.  In  neither  case  
can  proof  be  fully  automated,  and  the  com-
petence in formal reasoning needed to use the 
tools restricts the wider formal analysis. Some 
tools also dynamically execute a specification 
(simulation).
8.3.  Functional Test Case Generation Tools
The  more  formally  defined  a  requirements  
specification  language  is,  the  more  likely  it  
is  that  functional  test  cases  can  be  at  least  
partially derived mechanically. For example, 
converting BDD scenarios into test cases is 
not difficult. Another example involves state 
models.  Positive  test  cases  can  be  derived  
for  each  defined  transition  in  that  kind  of  
model.  Negative  test  cases  can  be  derived  
from  the  state  and  event  combinations  that  
do  not  appear.  (See  Section  8.2,  Testing  
Tools in the Testing KA, for more informa-
tion.) A process for deriving test cases from 
UML  requirements  models  can  be  found  
in [9, c12].
In  the  most  general  case,  such  tools  can  
only  generate  test  case  inputs.  Determining  
an  expected  result  is  not  always  possible,  
additional  business  domain  expertise  might  
be necessary.

SOFTWARE REQUIREMENTS   1-21
MATRIX OF TOPICS VS. REFERENCE MATERIAL
Wiegers  
2013
[1*]
Sommerville  
2018  
[2*]
To c k e y    
2005 
[3*
Wing  
1990  
[4*]
1.  Software Requirements Fundamentals
1.1. Definition of a Software Requirementc1pp5-6c4p102
1.2. Categories of Software Requirementsc1pp7-1 2s4.1
1.3. Software Product Requirements and 
Software Project Requirements
c1pp14 -15
1.4. Functional Requirementsc1p9s4.1.1
1.5. Nonfunctional Requirementsc1pp10 -11s4.1.2
1.6. Technology Constraints
1.7. Quality of Service Constraints
1.8. Why Categorize Requirements This Way?
1.9. System Requirements and Software 
Requirements
1.10. Derived Requirements
1.11. Software Requirements Activitiesc1pp15-18s4.2
2. Requirements Elicitation
2.1. Requirements Sourcesc6s4.3
2.2. Common Requirements Elicitation 
Techniques
c7s4.3
3.   Requirements Analysis
3.1. Basic Requirements Analysisc8-9
3.2. Economics of Quality of Service 
Constraints
c1-27
3.3. Formal Analysiss12.3.2-12.3.3
3.4. Addressing Conflict in Requirements
4. Requirements Specification
4.1. Unstructured Natural Language 
Requirements Specification
c11s4.4.1
4.2. Structured Natural Language 
Requirements Specification
c8s4.4.2
4.3. Acceptance Criteria-Based Requirements 
Specification
s3.2.3, s8.2
4.4. Model-Based Requirements Specificationc12c5pp8-11
4.5. Additional Attributes of Requirementsc27pp462-463
4.6. Incremental and Comprehensive 
Requirements Specification
5.  Requirements Validation
5.1. Requirements Reviewsc17pp332-342c4p130
5.2. Simulation and Execution
5.3. Prototypingc17p342c4p130

1-22   SWEBOK
®
 GUIDE V4.0
6.  Requirements Management Activities
6.1. Requirements Scrubbing
6.2. Requirements Change Controlc28s4.6
6.3. Scope Matching
7.     Practical Considerations
7.1. Iterative Nature of the Requirements Processs4.2
7.2. Requirements Prioritizationc16
7.3. Requirements Tracingc29
7.4. Requirements Stability and Volatilitys4.6
7.5. Measuring Requirementsc19
7.6. Requirements Process Quality and 
Improvement
c31
8. Software Requirements Tools
8.1. Requirements Management Toolsc30pp506-510
8.2. Requirements Modeling Toolsc30p506s12.3.3
8.3. Functional Test Case Generation Tools
FURTHER READINGS
IIBA, A Guide to the Business Analysis Body of 
Knowledge® (BABOK® Guide) v3 [30] 
The BABOK Guide is the reference body of 
knowledge for the Business Analysis commu-
nity  and  provides  a  comprehensive  descrip-
tion  of  that  discipline.  While  broader  than  
just requirements and just for software, a very 
large  portion  of  the  BABOK  Guide  content  
is relevant to software requirements.
P.   LaPlante,   Requirements   Engineering   for   
Software and Systems [5].
This book is one potential alternative to [1*], 
offering  a  comprehensive  discussion  of  soft-
ware requirements.
S. Robertson and J. Robertson, Mastering the 
Requirements   Process:   Getting   Requirements   
Right [6].
This  book  is  another  potential  alternative  to  
[1*],  offering  a  comprehensive  discussion  of  
software requirements.
T. Gilb, Competitive Engineering: A Handbook 
for      Systems      Engineering,      Requirements      
Engineering,  and  Software  Engineering  Using  
Planguage [7].
This  book  presents  a  unique  perspective  on  
requirements, emphasizing requirements pre-
cision  and  completeness  along  with  a  strong  
business value-driven motivation.
K. Wiegers, Software Development Pearls: Lessons 
from Fifty Years of Software Experience [21].
This  book  is  a  compendium  of  important  
but  often  unrecognized  key  success  factors  
based  on  Dr.  Wiegers’  extensive  real-world  
experience.  Chapter  2  is  specific  to  software  
requirements.
R. Fisher and W. Ury, Getting to Yes [25].
This  book  is  a  classic  reference  on  principled  
negotiation and conflict resolution that serves 
as  one  good  basis  for  addressing  inevitable  

SOFTWARE REQUIREMENTS   1-23
conflict in software requirements when there 
are multiple stakeholders. 
N. Ahmad, Effects of Electronic Communication 
on   the   Elicitation   of   Tacit   Knowledge   in   
Interview    Techniques    for    Small    Software    
Developments [29].
This  doctoral  thesis  shows  how  using  four  
different  types  of  electronic  communication  
tools to discuss interview agenda details with 
interviewees  before  conducting  semi-struc-
tured   interviews   for   requirements   elicita-
tion  improved  elicitation  of  tacit  (hidden)  
knowledge.
REFERENCES
[1*] K. E. Wiegers and J. Beatty, Software 
Requirements, 3rd ed., Redmond, WA: 
Microsoft Press, 2013.
[2*] I. Sommerville, Software Engineering, 10th 
ed., New York: Addison-Wesley, 2018.
[3*] S. Tockey, Return on Software: 
Maximizing the Return on Your Software 
Investment, Boston, MA: Addison-
Wesley, 2005.
[4*] J. M. Wing, “A Specifier’s Introduction 
to Formal Methods,” Computer, vol. 23, 
no. 9, 1990, pp. 8, 10-23.
[5]  P. Laplante and M. Kassab, Requirements 
Engineering for Software and Systems, 4th 
ed., Boca Raton, FL: CRC Press, 2022.
[6] S. Robertson and J. Robertson, 
Mastering the Requirements Process: 
Getting Requirements Right, Upper 
Saddle River, NJ: Addison-
Wesley, 2013.
[7] T. Gilb, Competitive Engineering: A 
Handbook for Systems Engineering, 
Requirements Engineering, and 
Software Engineering Using Planguage, 
Oxford, UK: Elsevier Butterworth-
Heinemann, 2005.
[8] E. Yourdon, Modern Structured Analysis, 
Englewood Cliffs, NJ: Prentice-
Hall, 1989.
[9] S. Tockey, How to Engineer Software, 
Hoboken, NJ: Wiley, 2019.
[10] S. Ambler, Agile Modeling: Effective 
Practices for eXtreme Programming 
and the Unified Process, Hoboken, NJ: 
Wiley, 2002.
[11] A. Cockburn, Writing Effective 
Use Cases, Upper Saddle River, NJ: 
Addison-Wesley, 2000.
[12] L. Constantine and L. Lockwood, 
Software for Use, Reading, MA: 
Addison-Wesley, 2000.
[13] J. Wood and D. Silver, Joint Application 
Development, New York, NY: 
Wiley, 1995.
[14] E. Gottesdiener, Requirements by 
Collaboration, Boston, MA: Addison-
Wesley, 2002.
[15] J.  Terninko, Step by Step QFD, 2nd ed., 
Boca Raton, FL: CRC Press, 1997.
[16] G. Salvendy, Handbook of Human Factors, 
4th ed., Hoboken, NJ: Wiley, 2012.
[17] T. Brown and B. Katz, Change by 
Design: How Design Thinking Transforms 
Organizations and Inspires Innovation, 
Revised and updated ed., New York, 
NY: Harper Collins, 2019.
[18] S. McMenamin and J. Palmer, Essential 
Systems Analysis, New York, NY: 
Yourdon Press, 1984.
[19] J. Smart, BDD in Action: Behavior-
Driven Development for the Whole 

1-24   SWEBOK
®
 GUIDE V4.0
Software Lifecycle, Shelter Island, NY: 
Manning Publications, 2015.
[20] D. Weiss and C. Lai, Software Product-
Line Engineering: A Family-Based 
Software Development Process, Reading, 
MA: Addison-Wesley, 1999.
[21] K. Wiegers, Software Development 
Pearls: Lessons from Fifty Years of 
Software Experience, Boston, MA: 
Addison-Wesley Professional, 2021.
[22] S.  McConnell, Rapid Development, 
Redmond, WA: Microsoft Press, 1996.
[23] O. Gotel and C. W. Finkelstein, “An 
Analysis of the Requirements Traceability 
Problem,” presented at the Proceedings 
of the 1st International Conference on 
Requirements Engineering, 1994.
[24] INCOSE, Systems Engineering 
Handbook: A Guide for System Life Cycle 
Processes and Activities, 3.2.2 ed., San 
Diego, US: International Council on 
Systems Engineering, 2012.
[25] R. Fisher and W. Ury, Getting to Yes, 3rd 
ed., New York, NY: Penguin, 2011.
[26] ISO/IEC/IEEE 29148 “Systems 
and software engineering – Life 
cycle processes – Requirements engi-
neering,” International Standards 
Organization, 2018.
[27] ISO/IEC 25010: “System and software 
engineering – Systems and software 
Quality Requirements and Evaluation 
(SQuaRE) – System and software 
quality models,” International Standards 
Organization, 2011.
[28] ISO/IEC/IEEE,  “ISO/IEC/IEEE 
24765:2017 Systems and Software 
Engineering — Vocabulary,” 
2nd ed. 2017.
[29] N.  Ahmad, Effects of Electronic 
Communication on the Elicitation 
of Tacit Knowledge in Interview 
Techniques for Small Software 
Developments, doctoral thesis, 
University of Huddersfield, 2021.
[30] I I BA ,  A Guide to the Business Analysis 
Body of Knowledge® (BABOK® 
Guide) v3, International Institute of 
Business Analysis, Toronto, Ontario, 
Canada, 2015.

2-1 
CHAPTER 02
Software Architecture
ACRONYMS
ADArchitecture Description
ADL
Architecture Description Language
API
Application Programming Interface
ASR
Architecturally Significant 
Requirement
ATA MArchitectural Tradeoff Analysis  
Method
IDL
Interface Description Language
MVC
Model View Controller
QAWQuality AttributeWorkshop
RAReference Architecture
RESTRepresentational State Transfer
SAAMSoftware Architecture Analysis 
Method
UMLUnified Modeling Language
INTRODUCTION
This  chapter  considers  software  architecture  
from  several  perspectives:  concepts;  repre-
sentation and work products; context, process 
and methods; and analysis and evaluation.
In contrast to the previous edition, this edi-
tion creates a software architecture knowledge 
area (KA), separate from the Software Design 
KA,  because  of  the  significant  interest  and  
growth of the discipline since the 1990s. 
BREAKDOWN OF TOPICS FOR 
SOF TWARE ARCHITECTURE
The  breakdown  of  topics  for  the  Software  
Architecture KA is shown in Figure 2.1.
1. Software Architecture Fundamentals 
 [2*c1-2, 38*c2, 41*c1-3, 29*, 34]
1.1.  The Senses of “Architecture” [2*c1, 29*]
Software  engineering  and  related  disciplines  
use   many   senses   of   “architecture”.   First,   
“architecture”  often  refers  to  a  discipline:  the  
art  and  science  of  constructing  things  —  in  
this case, software-intensive systems. The dis-
cipline involves concepts, principles, processes 
and  methods  the  community  has  discovered  
and adopted. 
Second, “architecture” refers to the various 
processes  through  which  that  discipline  is  
realized. Software architecture is also consid-
ered part of Software Design; generally con-
sidered a multistage process, divided into the 
following stages: 
•     Architectural design stage 
•     High-level design stage 
•     Detailed design stage
Software design is the focus of Chapter 3. 
This chapter focuses on architecting and archi-
tectural design.
Third,  “architecture”  refers  to  the  out-
come of applying architectural design disci-
pline  and  processes  to  devise  architectures  
for software systems. Architectures as out-
comes  are  expressed  in  architecture  descrip-
tions.  This  is  discussed  in  topic  Software 
Architecture   Description.   The   concept   of   
architecture  has  evolved,  and  many  defi-
nitions  are  in  use  today.  One  early  defini-
tion of architecture, from 1990, emphasized 
software structure:
Architecture.   The   organizational   struc-
ture of a system or component. [from: IEEE 

2-2   SWEBOK
®
 GUIDE V4.0
Std  610.12–1990,  IEEE  Glossary  of  Software  
Engineering Terminology] 
This definition did not do justice to evolving 
thinking about architecture; e.g., this definition 
does  not  allow  us  to  distinguish  the  detailed  
design  of  a  module  from  its  Makefile.  Either  
example  reflects  an  organizational  structure  of  
the  software  system  or  component  but  should  
not   be   considered   architecture.   Moreover,   
emphasis on the structure was often limited to 
the code’s structure and failed to encompass all 
the structures of the software system:
The  software  architecture  of  a  system  is  the  
set  of  structures  needed  to  reason  about  the  
system. These structures comprise software ele-
ments,  relations  among  them,  and  properties  
of both. [2*]
During  the  mid-1990s,  however,  software  
architecture  emerged  as  a  broader  discipline  
involving  a  more  generic  study  of  software  
structures  and  architectures.  Many  software  
system  structures  are  not  directly  reflected  
in  the  code  structure.  Both  types  of  struc-
ture  have  implications  for  the  system  as  a  
whole: What behaviors is the system capable 
of ? What interactions does it have with other 
systems?  How  are  properties  like  safety  and  
security  handled?  The  recognition  that  soft-
ware  contains  many  different  structures  has  
prompted  discussion  of  a  number  of  inter-
esting  concepts  about  software  architecture  
(and software design more generally) leading 
to current definitions such as: 
architecture (of  a  system).  fundamental  con-
cepts  or  properties  of  a  system  in  its  environ-
ment  embodied  in  its  elements,  relationships,  
and  in  the  principles  of  its  design  and  evo-
lution [23]
Key  ideas  in  that  definition  are  the  fol-
lowing:  (1)  Architecture  is  about  what  is  
fundamental  to  a  software  system;  not  every  
element, interconnection, or interface is con-
sidered  fundamental.  (2)  Architecture  con-
siders a system in its environment. Much like 
building    architecture,    software    architec-
ture  is  outward-looking;  it  considers  a  sys-
tem’s context beyond its boundaries including 
the  people,  organizations,  software,  hard-
ware and other devices with which the system 
must interact.
Software
Architecture
e Senses of
“architecture”
Architecture
Views and 
Viewpoints
Architecture
in Context
Goodness in
Architecture
Reasoning 
about
Architectures
Architecture
Reviews
Architecture
Metrics
Architectural
Design
Architecture
Methods and 
Tactics
Architecture
in the Large
Architecture
Styles and 
Patterns
Architecture
Description
Languages and
Architecture
Framework
Architecture 
as Signicant 
Decisions 
Stakeholders 
and Concerns
Uses of 
Architecture
Software
Architecture
Description
Software
Architecture
Fundamentals
Software
Architecture
Process
Software
Architecture
Evaluation
Figure 2.1. Breakdown of Topics for the Software Architecture KA

SOFTWARE ARCHITECTURE   2-3
1.2.  Stakeholders and Concerns 
 [2*c3-14, 38*c8-9, 41*c3, 12, 23, 24]
A  software  system  has  many  stakeholders  with  
varying  roles  and  interests  relative  to  that  
system. These varying interests are termed con-
cerns, following Dijkstra’s separation of concerns: 
Let me try to explain to you, what to my taste 
is  characteristic  for  all  intelligent  thinking.  
It  is,  that  one  is  willing  to  study  in  depth  an  
aspect  of  one’s  subject  matter  in  isolation  for  
the  sake  of  its  own  consistency,  all  the  time  
knowing  that  one  is  occupying  oneself  only  
with  one  of  the  aspects.  We  know  that  a  pro-
gram must be correct and we can study it from 
that  viewpoint  only;  we  also  know  that  it  
should  be  efficient  and  we  can  study  its  effi-
ciency on another day, so to speak. In another 
mood we may ask ourselves whether, and if so: 
why,  the  program  is  desirable.  But  nothing  is  
gained — on the contrary! — by tackling these 
various  aspects  simultaneously.  It  is  what  I  
sometimes  have  called  “the  separation  of  con-
cerns”,  which,  even  if  not  perfectly  possible,  is  
yet  the  only  available  technique  for  effective  
ordering of one’s thoughts, that I know of. This 
is  what  I  mean  by  “[ focusing]  one’s  attention  
upon  some  aspect”:  it  does  not  mean  ignoring  
the  other  aspects,  it  is  just  doing  justice  to  the  
fact  that  from  this  aspect’s  point  of  view,  the  
other is irrelevant. It is being one- and multi-
ple-track-minded simultaneously. [1 2]
What is fundamental about a system varies 
according to stakeholders’ concerns and roles. 
The  software  structures,  therefore,  also  vary  
with stakeholder roles and concerns. (See also 
topic Design Methods in Software Design KA.)
A software system’s customer is most inter-
ested  in  when  the  system  will  be  ready  and  
how  much  it  will  cost  to  build  and  operate.  
Users are most interested in what it does and 
how  to  use  it.  Designers  and  programmers  
building the system have their own concerns, 
such  as  whether  an  algorithm  will  meet  the  
system  requirements.  Those  responsible  for  
ensuring the system is safe to operate have dif-
ferent concerns.
Concerns  encompass  a  broad  range  of  
issues, possibly pertaining to any influence on 
a system in its environment, including devel-
opmental,   technological,   business,   opera-
tional,  organizational,  political,  economic,  
legal, regulatory, ecological and social influ-
ences. Like software requirements, they may 
be  classified  as  functional,  non-functional  
or  constraint.  (See  Software  Requirements  
KA.) Concerns manifest in various familiar 
forms, including requirements, quality attri-
butes or “ilities”, emergent properties (which 
may be either desired or prohibited) and var-
ious  kinds  of  constraints  (as  listed  above).  
See Software Quality KA. Topic 2, Software 
Architecture Description, shows how concerns 
shape  architecture  and  the  work  products  
describing   those   architectures.   Example   
of   concerns   are   depicted   in   Figure   2.2.   
Concerns are not static; concerns evolve over 
the  life  cycle  of  a  system  and  as  technolo-
gies,  policies  and  other  influences  evolve.  
For example, due to increased awareness of 
climate change, there is growing interest in 
concerns such as energy efficiency, and sus-
tainability [24].
Figure 2.2. Examples of Architectural Concerns
affordability,   agility,   assurance,   autonomy,   
availability,   behavior,   business   goals   and   
strategies, complexity, compliance with regu-
lation, concurrency, control, cost, data acces-
sibility,  deployability,  disposability,  energy  
efficiency,   evolvability,   extensibility,   feasi-
bility,  flexibility,  functionality,  information  
assurance,     inter-process     communication,     
interoperability,  known  limitations,  main-
tainability,  modifiability,  modularity,  open-
ness, performance, privacy, quality of service, 
reliability,  resource  utilization,  reusability,  
safety,  scalability,  schedule,  security,  system  
modes,  software  structure,  subsystem  inte-
gration,  sustainability,  system  features,  test-
ability, usability, usage, user experience

2-4   SWEBOK
®
 GUIDE V4.0
1.3.  Uses of Architecture 
 [2*c24, 38*c30, 23, 11, 28]
A  principal  use  of  a  software  system’s  archi-
tecture  is  to  give  those  working  with  it  a  
shared  understanding  of  the  system  to  guide  
its  design  and  construction.  An  architec-
ture  also  serves  as  a  preliminary  conception  
of  the  software  system  that  provides  a  basis  
to  analyze  and  evaluate  alternatives.  A  third  
common  usage  is  to  enable  reverse  engi-
neering  (or  reverse  architecting)  by  helping  
those   working   with   it   to   understand   an   
existing  software  system  before  undertaking  
maintenance,  enhancement  or  modification.  
To support these uses, the architecture should 
be documented (see topic Software Architecture 
Description).
Conway’s  Law  posits  that  “organizations  
which  design  systems  .  .  .  are  constrained  to  
produce designs which are copies of the com-
munication   structures   of   these   organiza-
tions”  [11].  Empirical  studies  have  observed  
that  the  architectures  of  these  systems  often  
mirror   the   communications   structures   of   
those  organizations  [28].  Depending  on  the  
software  system  and  the  organization,  this  
can  be  a  strength  or  a  weakness.  The  archi-
tecture can enhance communication within a 
large team or compromise it. Each part of the 
organization  can  base  its  planning,  costing  
and scheduling activities upon its knowledge 
of  the  architecture.  Creating  a  well-planned  
and documented architecture is one approach 
to increasing the applicability and reusability 
of  software  designs  and  components.  The  
architecture  forms  the  basis  for  design  fam-
ilies  of  programs  or  software  product  lines.  
This  can  be  done  by  identifying  commonali-
ties  among  members  of  such  families  and  by  
designing  reusable  and  customizable  com-
ponents  to  account  for  the  variability  among  
family members. 
2. Software Architecture Description 
 [2*c22, 38*, 40*c6, 41*c6-7, 9,23,25]
In topic 1, Software Architecture Fundamentals, 
a  software  architecture  was  defined  as  the  
fundamental concepts or properties of a soft-
ware  system  in  its  environment.  But  each  
stakeholder  can  have  a  different  notion  of  
what is fundamental to that software system, 
given   their   perspective.   Having   a   mental   
model  of  a  system’s  architecture  is  perhaps  
fine  for  small  systems  and  for  individuals  
working  alone.  However,  for  large,  complex  
systems  developed  and  operated  by  teams,  a  
tangible  representation  is  invaluable,  espe-
cially as the conception of the system evolves, 
and as people join or leave the team. Having a 
concrete representation as a work product can 
also  serve  as  a  basis  to  analyze  the  architec-
ture, organize its design and guide its imple-
mentation.  These  work  products  are  called  
architecture descriptions (A Ds).
ADs  document  an  architecture  for  a  soft-
ware  system.  It  is  targeted  to  those  stake-
holders of the system who have concerns about 
the  software  system  which  are  answered  by  
the architecture. As noted in topic 1, Software 
Architecture   Fundamentals,   a   primary   audi-
ence  comprises  the  designers,  engineers  and  
programmers whose concerns pertain to con-
structing  the  system.  For  these  stakeholders,  
ADs  serve  as  a  blueprint  to  guide  the  con-
struction  of  the  software  system.  For  others,  
the AD is a basis for their work—for example, 
testing  and  quality  assurance,  certification,  
deployment,  operation,  and  maintenance  and  
future evolution. 
Historically,  ADs  used  text  and  informal  
diagrams     to     convey     the     architecture.     
However,  the  diversity  of  stakeholder  audi-
ences and their different concerns have led to 
a diversity of representations of the architec-
ture. Notations should be chosen based on the 
need, purpose and the utility of those choices 
(such  as  understandability,  familiarity)  for  
the  stakeholders  who  need  that  information.    
Often,  these  representations  are  specialized  
based  upon  existing  practices  of  the  com-
munities or disciplines involved to effectively 
address  this  variety  of  stakeholders  and  con-
cerns (see Software Design KA and Software 
Engineering   Models   and   Methods   KA).   
These various representations are called archi-
tecture views. 

SOFTWARE ARCHITECTURE   2-5
2.1. Architecture Views and Viewpoints 
[6*c7, 38*c3,c15-23, 40*c6.2, 23]
An architecture  view  represents  one  or  more  
aspects  of  an  architecture  to  address  one  or  
more  concerns  [38*].  Views  address  distinct  
concerns — for example, a logical view (depicts 
how  the  system  will  satisfy  the  functional  
requirements); a process view (depicts how the 
system  will  use  concurrency);  a  physical  view  
(depicts how the system is to be deployed and 
distributed)  and  a  development  view  (depicts  
how  the  top-level  design  is  broken  down  
into  implementation  units,  the  dependencies  
among  those  units  and  how  the  implementa-
tion is to be constructed). Separating concerns 
by view allows interested stakeholders to focus 
on a few things at a time and offers a means of 
managing the architecture’s understandability 
and overall complexity. 
Architecture practice has evolved from the 
use  of  text  and  informal  diagrams  to  the  use  
of more rigorous representations. Each archi-
tecture view depicts architectural elements of 
the  system  using  well-defined  conventions,  
notations  and  models  [38*].  The  conventions  
for  each  view  are  documented  as  an  architec-
ture viewpoint [23]. Viewpoints guide the cre-
ation,  interpretation  and  uses  of  architecture  
views. Each viewpoint links stakeholder audi-
ence  concerns  with  a  set  of  conventions.  In  
model-based  architecting,  each  view  can  be  
machine-checked against its viewpoint.
Common  viewpoints  include  the  module  
viewpoint, used to express a software system’s 
implementation  in  terms  of  its  modules  and  
their  organization  [2*];  the  component  and  
connector viewpoint, used to express the soft-
ware’s  large-scale  runtime  organization  and  
interactions  [2*];  the  logical  viewpoint,  used  
to  express  fundamental  concepts  of  the  soft-
ware’s  domain  and  capability  [25];  the  sce-
narios/use  cases  viewpoint,  used  to  express  
how  users  interact  with  the  system  [25];  the  
information viewpoint, used to express a sys-
tem’s key information elements and how they 
are accessed and stored [38*]; and the deploy-
ment viewpoint, used to express how a system 
is configured and deployed for operation [38*]. 
Other  documented  viewpoints  include  view-
points  for  availability,  behavior,  communi-
cations,   exception   handling,   performance,   
reliability, safety and security.
Each  viewpoint  provides  a  vocabulary  or  
language  for  talking  about  a  set  of  concerns  
and  the  mechanisms  for  addressing  them.  
The  viewpoint  language  gives  stakeholders  
a  shared  means  of  expression.  Viewpoints  
need  not  be  limited  to  one  software  system  
but  are  reusable  by  an  organization  or  appli-
cation  community  for  many  similar  systems.  
When generic representations such as Unified 
Modeling  Language  (UML)  are  used,  they  
can  be  specialized  to  the  system,  its  domain  
or  the  organizations  involved.  (See  section  
2.3 Architecture   Description   Languages   and   
Architecture Frameworks.)
Beyond specifying forms of representation, 
an  architecture  viewpoint  can  capture  the  
ways  of  working  within  a  discipline  or  com-
munity  of  practice.  For  example,  a  software  
reliability  viewpoint  captures  existing  prac-
tices from the software reliability community 
for identifying and analyzing reliability issues, 
formulating   alternatives   and   synthesizing   
and  representing  solutions.  Like  engineering  
handbooks,    general-purpose    and    special-
ized viewpoints provide a means to document 
repeatable or reusable approaches to recurring 
software  issues.  Clements  et  al.  have  intro-
duced viewtypes which establish a 3-way cat-
egorization of viewpoints. These categories are 
module,  component  and  connector,  and  allo-
cation viewtypes [9].
Architecture   descriptions   frequently   use   
multiple architecture  views  to  represent  the  
diverse structures needed to address different 
stakeholders’  various  concerns.  There  are  two  
common  approaches  to  the  construction  of  
views: the synthetic approach and the projective 
approach. In the synthetic approach, architects 
construct  views  of  the  system-of-interest  and  
integrate  these  views  within  an  architecture  
description   using   correspondence   rules.   In   
the  projective  approach,  an  architect  derives  
each   view   through   some   routine,   possibly   
mechanical,  procedure  of  extraction  from  a  
single  unified  model  (or  “uber  model”)  [23].  

2-6   SWEBOK
®
 GUIDE V4.0
A  consequence  of  introducing  multiple  views  
into  an  AD  is  a  potential  mismatch  between  
the   views.   Are   they   consistent?   Are   they   
describing  the  same  system?  This  has  been  
called  the  multiple  views  problem  [39].  The  
projective  approach  limits  possible  inconsis-
tencies,  since  views  are  derived  from  a  single  
(presumably consistent) model, but at the cost 
of  expressiveness:  the  underlying  model  may  
not be capable of capturing arbitrary concerns. 
Under the synthetic approach, architects inte-
grate  views  into  a  whole,  using  linkages  or  
other   forms   of   traceability   to   cross-refer-
ence  view  elements  to  achieve  consistency  
[23,25].  Viewpoints  often  include  rules  for  
establishing consistency or other relationships 
among views.
2.2.  Architecture Patterns, Styles and Reference 
Architectures [6*c6,38*c11, 40*c6.3,  
 41*c11, 7, 9, 10c2, 13, 17, 18, 19, 37
Inspired  by  its  use  in  the  long  history  of  the  
architecture of buildings, an architectural style 
is a particular manner of construction yielding 
a software system’s characteristic features. An 
architectural  style  often  expresses  a  software  
system’s large-scale organization. In contrast, 
an architectural  pattern  expresses  a  common  
solution  to  a  recurring  problem  within  the  
context  of  a  software  system—it  need  not  
apply  to  the  whole  system.  Design  patterns  
are   discussed   in   section   4.4   of   Software   
Design KA.
Various  architectural  styles  and  patterns  
have been documented [7,39]: 
•    General  structures  (e.g.,  layered,  call-
and-return, pipes and filters, blackboard, 
services and microservices) 
•    Distributed  systems  (e.g.,  client-server,  
n-tier, broker, publish-subscribe, point-to- 
point,    representational    state    transfer     
(R EST)) 
•    Method-driven    (e.g.,    object-oriented,    
event-driven, data flow)
•    User-computer  interaction  (e.g.,  model- 
view-controller, presentation-abstraction- 
control) 
•    Adaptive    systems    (e.g.,    microkernel,    
reflection and meta-level architectures) 
•    Virtual machines (e.g., interpreters, rule-
based, process control) 
Pattern  catalogs  (or  systems  of  patterns)  are  
used  to  express  architectural  styles  and  solu-
tions  through  coordinated  sets  of  patterns.  
Examples  of  pattern  catalogs  are  [7],  [19]  for  
n-tier  architectures,  [13]  for  service-oriented  
architecture and [37] for microservice architec-
tures. Pattern catalogs are not limited to archi-
tecture styles and can be focused on addressing 
specific concerns, such as security [17].
There  is  no  strict  dividing  line  between  
architectural  styles  and  patterns.  Both  pat-
terns  and  styles  provide  solutions  to  specific  
problems  in  given  contexts.  An  architectural  
style  expresses  the  global  aspects  of  a  system  
or  subsystem  by  defining  its    major  parts  of  
that (sub)system and how they interact [7,38*]. 
An  architectural  style  can  be  expressed  as  an  
architectural  pattern  [7].  Architectural  pat-
terns  exist  at  varying  scales  and  could  apply  
once  to  a  single  element  of  a  system  or  be  
applied repeatedly throughout a system.
In   relation   to   architecture   viewpoints,   
which provide the languages for talking about 
various  aspects  of  software  systems,  a  uni-
fying notion is that both patterns and styles are 
idioms in those languages for expressing partic-
ular  aspects  of  architectures  (and  designs,  see  
section 4.4 Design Patterns in Software Design 
KA).  An  architectural  pattern  or  style  uses  a  
vocabulary,  drawn  from  the  viewpoint’s  lan-
guage,  in  a  specified  way,  to  talk  about  view  
elements, including element and relation types 
and  their  instances,  and  constraints  on  com-
bining  them  [23,39].  In  this  way,  viewpoints,  
patterns  and  styles  are  mechanisms  for  codi-
fying recommended practices to facilitate reuse.
A reference architecture (RA) is an architec-
ture  constraining  or  guiding  other  architec-
tures. Documented as a reference architecture 
description, an RA provides a common basis 
for the  development of architectures for indi-
vidual  systems,  product  lines  or  families  of  
systems  and  application  domains.  Reference  
architectures     capture     commonalities     to     

SOFTWARE ARCHITECTURE   2-7
promote   ease   of   development,   integration   
and  interoperability  and  other  kinds  of  stan-
dardization.   Reference   architectures   have   
been  developed  and  used  in  many  domains  
including   automotive   systems,   healthcare,   
Internet of Things, cloud computing, avionics, 
manufacturing and telecommunications.
2.3. Architecture Description Languages and 
Architecture Frameworks [2*c22,  
41*c6-7, 23,30]
An architecture description language (ADL) 
is  a  domain-specific  language  for  expressing  
software   architectures.   ADLs   arose   from   
module  interconnection  languages  [36]  for  
programming in the large. Some ADLs target 
a  single  application  domain  or  architectural  
style  (such  as  MetaH  for  avionics  systems  in  
an  event-driven  style),  others  are  wide  spec-
trum to frame concerns across the enterprise 
(such as ArchiMate™). UML has frequently 
been  used  as  an  ADL  due  to  its  widespread  
use in software design activities [41*]. ADLs 
often   provide   capabilities   beyond   descrip-
tion  to  enable  architecture  analysis  or  code  
generation.
An architecture   framework   captures   the   
“conventions,  principles  and  practices  for  the  
description of architectures established within 
a  specific  domain  of  application  and/or  com-
munity   of   stakeholders”   [23].   Frameworks   
codify  recommended  practices  within  a  spe-
cific domain and are implemented as an inter-
locking set of viewpoints or ADLs. Examples 
are  AUTOSAR  for  the  automotive  industry,  
OMG’s   Unified   Architecture   Framework   
(UAF®) and ISO Reference Model for Open 
Distributed Processing.
2.4.
 A
rchitecture as Significant Decisions 
[38*c8,
 40*c6.1, 1, 23, 26]
Architectural  design  is  a  creative  process.  
During  this  activity,  architects  make  many  
decisions  that  profoundly  affect  the  archi-
tecture,  the  downstream  development  pro-
cess  and  the  software  system.  Many  factors  
affect  decision-making,  including  prominent  
concerns   of   stakeholders   for   the   software   
system,  its  requirements,  and  the  available  
resources during development and throughout 
the life cycle. The impact on quality attributes 
and trade-offs among competing quality attri-
butes are often the basis for design decisions.
The   architectural   design   activity   creates   
a  network  of  decisions  as  its  outcome,  with  
some  decisions  deriving  from  prior  decisions.  
Decision  analysis  provides  one  approach  to  
architecture   evaluation.   Decisions   can   be   
explicitly documented, along with an explana-
tion  of  the  rationale  for  each  nontrivial  deci-
sion. Decision analysis provides one approach 
to   architecture   evaluation.   (See   topic   4,   
Software Architecture Evaluation.)
Architecture rationale captures why an archi-
tectural  decision  was  made.  This  includes  
assumptions  made  before  the  decision,  alter-
natives  considered,  and  trade-offs  or  criteria  
used  to  select  an  approach  and  reject  others.  
Recording  rejected  decisions  and  the  rea-
sons for their rejection can also be useful. In 
the  future,  this  could  either  prevent  a  soft-
ware  project  from  making  a  poor  decision—
one rejected earlier for forgotten reasons—or 
allow  the  development  to  recognize  that  rel-
evant conditions have changed and that they 
can revisit the decision. 
Architectural  technical  debt  has  been  intro-
duced  to  reflect  that  today’s  decisions  for  
an  architecture  may  have  significant  con-
sequences  later  in  the  software  system’s  life  
cycle.   Decisions   deferred   can   compromise   
its  maintainability  or  the  future  evolvability,  
and  that  debt  will  have  to  be  paid—typ-
ically   by   others,   not   necessarily   by   those   
who  caused  the  debt.  Such  debt  has  an  eco-
nomic  impact  on  the  system’s  future  devel-
opment  and  operations.  For  example,  when  
a  software  project  has  limited  time,  it  may  
develop  an  initial  design  with  little  concern  
for  modularity  for  its  first  release.  The  lack  
of  modularity  can  adversely  affect  the  devel-
opment  time  for  subsequent  releases,  impact  
developers,  and  perhaps  compromise  future  
maintainability   of   the   system.   Additional   
functionality can be added later only by doing 
extensive  refactoring  which  impacts  future  

2-8   SWEBOK
®
 GUIDE V4.0
timelines  and  introduces  additional  defects.  
[26]. Architectural technical debt can be ana-
lyzed and managed, like other concerns, using 
models and viewpoints [27]. 
3. Software Architecture Process 
 [38*c7, 41*c4, 14,42]
This  section  outlines  a  general  model  of  an  
architectural  design  process.  It  is  used  to  
demonstrate how architectural design fits into 
the  general  context  of  software  engineering  
processes  (see  Software  Engineering  Process  
KA) and as a framework for understanding the 
many architecture methods currently in use. It 
also  recognizes  that  architectural  design  can  
take place in a variety of contexts.
3.1.  Architecture in Context [41*c2, 29*]
Architecture  occurs  in  several  contexts.  In  
the traditional life cycle, there is an architec-
tural  design  stage  driven  by  software  system  
requirements   (see   Software   Requirements   
KA). Some requirements will be architectural 
drivers, influencing major decisions about the 
architecture,  while  other  requirements  are  
deferred to subsequent stages of the software 
process, such as design or construction.
In  product  line  or  product  family  settings,  
a  product  line/family  architecture  is  devel-
oped against a basic set of needs, requirements 
and other factors. That architecture will be the 
starting point for one or more product instances 
developed  against  specific  product  require-
ments, building upon the product baseline.
In agile approaches, there is not usually an 
architecture  design  stage.  The  only  architec-
ture  description  might  be  the  code  itself.  In  
some agile practices, the software architecture 
is  said  to  “emerge”  from  coding  the  system  
based on user stories through a rapid series of 
development  cycles.  Although  this  approach  
has   had   some   success   with   user-centric   
information  systems,  it  is  difficult  to  ensure  
an  adequate  architecture  emerges  for  other  
classes of applications, such as embedded and 
cyber-physical  systems,  when  critical  archi-
tectural  properties  might  not  be  articulated  
by any user stories.
In  enterprise  and  system-of-systems  con-
texts,  as  in  product  lines  and  families,  the  
Figure 2.3. A general model of architectural design

SOFTWARE ARCHITECTURE   2-9
overarching  architecture  (of  the  enterprise,  
system  or  product  line/family)  provides  pri-
mary requirements and guidance on the form 
and  constraints  upon  the  software  architec-
ture.  This  baseline  can  be  enforced  through  
specifications, additional requirements, appli-
cation programming interfaces (APIs) or con-
formance suites.
3.1.1.  Relation of Architecture to Design
Design and architecture are often blurred. It 
has  been  said  that  architecture  is  the  set  of  
decisions that one cannot trust to  designers. 
In  fact,  architecture  emerged  out  of  software  
design as the discipline matured, largely since 
the 1990s. There are various contrasts: design 
often focuses on an established set of require-
ments, whereas architecture often must shape 
the  requirements  through  negotiation  with  
stakeholders  and  requirements  analysis.  In  
addition,  architecture  often  must  recognize  
and  address  a  wider  range  of  concerns  that  
may or may not end up as requirements on the 
software system of interest.
3.2.  Architectural Design [2*c20, 20]
Architectural  design  is  the  application  of  
design   principles   and   methods   within   a   
process  to  create  and  document  a  software  
architecture.   There   are   many   architecture   
methods  for  carrying  out  this  activity.  This  
section describes a general model of architec-
tural  design  underlying  various  architecture  
methods based upon [20].
Architectural design involves identifying a 
system’s major components; their responsibil-
ities, properties, and interfaces; and the rela-
tionships  and  interactions  among  them  and  
with the environment. In architectural design, 
fundamentals  of  the  system  are  decided,  but  
other  aspects,  such  as  the  internal  details  of  
major components are deferred.
Typical  concerns  in  architectural  design  
include the following:
•    Overall   architecture   styles   and   com-
puting paradigms
•    Large-scale refinement of the system into 
key components
•    Communication  and  interaction  among  
components
•    Allocation    of    concerns    and    design    
responsibilities to components
•    Component interfaces
•    Understanding  and  analysis  of  scaling  
and   performance   properties,   resource   
consumption  properties,  and  reliability  
properties
•    Large-scale/system-wide   approaches   to   
dominating  concerns  (such  as  safety  and  
security, where applicable)
An overview of architectural design is pre-
sented in Figure 2.3.
Architectural   design   is   iterative,   com-
prising  three  major  activities:  analysis,  syn-
thesis  and  evaluation.  Often,  all  three  major  
activities  are  performed  concurrently  at  var-
ious levels of granularity.
3.2.1.  Architecture Analysis
Architecture  analysis  gathers  and  formulates  
architecturally  significant  requirements  (ASRs),  
defined as any ‘‘requirement upon a software 
system which influences its architecture’’ [31]. 
Architecture  analysis  is  based  on  identified  
concerns and on understanding the software’s 
context,    including    known    requirements,    
stakeholder needs and the environment’s con-
straints.  ASRs  reflect  the  design  problems  
the  architecture  must  solve.  Often  the  com-
bination  of  initial  requirements  and  known  
constraints cannot be satisfied without conse-
quences  to  cost,  schedule,  etc.  In  such  cases,  
negotiation is used to modify incoming needs, 
requirements and expectations to make solu-
tions possible. Architecture analysis produces 
ASRs,  initial  system-wide  decisions  and  any  
overarching  system  principles  derived  from  
the context (see Architecture in Context).
3.2.2.  Architecture Synthesis
Architecture   synthesis   develops   candidate   
solutions   in   response   to   the   outcomes   of   

2-10   SWEBOK
®
 GUIDE V4.0
architecture  analysis.  Synthesis  proceeds  by  
working out detailed solutions to design prob-
lems  identified  by  ASRs,  and  makes  trade-
offs  to  accommodate  interactions  between  
those  solutions.  These  outcomes  feedback  to  
architecture  analysis  resulting  in  elaborated  
ASRs,  principles  and  decisions  which  then  
lead to further detailed solution elements.
3.2.3.  Architecture Evaluation
Architecture evaluation validates whether the 
chosen  solutions  satisfy  ASRs  and  when  and  
where rework is needed. Architecture evalua-
tion methods are discussed in topic 4 Software 
Architecture Evaluation.
3.3.  Architecture Practices, Methods, and Tactics 
 [2*c19-23, 38*c9-14, 5, 8, 14, 15,  
 16, 21, 25, 35]
There  are  a  number  of  documented  architec-
ture methods (see Further Readings for a list).
3.4.  Architecting in the Large [29*]
Architectural  design  denotes  a  specific  stage  
of  the  life  cycle,  but  is  only  one  part  of  soft-
ware  architecting.  Software  architecting  does  
not occur in a vacuum, as noted in section 3.1 
Architecture  in  Context,  but  in  an  environment  
that  often  includes  other  architectures.  For  
example,  an  application  architecture  should  
conform to an enterprise architecture; to “play 
well” in a system of systems, the architecture of 
each constituent system should conform to the 
system  of  systems  architecture.  In  such  cases,  
these relations need to be reflected as ASRs on 
the software being architected. Many software 
architecting  activities  and  principles  are  not  
limited to software but equally apply to systems 
and  enterprise  architecting  [29].  Weinreich  
and   Buchgeher   have   extended   Hofmeister   
et  al.’s  model  used  in  section  3.2  Architectural 
Design to include these activities [42]:
• architecture    implementation:    overseeing    
implementation and certifying that imple-
mentations conform to the architecture
• architecture  maintenance:  managing  and  
extending  the  architecture  following  its  
implementation
• architecture   management:   managing   an   
organization’s   portfolio   of   interrelated   
architectures
• architecture       knowledge       management: 
extracting,   maintaining,   sharing   and   
exploiting   reusable   architecture   assets,   
including    decisions,    lessons    learned,    
specifications  and  documentation  across  
the organization
4. Software Architecture Evaluation 
 [2*c21, 38*c14, 41*c8, 10, 31, 33]
4.1.  “Goodness” in Architecture 
 [2*c2, 3, 10, 31]
Architecture  analysis  takes  place  throughout  
the  process  of  creating  and  sustaining  an  
architecture. Architecture  evaluation  is  typ-
ically  undertaken  by  third  parties  at  deter-
mined milestones as a form of assessment.
Given    the    multi-concern,    multi-disci-
plinary  nature  of  software  architecture,  there  
are many aspects to what makes an architecture 
“good.” The Roman architect Vitruvius posited 
that all buildings should have the attributes of 
firmitas, utilitas and venustas (translated  from  
Latin as strength, utility and beauty). 
Of  a  software  system  and  its  architecture,  
one can ask:
•    Is  it  robust  over  its  lifetime  and  possible  
evolution?
•    Is it fit for its intended use? 
•    Is it feasible and cost-effective to construct 
software systems using this architecture? 
•    Is  it,  if  not  beautiful,  then  at  least  clear  
and  understandable  to  those  who  must  
construct, use and maintain the software? 
Each  architecture  concern  may  be  a  basis  
for evaluation. Evaluation is conducted against 
requirements (when available) or against need, 
expectations  and  norms  (in  other  situations).  
A “good” architecture should address not only 
the  distinct  concerns  of  its  stakeholders,  but  

SOFTWARE ARCHITECTURE   2-11
also  the  consequences  of  their  interactions.  
For  example,  a  secure  architecture  may  be  
excessively costly to build and verify; an easy-
to-build architecture may not be maintainable 
over the system’s lifetime if it cannot incorpo-
rate new technologies. 
The Architecture Tradeoff Analysis Method 
(ATAM) [10] provides a methodical approach 
to  evaluating  software  architectures  based  on  
quality attributes in a utility tree (provide illus-
tration)  and  scenarios  illustrating  the  quali-
ties.  Analysis  of  tradeoffs  among  competing  
quality  requirements  and  their  architectural  
approaches  are  the  key  to  the  architecture  
evaluation.  Clements,  et  al.  describe  several  
methods   for   evaluation   including   ATAM,   
Software    Architecture    Analysis    Method    
(SAAM),  and  Quality  Attribute  Workshops  
(QAW)  [10].  The  SARA  Report  defines  a  
general  framework  for  software  architecture  
evaluation [31].
4.2.  Reasoning about Architectures 
 [38*c10, 3, 10, 31]
Each architecture concern has a distinct basis 
for  evaluation.  Evaluation  is  most  effective  
when it is based upon robust, existing archi-
tecture  descriptions.  ADs  can  be  queried,  
examined  and  analyzed.  For  example,  eval-
uation  of  functionality  or  behavior  benefits  
from  having  an  explicit  architecture  view  
or  other  representation  of  that  aspect  of  the  
system to study. Specialized concerns such as 
reliability,  safety  and  security  often  rely  on  
specialized  representations  from  the  respec-
tive discipline.
Often architecture documentation is unfin-
ished, incomplete, out of date or nonexistent. 
In such cases, the evaluation effort must rely 
on the knowledge of participants as a primary 
information source. 
Use  cases  are  frequently  used  to  check  
an  architecture’s  completeness  and  consis-
tency (see Software Engineering Models and 
Methods KA) by comparing the steps in the 
use case to the software architecture elements 
that would be involved in carrying out those 
steps [23].
For   a   general   framework   for   reasoning   
about various concerns, see Bass et al. [3].
4.3.  Architecture Reviews [2*c21, 1, 31]
Architecture reviews are an effective approach 
to  assess  an  architecture’s  status  and  quality  
and  identify  risks  by  assessing  one  or  more  
architecture  concerns  [1].  Many  reviews  are  
informal  or  expertise-based,  and  some  are  
more structured, organized around a checklist 
of topics to cover. Parnas and Weiss proposed 
an  effective  approach  to  conducting  reviews,  
called active  reviews  [33],  where  instead  of  
checklists,   each   evaluation   item   entails   a   
specific  activity  by  a  reviewer  to  obtain  the  
needed information.
Many   organizations   have   institution-
alized   architecture   review   practices.   For   
example,  an  industry  group  developed  a  
framework  for  defining,  conducting  and  
documenting architecture reviews and their 
outcomes [31].
4.4.  Architecture Metrics [2*c23]
An architecture  metric  is  a  quantitative  mea-
sure  of  a  characteristic  of  an  architecture.  
Various    architecture    metrics    have    been    
defined. Many of these originated as design or 
code metrics that have been “lifted” to apply 
to  architecture.  Metrics  include  component  
dependency,  cyclicity  and  cyclomatic  com-
plexity,  internal  module  complexity,  module  
coupling and cohesion, levels of nesting, and 
compliance  with  the  use  of  patterns,  styles  
and (required) APIs.
In   continuous   development   paradigms   
(such as DevOps), other metrics have evolved 
that focus not on the architecture directly but 
on the responsiveness of the process, such as 
metrics for lead time for changes, deployment 
frequency,  mean  time  to  restore  service,  and  
change failure rate—as indicative of the state 
of the architecture.

2-12   SWEBOK
®
 GUIDE V4.0
MATRIX OF TOPICS VS. REFERENCE MATERIAL
cX refers to chapter X
Bass 
et al. [2*]
Budgen  
[6*]
Rozanski  
Woods  
[38 *]
Sommerville  
[40 *]
Ta y l o r    
et al. 
[41*]
See also
Software 
Architecture 
Fundamentals
c1-2c2c1-3[29 *,34]
The senses of 
“architecture”
c1[29 *]
Stakeholders 
and Concerns
c 3-14c8-9c3[12,23,24]
Uses of Architecturec24c30[23,11, 28]
Software 
Architecture 
Description
c22allc6c6-7[9,23,25]
Architecture Views 
and Viewpoints
c7c3,c15-23c6.2[23]
Architectural Styles 
and Patterns
c6c11c6.3c11[7,9,10c2,13, 
17,18,19,37]
Architecture 
Description 
Languages and 
Architecture 
Frameworks
c22c6-7[23,30]
Architecture as 
Significant Decisions
c8c6.1[1,23,26]
Architecture  
Processes
c7c4[14 ,42]
Architecture 
in Context
c2[29 *]
Architectural Designc20[20]
Architecture 
Methods and Tactics
c19-23c9-14[5,8,14,15,16,
21,25,35] 
Architecting 
in the Large
[29 *]
Architecture 
Evaluation
c21c14c8[10,31,33]
“Goodness” in 
Architecture
c2[3 ,10 , 31]
Reasoning about 
Architectures
c10[3 ,10 , 31]
Architecture Reviewsc21[1, 31]
Architecture Metricsc23

SOFTWARE ARCHITECTURE   2-13
FURTHER READINGS
Perry  and  Wolf,  Foundations  for  the  study  of  
software architecture [34]
Perry and Wolf ’s Foundations circulated infor-
mally for several years before its publication in 
1992. It has indeed served as a foundation the 
evolution  of  the  discipline  of  software  archi-
tecture, introducing a number of ideas that are 
fundamental  to  the  field,  including  architec-
ture as a discipline; distinguishing architecture 
and design; elements of software architectures; 
multiple  views;  architecture  styles  and  types;  
and analogies with other fields.
Bass et al., Software Architecture in Practice [2*]
This  book  introduces  concepts  and  recom-
mended  practices  of  software  architecture,  
meaning how software is structured and how 
the software’s components interact. The book 
addresses  several  quality  concerns  in  detail,  
including:  availability,  deployability,  energy  
efficiency,  modifiability,  performance,  test-
ability and usability. The authors offer recom-
mended  practices  focusing  on  architectural  
design,  architecture  description,  architecture  
evaluation  and  managing  architecture  tech-
nical  debt.  They  also  emphasize  the  impor-
tance  of  the  business  context  in  which  large  
software is designed. In doing so, they present 
software  architecture  in  a  real-world  setting,  
reflecting  both  the  opportunities  and  con-
straints that organizations encounter. 
Kruchten, The      4+1      View      Model      of      
Architecture [25]. 
This  seminal  paper  organizes  an  approach  
to  architecture  description  using  five  archi-
tecture viewpoints. The first four are used to 
produce  the  logical  view,  the  development  
view, the process view, and the physical view. 
These  are  integrated  through  selected  use  
cases  or  scenarios  to  illustrate  the  architec-
ture. Hence, the model results in 4+1 views. 
The views are used to describe the software as 
envisioned by different stakeholders—such as 
end-users, developers, and project managers. 
Rozanski    and    Woods,    Software    Systems    
Architecture [38 *]
This  is  a  handbook  for  the  software  sys-
tems  architect.  It  develops  key  concepts  of  
stakeholder,   concern,   architecture   descrip-
tion, architecture viewpoint and architecture 
view,  architecture  patterns  and  styles,  with  
examples.  It  provides  an  end-to-end  archi-
tecting  process.  The  authors  provide  a  cat-
alog of ready-to-use, practical viewpoints for 
the architect to employ that are applicable to 
a  wide  range  of  systems.  The  book  is  filled  
with  guidance  for  applying  these  concepts  
and methods.
R.N.  Taylor,  N.  Medvidović,  E.  Dashofy,  
Software Architecture: Foundations, Theory, and 
Practice [41*]
This  is  a  comprehensive  textbook  on  many  
aspects  of  software  architecture,  including  
key  ideas;  software  architecture  in  the  con-
text of software engineering; the design pro-
cess;   architecture   modeling,   analysis   and   
visualization;  and  chapters  on  several  con-
cerns including implementation, deployment, 
adaptation,  non-functional  properties,  trust  
and security.
P.   Clements   et   al.   Documenting   Software   
Architecture: Views and Beyond, 2nd edition [9].
This book provides detailed guidance on cap-
turing software architectures, using guidance 
and  examples  to  express  an  architecture  so  
that  stakeholders  can  build,  use,  and  main-
tain   that   system.   The   book   introduces   a   
3-way  categorization  of  views  and  therefore  
viewpoints:   into   module,   component   and   
connector  and  allocation  called  viewtypes,  
providing numerous examples of each.
Brown, Software Architecture for Developers [5]
Brown   provides   an   overview   of   software   
architecture  topics  from  the  perspective  of  a  

2-14   SWEBOK
®
 GUIDE V4.0
developer.  He  discusses  common  architec-
ture drivers including architecture principles, 
quality  concerns,  constraints  and  functional  
requirements. He has an in-depth discussion 
of  the  role  of  the  architect  in  a  development  
setting and requisite knowledge and skills for 
architects.  He  focuses  on  the  practical  issues  
of  architecture  in  the  delivery  process  and  
on  managing  risk.  An  appendix  provides  a  
case study.
Fairbanks, Just  Enough  Software  Architecture:  
A risk-driven approach [16]
Fairbanks  offers  a  risk-driven  approach  to  
architecting  within  the  context  of  develop-
ment:  do  just  enough  software  architecture  
to  mitigate  the  identified  risks  where  those  
risks could result from a small solution space, 
from extremely demanding quality require-
ments  or  from  possible  high-risk  failures.  
The  risk-driven  approach  is  harmonious  
with  low-ceremony  and  agile  approaches.  
Architecting,  as  argued  by  Fairbanks,  is  
not just for architects—but is relevant to all 
developers.
Erder,    Pureur    and    Woods,    Continuous 
Architecture in Practice: Software Architecture in 
the Age of Agility and DevOps. [1 5 ]
This  book  shows  how  “classical”  thinking  
about   software   architecture   has   evolved   
in  the  present  day  in  the  contexts  of  agile,  
cloud-based   and   DevOps   approaches   to   
software  development  by  providing  prac-
tical  guidance  on  a  range  of  quality  and  
cross-cutting  concerns  including  security,  
resilience,   scalability   and   integration   of   
emerging technologies. 
REFERENCES
[1]   M. Ali Babar, and I. Gorton, “Software 
Architecture Review: The State of the 
Practice”, IEEE Computer, July 2009.
[2]   * L. Bass, P. Clements, and R. Kazman, 
Software Architecture in Practice, 4th edi-
tion, 2021.
[3]   L. Bass, J. Ivers, M.H. Klein, and 
P. Merson, Reasoning Frameworks, 
CMU/SEI-2005-TR-007, 2005.
[4]   * F. Brooks, The Design of Design, 
Addison-Wesley, 2010.
[5]  S. Brown, Software Architecture for 
Developers, 2018, http://leanpub.com/
software-architecture-for-developers 
[6]   * D. Budgen, Software Design: Creating 
Solutions for Ill-Structured Problems, 
3rd Edition, CRC Press, 2021.
[7]   F. Buschmann, R. Meunier, H. 
Rohnert, P. Sommerlad, and M. Stal, 
Pattern Oriented Software Architecture, 
John Wiley & Sons, 1996.
[8]   H. Cervantes, R Kazman, Designing 
Software Architectures: A Practical 
Approach, 2nd ed., Addison-Wesley, 2024.
[9]   P. Clements et al., Documenting Software 
Architecture: Views and Beyond, 2
nd
 edi-
tion Addison-Wesley, 2011.
[10] P. Clements, R. Kazman, M. Klein, 
Evaluating Software Architectures, 
Addison-Wesley, 2001
[11]  M.E. Conway, “How Do Committees 
Invent?” Datamation, 14(4), 28-31, 1968.
[1 2] E.W. Dijkstra, “On the role of scientific 
thought”, 1974, available at http://www.
cs.utexas.edu/users/EWD/transcrip-
tions/EWD04xx/EWD447.html.
[13] T. Earl, SOA Design Patterns, 
Prentice-Hall, 2009
[14] P. Eeles, and P. Cripps, The Process 
of Software Architecting, Addison 
Wesley, 2010. 

SOFTWARE ARCHITECTURE   2-15
[1 5 ] M. Erder, P. Pureur and E. Woods, 
Continuous Architecture in Practice: 
Software Architecture in the Age of Agility 
and DevOps, Addison-Wesley, 2021.
[16] G. Fairbanks, Just Enough Software 
Architecture: A Risk-Driven Approach, 
Marshall & Brainerd, 2010.
[17] E. Fernandez-Buglioni, Security 
Patterns in Practice: Designing Secure 
Architectures Using Software Patterns, 
Wiley, 2013.
[18] R.T. Fielding and R.N. Taylor, 
Principled design of the modern web 
architecture, ACM Transactions on 
Internet Technology, 2(2), 115–150, 2002.
[19] M. Fowler, D. Rice, M. Foemmel, 
E. Hieatt, R. Mee and R. Stafford, 
Patterns of Enterprise Application 
Architecture, Addison-Wesley, 2003.
[20] C. Hofmeister, P.B. Kruchten, R.L. 
Nord, H. Obbink, A. Ran, and P. 
America, “A general model of soft-
ware architecture design derived 
from five industrial approaches”, The 
Journal of Systems and Software, 80, 
10 6 –1 2 6 , 2 0 0 7.
[21] C. Hofmeister, R.L. Nord, and D. Soni, 
Applied Software Architecture, Addison- 
Wesley, 2000. 
[22] ISO/IEC/IEEE, “ISO/IEC/IEEE 
24765:2017 Systems and Software 
Engineering — Vocabulary,” 2nd ed. 2017.
[23] ISO/IEC/IEEE 42010:2011, 
Systems and software engineering — 
Architecture description.
[24] R. Kazman, S. Haziyev, A. Yakuba, 
and D.A. Tamburri, Managing Energy 
Consumption as an Architectural 
Quality Attribute, IEEE Software, 
35(5), 102–107, 2018
[25] P.B. Kruchten, The “4+1” View Model of 
Architecture, IEEE Software 12(6), 1995. 
[26] P.B. Kruchten, R.L. Nord, and 
I. Ozkaya, Managing Technical 
Debt: Reducing Friction in Software 
Development. Addison-Wesley, 2019.
[27] Z. Li, P. Liang and P. Avgeriou, 
Architecture viewpoints for documenting 
architectural technical debt. Software 
Quality Assurance, Elsevier, 2016.
[28] Alan MacCormack, John Rusnak & 
Carliss Baldwin, Exploring the Duality 
between Product and Organizational 
Architectures: A Test of the 
‘Mirroring’ Hypothesis. Research Policy, 
41:1309–1324, 2012
[29] * M.W. Maier and E. Rechtin, The Art 
of Systems Architecting, 3rd edition, CRC 
Press, 2021.
[30] N. Medvidović, D.S. Rosenblum, D.F. 
Redmiles and J.E. Robbins, Modeling 
software architectures in the Unified 
Modeling Language, ACM Transactions 
on Software Engineering and Methodology, 
11(1), 2–57, 2002
[31]  H. Obbink et al., Report on Software 
Architecture Review and Assessment 
(SARA), version 1.0, available at https://
philippe.kruchten.com/architecture/
SARAv1.pdf, 2002. 
[32] D.L. Parnas, “On the criteria to be used 
in decomposing systems into modules”, 
Communications of the ACM 15(12), 
1053-1058, 1972. 
[33] D.L. Parnas and D.M. Weiss, 
“Active Design Reviews: Principles 
and Practices”, Proceedings of 8th 
International Conference on Software 
Engineering, 215-222, 1985.
[34] D. Perry, A. Wolf, Foundations for the 

2-16   SWEBOK
®
 GUIDE V4.0
study of software architecture, ACM 
SIGSOFT Software Engineering Notes, 
17(4), 40–52, 1992
[35] E. Poort, H. van Vliet, RCDA: 
Architecting as a Risk- and Cost 
Management Discipline, Journal of 
Systems and Software, https://www 
.cs.vu.nl/~hans/publications/y2012 
/JSS-RCDA.pdf, 2012
[36] R. Prieto-Diaz and J.M. Neighbors, 
“Module Interconnection Languages”, 
Journal of Systems and Software, 6(4), 
307–334, 1986.
[37] C. Richardson, Microservices Patterns, 
Manning Publications, 2019
[38] *N. Rozanski and E. Woods, Software 
Systems Architecture: Working with 
Stakeholders Using Viewpoints and 
Perspectives, 2nd edition, Addison-
Wesley, 2011.
[39] M. Shaw and D. Garlan, Software 
Architecture: Perspectives on an Emerging 
Discipline, Prentice Hall, 1996.
[4 0] *I. Sommerville, Software Engineering, 
10th edition, 2016.
[41]  R.N. Taylor, N. Medvidović, E. Dashofy, 
Software Architecture: Foundations, Theory, 
and Practice, Wiley, 2009
[42] R. Weinreich and G. Buchgeher, 
Towards supporting the software archi-
tecture life cycle, The Journal of Systems 
and Software, 85, 546–561, 2012.

3-1 
CHAPTER 03
Software Design
ACRONYMS
APIApplication Programming  
Interface
AODAspect-Oriented Design
CBDComponent-Based Design
CRCClass Responsibility Collaborator 
(Or Collaboration)
DFDData Flow Diagram
DSLDomain-Specific Language
ERDEntity Relationship Diagram
FOSSFree And Open Source Software
IDLInterface Description Language
MBDModel-Based Design
MDDModel-Driven Design
OOObject-Oriented
PDLProgram Design Language
SDDSoftware Design Description
SoCSeparation of Concerns
UMLUnified Modeling Language
INTRODUCTION
This  chapter  considers  software  design  from  
several  perspectives—focusing  on  basic  con-
cepts, context and processes, software design 
qualities  and  strategies,  and  recording  and  
evaluating designs.
Design is used in distinct but closely related 
ways to refer to (1) the discipline (“use of sci-
entific  principles,  technical  information,  and  
imagination  in  the  definition  of  a  software  
system  to  perform  [prespecified]  functions  
with   maximum   economy   and   efficiency”)   
[11];  (2)  the  processes  for  performing  within  
that  discipline;  (3)  the  result  of  applying  that  
discipline;  and  (4)  the  stage  in  the  life  cycle  
of a software system during which those pro-
cesses yield those results. 
A software  design  description  (SDD)  docu-
ments the result of software design. It is a “rep-
resentation  of  software  created  to  facilitate  
analysis,  planning,  implementation,  and  deci-
sion-making.  The  software  design  description  
is  used  as  a  medium  for  communicating  soft-
ware design information and can be thought of 
as a blueprint or model of the system” [11]. 
The  SDD,  which  may  take  many  forms,  
encompasses  the  refinement  of  that  software  
into  components,  the  organization  of  those  
components,  and  the  definition  of  interfaces  
among  them  and  between  the  software  and  
the  outside  world—to  a  level  of  detail  that  
enables their construction. 
Software  design,  viewed  as  a  life  cycle  
activity,  is  the  application  of  software  engi-
neering discipline in which software require-
ments  are  analyzed  to  define  the  software’s  
external characteristics and internal structure 
as the basis for the software’s construction.
Software design takes place in three stages:
•    architectural design of the software system
•    high-level  or  external-facing  design  of  
the system and its components 
•    detailed or internal-facing design
Architectural design is a part of architecting, 
discussed in the Software Architecture KA.
BREAKDOWN OF TOPICS FOR 
SOF TWARE DESIGN
The  breakdown  of  topics  for  the  Software  
Design KA is shown in Fig. 3.1.

3-2   SWEBOK
®
 GUIDE V4.0
1. Software Design Fundamentals [3*][4*]
The concepts, notions and terminology intro-
duced here form a basis for understanding the 
role and scope of software design. 
1.1.  Design Thinking [3* c1, c2, c3]  
 [4* c1, c2] [20]
Design  is  all  around  us,  in  the  things  and  
organizations that have been created to meet 
a need or solve a problem. 
In a general sense, design can be viewed as 
a  form  of  problem-solving.  For  example,  the  
concept of a wicked problem—a problem with 
no definitive solution—is interesting in terms 
of  understanding  the  limits  of  design.  Many  
other notions and concepts help us understand 
design in its general sense: goals, constraints, 
alternatives,   representations   and   solutions.   
(See also Design as a Problem-Solving Activity 
in Engineering Foundations KA.)
Design  thinking  comprises  two  essentials:  
(1)  understanding  the  need  or  problem  and  
(2)  devising  a  solution.  Ross,  Goodenough  
and  Irvine  offer  an  elaboration  of  design  
thinking appropriate to software:
This process consists of five basic steps: (1) crys-
tallize a purpose or objective; (2) formulate a 
concept  for  how  the  purpose  can  be  achieved;  
(3) devise a mechanism that implements the con-
ceptual  structure;  (4)  introduce  a  notation  for  
expressing  the  capabilities  of  the  mechanism  
and invoking its use; (5) describe the usage of the 
notation in a specific problem context to invoke 
the mechanism so the purpose is achieved. [20]
This   is   particularly   appropriate   because   
much  of  software  design  consists  of  cre-
ating  the  necessary  vocabulary  to  express  a  
problem,  express  its  solution  and  implement  
that  solution.  The  steps  emphasize  the  lin-
guistic  nature  of  software  design  problem  
solving.  This  is  a  recurring  pattern  we  see  
throughout high-level design, detailed design 
and architecting (see Architecting in the Large 
in   Software   Architecture   KA).   Therefore,   
Software  Design  is  a  practical  process  of  
transforming a problem statement into a solu-
tion  statement.  Software  design  shares  com-
monalities with other kinds of design. Design 
can be further understood via design theory [8]. 
1.2.  Context of Software Design [4* c13, c14] 
 [21* c19, c20]
Software  design  is  an  important  part  of  the  
software development process. To understand 
the role of software design is to see how it fits 
Software
Design
Software
Design
Fundamentals
Design
inking
Context of
Software
Design
Key Issues 
in Software 
Design
Software
Design
Principles
High-Level
Design
Detailed
Design
Concurrency
Control and Event
Handling
Data Persistence
Distribution of
Components
Errors and Exception
Handling
Integration and
Interoperability
Assurance, Security, 
Safety
Variability
Model-Based
Design
Structural 
Design Description
Behavioral
Design Description
Design Patterns
Specialized
Domain-Specific
Languages
Design
Rationale
General Strategies
Function-Oriented
Data-Centered
Object-Oriented
User-Centered
Component-Based
Event-Driven
Aspect-Oriented
Constraint-Based
Domain-Driven Design
Other Methods
Design Reviews 
and Audits
Quality Attributes
Quality Analysis 
and Evaluation 
Techniques
Measures and 
Metrics
Verification, 
Validation and
Certification
Software
Design
Processes
Software
Design
Qualities
Recording
Software
Design
Software Design
Strategies and 
Methods
Software Design
Analysis and 
Evaluations
Figure 3.1. Breakdown of topics for the Software Design KA

SOFTWARE DESIGN   3-3
into  the  software  development  life  cycle  (see  
Software  Process  KA).  To  understand  that  
context,  it  is  important  to  understand  the  
major  characteristics  and  roles  of  software  
requirements, software construction, software 
testing,  and  software  maintenance.  The  con-
text varies with many factors, including degree 
of formality and stage of the life cycle.
Software  design  is  the  transformation  of  
customer and other requirements, needs, and 
concerns into implementable design specifica-
tions. Its contexts include the following:
•    Software Design’s relationship with soft-
ware   requirements:   The   requirements   
establish  a  set  of  problems  that  the  soft-
ware design must solve.
•    Software Design’s relationship with soft-
ware   architecture:   In   cases   where   an   
architecture  has  been  established,  that  
architecture   constrains   the   design   by   
capturing   fundamental   aspects   of   the   
system: such as its major components and 
their  interconnections,  application  pro-
gramming  interfaces  (APIs),  styles  and  
patterns  to  be  used,  and  architectural  
principles to be observed and enforced.
•    Software Design’s relationship with soft-
ware  construction:  The  software  design  
must provide a guide to implementors on 
building the system.
•    Software Design’s relationship with soft-
ware testing: Software design provides a 
foundation for an overall testing strategy 
and test cases that ensure that the design 
is   properly   implemented   and   operates   
as intended.
1.3.  Key Issues in Software Design [2, 12]
Many  key  issues  must  be  dealt  with  when  
designing  software.  Some  are  quality  con-
cerns  that  all  software  must  address  (per-
formance,    security,    reliability,    usability,    
maintainability,   etc.).   Another   important   
issue  is  how  to  refine,  organize,  intercon-
nect   and   package   software   components.   
These  issues  are  so  fundamental  that  all  
design   approaches   address   them   in   one   
way  or  another.  (See  topic  Stakeholders  and  
Concerns in Software Architecture KA, sec-
tion 1.4 Software Design Principles, and topic 
5 Software Design Strategies and Methods.) 
In  contrast,  other  issues  “deal  with  some  
aspect of software’s behavior that is not in the 
application domain, but which addresses some 
of  the  supporting  domains”  [2].  Such  issues,  
which  often  crosscut  the  system’s  function-
ality, are referred to as aspects, which “tend not 
to be units of software’s functional decompo-
sition,  but  rather  to  be  properties  that  affect  
the  performance  or  semantics  of  the  compo-
nents in systemic ways” [12]. 
1.4.  Software Design Principles [5, 10, 17, 20]
A principle is “a fundamental truth or proposi-
tion that serves as the foundation for a system 
of  belief  or  behavior  or  for  a  chain  of  rea-
soning.” [Oxford English Dictionary] 
Design principles provide direction or guid-
ance   for   making   decisions   during   design.   
Some  principles  originated  during  the  early  
days of software engineering, others even pre-
date  the  discipline,  deriving  from  best  prac-
tices  in  engineering  unrelated  to  software.  
(See  Engineering  Foundations  KA.)  Decision  
making   can   also   be   assisted   by   quantita-
tive  methods,  such  as  discussed  in  Software  
Engineering Economics KA. Software design 
principles are key notions that provide the basis 
for  many  different  software  design  concepts,  
approaches and methods. The principles listed 
below apply to any of the three stages of design. 
Many   of   these   principles   are   interrelated.   
Whether  alone  or  used  in  combination  with  
other  principles,  they  are  reflected  elsewhere  
in  software  design  to  produce  many  concepts  
and  constructs  found  in  design  capture,  strat-
egies and methods. This is itself an application 
of the design thinking process above. Software 
design principles include the following:
• Abstraction  is  “a  view  of  an  object  that  
focuses  on  the  information  relevant  to  
a   particular   purpose   and   ignores   the   
remainder  of  the  information”  [11].“The  
abstraction principle . . . helps 
to 
identify 

3-4   SWEBOK
®
 GUIDE V4.0
essential  properties  common  to  super-
ficially 
different 
entities”  [20].  (See  also  
topic Abstraction    in    the    Computing    
Foundations KA.)
• Separation of concerns (SoC). A design con-
cern is an “area of interest with respect to 
a  software  design”  [11]  that  is  relevant  
to  one  or  more  of  its  stakeholders.  By  
identifying  and  separating  concerns,  the  
designer can focus on each concern for the 
system in isolation about which Dijkstra 
said “even if not perfectly possible, [SoC] 
is  yet  the  only  available  technique  for  
effective  ordering  of  one’s  thoughts  ”  [5]  
(See  also  topic  Stakeholders  and  Concerns 
in Software Architecture KA.)
• Modularization (or refinement or decompo-
sition)  structures  large  software  as  com-
prising smaller components or units. Each 
component  is  named  and  has  well-de-
fined  interfaces  for  its  interactions  with  
other  components.  Smaller  components  
are easier to understand and, therefore, to 
maintain.  There  are  numerous  modular-
ization  strategies.  (See  topic  5  Software  
Design Strategies and Methods.) 
     Traditionally,  the  goal  is  to  place  distinct  
functionalities  and  responsibilities  in  dif-
ferent  components.  David  Parnas  advo-
cated that each module in a system should 
have a single responsibility [17]. One way 
to  think  of  modularization  is  as  a  special  
case of more general strategies, such as sep-
aration of concerns or divide and conquer. 
(see topic Problem-Solving Techniques in 
Computing Foundations).
• Encapsulation    (or    information    hiding) 
builds upon the principles of abstraction 
and  modularization  so  that  nonessential  
information  is  less  accessible,  allowing  
users of the module to focus on the essen-
tial elements at the interface. 
• Separation   of   interface   and   implementa-
tion  is  an  application  of  encapsulation  
that  involves  defining  a  component  by  
specifying  its  public  interfaces,  which  
are  known  to  and  accessible  to  clients;  
isolating  the  use  of  a  component  from  
the  details  of  how  that  component  is  
built.  (See  Encapsulation  (or  information 
hiding) above.)
• Coupling  is  defined  as  “a  measure  of  the  
interdependence   among   modules   in   a   
computer  program”  [11].  Most  design  
methods  advocate  that  modules  should  
be loosely or weakly coupled.
• Cohesion  (or  localization)  is  defined  as  “a  
measure  of  the  strength  of  association  
of  the  elements  within  a  module”  [11].  
Cohesion  highlights  organizing  a  mod-
ule’s  constituents  based  on  their  relat-
edness.  Most  design  methods  advocate  
that   modules   should   maximize   their   
cohesion/locality. 
• Uniformity  is  a  principle  of  consistency  
across   software   components—common   
solutions  should  be  produced  to  address  
common  or  recurring  problems.  These  
include  naming  schemes,  notations  and  
syntax,  interfaces  that  define  access  to  
services  and  mechanisms,  and  ordering  
of  elements  and  parameters.  This  can  be  
achieved  through  conventions  such  as  
rules, formats and styles.
• Completeness (or sufficiency) means ensuring 
that  a  software  component  captures  the  
important  characteristics  of  an  abstrac-
tion and leaves nothing out. Completeness 
takes   various   forms,   perhaps   the   most   
important of which is design completeness 
against  requirements:  a  design  should  be  
sufficient for designers to demonstrate how 
requirements  will  be  met  and  how  subse-
quent work will satisfy those requirements. 
Design should be complete with respect to 
the modes and states of the software. 
• Verifiability    means    that    information    
needed  to  verify  the  design  against  its  
requirements   and   other   constraints   is   
available. This is relevant for any software 
but is of particular importance for high-as-
surance software, such as software where 
security, reliability or safety-critical con-
cerns  are  present.  An  SDD  should  be  
sufficient as a basis for verifying a design. 
(See Software Testing KA and Software 
Qua lit y K A.).)
• Other  design  principles.  Recently,  with  the  

SOFTWARE DESIGN   3-5
increased  appearance  of  autonomous  sys-
tems,  the  use  of  machine  learning  and  
artificial    intelligence,    and,    generally,    
systems   with   widening   social   impacts,   
approaches   to   Ethically   Aligned   Design 
have  been  developed  to  address  concerns  
including  universal  human  values,  polit-
ical  self-determination,  and  data  agency  
and  technical  dependability  [9].  The  gen-
eral principles of Ethically Aligned Design 
are human rights, well-being, data agency, 
effectiveness, transparency, accountability, 
awareness of misuse, and competence.
2. Software Design Processes 
 [4* c3] [21* c2, c7] [10]
Software design is generally considered a mul-
tistage  process  or  activity.  Software  design  
can  be  divided  into  the  following  stages  or  
phases.  When  necessary,  we  distinguish  the  
phase from the general activity:
•    Architectural design stage
•    High-level design stage
•    Detailed design stage
The  architectural  design  stage  addresses  
the fundamentals of the system as a whole and 
in  relation  to  its  environment  (see  Software  
Architecture KA).
The    high-level    design    stage    is    out-
ward-facing—developing  the  top-level  struc-
ture    and    organization    of    the    software,    
identifying  its  various  components  and  how  
that   software   system   and   its   components   
interact with the environment and its elements.
The   detailed   design   stage   is   inward-
facing—specifying  each  component  in  suffi-
cient  detail  to  facilitate  its  construction  and  
to meet its outside obligations, including how 
software components are further refined into 
modules and units.
Each  stage  reflects  the  basic  pattern  out-
lined in section 1.1 Design Thinking. 
Not  all  stages  are  found  in  every  soft-
ware  process.  However,  when  present,  each  
stage  creates  an  obligation  upon  the  next  
stage  regarding  the  software  which  is  under  
development. 
Although   software   developers   generally   
follow  similar  guidelines  for  what  happens  
in  each  stage,  there  are  no  strict  bound-
aries between stages regarding what must be 
done  and  when.  For  example,  for  many  soft-
ware  systems,  the  choice  of  an  algorithm  to  
sort  data  will  be  deferred  to  programmers,  
within the constraints and guidance provided 
by the system’s requirements, its architecture 
description or design specifications. However, 
for another software system, the existence of 
a  suitable  algorithm  could  be  architecturally  
significant  and  must  be  determined  early  in  
the  life  cycle.  Without  that  algorithm,  there  
is no possibility of constructing the software 
to meet its requirements.
Some rules of thumb for each stage include 
the following:
•    The  architectural  design  stage  defines  
a  computational  model,  the  major  com-
putational  elements,  and  the  important  
protocols and relationships among them. 
This  stage  develops  strategies  to  address  
crosscutting  concerns,  such  as  perfor-
mance,  reliability,  security  and  safety,  
and   articulation   of   crosscutting   deci-
sions,  including  system-wide  styles  (e.g.,  
a transactional n-tier style versus a pipes 
and filters style, together with the ratio-
nale for such decisions).
•    The   high-level   design   stage   includes   
identification  of  the  primary  computa-
tional  elements  and  significant  relation-
ships among them, with a focus on each 
major  component’s  existence,  role  and  
interfaces. That definition should be suf-
ficiently  detailed  to  allow  designers  or  
programmers   of   client   components   to   
correctly  and  efficiently  access  each  ser-
vice’s   capabilities—without   having   to   
read its code. 
•    The  detailed  design  stage  defines  each  
module’s  internal  structure,  focusing  on  
detailing  and  justifying  choices  of  algo-
rithms,  data  access  and  data  representa-
tion.  The  detailed  design  specifications  
should be sufficient to allow programmers 

3-6   SWEBOK
®
 GUIDE V4.0
to  code  each  module  during  construction  
(see   Software   Construction   KA).   The   
code is a representation of the solution that 
is sufficiently detailed and complete that a 
compiler (or interpreter) can execute it.
2.1.  High-Level Design [3* c5] [4* c6] [10]
High-level design specifies the interaction of 
a system’s major components with one another 
and  with  the  environment,  including  users,  
devices and other systems. High-level design 
addresses the following:
•    External  events  and  messages  to  which  
the system must respond
•    Events  and  messages  which  the  system  
must produce
•    Specification of the data formats and pro-
tocols for events and messages
•    Specification of the ordering and timing 
relationships  between  input  events  and  
messages, and output events and messages
•    Tracing and analysis of end-to-end trans-
actions and event threads
•    Data   persistence   (how   data   is   stored   
and managed)
High-level  design  is  undertaken  within  
the envelope established by the system’s soft-
ware  architecture  (if  any).  Each  of  the  above  
may be guided or constrained by architecture 
directives.  For  example,  event  signaling  and  
messaging  will  use  the  protocols  and  modes  
of interaction established by the architecture. 
Data formats and protocols will use data and 
communication  standards  specified  by  the  
architecture.  Absent  an  explicit  architecture  
design stage, some of these directives will be 
established  by  the  software  requirements  or  
decided during high-level design.
2.2.  Detailed Design [10]
The detailed design stage proceeds within the 
constraints established by the high-level design. 
It specifies major system components’ internal 
characteristics,   internal   modules   and   their   
interconnections  to  other  modules,  services  
and processes they provide, computing proper-
ties, algorithms, and data access rules and data 
structures. This includes the following:
•    Refinement  of  major  system  components  
into modules or program units, including 
opportunities for using off-the-shelf com-
ponents and application frameworks
•    Allocation  of  design  responsibilities  to  
modules and program units
•    Interactions among modules
•    Scope  and  visibility  among  components,  
modules and program units 
•    Component   modes,   component   states   
and transitions among them
•    Data and control interdependencies
•    Data     organization,     packaging     and     
implementation
•    User interfaces
•    Requisite algorithms and data structures
3. Software Design Qualities [4* c4] [20]
Software requirements and architecture direc-
tives  are  intended  to  guide  software  toward  
certain   characteristics   or   design   qualities. 
Design qualities are an important subclass of 
concerns  (see  topic  Stakeholders  and  Concerns 
in  Software  Architecture  KA).  One  role  of  
design  principles  (see  section  1.4  Software 
Design  Principles)  is  to  help  software  achieve  
these  qualities.  Among  the  characteristics  of  
interest to designers are the following:
3.1.  Concurrency [21* c17]
Design for concurrency concerns how software 
is  refined  into  concurrent  units  such  as  pro-
cesses, tasks, and threads and the consequences 
of  those  decisions  with  respect  to  efficiency,  
atomicity, synchronization and scheduling. 
3.2.  Control and Event Handling [21* c21]
Event  handling  is  concerned  with  how  to  
organize control flow as well as how to handle 
reactive  and  temporal  events  through  var-
ious  mechanisms  including  synchronization,  
implicit invocation and callbacks. 

SOFTWARE DESIGN   3-7
3.3.  Data Persistence [21* c6, c16]
Data  persistence  concerns  the  storage  and  
management of data throughout the system.
3.4.  Distribution of Components [21* c17]
Distribution   concerns   how   software   com-
ponents   are   distributed   across   hardware   
(including  computers,  networks  and  other  
devices) and how those components commu-
nicate while meeting performance, reliability, 
scalability,  availability,  monitorability,  busi-
ness continuity and other expectations. 
3.5.  Errors and Exception Handling, Fault 
Tolerance [21* c11]
This  concern  pertains  to  how  to  prevent,  
avoid,  mitigate,  tolerate  and  process  errors  
and exceptional conditions. 
3.6.  Integration and Interoperability 
 [4* c11, c14, c16]
This  issue  arises  at  the  enterprise  or  sys-
tem-of-systems   level   or   for   any   complex   
software   when   heterogeneous   systems   or   
applications    need    to    interwork    through    
exchanges  of  data  or  accessing  one  another’s  
services. Within a software system, the issue 
arises  when  components  are  designed  using  
different frameworks, libraries or protocols.
3.7.  Assurance, Security, and Safety 
 [21* c10–c14]
High  assurance  spans  a  number  of  software  
qualities,  including  security  and  safety  con-
cerns,  pertaining  to  whether  the  software  
behaves as intended in critical situations, such 
as  in  the  face  of  hazards.  Security  becomes  a  
key concern for distributed applications where 
components communicate using different pro-
tocols  and  media.  Design  for  security  concerns  
how  to  prevent  unauthorized  disclosure,  cre-
ation,  change,  deletion,  or  denial  of  access  to  
information and other resources in the face of 
attacks upon the system or violations of system 
policies to limit damage; provide continuity of 
service; and assist repair and recovery. Design 
for  safety  pertains  to  managing  the  software’s  
behavior in circumstances which might lead to 
harm  to  or  loss  of  human  life  or  damage  to  
property or the environment.
3.8.  Variability [6]
Variability concerns permissible variations in 
a software system. It is a fundamental aspect 
of most software [6]. It is the ability to create 
software system variants for different market 
segments or contexts of use.
Interest in variability first arose in software 
product lines and system families, to accom-
modate  and  manage  deployment  of  multiple  
variants  such  as  for  different  organizations  
or markets. (See appendix B 6, Standards for 
product  line,  methods  and  tools).  It  is  also  
relevant   to   software   ecosystems   and   con-
text-aware  software.  (See  also  3.5  Reuse  in  
Construction, Software Construction KA.)
Feature models are used to gather require-
ments  and  dependencies  into  bundles.  (See  
Feature-Driven   Development,   under   topic   
4.1  Agile  Methods  in  Software  Engineering  
Models and Methods KA)
4. Recording Software Designs 
 [4* c7, c8] [1]
The  outcome  of  design  processes  is  accumu-
lated knowledge and work products recording 
that  knowledge.  Work  products  of  software  
design capture (1) aspects of the problems to 
be solved, using the vocabulary of the domain; 
(2) a solution vocabulary for solving the design 
problems  (see  section  1.1  Design  Thinking); 
(3) the major decisions that have been taken; 
and (4) explanations of the rationale for each 
nontrivial  decision.  Recording  the  rationale  
for important decisions enhances the software 
product’s   long-term   maintainability   when   
modifications  or  enhancements  are  consid-
ered (see section 4.6 Design Rationale). These 
work  products,  often  termed  design  descrip-
tions or design specifications, can take the form 
of  texts,  diagrams,  models  and  prototypes  

3-8   SWEBOK
®
 GUIDE V4.0
that  comprise  the  blueprints  of  the  software  
to be implemented.
A  fundamental  aspect  of  software  design  
is  communication  about  the  design  among  
designers, and to customers, implementers and 
other  stakeholders.  This  is  the  case  whether  
the  software  is  developed  using  agile,  tradi-
tional or formal methods. The communication 
will  vary  depending  upon  the  target  audi-
ence, the level of detail being communicated, 
and  relevance  to  the  concerns  of  the  stake-
holders.  For  example,  when  using  traditional  
or  formal  methods,  the  design  often  evolves  
through  a  progression  of  design  descriptions,  
while in agile approaches the evolving design 
may  be  implicit  in  the  minds  of  developers  
and  only  explicit  as  code.  While  the  latter  
approach  supports  the  agility  of  developers,  
other  stakeholders,  such  as  those  concerned  
with  requirements,  certification,  testing  and  
quality  assurance  may  need  explicit  design  
information   to   do   their   work.   Therefore,   
projects   should   make   conscious   decisions   
about  which  design  specifications  are  needed  
based upon stakeholder audience, subject and 
intended usage.
Designers  can  analyze  and  evaluate  these  
work   products   to   determine   whether   the   
design  can  meet  the  requirements  and  con-
straints on the software. Software design also 
examines  and  evaluates  alternative  solutions  
and  trade-offs.  In  addition  to  using  them  
as  inputs  and  as  the  starting  point  for  con-
struction  and  testing,  stakeholders  can  use  
the design work products to plan subsequent 
activities,  such  as  system  verification  and  
validation.
As design concepts evolve, so do their rep-
resentations (see section 1.1 Design Thinking); 
part  of  the  design  process  involves  creating  
appropriate   vocabularies   for   problems   and   
solutions.  An  informal  sketch  may  be  most  
appropriate  for  the  early  stages.  It  is  useful  
to  distinguish  in-process  (“working”)  spec-
ifications   from   final   design   products.   The   
former are produced by the design team for the 
design  team;  the  latter  may  be  produced  for  
known  stakeholders  or  even  for  an  unknown  
future audience.
Many notations exist to represent software 
design artifacts. Software design is often car-
ried out using multiple types of notation. Two 
broad  areas  of  concern  are  software  struc-
tures  and  software  behaviors.  Some  are  used  
to describe a design’s structural organization, 
others  to  represent  the  software’s  intended  
behavior. Below, they are categorized as nota-
tions  for  structural  and  behavioral  concerns  
(see  section  4.2  Structural  Design  Descriptions 
and section 4.3 Behavioral Design Descriptions, 
respectively).   Certain   notations   are   used   
mostly during architectural design and others 
mainly during detailed design; some are useful 
throughout all stages of software design. Some 
notations are closely tied to the context of spe-
cific  design  methods  (see  Software  Design  
Strategies and Methods KA).
The Unified Modeling Language (UML) is 
a  widely  used  family  of  notations  addressing  
both  structural  and  behavioral  concerns  and  
is used in all design stages, from architectural 
through detailed design [1].
4.1.  Model-Based Design [4* c7.3] [21* c5.5] 
Over  the  history  of  software  engineering,  
including   architecture   and   design,   there   
has been an evolution from document-based 
artifacts  to  model-based  artifacts.  Model-
Based   Design   (MBD)   is   an   approach   to   
recording  designs  where  models  play  an  
important role.
This trend reflects the limitations of docu-
ment-based artifacts and the increased capa-
bilities  of  automated  tools.  Document-based  
artifacts  use  natural  language  and  informal  
diagrams   to   convey   designers’   intentions,   
which    might    introduce    ambiguity    and    
incompleteness.  Even  when  documents  use  
well-defined  formats,  relevant  information  
might  be  spread  across  documents,  making  
understandability    and    analysis    difficult.    
With  MBD,  appropriate  tooling  can  gather  
and organize relevant information for use by 
designers and other stakeholders in an acces-
sible form.
Modern  tools  have  accelerated  the  trend  
from   document   to   model-based   artifacts.   

SOFTWARE DESIGN   3-9
Tooling  enables  animation  or  simulation  of  
various  software  aspects,  analyses  of  what-if  
scenarios  and  trade-offs,  and  rapid  proto-
typing.   Tooling   also   facilitates   continuous   
testing  and  integration  approaches,  enhanced  
and  interactive  traceability,  and  knowledge  
capture  and  management,  which  are  ineffi-
cient  or  even  infeasible  with  document-based  
approaches.
Model-driven   development   (MDD)   is   a   
development  paradigm  that  uses  models  as  
the development process’ primary artifacts (see 
Software Engineering Models and Methods K A). 
4.2.  Structural Design Descriptions 
 [4* c7, c10] [7* c4] [21* c5.3]
The following types of notation, most of which 
are graphical, are used to represent the struc-
tural  aspects  of  a  software  design—that  is,  
they  are  used  to  describe  the  major  compo-
nents and how they are interconnected (static 
view)  and  the  allocation  of  responsibilities  to  
components and modules: 
•    Class and object diagrams are used to rep-
resent a set of classes and objects and their 
interrelationships. 
•    Component  diagrams  are  used  to  rep-
resent  a  set  of  components  (replaceable  
elements  of  a  system  that  conform  to  
and  provide  the  realization  of  a  set  of  
interfaces)   and   their   interconnections.   
Component  models  evolved  from  ear-
lier   module   interconnection   languages   
into  the  package  systems  of  program-
ming  languages  like  Ada  and  Java  and  
the  sophisticated  module  systems  of  cur-
rent  functional  language  systems  such  as  
Haskell and Coq.
•    Class   responsibility   collaborator   cards   
(CRCs)  are  used  to  denote  the  names  of  
components  (classes),  their  responsibil-
ities  and  the  components  they  interact  
with to meet those responsibilities. 
•    Deployment  diagrams  are  used  to  repre-
sent a set of physical nodes and their inter-
connections to model the physical aspects 
of software as deployed on hardware. 
•    Entity relationship diagrams (ERDs) are 
used  to  represent  conceptual,  logical  and  
physical models of data as stored in infor-
mation  repositories  or  as  a  part  of  inter-
face descriptions. 
•    Interface  description  languages  (IDLs)  
are  programming-like  languages  used  to  
define  the  interfaces  (names  and  types  
of    exported    operations)    of    software    
components. 
•    Structure  charts  are  used  to  describe  the  
calling structure of programs (that is, they 
show  which  modules  call,  and  are  called  
by, which other modules). 
4.3.  Behavioral Design Descriptions 
 [4* c9, c10] [7* c5] [21* c5.4]
The  following  notations  and  languages,  some  
graphical and some textual, are used to describe 
the dynamic behavior of software systems and 
their  components.  Many  of  these  notations  
are  useful  mostly,  but  not  exclusively,  during  
detailed design. Moreover, behavioral descrip-
tions can include rationale for design decisions 
(see section 4.6 Design Rationale). 
•    Activity  diagrams  are  used  to  show  flow  
of a computation from activity to activity. 
They also can represent concurrent activ-
ities, their inputs and outputs and oppor-
tunities for concurrency.
•    Interaction   diagrams   characterize   the   
interaction  among  a  group  of  objects.  
There  are  two  major  kinds  of  interaction  
diagrams:  communication  (or  collabora-
tion)  diagrams  and  sequence  diagrams.  
Communication   diagrams   show   inter-
actions  among  objects  with  an  emphasis  
on  their  links  and  the  messages  they  
exchange  on  those  links.  Sequence  dia-
grams  show  interactions  among  objects,  
with an emphasis on the temporal ordering 
of messages passed among those objects.
•    Data  flow  diagrams  (DFDs)  are  used  to  
show  data  flow  among  computing  ele-
ments.  A  DFD  provides  “a  description  
based  on  modeling  the  flow  of  infor-
mation  around  a  network  of  operational  

3-10   SWEBOK
®
 GUIDE V4.0
elements,  with  each  element  making  use  
of  or  modifying  the  information  flowing  
into  that  element”  [4].  DFDs  have  other  
uses,  such  as  security  analysis,  as  they  
identify possible paths for attack and dis-
closure of confidential information. 
•Decision tables and diagrams are used to
represent  complex  combinations  of  con-
ditions and actions.
•Flowcharts are used to represent the flow
of  control  and  the  sequence  of  associ-
ated actions.
•State (transition) diagrams and statecharts 
are used to show transitions from state to
state  and  how  a  component’s  behavior
changes  based  on  its  current  state  and
response to input events.
•Formal specification languages are predomi-
nantly textual languages founded upon basic
notions   from   mathematics   (for   example,
type,  set,  sequence,  logical  proposition)  to
rigorously  and  abstractly  define  software
component interfaces and behavior, often in
terms of pre- and post-conditions, invariants, 
type  checking,  and  computational  models
(see  section  Formal  Methods  in  Software
Engineering Models and Methods KA).
•Pseudocode   and   program   design   lan-
guages  (PDLs)  are  structured,  program-
ming   language-like   notations   used   to
describe a procedure’s processing behavior,
generally at the detailed design stage. The
use  of  these  languages  is  less  common
today but is still found in the documenta-
tion of algorithms.
4.4. Design Patterns and Styles 
[3* c12] [4* c15] [7* c1, c2] [21* 7.2]
Succinctly  described,  a  pattern  is  “a  common  
solution to a common problem in a given context” 
[7]. Design patterns include the following: 
•Creational patterns (e.g., builder, factory,
prototype, singleton)
•Structural patterns (e.g., adapter, bridge,
composite,     decorator,     façade,     fly-
weight, proxy)
•Behavioral    patterns    (e.g.,    command,
interpreter,  iterator,  mediator,  memento,  
observer, peer-to-peer, publish-subscribe, 
state, strategy, template, visitor) 
Design patterns can be used to reflect idioms 
that  have  proven  useful  in  solving  particular  
design problems in the past, establish a solution 
vocabulary,  and  document  and  explain  design  
decisions.  They  arise  at  all  stages  of  design,  
including  architectural  design.  Often  architec-
tural  styles  can  be  viewed  as  patterns  “in  the  
large,”  describing  common  solutions  to  archi-
tecture-level  problems  that  pervade  the  soft-
ware. (See also topic 2.2 Architecture Styles and 
Patterns, Software Architecture KA).
4.5. Specialized and Domain-Specific 
Languages [21* c15]
Not  every  design  representation  falls  easily  
into  the  structure/behavior  dichotomy.  For  
example,   user   interface   design   mixes   the   
structural layout of what a user might see with 
the  behavioral  logic  of  sequencing  screens  
based upon user actions. Specialized concerns 
such as safety and reliability often have their 
own forms of representation that have evolved 
among specialists in those communities [21].
A  recent  trend  has  been  the  maturing  of  
domain-specific  languages  (DSLs)  and  widely  
available   tools   to   develop   them.   In   this   
approach, part of the design process is codifying 
concepts and constructs of a specific application 
domain to create a computer language for that 
domain  so  that  representing  the  design  using  
these  constructs  leads  to  an  animated  or  exe-
cutable  implementation.  DSLs  blur  the  lines  
among  modeling  languages,  design  languages  
and programming languages in this approach. 
There  are  DSLs  and  supporting  tools  for  
domains such as simulation; real-time, reactive 
and  distributed  systems;  game  development;  
user interfaces; test development; and language 
processing tools. The growth of DSLs has been 
facilitated   by   increasingly   powerful   gram-
mar-driven  tools  that,  given  a  language  defi-
nition, can generate a graphical user interface, 
syntax  checkers,  code  generators,  compilers  
and linkers for the specialized language.

SOFTWARE DESIGN   3-11
4.6.  Design Rationale [3* c16] [4* c12] 
 [21* c6.1]
A  useful  design  outcome  is  insight  into  and  
explicit documentation of the major decisions 
taken, along with an explanation of the ratio-
nale  for  each  decision.  Design  rationale  cap-
tures why  a  design  decision  was  made.  This  
includes prior assumptions made, alternatives 
considered,  and  trade-offs  and  criteria  ana-
lyzed to select one approach and reject others. 
Although  the  reasons  for  decisions  are  likely  
to  be  obvious  to  the  current  design  team,  they  
can be less obvious to those who modify or main-
tain the system after deployment. Recording the 
rationale enhances the software product’s long-
term  maintainability.  Continuing  to  capture  
the  rationale  for  changes  during  maintenance  
also contributes to the software’s viability.
It can also be useful to capture rejected deci-
sions and the reasons for rejection. Capturing 
these  rationales  can  enable  a  team  to  revisit  
a  previously  rejected  decision  when  assump-
tions, requirements or constraints change. The 
importance of rationale is visible, for example, 
in   free   and   open-source   software   (FOSS)   
projects, which often involve large, distributed 
teams of developers with frequent turnover.
Design  rationale  may  be  captured  as  part  
of a software design description or as a com-
panion artifact. Often rationale is captured in 
text, but other forms of representation can also 
be used, such as graphs that portray a design 
as an interconnected network of decisions.
5. Software Design Strategies and Methods 
 [21* c3]
Various strategies and methods exist to struc-
ture  and  guide  the  design  process;  many  of  
these  evolved  from  programming  styles  or  
paradigms.  In  addition  to  embodying  one  or  
more general strategies, most design methods 
focus on making one or more design concepts 
(whether  objects,  methods  or  events)  promi-
nent  as  organizing  themes  for  the  software.  
These  themes  then  guide  the  designers  as  to  
what  to  focus  on  first,  how  to  proceed,  and  
how to structure modules. 
5.1.  General Strategies [4* c13]
Some often-cited examples of general strategies 
useful in the design process include divide-and-
conquer and stepwise refinement strategies; top-
down vs. bottom-up strategies; strategies using 
heuristics, patterns and pattern languages; and 
iterative and incremental approaches. 
5.2.  Function-Oriented (or Structured)  
Design [4* c9]
This  is  one  of  the  classical  software  design  
methods.  It  focuses  on  refinement  (or  decom-
position)   to   identify   major   software   func-
tions, elaborating them in a top-down manner. 
Structured design often follows structured anal-
ysis,  producing  DFDs  and  associated  process  
descriptions. Various tools enable the automated 
translation of DFDs into high-level designs.
5.3.  Data-Centered Design [4* c9]
Data-centered   design   starts   from   the   data   
structures  a  program  manipulates  rather  than  
from  the  functions  it  performs.  The  software  
designer  specifies  the  input  and  output  data  
structures  and  then  develops  program  units  
that  transform  inputs  into  outputs.  Various  
heuristics have been proposed to deal with spe-
cial  cases,  such  as  cases  where  there  is  a  mis-
match between the input and output structures. 
5.4.  Object-Oriented Design [4* c10]
Numerous  software  design  methods  based  
on  objects  have  been  proposed.  The  field  
has  evolved  from  the  early  object-oriented  
design of the mid-1980s (where nouns depict 
objects;   verbs   depict   methods;   and   adjec-
tives   depict   attributes),   where   inheritance   
and polymorphism play key roles, to the field 
of  component-based  design  (CBD),  where  
metainformation can be defined and accessed 
(through  reflection,  for  example).  Although  
OOD’s  roots  stem  from  the  concept  of  data  
abstraction,  responsibility-driven  design  has  
been  proposed  as  an  alternative  underlying  
principle  of  OOD.  Often  design  strategies  

3-12   SWEBOK
®
 GUIDE V4.0
are provided with mnemonics such as SOLID 
(Single-responsibility,  Open–closed,  Liskov  
substitution,    Interface    segregation,    and    
Dependency   inversion)   principles   of   class   
design  and  SOFA  (Short,  One  thing,  Few  
arguments and Abstraction level consistency) 
principles for method design.
5.5.  User-Centered Design [3* c9] [16]
User-centered  design  is  more  than  a  design  
method;  it  is  a  multidisciplinary  approach  
emphasizing  a  deep  understanding  of  users  
and their needs as the basis for designing user 
experiences within the context of their orga-
nization and the tasks to be accomplished. It 
involves gathering user requirements, creating 
a  user  flow  of  tasks  and  decisions,  creating  
prototypes or mockups representative of user 
interfaces, and evaluating the design solution 
against original requirements [16].
5.6.  Component-Based Design (CBD) 
 [4* c11, c16] [21* c16]
CBD decomposes a software system into one 
or  more  standalone  components  that  com-
municate only on well-defined interfaces and 
conform  to  a  system-wide  standard  com-
ponent  model.  A  software  component  is  an  
independent  unit,  having  well-defined  inter-
faces and dependencies that can be composed 
and  deployed  independently.  CBD  addresses  
issues  related  to  providing,  developing  and  
integrating   such   components   to   improve   
reuse. CBD often emphasizes common APIs 
for  all  components  and  specialized  APIs  for  
specific services or responsibilities.
5.7.  Event-Driven Design [14, 15]
Event-driven  design  is  an  approach  where  a  
system or component invokes its operations in 
reaction  to  events  (indirect  invocation)  [15].  
Publish/subscribe  messaging  (broadcasting)  
is often used as means of transporting events 
via the network to all interested subscribers. 
Publish/subscribe  keeps  the  producers  and  
consumers decoupled using a message broker 
with channels called topics. This differs from 
Point-to-point messaging where senders and 
receivers need to know each other to deliver 
and  receive  a  message.  Different  types  of  
event processing exist, i.e. simple event pro-
cessing, event stream processing and complex 
event   processing.   Message-based   systems   
frequently   incorporate   identifiable   senders   
and   receivers   within   the   design.   Event-
driven systems may not identify senders and 
receivers   explicitly—instead   each   module   
produces events while listening for any events 
they  care  about  or  need  to  respond  to  [14].  
“Anonymous”   asynchronous   message   and   
event processing are good strategies for scal-
able systems. 
5.8.  Aspect-Oriented Design (AOD) [12]
AOD is a method by which software is con-
structed using aspects to implement the cross-
cutting concerns and extensions identified in 
software  requirements  [12].  AOD  evolved  
from  object-oriented  design  and  program-
ming practices. Although it has yet to become 
a  widespread  design  or  programming  para-
digm,  the  aspect-oriented  perspective  is  fre-
quently  used  in  application  frameworks  and  
software  libraries  where  parameters  of  the  
framework  or  library  can  be  configured  with  
aspect declarations. 
5.9.  Constraint-Based Design [3* c11]
Constraints’  role  in  the  design  process  is  to  
limit the size of a design space to exclude infea-
sible or unacceptable alternatives. Constraints 
accelerate design because they force a few early 
decisions.  The  constraints  can  reflect  limits  
imposed  on  the  hardware,  software,  data,  
operational procedures, interfaces or anything 
that  affects  the  software.  The  constrained  
design space can then be explored with search 
or  backtracking  methods.  Constraint-based  
design  approaches  are  used  in  user  interface  
design,  gaming  and  other  applications.  In  
general,  constraint  satisfaction  problems  can  
be computationally intractable; however, var-
ious  kinds  of  constraint-based  programming  

SOFTWARE DESIGN   3-13
can  be  used  to  approximate  or  solve  con-
straint problems.
5.10.   Domain-Driven Design [14]
Domain-driven  design  is  a  method  in  which  
the  designer  uses  a  domain-specific  language  
shared with analysts and other stakeholders to 
describe  the  target  software  system.  Through  
this  shared  language,  objects,  roles,  events,  
and activities specified in the software require-
ments can be expressed in the software design 
descriptions. (See the Requirements KA).
5.11.  Other Methods [21* c18–c21]
Other approaches to design exist (see Software 
Engineering   Models   and   Methods   KA).   
For  example,  iterative  and  adaptive  methods  
implement  software  increments  and  reduce  
the  emphasis  on  rigorous  software  require-
ments and design. 
Service-oriented  methods  builds  distrib-
uted software using web services executed on 
distributed  computers.  Software  systems  are  
often constructed using services from different 
providers  interconnect  with  standard  proto-
cols  (e.g.,  HTTP,  HTTPS,  SOAP)  designed  
to support service communication and service 
information exchange. 
6. Software Design Quality Analysis and 
Evaluation [4* c7] [21* c24]
6.1.  Design Reviews and Audits [4* c5.3]
Design   reviews   are   intended   as   compre-
hensive  examinations  of  a  design  to  assess  
concerns  such  as  status  or  degree  of  com-
pletion,  coverage  of  requirements,  open  or  
unresolved  issues  and  potential  problems.  A  
design review can be undertaken at any stage 
of  design.  Design  reviews  can  be  conducted  
by the design team, by an independent third 
party or other stakeholder. A design audit is 
more  narrowly  focused  on  a  set  list  of  char-
acteristics (e.g., a functional audit). (See also 
section  2.3  Reviews  and  Audits  in  Software  
Quality K A).
6.2.  Quality Attributes [21* c24]
Various attributes contribute to the quality of 
a  software  design,  including  various  “ilities”  
(modu larit y, maintainabilit y, por tabilit y, test-
ability,  usability)  and  “nesses”  (correctness,  
robustness).  Qualities  are  a  major  subset  of  
concerns  (see  topic  Stakeholders  and  Concerns 
in Software Architecture KA). Some qualities 
can be observed at runtime (e.g., performance, 
security, availability, functionality, usability); 
others  cannot  (e.g.,  modifiability,  portability,  
reusability,  testability);  some  (e.g.,  concep-
tual  integrity,  correctness,  completeness)  are  
observable in the design of the software.
6.3.  Quality Analysis and Evaluation 
Techniques [21* c24]
Various tools and techniques can help in ana-
lyzing and evaluating software design quality. 
(See  also  topic  Software  Quality  Tools  in  
Software Quality KA.)
•    Software design reviews include informal 
and   rigorous   techniques   to   determine   
software  qualities  based  on  SDDs  and  
other design artifacts for example, archi-
tecture    reviews,    design    reviews    and    
inspections;   scenario-based   techniques;   
requirements tracing. 
•    Static analysis: formal or semiformal static 
(nonexecutable)  analysis  that  can  be  used  
to  evaluate  a  design  (for  example,  fault-
tree analysis or automated cross-checking). 
Design vulnerability analysis (for example, 
static   analysis   for   security   weaknesses)   
can  be  performed  if  security  is  a  concern.  
Formal  design  analysis  uses  mathemat-
ical models that allow designers to predict 
the behavior and validate the performance 
of  the  software  instead  of  having  to  rely  
entirely  on  testing.  Formal  design  anal-
ysis  can  be  used  to  detect  residual  speci-
fication and design errors (perhaps caused 
by imprecision, ambiguity, and sometimes 
other kinds of mistakes). (See also Software 
Engineering Models and Methods KA.) 
•    Simulation   and   prototyping:   dynamic   

3-14   SWEBOK
®
 GUIDE V4.0
techniques   to   evaluate   a   design   (for   
example,  performance  simulation  or  fea-
sibility prototypes). 
6.4.  Measures and Metrics 
 [4* c5, c17] [21* c24.5]
Measures can be used to assess or to quanti-
tatively estimate various aspects of a software 
design; for example, size, structure, or quality. 
Most  measures  that  have  been  proposed  are  
based  upon  the  approach  used  for  producing  
the   design   (see   topic   5   Software   Design   
Strategies and Methods). These measures are 
classified in two broad categories: 
•    Function-based  (structured)  design  mea-
sures:   measures   obtained   by   analyzing   
functional  decomposition;  generally  rep-
resented using a structure chart (or hierar-
chical diagram) on which various measures 
can be calculated. 
•    Object-oriented    design    measures:    the    
design  structure  is  typically  represented  
as a class diagram, on which various mea-
sures   can   be   computed.   Measures   on   
the  properties  of  the  internal  content  of  
each  class  can  also  be  calculated.  Object-
oriented  measures  also  consider  the  com-
plexity  of  the  code  based  on  the  lines  of  
code  per  method  or  the  number  of  mes-
sages sent.
6.5.  Verification, Validation, and Certification 
 [21* c7, c8]
Systematic analysis or evaluation of the design 
plays  an  important  role  in  each  of  these  
three areas:
•    verification:  to  confirm  that  the  design  
satisfies stated requirements;
•    validation: to establish that the design will 
allow the system to meet the expectations 
of  its  stakeholders,  including  customers,  
users, operators and maintainers;
•    certification:   third-party   attestation   of   
conformity  of  design  to  its  overall  spec-
ification and intended usage.
(See   also   section   2.2   Verification   and   
Validation in Software Quality KA.)
MATRIX OF TOPICS VS. REFERENCE MATERIAL
In table below, cX means chapter X
1. Software Design 
Fundamentals
Brooks  
[3*]
Budgen  
[4*]
Gamma et al.  
[7 *]
Sommerville  
[21*]See also
1.1 Design Thinkingc1, c2, c3c1, c2[20]
1.2  Context of Software Designc13, c14c19, c20
1.3 Key Issues in Software Design[2, 12]
1.4 Software Design Principles[5, 10,  
17, 2 0]
2. Software Design Processesc3c2, c7[10]
2.1 High-level Designc5c6[10]
2.2 Detailed Design[10]
3. Software Design Qualitiesc4[20]
3.1 Concurrencyc17
3.2 Control and 
Handling of Events
c21
3.3 Data Persistencec6, c16

SOFTWARE DESIGN   3-15
3.4 Distribution of Componentsc17
3.5 Errors and Exception 
Handling, Fault Tolerance
c11
3.6 Integration and 
Interoperability
c11, c14,  
c16
3.7 Assurance, Security and Safetyc10–c14
3.8 Variability[6]
4. Recording 
Software Designs
c7, c 8[1]
4.1 Model-based Designc7. 3c5.5
4.2 Structural Design 
Descriptions
c7, c10c4c5.3
4.3 Behavioral Design 
Descriptions
c9, c10c5c5.4
4.4 Design Patterns and Stylesc12c15c1, c2c7. 2[7]
4.5 Specialized and Domain-
Specific Languages
c15
4.6 Design Rationalec16c12c6.1
5. Software Design Strategies 
and Methods
c3
5.1 General Strategiesc13
5.2 Function-Oriented (or 
Structured) Design
c9
5.3 Data-Centered Designc9
5.4 Object-Oriented Designc10
5.5 User-Centered Designc9[16]
5.6 Component-Based 
Design (CBD)
c11, c16c16
5.7 Event-Driven Design[14 , 1 5 ]
5.8 Aspect-Oriented Design (AOD)[1 2]
5.9 Constraint-Based Designc11
5.10 Domain-Driven Design[13]
5.11 Other Methodsc18–c21
6. Software Design Quality 
Analysis and Evaluation
c17c24
6.1 Design Reviews and Auditsc5.3
6.2 Quality Attributesc24
6.3 Quality Analysis and 
Evaluation Techniques
c24
6.4 Measures and Metricsc5, c17c24.5
6.5 Verification, Validation and 
Certification
c7,c 8

3-16   SWEBOK
®
 GUIDE V4.0
FURTHER READINGS
Brooks, The Design of Design [3*]
Brooks, one of the pioneers of software engi-
neering,  provides  a  collection  of  essays  and  
case studies on all aspects of software design.
REFERENCES
[1]    *G. Booch, J. Rumbaugh, and I. 
Jacobson, The Unified Modeling Language 
User Guide, 2
nd
 edition, Addison-
Wesley, 2005. 
[2]   J. Bosch, Design and Use of Software 
Architectures: Adopting and Evolving 
a Product-Line Approach, ACM 
Press, 2000.
[3]   *F. Brooks, The Design of Design, 
Addison-Wesley, 2010.
[4]   *D. Budgen, Software Design: Creating 
Solutions for Ill-Structured Problems, 3
rd
 
Edition CRC Press, 2021.
[5]  E.W. Dijkstra, On the Role of Scientific 
Thought. 1974. http://www.cs.utexas 
.edu/users/EWD/transcriptions/
EWD04xx/EWD447.html.
[6]   M. Galster, D. Weyns, D. Tofan, B. 
Michalik, and P. Avgeriou, Variability 
in Software Systems—A Systematic 
Literature Review, IEEE Transactions on 
Software Engineering, 40(3), 2014.
[7]   *E. Gamma et al., Design Patterns: 
Elements of Reusable Object-Oriented 
Software, 1st ed, Addison-Wesley, 1994.
[8]   S. Gregor and D. Jones, The Anatomy 
of a Design Theory, Association for 
Information Systems, 2007.
[9]   IEEE Std 7000™-2021, IEEE Standard 
Model Process for Addressing Ethical 
Concerns during System Design. 
[10] ISO/IEC/IEEE 12207, Systems and 
Software Engineering — Software Life 
Cycle Processes.
[11]  ISO/IEC/IEEE, “ISO/IEC/IEEE 
24765:2017 Systems and Software 
Engineering — Vocabulary,” 
2nd ed. 2017.
[1 2] G. Kiczales et al., Aspect-Oriented 
Programming, Proc. 11th European Conf. 
Object-Oriented Programming (ECOOP 
97), Springer, 1997. 
[13] T. Kosar, S. Bohra, M. Mernik, 
Domain-Specific Languages: A 
Systematic Mapping Study, Information 
and Software Technology, 71, 77-91, 2016.
[14] D. Luckham, The Power of Events: an 
Introduction to Complex Event Processing, 
Addison-Wesley, 2002.
[1 5 ] G. Mühl, L. Fiege, and P. Pietzuch, 
Distributed Event-Based Systems, Spring-
Verlag, 2006.
[16] J. Nielsen, Usability Engineering, Morgan 
Kaufman, 1994.
[17] D.L. Parnas, On the Criteria To Be 
Used In Decomposing Systems Into 
Modules, Communications of the ACM 
15(12), 1053–1058, 1972. 
[18] D.L. Parnas and P.C. Clements, A 
Rational Design Process: How and Why 
to fake it, IEEE Transactions on Software 
Engineering 12(2), 251– 257, 1986. 
[19] D.L. Parnas and D.M. Weiss, Active 
Design Reviews: Principles and 
Practices, Journal of Systems & Software 
7, 259–265, 1987 
[20] D.T. Ross, J.B. Goodenough, and 
A. Irvine, Software Engineering: 

SOFTWARE DESIGN   3-17
Process, Principles, and Goals, IEEE 
Computer, May 1975.
[21]  *I. Sommerville, Software Engineering, 
10
th
 edition, Pearson, 2016.

4-1 
CHAPTER 04
Software Construction
ACRONYMS
API
Application 
Programming Interface
ASIC
Application-Specific 
Integrated Circuit
BaaS
Backend As A Service
CI
Continuous Integration
COTS
Commercial Off-The-Shelf
CSS
Cascading Style Sheets
DSL
Domain-Specific Language
DSP
Digital Signal Processor
ESB
Enterprise Service Bus
FPGA
Field Programmable 
Gate Array
GPU
Graphic Processing Unit
GUI
Graphical User Interface
HTML5
Hypertext Markup 
Language Version 5
IDE
Integrated Development 
Environment
IEEE
Institute Of Electrical And 
Electronics Engineers
ISO
International Organization 
For Standardization
JEE
Jakarta Enterprise Edition
KA
Knowledge Area
MDA
Model-Driven Architecture
NPM
Node Package Manager
OMG
Object Management Group
PIM
Platform Independent Model
POSIX
Portable Operating 
System Interface
PSM
Platform-Specific Model
SDK
Software Development Kit
TDD
Test-Driven Development
UML
Unified Modeling Language
WYSIWYG
What You See Is 
What You Get
INTRODUCTION
Software construction refers to the detailed cre-
ation  and  maintenance  of  software  through  
coding, verification, unit testing, integration 
testing and debugging.
The software construction knowledge area 
(KA) is linked to all the other KAs, but it is 
most strongly linked to the Software Design 
and  Software  Testing  KAs  because  the  soft-
ware  construction  process  involves  signifi-
cant design and testing. The process uses the 
design output and provides an input to testing 
(“design”  and  “testing”  in  this  case  referring  
to  the  activities,  not  the  KAs).  Boundaries  
among  design,  construction  and  testing  (if  
any) vary depending on the software life cycle 
processes used in a project.
Although  some  detailed  design  might  be  
performed before construction,  much  design  
work is performed during construction. Thus, 
the   Software   Construction   KA   is   closely   
linked to the Software Design KA.
Also,  throughout  construction,  software  
engineers  both  unit-test  and  integration-test  
their work. Thus, the Software Construction 
KA is closely linked to the Software Testing 
KA as well.

4-2   SWEBOK
®
 GUIDE V4.0
The  Software  Construction  KA  is  also  
related to configuration management, quality, 
project management and computing, and thus 
to the relevant KAs. 
First,  software  construction  typically  pro-
duces  the  highest  number  of  configuration  
items that need to be managed in a software 
project (e.g., source files, documentation, test 
cases). Thus, the Software Construction KA is 
closely linked to the Software Configuration 
Management KA.
Second, while quality is important in all the 
KAs, code is a software project’s ultimate deliv-
erable, and code is produced during construc-
tion. Thus, the Software Quality KA is closely 
linked to the Software Construction KA.
Third,  while  project  management  involves  
various   software   development   tasks,   soft-
ware construction typically produces the most 
deliverables  of  a  software  project.  Thus,  the  
Software Construction KA is closely linked to 
the Software Engineering Management KA.
Fourth, since software construction requires 
knowledge of algorithms and coding practices, 
this  KA  is  closely  related  to  the  Computing  
Foundations  KA,  which  concerns  the  com-
puter science foundations supporting software 
product design and construction.
BREAKDOWN OF TOPICS FOR 
SOF TWARE COSTRUCTION
The  breakdown  of  topics  for  the  Software  
Architecture KA is shown in Figure 4-1.
1. Software Construction Fundamentals
Software  construction  fundamentals  include  
the following:
•    Minimizing complexity
•    Anticipating and embracing change
•    Constructing for verification
•    Reusing assets
•    Applying standards in construction
The  first  four  concepts  apply  to  design  as 
well as to construction. The following sections 
define  these  concepts  and  describe  how  they  
apply to construction.
1.1.  Minimizing Complexity  [1, c2, c3,  
 c7-9, c24, c27, c28, c3, 1, c32, c34]
Most   people   have   limited   ability   to   hold   
complex  structures  and  information  in  their  
working    memories,    especially    over    long    
periods.  This  greatly  influences  how  people  
convey  intent  to  computers  and  drives  one  
of  the  key  goals  in  software  construction  —  
to  minimize  complexity.  The  need  to  reduce  
complexity  applies  to  essentially  every  aspect  
of  software  construction  and  is  particularly 
critical to testing software constructions.
Several   types   of   complexity   can   affect   
software  construction.  Tools  can  be  used  to  
manage  different  aspects  of  the  complexity  
of  software  components  and  their  construc-
tion.  For  example,  cyclomatic  complexity  is  a  
static analysis measure of how difficult code is 
to test and understand. The tool, developed by 
Thomas J. McCabe, Sr., in 1976, calculates the 
number of linearly independent paths through 
a program’s source code. Ideally, there should 
be  at  least  that  number  of  test  cases.  Other  
examples are tools like Make, which can build 
an   application,   or   integrated   development   
environments (IDEs) for entering, editing and 
compiling  code.  These  tools  help  manage  the  
complexity of the construction process.
In   software   construction,   reduced   com-
plexity  is  achieved  by  creating  simple  and  
readable  code  rather  than  clever  code.  This  is  
accomplished  by  using  standards  (see  section  
3.1.5,  Standards  in  Construction),  modular  
design  (see  section  3.1,  Construction  Design)  
and  numerous  other  specific  techniques  (see  
section   3.3,   Coding).   Construction-focused   
quality  techniques  also  support  this  (see  sec-
tion 3.6, Construction Quality).
1.2.  Anticipating and Embracing Change 
[1-c3-c5, c24, c31,  
c32, c34, 2-c1, c3, c9, 3-c1]
Most   software   changes   over   time,   and   
anticipating   change   drives   many   aspects   

SOFTWARE CONSTRUCTION   4-3
of  software  construction;  changes  in  the  
environments   in   which   software   oper-
ates  also  affect  software  in  diverse  ways.  
Anticipating  change  helps  software  engi-
neers build  extensible  software,  enhancing  
a  software  product  without  disrupting  the  
underlying  structure.  Anticipating  change  
is  supported  by  many  specific  techniques  
(see section 3.3, Coding).
Moreover,  today’s  business  environments  
require  many  organizations  to  deliver  and  
deploy software more frequently, faster and 
more  reliably.  Anticipating  specific,  nec-
essary  changes  can  be  difficult,  so  soft-
ware  engineers  should  be  careful  to  build  
flexibility  and  adaptability  into  the  soft-
ware to incorporate changes with less diffi-
culty. These software teams should embrace 
change   by   adopting   agile   development,   
practicing  DevOps,  and  by  adopting  con-
tinuous  delivery  and  deployment  practices.  
Such  practices  align  the  software  develop-
ment process and management with an evo-
lutionary environment.
Software
Construction
Software
Construction
Fundamentals
Minimizing
Complexity
Anticipating and 
Embracing Change
Construction for 
Verication
Reusing Assets
Applying Standards 
in Construction
Construction in 
Life Cycle Models
Construction 
Planning
Construction 
Measurements
Managing
Dependencies
Construction 
Design
Construction 
Languages
Coding
Construction 
Testing
Reuse in
Construction
Construction 
Quality
Integration
Cross-Platform
Development 
and Migration 
API Design 
and Use
Object-Oriented 
Runtime Issues
Parameterization,
Templates and
Generics
Assertions,
Design by Contract 
and Defensive 
Programming
Error Handling,
Exception Handling
and Fault Tolerance
Executable Models
State-Based and 
Table-Driven 
Construction Techniques
Runtime Conguration and
Internationalization
Grammar-Based
Input Processing
Concurrency Primitives
Middleware
Construction Methods
for Distribution and
Cloud-Based Software
Constructing
Heterogeneous Systems
Performance Analysis
and Tuning
Platform Standards
Test-First Programming
Feedback Loop 
for Construction
Development
Environments
Visual Programming
and Low-Code/
Zero-Code Platforms
Unit Testing Tools
Proong, Performance
Analysis and Slicing Tools
Managing
Construction
Practical
Considerations
Construction
Technologies
Software
Construction
Tools
Figure 4.1. Breakdown of Topics for the Software Construction KA

4-4   SWEBOK
®
 GUIDE V4.0
1.3.  Constructing for Verification  [1-c8, 
 c20-c23, c31, c34]
Constructing for verification builds software in 
such a way that faults can be readily found by 
the software engineers writing the software as 
well  as  by  the  testers  and  users  during  inde-
pendent   testing   and   operational   activities.   
Specific techniques that support constructing 
for   verification   include   following   coding   
standards  to  support  code  reviews  and  unit  
testing, organizing code to support automated 
testing,  restricting  the  use  of  complex  or  dif-
ficult-to-understand  language  structures,  and  
recording software behaviors with logs.
1.4.  Reusing Assets  [2-c15]
Reuse means using existing assets to solve dif-
ferent   problems.   In   software   construction,   
typical  assets  that  are  reused  include  frame-
works, libraries, modules, components, source 
code  and  commercial  off-the-shelf  (COTS)  
assets.  Reuse  has  two  closely  related  facets:  
construction for reuse and construction with reuse. 
The  former  means  creating  reusable  software  
assets,  whereas  the  latter  means  reusing  soft-
ware assets to construct a new solution. Reuse 
often  transcends  project  boundaries,  which  
means  reused  assets  can  be  constructed  in  
other projects or organizations.
1.5.  Applying Standards in Construction  [1-c4]
Applying  external  or  internal  development  
standards  during  construction  helps  achieve  
a  project’s  efficiency,  quality  and  cost  objec-
tives.  Specifically,  the  choices  of  allowable  
programming   language   subsets   and   usage   
standards  are  important  aids  in  achieving  
higher security.
Standards that directly affect construction 
issues include the following:
•    Communication methods (e.g., standards 
for document formats and content)
•    Programming  languages  (e.g.,  standards  
for languages like Java and C++)
•    Coding     standards     (e.g.,     standards     
for   naming   conventions,   layout   and   
indentation)
•    Exception  handling  policies  (e.g.,  stan-
dards  for  the  information  included  in  
exceptions  and  the  way  how  exceptions  
are handled after catching)
•    Platforms  (e.g.,  interface  standards  for  
operating system calls)
•    Tools    (e.g.,    diagrammatic    standards    
for   notations   like   UML   -   Unified   
Modeling Language)
Use   of   external   standards:   Construction   
depends on external standards for construction 
languages,  construction  tools,  technical  inter-
faces  and  interactions  between  the  Software  
Construction  KA  and  other  KAs.  Standards  
come    from    numerous    sources,    including    
hardware   and   software   interface   specifica-
tions   (e.g.,   OMG   -   Object   Management   
Group)     and     international     organizations     
(e.g.,  IEEE  -  the  Institute  of  Electrical  and  
Electronics Engineers, ISO - the International 
Organization for Standardization).
Use  of  internal  standards:  Standards  may  
also be created on an organizational basis at the 
corporate  level  or  for  use  on  specific  projects.  
These  standards  support  coordinating  group  
activities, minimizing complexity, anticipating 
change and constructing for verification.
2. Managing Construction
2.1.  Construction in Life Cycle Models  
 [1-c2, c3, c27, c29, 2-c3, c7, 3-c1]
Numerous   models   have   been   created   to   
develop  software;  some  emphasize  construc-
tion more than others.
Some  models  are  more  linear  from  the  
construction  viewpoint,  such  as  the  water-
fall   and   staged-delivery   life   cycle   models.   
These models treat construction as an activity 
that  occurs  only  after  the  completion  of  sig-
nificant  prerequisite  work,  including  detailed  
requirements work, extensive design work and 
detailed planning. The more linear approaches 
emphasize the  activities  that  precede  con-
struction (requirements and design) and create 

SOFTWARE CONSTRUCTION   4-5
more  distinct  separations  between  activities.  
In these models, construction’s main emphasis 
might be coding.
Other models, such as evolutionary proto-
typing and agile development, are more iter-
ative. These approaches treat construction as 
an  activity  that  occurs  concurrently  with  or  
overlaps  other  software  development  activi-
ties (including requirements, design and plan-
ning).  These  approaches  mix design,  coding  
and testing activities, and they often treat the 
combination of activities as construction (see 
the  Software  Engineering  Management  and  
Software Process KAs). 
The  practices  of  continuous  delivery  and  
deployment   further   mix   coding,   testing,   
delivery  and  deployment  activities.  In  these  
practices, software updates made during con-
struction activities are continuously delivered 
and  deployed  into  the  production  environ-
ment.  The  whole  process  is  fully  automated  
by a deployment pipeline that consists of var-
ious testing and deployment activities.
Consequently, what is considered construc-
tion  depends  on  the  life  cycle  model  used.  
In  general,  software  construction  is  mostly  
coding  and  debugging,  but  it  also  involves  
construction  planning,  detailed  design,  unit  
testing, integration testing and other activities.
2.2.  Construction Planning  [1-c3, c4,  
 c21, c27-c29]
The  choice  of  construction  method  is  a  key  
aspect  of  the  construction  planning  activ it y.  
This  choice  affects  the  extent  to  which  con-
struction   prerequisites   are   performed,   the   
order  in  which  they  are  performed  and  the 
degree  to  which  they  should  be  completed  
before construction work begins.
The  approach  to  construction  affects  the  
project  team’s  ability  to  reduce  complexity,  
anticipate  change  and  construct  for  verifica-
tion. Each objective may also be addressed at 
the  process,  requirements  and  design  levels,  
but  the  choice  of  construction  method  will  
influence them.
Construction   planning   also   defines   the   
order  in  which  components  are  created  and  
integrated,    the    integration    strategy    (for    
example,  phased  or  incremental  integration),  
the  software  quality  management  processes,  
the  allocation  of  task  assignments  to  specific  
software engineers, and other tasks, according 
to the chosen method.
2.3.  Construction Measurement  [1-c25, c28]
Numerous  construction  activities  and  arti-
facts  can  be  measured,  including  code  devel-
oped,  modified,  reused,  and  destroyed;  code  
complexity; code inspection statistics; fault-fix 
and  fault-find  rates;  effort;  and  scheduling.  
These  measurements  can  be  useful  for  man-
aging  construction,  ensuring  quality  during  
construction   and   improving   the   construc-
tion   process,   among   other   uses   (see   the   
Software  Engineering  Process  KA  for  more  
on measurement).
2.4.  Managing Dependencies  [2-c25]
Software products often heavily rely on depen-
dencies, including internal and external (com-
mercial  or  open-source)  dependencies,  which  
allow developers to reuse common functional-
ities instead of reinventing the wheel and sub-
stantially improve developers’ productivity. In 
addition,  package  managers  (e.g.,  Maven  in  
Java and NPM in JavaScript) are widely used to 
automate the process of installing, upgrading, 
configuring and removing dependencies. 
The  direct  and  indirect  dependencies  of  
software  products  constitute  a  dependency  
supply chain network. Any dependency in the 
supply  chain  network  can  introduce  poten-
tial  risk  to  software  products  and  should  be  
managed by developers or tools. Unnecessary 
dependencies  should  be  avoided  to  improve  
build  efficiency.  License  conflicts  between  
dependencies  and  software  products  should  
be  avoided  to  reduce  legal  risk.  Propagation  
of dependencies’ defects or vulnerabilities into 
software products should be avoided to improve 
the quality of software products. Regulations 
and monitoring mechanisms should be devel-
oped  to  prevent  developers  from  introducing  
untrusted external dependencies.

4-6   SWEBOK
®
 GUIDE V4.0
3. Practical Considerations
Construction is an activity in which the soft-
ware  engineer  often  has  to  deal  with  some-
times chaotic, changing and even conflicting 
real-world  constraints.  Because  of  real-world  
constraints,   practical   considerations   drive   
construction more than some other KAs, and 
software  engineering  is  perhaps  most  craft-
like  in  the  construction  activities  compared  
with other activities.
3.1.  Construction Design [1-c3, c5, c24, 2-c7]
Some  projects  allocate  considerable  design  
activity  to  construction,  whereas  others  allo-
cate  design  to  a  phase  explicitly  focused  on  
design.  Regardless  of  the  exact  allocation,  
some detailed design work occurs at the con-
struction  level,  and  that  design  work  is dic-
tated by constraints imposed by the real-world 
problem the software addresses.
Just  as  construction  workers  building  a  
physical  structure  must  make  small  modifi-
cations for unanticipated gaps in the builder’s 
plans,  software  construction  workers  must  
make small or large modifications to flesh out 
software design details during construction.
The  details  of  the  design  activity  at  the  
construction  level  are  essentially  the  same  as  
described  in  the  Software  Design  KA,  but  
they  are  applied  at  a  smaller  scale  to  algo-
rithms, data structures and interfaces.
3.2.  Construction Languages  [1-c4]
Construction    languages    include    all    forms    
of  communication  by  which  a  human  can  
specify  an  executable  solution  to  a  problem.  
Consequently,   construction   languages   and   
their  implementations  (e.g.,  compilers)  can  
affect software quality attributes such as per-
formance,  reliability  and  portability.  As  a  
result,  they  can  seriously  contribute  to  secu-
rity vulnerabilities.
The  simplest  construction  language  is  a  
configuration   language,   in   which   software   
engineers  choose  from  a  limited  set  of  pre-
defined   options   to   create   new   or   custom   
software installations. The text-based config-
uration  files  used  in  both  the  Windows  and  
Unix operating systems are examples of this, 
and   some   program   generators’   menu-style   
selection lists constitute another example of a 
configuration language.
Toolkit  languages  are  used  to  build  appli-
cations  from  elements  in  toolkits  (integrated  
sets  of  application-specific  reusable  parts);  
they  are  more  complex  than  configuration  
languages.  Toolkit  languages  may  be  explic-
itly  defined  as  application  programming  lan-
guages,  or  the  applications  might  be  implied  
by a toolkit’s set of interfaces.
Scripting   languages   are   commonly   used   
application programming languages. In some 
scripting  languages,  scripts  are  called  batch 
files or macros.
Programming  languages  are  the  most  flex-
ible construction languages. They also contain 
the least amount of information about specific 
application areas and development processes. 
Therefore, they require the most training and 
skill to use effectively. The choice of program-
ming  language  can  greatly  affect  the  like-
lihood   of   vulnerabilities   being   introduced   
during coding (e.g., unsafe use of C and C++ 
library functions is questionable from a secu-
rit y viewpoint).
Three  general  notations  are  used  for  pro-
gramming languages:
•    Linguistic (e.g., C/C++, Java)
•    Formal (e.g., Event-B)
•    Visual (e.g., MATLAB)
Linguistic   notations   are   distinguished   in   
particular by the use of textual strings to rep-
resent  complex  software  constructions.  The  
combination of textual strings in patterns may 
have  a  sentence-like  syntax.  Properly  used,  
each  string  should  have  a  strong  semantic  
connotation  providing  an  immediate  intui-
tive understanding of what happens when the 
software construction is executed.
Formal   notations   rely   less   on   intuitive,   
everyday  meanings  of  words  and  text  strings  
and  more  on  definitions  backed  by  precise,  
unambiguous  and  formal  (or  mathematical)  

SOFTWARE CONSTRUCTION   4-7
definitions.   Formal   construction   notations   
and methods are at the semantic base of most 
system  programming  notations,  where  accu-
racy,  time  behavior  and  testability  are  more  
important than ease of mapping into natural 
language. Formal constructions also use pre-
cisely defined ways of combining symbols that 
avoid the ambiguity of many natural language 
constructions.
Visual   notations   rely   much   less   on   the   
textual  notations  of  linguistic  and  formal  
construction and more on direct visual inter-
pretation and placement of visual entities that 
represent   the   underlying   software.   Visual   
construction is somewhat  limited  by  the  dif-
ficulty of making “complex” statements using 
only  the  arrangement  of  icons  on  a  display.  
However,  these  icons  can  be  powerful  tools  
in cases where the primary programming task 
is to build and “adjust” a visual interface to a 
program,  the  detailed  behavior  of  which  has  
an underlying definition.
Nowadays,     domain-specific     languages     
(DSLs) are widely used to build domain-spe-
cific   applications.   Unlike   a   general-pur-
pose  programming  language,  such  as  C/C++  
or  Java,  a  DSL  is  designed  for  the  applica-
tion   construction   of   a   particular   domain.   
Therefore,  a  DSL  usually  can  be  defined  
based  on  a  higher  level  of  abstraction  of  the  
target  domain  and  can  be  optimized  for  a  
specific  class  of  problems.  Furthermore,  A  
DSL usually can be expressed by visual nota-
tions   defined   by   domain-specific   concepts   
and rules.
3.3.  Coding  [1-c5-c19, c25-c26]
The  following  considerations  apply  to  the  
software construction coding activity:
•    Techniques  for  creating  understandable  
source  code,  including  naming  conven-
tions and source code layout
•    Use  of  classes,  enumerated  types,  vari-
ables,  named  constants  and  other  sim-
ilar entities
•    Use of control structures 
•    Handling  of  error  conditions  —  both  
anticipated  and  exceptional  (e.g.,  input  
of bad data)
•    Prevention      of      code-level      security      
breaches  (e.g.,  buffer  overflows  or  array  
index bounds)
•    Resource  use  through  use  of  exclusion 
mechanisms  and  discipline  in  accessing  
serially    reusable    resources,    including    
threads and database locks
•    Source   code   organization   into   state-
ments,   routines,   classes,   packages   or   
other structures
•    Code documentation
•    Code tuning
3.4.  Construction Testing  [1-c22, c23, 2-c8]
Construction  involves  two  forms  of  testing,  
which  are  often  performed  by  the  software  
engineer who wrote the code: unit testing and 
integration testing.
Construction testing aims to reduce the gap 
between when faults are inserted into the code 
and  when  those  faults  are  detected,  thereby 
reducing  the  cost  incurred  to  fix  them.  In 
some instances, test cases are written after the 
code has been written. In other instances, test 
cases might be created before code is written.
Construction  testing  typically  involves  a  
subset of the various types of testing, described 
in  the  Software  Testing  KA.  For  instance,  
construction testing does not typically include 
system  testing,  alpha  testing,  beta  testing,  
stress  testing,  configuration  testing,  usability  
testing, or other more specialized testing.
Two  standards  have  been  published  on  
construction  testing:  IEEE  Standard  829-
1998, “IEEE   Standard   for   Software   Test   
Documentation,”     and     IEEE     Standard     
1008-1987,   “IEEE   Standard   for   Software   
Unit Testing.”
See sections 2.1.1 and 2.1.2 in the Software 
Testing   KA   for   more   specialized   refer-
ence material.
3.5.  Reuse in Construction  [2-c15, c16]
Reuse  in  construction  includes  both  construc-
tion for reuse and construction with reuse. 

4-8   SWEBOK
®
 GUIDE V4.0
Construction   for   reuse   creates   software   
with  the  potential  to  be  reused  in  the  future  
for  the  present  project  or  for  other  projects  
with   a   broad-based,   multisystem   perspec-
tive.  Construction  for  reuse  is  usually  based  
on  variability  analysis  and  design.  To  avoid  
the problem of code clones, developers should 
encapsulate   reusable   code   fragments   into   
well-structured libraries or components.
The  tasks  related  to  software  construc-
tion  for  reuse  during  coding  and  testing  are 
as follows:
•    Variability  implementation  with  mech-
anisms  such  as  parameterization,  condi-
tional compilation and design patterns
•    Variability     encapsulation     to     make     
the   software   assets   easy   to   configure   
and customize
•    Testing  the  variability  provided  by  the  
reusable software assets
•    Description  and  publication  of  reusable  
software assets
Construction  with  reuse  means  creating  
new  software  by  reusing  existing  software  
assets.  The  most  popular  reuse  method  is  
to  reuse  code  from  the  libraries  provided  by  
the  language,  platform,  tools  or  an  organi-
zational  repository.  Aside  from  these,  many  
applications developed today use open-source 
libraries.  In  addition,  reused  and  off-the-
shelf software often have the same (or better) 
quality requirements as newly developed soft-
ware (e.g., security level requirements).
The  tasks  related  to  software  construc-
tion with reuse during coding and testing are 
as follows:
•    Selecting  reusable  units,  databases,  test  
procedures or test data
•    Evaluating code or test reusability
•    Integrating  reusable  software  assets  into  
the current software
•    Reporting   reuse   information   on   new   
code, test procedures or test data
The  forms  of  reusable  software  assets  are  
not limited to software artifacts that must be 
locally  integrated.  Nowadays,  cloud  services  
that  provide  various  services  through  online  
interfaces  such  as  RESTful  application  pro-
gramming interfaces (APIs) are widely used in 
applications.  In  the  new  cloud  service  model  
BaaS (backend as a service), applications del-
egate their backend implementations to cloud 
service providers — for example, utilities such 
as  authentication,  messaging  and  storage  are  
usually provided by cloud providers.
Reuse   is   best   practiced   systematically,   
according  to  a  well-defined,  repeatable  pro-
cess.   Systematic   reuse   can   enable   signifi-
cant  software  productivity,  quality  and  cost  
improvements.  Systematic  reuse  is  supported  
by  methodologies  such  as  software  product  
line engineering and various software frame-
works and platforms. Widely used frameworks 
such  as  Spring  provide  reusable  infrastruc-
tures   for   enterprise   applications   so   soft-
ware  teams  can  focus  on  application-specific  
business  logic.  Commercial  platforms  pro-
vide  various  reusable  frameworks,  libraries,  
components  and  tools  to  support  application  
development to build their ecosystems.
3.6.  Construction Quality  [1-c8,  c20-c25,  
 2-c8, c24]
In addition to faults occurring during require-
ments and design activities, faults introduced 
during construction can cause serious quality 
problems (e.g., security vulnerabilities). These 
include  not  only  faults  in  security  function-
ality   but   also   faults   elsewhere   that   allow   
bypassing  of  the  security  functionality  or  
create other security weaknesses or violations.
Numerous  techniques  exist  to  ensure  the  
quality  of  code  as  it  is  constructed.  The  pri-
mary  techniques  used  to  ensure  construction  
quality are the following:
•    Unit  testing  and  integration  testing  (see  
section 3.4, Construction Testing)
•    Test-first  development  (see  section  6.1.2  
in the Software Testing KA)
•    Use     of     assertions     and     defensive     
programming
•    Debugging

SOFTWARE CONSTRUCTION   4-9
•    Inspections
•    Technical    reviews,    including    securi-
ty-oriented reviews (see section 2.3 in the 
Software Quality KA)
•    Static  analysis  (see  section  2.2.1  of  the  
Software Quality KA)
The    specific    technique    or    techniques    
selected  depend  on  the  software  constructed  
and  on  the  skill  set  of  the  software  engi-
neers  performing  the  construction  activities.  
Programmers should know good practices and 
common vulnerabilities (e.g., from widely rec-
ognized  lists  about  common  vulnerabilities).  
Automated  static  code  analysis  for  security  
weaknesses  is  available  for  several  common  
programming  languages  and  can  be  used  in  
security-critical projects.
Construction  quality  activities  are  dif-
ferentiated  from  other  quality  activities  by  
their  focus.  These  activities  focus  on  arti-
facts that are closely related to code — such 
as  detailed  design  —  as  opposed  to  other  
artifacts  that  are  less  directly  connected  to  
the  code,  such  as  requirements,  high-level  
designs and plans.
3.7.  Integration  [1-c29, 2-c8, 3-c11]
During  construction,  a  key  activity  is  inte-
grating   individually   constructed   routines,   
classes,  components  and  subsystems  into  a  
single  system.  In  addition,  a  particular  soft-
ware  system  may  need  to  be  integrated  with  
other software or hardware systems.
Concerns  related  to  construction  integra-
tion  include  planning  the  sequence  in  which  
components  are  integrated,  identifying  what  
hardware  is  needed,  creating  scaffolding  to  
support   interim   versions   of   the   software,   
determining the degree of testing and quality 
work  performed  on  components  before  they  
are integrated, and determining points in the 
project at which interim versions of the soft-
ware are tested.  
Programs   can   be   integrated   by   means   
of   either   the   phased   or   the   incremental   
approach.   Phased   integration,   also   called   
big   bang   integration,   entails   delaying   the   
integration of component software parts until 
all parts intended for release in a version are 
complete. Incremental integration is thought 
to offer many advantages over the traditional 
phased  integration  (e.g.,  easier  error  loca-
tion,  improved  progress  monitoring,  earlier  
product delivery and improved customer rela-
tions). In incremental integration, the devel-
opers write and test a program in small pieces 
and  then  combine  the  pieces  one  at  a  time.  
Additional test infrastructure, including, for 
example,  stubs,  drivers  and  mock  objects,  is  
usually needed to enable incremental integra-
tion. In addition, by building and integrating 
one  unit  at  a  time  (e.g.,  a  class  or  compo-
nent),  the  construction  process  can  provide  
early  feedback  to  developers  and  customers.  
Other advantages of incremental integration 
include easier error location, improved prog-
ress  monitoring  and  more  fully tested  units,  
among others.
Nowadays, continuous integration (CI) has 
been  widely  adopted  in  practice.  A  software  
team using CI integrates its work frequently, 
leading  to  multiple  integrations  per  day.  CI  
is usually automated by a pipeline that builds 
and tests each integration to detect errors and 
provide fast feedback.
3.8.  Cross-Platform Development and 
Migration  [4-c]
Some  applications,  such  as  mobile  applica-
tions,  heavily  rely  on  specific  platforms  (e.g.,  
Apple,   Android),   which   usually   include   
operating  systems,  development  frameworks  
and  APIs.  To  support  multiple  platforms,  
the  developers  need  to  develop  and  build  an  
application  separately  for  each  target  plat-
form  using  the  corresponding  program  lan-
guage  and  software  development  kit  (SDK).  
However, multi-platform development in this 
way  requires  more  time  and  cost  and  might  
cause different user experiences between dif-
ferent implementations.
Cross-platform    development    allows    the    
developers  to  develop  an  application  using  a  
universal  language  and  export  it  to  various  
platforms.  This  usually  can  be  done  in  two  

4-10   SWEBOK
®
 GUIDE V4.0
ways  for  mobile  applications.  One  way  is  to  
generate   native   applications   using   specific   
tools that can compile the universal language 
into  platform-specific  formats.  The  other  is  
to  develop  hybrid  applications  that  combine  
web  applications  developed  using  languages  
like  hypertext  markup  language  version  5  
(HTML5)  and  cascading  style  sheets  (CSS)  
and native containers or wrappers for various 
operations systems.
For  applications  that  are  not  developed  in  
this  way,  developers  may  consider  migrating  
the applications from one platform to another. 
The  migration  usually  involves  translation  of  
different  programming  languages  and  plat-
form-specific APIs and can be partially auto-
mated by tools.
4. Construction Technologies
4.1.  API Design and Use  [5-c7]
An API is a set of signatures that are exported 
and  available  to  the  users  of  a  library  or  a  
framework to write their applications. Besides 
signatures,  an  API  should  always  include  
statements about the program’s effects and/or 
behaviors (i.e., its semantics).
API  design  should  make  the  API  easy  to  
learn and memorize, lead to readable code, be 
difficult to misuse, be easy to extend, be com-
plete,  and  maintain  backward  compatibility.  
As  the  APIs  usually  outlast  their  implemen-
tations for a widely used library or framework, 
an API should be straightforward and stable, 
to  facilitate  client  application  development  
and maintenance.
API    use    involves    selecting,    learning,    
testing,  integrating  and  possibly  extending  
APIs provided by a library or framework (see 
section 3.5, Reuse in Construction).
For  online  interfaces  such  as  RESTful  
APIs,  open  standers  such  as  OpenAPI  play  
an  important  role.  OpenAPI  defines  a  stan-
dard,  language-agnostic  interface  to  HTTP  
APIs  and  supports  the  automatic  generation  
of  server-side  and  client-side  code,  covering  
popular  languages  such  as  Java,  JavaScript,  
Python,  etc..  At  the  same  time,  API-first  
approach   has   been   widely   used,   which   
emphasizes designing and building the APIs 
of  an  application  first.  In  practice,  API-first  
approach is usually accomplished by using an 
API description language to establish a con-
tract for how the API is supposed to behave.
4.2.  Object-Oriented Runtime Issues  [1-c6, c7]
Object-oriented    languages    support    run-
time  mechanisms,  including  polymorphism  
and  reflection.  These  runtime  mechanisms  
increase  the  flexibility  and  adaptability  of  
object-oriented programs. 
Polymorphism  is  a  language’s  ability  to  
support  general  operations  without  knowing  
until  runtime  what  kind  of  concrete  objects  
the  software  will  include.  Because  the  pro-
gram does not know the types of the objects 
in  advance,  the  exact  behavior  is  determined  
at runtime (called dynamic binding).
Reflection is a program’s ability to observe 
and modify its structure and behavior at run-
time. For example, reflection allows inspection 
of  classes,  interfaces,  fields  and  methods  at  
runtime without knowing their names at com-
pile  time.  It  also  allows  instantiation  of  new  
objects at runtime and invocation of methods 
using parameterized class and method names.
4.3.  Parameterization, Templates, and Generics 
 [6-c1]
Parameterized  types,  also  known  as  generics 
(Ada, Java, Eiffel) and templates (C++), enable 
a  type  or  class  definition  without  specifying  
all the other types used. The unspecified types 
are supplied as parameters at the point of use. 
Parameterized   types   provide   a   third   way   
(besides  class  inheritance  and  object  compo-
sition)  to  compose  behaviors  in  object-ori-
ented software.
4.4.  Assertions, Design by Contract, and 
Defensive Programming  [1-c8, c9]
An assertion is an executable predicate placed 
in  a  program  —  usually  a  routine  or  macro  
— that allows runtime checks of the program. 

SOFTWARE CONSTRUCTION   4-11
Assertions  are  especially  useful  in  high-reli-
ability programs. They enable programmers to 
more  quickly  flush  out  mismatched  interface  
assumptions, errors that creep in when code is 
modified, and other problems. Assertions are 
typically  compiled  into  the  code  at  develop-
ment  time  and  are  later  compiled  out  of  the  
code so they don’t degrade the performance.
Design by contract is a development approach 
in which preconditions and postconditions are 
included  for  each  routine.  When  precondi-
tions  and  postconditions  are  used,  each  rou-
tine  or  class  is  said  to  form  a  contract  with  
the  rest  of  the  program.  A  contract  precisely  
specifies  the  semantics  of  a  routine  and  thus  
helps clarify its behavior. Design by contract 
is thought to improve the quality of software 
construction.
Defensive  programming  means  to  protect  a  
routine  from  being  broken  by  invalid  inputs.  
Common   ways   to   handle   invalid   inputs   
include  checking  the  values  of  all  the  input  
parameters  and  deciding  how  to  handle  bad  
inputs. Assertions are often used in defensive 
programming to check input values.
4.5.  Error Handling, Exception Handling, and 
Fault Tolerance  [1-c8, c9]
How errors   are   handled   affects   software’s   
ability to meet requirements related to correct-
ness, robustness and other nonfunctional attri-
butes. Assertions are sometimes used to check 
for errors. Other error-handling techniques — 
such as returning a neutral value, substituting 
the next piece of valid data, logging a warning 
message, returning an error code or shutting 
down the software — are also used.
Exceptions  are  used  to  detect  and  process  
errors or exceptional events. The basic struc-
ture  of  an  exception  is  as  follows:  A  routine  
uses throw  to  throw  a  detected  exception,  
and  an  exception-handling  block  will  catch 
the  exception  in  a  try-catch  block.  The  try-
catch block may process the erroneous condi-
tion  or  return  control  to  the  calling  routine.  
Exception-handling  policies  should  be  care-
fully designed following common principles, 
such  as  including  in  the  exception  message  
all  information  that  led  to  the  exception,  
avoiding  empty  catch  blocks,  knowing  the  
exceptions  the  library  code  throws,  perhaps  
building   a   centralized   exception   reporter,   
and   standardizing   the   program’s   use   of   
exceptions.
Fault tolerance is a collection of techniques 
that increase software reliability by detecting 
errors and then recovering from them or con-
taining their effects if recovery is not possible. 
The   most   common   fault   tolerance   strate-
gies  include  backing  up  and  retrying,  using  
auxiliary  code  and  voting  algorithms,  and  
replacing  an  erroneous  value  with  a  phony  
value that will have a benign effect.
4.6.  Executable Models  [7]
Executable models abstract away the details of 
specific  programming  languages  and  deci-
sions   about   the   software’s   organization.   
Different  from  traditional  software  models,  
a  specification  built  in  an  executable  mod-
eling language like xUML (executable UML) 
can be deployed in various software environ-
ments without change. Furthermore, an exe-
cutable-model   compiler   (transformer)   can   
turn  an  executable  model  into  an  implemen-
tation using a set of decisions about the target 
hardware  and  software  environment.  Thus,  
constructing  executable  models  is  a  way  of  
constructing executable software.
Executable   models   are   one   foundation   
supporting   the   model-driven   architecture   
(MDA) initiative of the OMG. An executable 
model is a way to specify a platform-indepen-
dent  model  (PIM);  a  PIM  is  a  model  of  a  
solution to a problem that does not rely on any 
implementation  technologies.  Then  a  plat-
form-specific model (PSM), which is a model 
that  contains  the  details  of  the  implementa-
tion, can be produced by weaving together the 
PIM and the platform on which it relies.
4.7.  State-Based and Table-Driven 
Construction Techniques  [1-c18]
State-based  programming,  or  automata-based 
programming,  is  a  programming  technology  

4-12   SWEBOK
®
 GUIDE V4.0
that  uses  finite-state  machines  to  describe  
program behaviors. A state machine’s transi-
tion graphs are used in all stages of software 
development  (specification,  implementation,  
debugging  and  documentation).  The  main  
idea is to construct computer programs in the 
same  way  technological  processes  are  auto-
mated.  State-based  programming  is  usually  
combined with object-oriented programming, 
forming  a  new  composite  approach  called  
state-based, object-oriented programming.
A table-driven method is  a  schema  that  
uses  tables  to  display  information  rather  
than  convey  information  with  logic  state-
ments  (such  as  if and case).  When  used  in  
appropriate circumstances,     table-driven     
code  is  simpler  than  complicated  logic  and  
easier  to  modify.  When  using  table-driven  
methods,  the  programmer  addresses  two  
issues: what information to store in the table 
or tables and how to efficiently access infor-
mation in the table.
4.8.  Runtime Configuration and 
Internationalization  [1-c3, c10]
To  achieve  more  flexibility,  a  program  is  
often constructed to support its variables’ late 
binding  time.  For  example,  runtime  configu-
ration binds variable values and program set-
tings when the program is running, usually by 
updating and reading configuration files in a 
just-in-time mode.
Internationalization is the technical activity 
of  preparing  a  program,  usually  interactive  
software, to support multiple locales. The cor-
responding  activity,  localization,  modifies  a  
program to support a specific local language. 
Interactive  software  may  contain  dozens  or  
hundreds  of  prompts,  status  displays,  help  
messages,  error  messages  and  so  on.  The  
design   and   construction   processes   should   
accommodate string and character set issues, 
including  which  character  set  is  used,  what  
kinds of strings are used, how to maintain the 
strings without changing the code and how to 
translate  the  strings  into  different  languages  
with minimal impact on the processing code 
and the user interface.
4.9.  Grammar-Based Input Processing  [1, 8]
Grammar-based    input    processing    involves    
syntax analysis, or parsing, of the input token 
stream. It involves the creation of a data struc-
ture  (called  a  parse  tree  or  syntax  tree)  repre-
senting  the  input  data.  The  inorder  traversal  
of  the  parse  tree  usually  gives  the  expres-
sion just parsed. Next, the parser checks the 
symbol  table  for  programmer-defined  vari-
ables  that  populate  the  tree.  After  building  
the parse tree, the program uses it as an input 
to the computational processes.
4.10. Concurrency Primitives  [9-c6]
A synchronization primitive is a programming 
abstraction  provided  by  a  programming  lan-
guage or the operating system that facilitates 
concurrency    and    synchronization.    Well-
known concurrency primitives include sema-
phores, monitors and mutexes.
A semaphore  is  a  protected  variable  or  
abstract  data  type  that  provides  a  simple  
but  useful  abstraction  for  controlling  access  
to  a  common  resource  by  multiple  processes  
or   threads   in   a   concurrent   programming   
environment.
A monitor is an abstract data type that pres-
ents  a  set  of  programmer-defined  operations  
executed  with  mutual  exclusion.  A  monitor  
contains  the  declaration  of  shared  variables  
and  procedures  or  functions  that  operate  on  
those variables. The monitor construct ensures 
that  only  one  process  at  a  time  is  active  in  
the monitor.
A mutex  (mutual  exclusion)  is  a  synchro-
nization primitive that grants exclusive access 
to  a  shared  resource  by  only  one  process  or  
thread at a time.
4.11. Middleware  [5-c1, 8-c8]
Middleware  is  a  broad  classification  for  soft-
ware that provides services above the operating 
system  layer  yet  below  the  application  pro-
gram  layer.  Middleware  can  provide  runtime  
containers for software components to provide 
message passing, persistence and a transparent 

SOFTWARE CONSTRUCTION   4-13
location  across  a  network.  Middleware  can  
be  viewed  as  a  connector  between  the  com-
ponents  using  the  middleware.  Modern  mes-
sage-oriented middleware usually provides an 
enterprise service bus (ESB) that supports ser-
vice-oriented  interaction  and  communication  
among multiple software applications.
4.12. Construction Methods for Distributed and 
Cloud-Based Software  [2-c17, c18, 9-c2]
A distributed system is a collection of physically 
separate,   possibly   heterogeneous   computer   
systems  networked  to  provide  the  users  with  
access to the resources the system maintains. 
The  construction  of  distributed  software  is  
distinguished  from  traditional  software  con-
struction  by  issues  such  as  parallelism,  com-
munication and fault tolerance.
Distributed   programming   typically   falls   
into   several   basic   architectural   categories:   
client-server,   three-tier   architecture,   n-tier   
architecture,  distributed  objects,  loose  cou-
pling or tight coupling (see section 5.6 in the 
Computing Foundations KA and section 2.2 
in the Software Architecture KA).
Nowadays, more applications are migrated 
to the cloud. Cloud-based software often adopts 
microservice architecture and container-based 
deployment.  In  addition  to  traditional  dis-
tributed  software  issues,  cloud-based  soft-
ware  developers  also  need  to  consider  cloud  
infrastructure  issues  such  as  use  of  an  API  
gateway, service registration and discovery.
Distributed  systems  based  on  n-tier/ser-
vice-oriented   architectures   usually   rely   on   
ACID distributed transactions for the imple-
mentation  of  transactions  involving  multiple  
distributed  components.  In  contrast,  cloud-
based microservices cannot enforce distributed 
transactions consistency, and use some form of 
SAGA-based  eventual  consistency,  initially  
intended for long-running transactions.
4.13. Constructing Heterogeneous Systems  [8-c9]
Heterogeneous  systems  consist  of  various  special-
ized  computational  units  of  different  types,  
such as Graphic Processing Units (GPUs) and 
Digital   Signal   Processors   (DSPs),   micro-
controllers  and  peripheral  processors.  These  
computational  units  are  independently  con-
trolled  and  communicate  with  one  another.  
Embedded  systems  are  typically  heteroge-
neous systems.
The   design   of   heterogeneous   systems   
may  require  combining  several  specifica-
tion  languages  to  design  different  system  
parts   (hardware/software   codesign).   The   
key issues include multilanguage validation, 
co-simulation and interfacing.
During    the    hardware/software    code-
sign, software and virtual hardware develop-
ment  proceed  concurrently  through  stepwise  
decomposition.  The  hardware  part  is  usually  
simulated  in  field  programmable  gate  arrays  
(FPGAs)  or  application-specific  integrated  
circuits  (ASICs).  The  software  part  is  trans-
lated into a low-level programming language.
4.14.  Performance Analysis and Tuning  
 [1-c25, c26]
Code  efficiency  —  determined  by  architec-
ture, detailed design decisions, and data struc-
ture  and  algorithm  selection  —  influences  
execution speed and size. Performance analysis 
investigates a program’s behavior using infor-
mation  gathered  as  the  program  executes  to  
identify possible hot spots in the program to 
be improved.
Code tuning, which improves performance 
at  the  code  level,  modifies  correct  code  to  
make  it  run  more  efficiently.  Code  tuning  
usually involves only small changes that affect 
a single class, a single routine or, more com-
monly, a few lines of code. A rich set of code 
tuning techniques is available, including those 
for tuning logic expressions, loops, data trans-
formations, expressions and routines. Using a 
low-level  language  is  another  common  tech-
nique for improving hot spots in a program.
4.15. Platform Standards  [4-c, 8-c10, 9-c1]
Platform   standards   enable   programmers   to   
develop portable applications that can be exe-
cuted  in  compatible  environments  without  

4-14   SWEBOK
®
 GUIDE V4.0
changes. Platform standards usually involve 
standard  services  and  APIs  that  compat-
ible   platform   implementations   must   use.   
Typical  examples  of  platform  standards  are  
Jakarta  Enterprise  Edition  (JEE);  the  por-
table  operating  system  interface  (POSIX)  
standard  for  operating  systems,  which  rep-
resents  a  set  of  standards  implemented  pri-
marily  for  Unix-based  operating  systems;  
and  HTML5,  which  defines  the  standards  
for  developing  web  applications  that  can  
run  on  different  environments  (e.g.,  Apple  
iOS, Android).
4.16.  Test-First Programming  [1-c22, 2-c8]
Test-first programming (also known as TDD - 
Test-Driven Development) is a popular devel-
opment  style  in  which  test  cases  are  written  
before any code. These test cases, when applied 
to the current code base, will fail. Code is then 
written  that  will  allow  the  test  cases  to  pass.  
At  that  time,  the  new  code  and  associated  
parts of the project can be refactored and opti-
mized.  Test-first  programming  can  usually  
detect  defects  earlier  and  correct  them  more  
easily  than  traditional  programming  styles.  
Furthermore,  writing  test  cases  first  forces  
programmers to think about requirements and 
design  before  coding,  thus  exposing  require-
ments and design problems sooner.
4.17.  Feedback Loop for Construction 
  [3-c3, c16]
Early   and   continuous   feedback   for   the   
construction  activity  is  one  of  the  most  
important advantages of agile development 
and  DevOps.  Agile  development  provides  
early feedback for construction through fre-
quent iterations in the development process. 
DevOps provides even faster feedback from 
the  operation,  allowing  the  developers  to  
learn how well their code performs in pro-
duction environments. This fast feedback is 
achieved  through  techniques  and  practices  
in the DevOps pipeline, such as automated 
building  and  testing,  canary  release,  and  
A/B testing.
5.  Software Construction Tools
5.1.  Development Environments  [1-c30]
A development   environment,   or   integrated 
development    environment    (IDE),    provides    
comprehensive  facilities  to  programmers  for  
software  construction  by  integrating  a  set  of  
development  tools.  The  programmers’  choice  
of  development  environment  can  affect  soft-
ware construction efficiency and quality.
Besides    basic    code    editing    functions,    
modern  IDEs  often  offer  other  features,  like  
compilation  and  error  detection  within  the  
editor,  integration  with  source  code  control,  
build/test/debugging   tools,   compressed   or   
outline  views  of  programs,  automated  code  
transforms, and support for refactoring.
Nowadays, cloud-based development envi-
ronments  are  available  in  public  or  private  
cloud  services.  These  environments  can  pro-
vide  all  the  features  of  modern  IDEs  and  
even  more  (e.g.,  containerized  building  and  
deployment), powered by the cloud.
Moreover, modern IDEs are often equipped 
with    AI-assisted    programming    which    is    
boosted   by   the   recent   advances   in   Large   
Language Models (LLMs). With the support 
a programmer can define a function in pseudo-
code  comments  or  outline  its  implementa-
tion  as  a  prompt  for  an  LLM  to  generate  or  
complete  the  code.  The  programmer  lets  the  
LLM  complete  many  of  the  details,  but  still  
reviews  the  generated  code  and  integrates  it  
into their project.
5.2.  Visual Programming and Low-Code/Zero-
Code Platforms  [1-c30]
Visual programming allows users to create pro-
grams  by  manipulating  visual  program  ele-
ments  graphically.  As  a  visual  programming  
tool, a GUI (graphical user interface) builder 
enables  the  developer  to  create  and  main-
tain  GUIs  in  a  WYSIWYG  (what  you  see  
is  what  you  get)  mode.  A  GUI  builder  usu-
ally  includes  a  visual  editor  that  enables  the  
developer  to  design  forms  and  windows  and  
manage  the  layout  of  the  widgets  with  drag,  

SOFTWARE CONSTRUCTION   4-15
drop  and  parameter  setting  features.  Some  
GUI  builders  can  automatically  generate  the  
source code corresponding to the visual GUI 
design.   Because   GUI   applications   usually   
follow the event-driven style (in which events 
and  event  handling  determine  the  program  
flow), GUI builder tools usually provide code 
generation   assistants,   which   automate   the   
most  repetitive  tasks  required  for  event  han-
dling.  The  supporting  code  connects  widgets  
with  the  outgoing  and  incoming  events  that  
trigger the functions providing the application 
logic. Some modern IDEs provide integrated 
GUI builders or GUI builder plug-ins. There 
are also many stand-alone GUI builders.
Visual programming and other rapid appli-
cation  development  tools  have  evolved  into  
low-code/zero-code  platforms.  These  platforms  
allow  developers  to  build  complete  applica-
tions visually through a drag-and-drop inter-
face  and  with  minimal  hand-coding.  They  
are  usually  based  on  the  principles  of  mod-
el-driven  design,  visual  programming  and  
code generation. The difference between low-
code development and zero-code development 
lies  in  hand-coding;  the  former  requires  a  
little hand-coding, whereas the latter requires 
practically none.
5.3.  Unit Testing Tools  [1-c22, 2-c8]
Unit  testing  verifies  the  functioning  of  soft-
ware  modules  in  isolation  from  other  sepa-
rately testable software elements (for example, 
classes,  routines,  components).  Unit  testing  
is  often  automated.  Developers  can  use  unit  
testing  tools  and  frameworks  to  extend  and  
create an automated testing environment. For 
example, the developer can code criteria into 
the  test  with  unit  testing  tools  and  frame-
works  to  verify  the  unit’s  correctness  under  
various  data  sets.  Each  test  is  implemented  
as an object, and a test runner runs the tests. 
Failed test cases will be automatically flagged 
and reported during the test execution.
5.4.  Profiling, Performance Analysis,  
and Slicing Tools  [1-c25, c26]
Performance  analysis  tools  are  usually  used  to  
support code tuning. The most common per-
formance analysis tools are profiling tools. An 
execution  profiling  tool  monitors  the  code  
while  it  runs  and  records  how  often  each  
statement is executed or how much time the 
program  spends  on  each  statement  or  exe-
cution path. Profiling the code while it runs 
gives  insight  into  how  the  program  works,  
where the hot spots are and where the devel-
opers should focus the code tuning efforts.
Program  slicing  involves  computing  the  set  
of program statements (i.e., the program slice) 
that might affect the values of specified vari-
ables at some point of interest, which is called 
a slicing criterion. Program slicing can be used 
for  locating  error  sources,  program  under-
standing and optimization analysis. Program 
slicing  tools  compute  program  slices  for  var-
ious  programming  languages  using  static  or  
dynamic analysis methods.
MATRIX OF TOPICS VS. REFERENCE MATERIAL
McConnell, 
 
2 0 0 4 [1]Sommerville, 
 
2016 [2] Kim et al.,   2 021 [3]Heitkötter 
 
et al., 2013 [4]Clements 
 
et al., 2010 [5]Gamma et al. 
 
1994 [6]Mellor and Balcer, 
 
2 0 02 [7]Null and Lobur, 
 
20 06 [8]Silberschatz 
 
et al., 2008 [9]
1. Software Construction 
Fundamentals

4-16   SWEBOK
®
 GUIDE V4.0
1.1. Minimizing 
Complexity
c2, c3, c7-c9, 
c24, c27, c28, 
c31, c32, c34
1.2. Anticipating and 
Embracing Change
c3-c5, c24, 
c31, c32, c34
c1, c3,  
c9
c1
1.3. Constructing for 
Verification
c8, c20-c23,  
c31, c34
1.4. Reusec15
1.5. Standards in 
Construction 
c4
2. Managing Construction
2.1. Construction in Life 
Cycle Models
c2, c3, c27,  
c29
c3, 
c7
c1
2.2. Construction  
Planning
c3, c4, c21,  
c27-c29
2.3. Construction 
Measurement
c25, c28
2.4. Managing 
Dependencies
c25
3. Practical 
Considerations
3.1. Construction Designc3, c5, c24c7
3.2. Construction  
Languages
c4
3.3. Codingc5-c19,  
c25-c26
3.4. Construction Testingc22, c23c8
3.5. Reuse in Constructionc15, 
c16
3.6. Construction Qualityc8, c20-c25c8, 
c24
3.7. Integrationc29c8c11
3.8. Cross-Platform 
Development 
and Migration
c
4. Construction 
Technologies
4.1. API Design and Usec7
4.2. Object-Oriented 
Runtime Issues
c6, c7

SOFTWARE CONSTRUCTION   4-17
4.3. Parameterization, 
Templates and Generics
c1
4.4. Assertions, Design by 
Contract and Defensive 
Programming
c8, c9
4.5. Error Handling, 
Exception Handling and 
Fault Tolerance
c3, c8
4.6. Executable Models
4.7. State-Based and 
Table-Driven Construction 
Techniques
c18
4.8. Runtime 
Configuration and 
Internationalization
c3, c10
4.9. Grammar-Based Input 
Processing
c5c8
4.10. Concurrency 
Primitives
c6
4.11. Middlewarec1c8
4.12. Construction 
Methods for Distributed 
and Cloud-Based Software
c17, 
c18
c2
4.13. Constructing 
Heterogeneous Systems
c9
4.14. Performance Analysis 
and Tuning
c25, c26
4.15. Platform Standardscc10c1
4.16. Test-First 
Programming
c22c8
4.17. Feedback Loop for 
Construction
c3, 
c16
5. Software 
Construction Tools
5.1. Development 
Environments
c30
5.2. Visual Programming 
and Low-Code/Zero-
Code Platforms
c30
5.3. Unit Testing Toolsc22c8
5.4. Profiling, Performance 
Analysis and Slicing Tools
c25, c26

4-18   SWEBOK
®
 GUIDE V4.0
FURTHER READINGS
IEEE   Std.   1517-1999:   IEEE   Standard   for   
Information   Technology--Software   Life   Cycle   
Processes--Reuse Processes, IEEE, 1999 [8].
This  standard  specifies  the  processes,  activi-
ties, and tasks to be applied during each phase 
of  the  software  life  cycle  to  enable  a  soft-
ware product to be constructed from reusable 
assets.  It  covers  the  concept  of  reuse-based  
development  and  the  processes  of  construc-
tion for reuse and construction with reuse.
ISO/IEC           12207:2008:           Information           
Technology--Software Life Cycle Processes, ISO/
IEC, 2008 [9].
This  standard  defines  a  series  of  software  
development   processes,   including   software   
construction   process,   software   integration   
process, and software reuse process.
Martin    Fowler,    Kent    Beck.    Refactoring:    
Improving    the    Design    of    Existing    Code    
(2nd    Edition),        Addison-Wesley    Signature    
Series (Fowler).
Robert  C.  Martin.Clean  Code:  A  Handbook  
of    Agile    Software    Craftsmanship,    Pearson    
Education, Inc.
REFERENCES
[1]   S. McConnell, Code Complete, 2nd edition, 
Redmond, WA: Microsoft Press, 2004.
[2] I. Sommerville, Software Engineering, 
10th edition, Addison-Wesley, 2016.
[3] G. Kim et al., The DevOps Handbook: 
How to Create World-Class Agility, 
Reliability & Security in Technology 
Organizations, 2nd edition, IT 
Revolution, 2021.
[4] H. Heitkötter, S. Hanschke, and T.A. 
Majchrzak, Evaluating Cross-Platform 
Development Approaches for Mobile 
Applications, 2013, in Cordeiro, J., 
Krempels, K.H. (eds.), Web Information 
Systems and Technologies. WEBIST 
2012. Lecture Notes in Business 
Information Processing, vol. 140, 
Springer, Berlin, Heidelberg.
[5]  P. Clements et al., Documenting Software 
Architectures: Views and Beyond, 2nd edi-
tion, Boston: Pearson Education, 2010.
[6] E. Gamma et al., Design Patterns: 
Elements of Reusable Object-Oriented 
Software, 1st edition, Reading, MA: 
Addison-Wesley Professional, 1994.
[7] S.J. Mellor and M.J. Balcer, Executable 
UML: A Foundation for Model-Driven 
Architecture, 1st edition, Boston: 
Addison-Wesley, 2002.
[8] L. Null and J. Lobur, The Essentials of 
Computer Organization and Architecture, 
2nd edition, Sudbury, MA: Jones and 
Bartlett Publishers, 2006.
[9] A. Silberschatz et al., Operating System 
Concepts, 8th edition, Hoboken, NJ: 
Wiley, 2008.

5-1 
CHAPTER 05
Software Testing
ACRONYMS
AIArtificial Intelligence
APIApplication Program Interface 
ARINCAeronautical Radio Incorporated
ATDDAcceptance Test-Driven 
Development
CMMICapability Maturity Model 
Integration 
CSSCascading Style Sheets 
DICOMDigital Imaging and 
Communications in Medicine
DLDeep Learning 
DUDefinition and Use
EBSEEvidence-Based Software 
Engineering 
ECSEcosystem
ETSIEuropean Telecommunications 
Standards Institute 
FHIRFast Healthcare Interoperability 
Resources 
GDPRGeneral Data Protection 
Regulation 
GPSGlobal Positioning System
GUIGraphical User Interface 
HILHardware-In-the-Loop 
H I PA AHealth Insurance Portability and 
Accountability Act 
HL7Health Level Seven 
IoTInternet of Things 
KPIKey Performance Indicator
MC/DCModified Condition 
Decision Coverage
MLMachine Learning 
MTTRMean Time to Recovery 
OATOrthogonal Array Testing
ODCOrthogonal Defect Classification
SoSSystem of Systems
SPISoftware Process Improvement 
SPICESoftware Process Improvement 
and Capability Determination 
SUTSystem Under Test
TDDTest-Driven Development
TMMiTest Maturity Model integration
UIUser Interface
UPUnified Process
INTRODUCTION 
Software testing consists of the dynamic vali-
dation that a system under test (SUT) provides 
expected  behaviors  on  a  finite  set  of  test  cases 
suitably selected from the usually infinite exe-
cution domain. 
In  the  above  statement,  italicized  words  
correspond  to  key  issues  in  the  Software  
Testing  knowledge  area  (KA).  Those  terms  
are discussed below.
• System  Under  Test:  This  term  can  refer  to  
the  tested  object,  which  could  be  a  pro-
gram,  a  software  product,  an  applica-
tion,  a  service-oriented  application  (e.g.,  
web  services,  microservices),  middleware  
(HW/SW),   a   services   composition,   a   
system, a System of Systems (SoS), or an 
Ecosystem (ECS).
• Test  Case:  A  test  case  is  the  specification  
of all the entities that are essential for the 
execution, such as input values, execution 

5-2   SWEBOK
®
 GUIDE V4.0
and timing conditions, testing procedure, 
and  the  expected  outcomes  (e.g.,  pro-
duced values, state changes, output mes-
sages).  Input  values  alone  are  not  always  
sufficient to specify the test cases because 
the  SUT  might  react  to  the  same  input  
with  different  behaviors,  depending,  for  
instance,  on  the  SUT  state  or  environ-
mental  conditions.  A  set  of  test  cases  is  
usually called a test suite.
• Dynamic:  Dynamic  validation  requires  
executing the SUT on a test suite. Static 
techniques complement dynamic testing, 
and  they  are  covered  in  the  Software  
Quality KA.
1
 
• Finite: Even  in  a  simple  SUT,  executing  
all  the  possible  test  cases  (i.e.,  exhaus-
tive  testing)  could  require  months  or  
years.  Consequently,  in  practice,  testing  
targets  a  subset  of  all  possible  test  cases  
determined  by  different  criteria.  Testing  
always  implies  a  trade-off  between  lim-
ited  resources  and  schedules  on  the  one  
hand    and    inherently    unlimited    test    
requirements on the other.
• Selected: Identifying   the   most   suitable   
selection  criteria  under  given  conditions  
is  a  complex  problem.  Different  tech-
niques  can  be  considered  and  combined  
to tackle that problem, such as risk anal-
ysis,  software  requirements,  cost  reduc-
tion,    quality    attributes    satisfaction,    
prioritization,  and  fault  detection.  The  
many  proposed  test  techniques  differ  in  
how  the  test  suite  is  selected,  and  soft-
ware  engineers  must  be  aware  that  dif-
ferent selection criteria might yield vastly 
different degrees of effectiveness. 
• Expected:  For  each  executed  test  case,  it  
must  be  possible,  although  it  might  not  
be  easy,  to  decide  whether  the  observed  
SUT  outcomes  match  the  expected  ones.  
Indeed,  the  observed  behavior  may  be  
checked  against  user  needs  (commonly  
referred to as testing for validation), against 
a specification (testing for verification), or, 
1  It is worth noting that terminology is not uniform among different communities, and some use the 
term testing to refer to static techniques as well.
perhaps,  against  the  foreseen  behavior  
from implicit requirements or expectations. 
(See  Section  4.3,  Acceptance  Criteria-
Based  Requirements  Specification,  in  the  
Software Requirements KA.) 
As  reflected  in  this  discussion,  software  
testing  is  a  pervasive  and  holistic  activity  
involving  all  the  steps  of  any  process  devel-
opment life cycle (e.g., traditional or shift-left 
development).  The  remainder  of  this  chapter  
presents the basics of software testing and its 
challenges,  issues,  and  commonly  accepted  
practices and solutions. 
BREAKDOWN OF TOPICS FOR 
SOF TWARE TESTING 
Figure  5.1  shows  the  breakdown  of  topics  
for  the  Software  Testing  KA.  The  Matrix  
of  Topics  vs.  Reference  Material  provides  
a  more  detailed  breakdown  at  the  end  of  
this  KA.  The  first  topic,  Software  Testing  
Fundamentals, covers the basic definitions in 
software  testing,  the  basic  terminology  and  
key issues, and software testing’s relationship 
with other activities.
The  second  topic,  Test  Levels,  contains  
two (orthogonal) subtopics. The first subtopic, 
The  Target  of  the  Test,  lists  the  levels  into  
which  the  testing  of  large  software  is  tradi-
tionally subdivided, and the second subtopic, 
Objectives  of  Testing,  discusses  testing  for  
specific conditions or properties. Not all types 
of testing apply to every software product, nor 
has every possible type been listed. The Target 
of the Test and Objectives of Testing together 
determine how the test suite is identified, both 
regarding its consistency (How much testing 
is enough for achieving the stated objective?) 
and its composition (Which test cases should 
be  selected  for  achieving  the  stated  objec-
tive?).  (However,  usually,  “for  achieving  the  
stated  objective”  remains  implicit,  and  only  
the  first  part  of  the  two  questions  above  is  

SOFTWARE TESTING   5-3
posed.) Criteria for addressing the first ques-
tion  are  test  adequacy criteria,  whereas  those  
used  for  addressing  the  second  question  are  
the test selection criteria.
Several  Test  Techniques  have  been  devel-
oped  in  the  past  few  decades,  and  new  ones  
are  still  being  proposed.  Therefore,  the  third  
topic covers generally accepted and standard-
ized techniques.
Test-Related  Measures  are  dealt  with  in  
the  fourth  topic,  while  the  issues  relative  to  
the Test Process are covered in the fifth. 
Software   Testing   in   the   Development   
Processes  and  the  Application  Domains  is  
described  in  the  sixth  topic,  and  Testing  of  
and Testing Through Emerging Technologies 
are  described  in  the  seventh  topic.  Finally,  
Software   Testing   Tools   are   presented   in   
topic eight.
1. Software Testing Fundamentals
[1*, c1, c2; 2*, c8; 14*, c7]
This section provides an overview of the main 
testing  issues  and  the  relationship  of  testing  
to  the  other  activities.  Most  of  the  testing  
terms  used  here  are  also  defined.  A  more  
comprehensive  overview  of  the  testing  and  
testing-related  terminology  can  be  found  in  
the cited references.
1.1 Faults vs. Failures 
[1*, c1s5; 2*, c1; 14*, c1s3]
Many  terms  are  used  in  the  software  engi-
neering  literature  to  describe  a  malfunction:  
notably fault (see,  for  comparison,  defect in 
Section  3.2,  Defect  Characterization,  in  the  
Software Quality KA), failure and error. It is 
essential to distinguish between the cause of a 
malfunction (for which the term fault is used 
here) and an undesired effect observed in the 
system’s  delivered  service  (a  failure).  Indeed,  
there might well be faults in the software that 
never  manifest  as  failures.  (See  Theoretical  
and   Practical   Limitations   of   Testing   in   
Section  1.2.8.)  Thus,  testing  can  reveal  fail-
ures, but the faults causing them are what can 
and  must  be  removed.  However,  a  failure’s  
cause  cannot  always  be  unequivocally  iden-
tified.  No  theoretical  criteria  exist  to  defin-
itively  determine,  in  general,  the  fault  that  
caused  an  observed  failure.  The  fault  might  
have to be modified to remove the failure, but 
Software
Testing
Software
Testing
Fundamentals
Software Testing
in the Development 
Processes and the 
Application Domains
Faults vs. 
Failures
Key Issues
Relationship 
of Testing to 
other Activities
e Target 
of the Test
Objectives of 
Testing
Specification-
Based
Techniques
Structure-
Based Test 
Techniques
Experience-Based
Techniques
Fault-Based 
and Mutation 
Techniques
Techniques Based 
on the Nature of 
the Application
Selecting and 
Combining 
Techniques
Techniques 
Based on Derived 
Knowledge
Evaluation of 
the SUT
Evaluation of the 
Test Performed
Practical 
Considerations
Test Sub-
Processes
 and Activities
Staffing
Testing Inside 
Software
Development 
Process
Testing in the
Application 
Domains
Test LevelsTest Techniques
Test-Related
Measures
Test Process
Testing of and 
Testing rough
Emerging 
Technologies
Testing of 
Emerging 
Technologies
Testing rough
Emerging 
Technologies
Software 
Testing
Tools
Testing Tool
Support and 
Selection
Categories 
of Tools
Figure 5.1. Breakdown of Topics for the Software Testing KA

5-4   SWEBOK
®
 GUIDE V4.0
other modifications might also work. To avoid 
ambiguity,  we  could  refer  to  failure-causing 
inputs instead of faults — those sets of inputs 
that cause a failure to appear.
1.2. Key Issues
This  subsection  provides  an  overview  of  the  
main testing issues. 
1.2.1. Test Case Creation 
[1*, c12s1, c12s3, 2*, c8]
Test case creation or generation creates the test 
suite  useful  for  testing  the  SUT  for  specific  
purposes  (e.g.,  adequacy,  accuracy,  or  assess-
ment). Because test case generation is among 
the  most  important  and  intensive  software  
testing  activities,  it  is  usually  supported  by  
approaches, techniques, and tools to automate 
the process. 
1.2.2. Test Selection and Adequacy Criteria
[1*, c1s14, c6s6, c12s7, 2*, c8] 
A   test   selection   criterion   is   a   means   of   
selecting  test  cases  or  determining  that  a  
test suite is sufficient for a specified purpose. 
Test  case  selection  aims  to  reduce  the  car-
dinality  of  the  test  suites  while  keeping  the  
same  effectiveness  in  terms  of  coverage  or  
fault  detection  rate.  Test  adequacy  criteria  
can be used to decide when sufficient testing 
is accomplished.
1.2.3 Prioritization/Minimization
[4, part 2, part 3, c5]
Suitable  strategies  for  test  case  selection  or  
prioritization   can   be   adopted   to   improve   
testing  efficacy.  Test  case  prioritization  aims  
to  define  a  test  execution  order  according  to  
some  criteria  (e.g.,  coverage,  fault  detection  
rate, similarity, and risk), so those tests with a 
higher priority are executed before those with 
a  lower  priority.  Test  case  minimization  usu-
ally  aims  to  reduce  a  test  suite  by  removing  
redundant test cases according to some crite-
rion or purpose.
1.2.4. Purpose of Testing
[1*, c13s11, c11s4, 2*, c8]
Different  well-defined  purposes  can  guide  
testing  activity;  it  is  only  by  considering  a  
specific  purpose  that  a  test  suite  can  be  gen-
erated (selected), executed, and evaluated (see 
Section 2 for more details).
1.2.5. Assessment and Certification 
[4, part 1, c5; 2*, c7, c25; 8]
Testing needs to focus on specific (mandatory) 
prescriptions, such as requirements, laws, and 
standards. Test cases should be generated and 
executed  to  provide  evidence  useful  for  eval-
uating  and/or  certifying  adherence  to  the  
selected prescriptions. Usually, assessment and 
certification of the test results include verifying 
that the test cases have been derived and gen-
erated  using  baseline  requirements,  adopting  
a  configuration  control  process,  and  using  
repeatable processes. 
1.2.6. Testing for Quality Assurance/ 
  Improvement  
[1*, c16s2; 4, part 1, c5; 9]
Testing  has  many  aspects,  including  quality  
improvement  and  assurance.  These  charac-
teristics  involve  planned  and  systematic  sup-
porting  processes  and  activities  leveraging  
confidence  that  the  SUT  fulfills  established  
technical   or   quality   requirements.   Thus,   
quality improvement   and   assurance   involve   
defining  methods,  tools,  skills,  and  prac-
tices  to  achieve  the  specific  quality  level  and  
objectives.  The  list  of  the  main  quality  char-
acteristics  that  testing  can  measure  or  assess  
is reported in ISO/IEC 25010:2011 [9]. (See 
also Section 1.3.2, Software Product Quality, 
in the Software Quality KA.)
1.2.7. The Oracle Problem 
[1*, c1s9, c9s7]
An   important   testing   component   is   the   
oracle.  Indeed,  a  test  is  meaningful  only  if  
it is possible to decide its observed outcome. 

SOFTWARE TESTING   5-5
An oracle  can  be  any  human  or  mechanical  
agent that decides whether the SUT behaved 
correctly  in  each  test  and  according  to  the  
expected outcomes. Consequently, the oracle 
provides a “pass” or “fail” verdict. The oracle 
cannot always decide; in these cases, the test 
output is classified as inconclusive. There are 
many kinds of oracles — for example, unam-
biguous  requirements  specifications,  behav-
ioral   models,   and   code   annotations.   The   
automation  of  oracles  can  be  difficult  and  
expensive.
1.2.8. Theoretical and Practical Limitations 
[1*, c 2 s7]
Testing theory warns against ascribing unjus-
tified confidence to a series of successful tests. 
Unfortunately,  most  established  results  of  
the testing theory are negative results in that 
they  state  what  is  not  achieved  as  opposed  
to  what  is  achieved.  The  most  famous  quo-
tation on this point is the Dijkstra aphorism 
that  “program  testing  can  be  used  to  show  
the presence of bugs, but never to show their 
absence”  [3].  The  obvious  reason  for  this  is  
that  complete  testing  is  not  feasible  in  real-
istic software.
1.2.9. The Problem of Infeasible Paths 
[1*, c4 s7]
Infeasible  paths  are  control  flow  paths  that  
cannot be exercised by any input data (i.e., test 
cases). Managing (i.e., identifying, solving  or 
removing) the infeasible paths can help reduce 
the  time  and  resources  devoted  to  testing.  
They  are  a  significant  problem  in  path-based  
testing,  particularly  in  the  automated  deri-
vation  of  test  cases  to  exercise  control  flow  
paths. Additionally, the detection of infeasible 
paths can also play a role in reducing security 
vulnerabilities.
1.2.10. Testability 
[1*, c17s 2]
The  term  software  testability  has  two  related  
but  different  meanings.  On  the  one  hand,  it  
refers to the ease with which a given test cov-
erage  criterion  can  be  satisfied;  on  the  other  
hand, it is defined as the likelihood, possibly 
measured  statistically,  that  a  test  suite  will  
expose a failure if the software is faulty. Both 
meanings are important.
1.2.11 Test Execution and Automation 
[4, part 1, c4]
An  important  challenge  of  testing  is  to  
improve   attainable   automation,   either   
by  developing  advanced  techniques  for  
generating   the   test   inputs   or,   beyond   
test  generation,  by  finding  innovative  sup-
port  procedures  to  (fully)  automate  the  dif-
ferent  testing  activities  —  for  instance,  to  
increase  the  number  of  test  cases  generated  
or executed.
1.2.12. Scalability 
[1*, c 8 s7] 
Scalability is the software’s ability to increase 
and  scale  up  on  its  nonfunctional  require-
ments, such as load, number of transactions, 
and  volume  of  data.  Scalability  is  also  con-
nected to the complexity of the platform and 
environment in which the program runs, such 
as distributed, wireless networks and virtual-
ized  environments,  large-scale  clusters,  and  
mobile clouds.
1.2.13 Test Effectiveness
[1* c1s1; 2* c8s1; 8]
Evaluating  the  SUT,  measuring  a  testing  
technique’s   efficacy,   and   judging   whether   
testing  can  be  stopped  are  important  evi-
dences  for  software  testing,  and  they  may  
require defining and selecting the proper test 
effectiveness measures. 
1.2.14 Controllability, Replication, and  
   Generalization   
[1* c12s12; 4, part 2, c7]
Specific    aspects    of    testing    include    the    
following: 

5-6   SWEBOK
®
 GUIDE V4.0
• Controllability   refers   to   the   transition   
of  testing  activities  from  the  laboratory  
(i.e., controlled conditions) to reality (i.e., 
uncontrolled conditions). 
• Replication  refers  to  the  ability  for  dif-
ferent   people   to   perform   the   same   
testing activities. The purpose is to verify 
whether a given testing theory works, at 
least in the laboratory. 
•    The generalization  of  testing  is  connected  
to  external  validity  —  i.e.,  the  extent  to  
which  the  test  approach  can  be  applied  
to  broader  settings  or  target  populations.  
The generalizability of the software testing 
can be important for managing the testing 
activities  (in  terms  of  cost  and  effort)  and  
increasing confidence in the test results. 
1.2.15. Offline vs. Online Testing
[10 , c 3]
The  testing  process  can  be  executed  in  two  
settings: offline   and   online.   Usually,   the   
SUT  is  validated  in  an  environment  without  
external interaction in offline testing, whereas 
the  SUT  interacts  with  the  real  application  
environment in online testing. The test cases 
are  either  manually  or  automatically  derived  
in both cases, and the expected outcomes are 
used to assess the SUT.
1.3. Relationship of Testing to Other Activities
Software  testing  is  related  to  but  different  
from   static   software   quality   management   
techniques, proofs of correctness, debugging, 
and  program  construction.  However,  it  is  
informative to consider testing from the view-
point  of  software  quality  analysts  and  certi-
fiers. For further discussion, see the following:
•    Testing   vs.   Static   Software   Quality   
Management   Techniques:   See   Section   
2.2.1, Static Analysis Techniques, in the 
Software Quality KA. 
•    Testing     vs.     Quality     Improvement/
Assurance:  See  Section  1.3.2,  Software  
Product    Quality,    in    the    Software    
Quality KA.
•    Testing    vs.    Correctness    Proofs    and    
Formal  Verification:  See  the  Software  
Engineering Models and Methods KA.
•    Testing vs. Debugging: See Construction 
Testing in the Software Construction KA 
and Debugging Tools and Techniques in 
the Computing Foundations KA.
•    Testing  vs.  Program  Construction:  See  
Construction  Testing  in the  Software  
Construction KA. 
•    Testing  vs.  Security:  See  the  new  KA:  
Software Security.
•    Testing  vs.  Effort  Estimation:  See  the  
Software Engineering Management KA. 
•    Testing vs. Legal Issues: See the Software 
Engineering Professional Practice KA.
2. Test Levels
[1*, c1s13; 2*, c8s1]
Software  testing  is  usually  performed  at  dif-
ferent levels   throughout   development   and   
maintenance.   Levels   can   be   distinguished   
based  on  the  object  of  testing,  the  target,  or  
on the purpose or objective (of the test level). 
2.1. The Target of the Test 
[1*, c1s13, 2*, c8s1]
The  target  of  the  test  can  vary  depending  
on  the  SUT,  the  conditions  of  the  environ-
ment,  and  the  budget/time  devoted  to  the  
testing activity. Four test stages can be distin-
guished: unit, integration, system, and accep-
tance.  These  four  test  stages  do  not  imply  
any  development  process,  nor  is  any  one  of  
them assumed to be more important than the 
other three. 
2.1.1. Unit Testing 
[1*, c3, 2*, c8] 
Unit testing verifies the functioning in isola-
tion of SUT elements that are separately test-
able.  Depending  on  the  context,  these  could  
be the individual subprograms or components, 
a  subsystem,  or  a  composition  of  SUT  com-
ponents. Typically, but not always, the person 
who wrote the code conducts the unit testing. 

SOFTWARE TESTING   5-7
2.1.2. Integration Testing 
[1*, c7, 2*, c8]
Integration   testing   verifies   the   interac-
tions  among  SUT  elements  (for  instance,  
components,    modules,    or    subsystems).    
Integration   strategies   involve   the   incre-
mental  (and  systematic)  integration  of  the  
SUT elements considering either identified 
functional threads or architecture specifica-
tions.  Typical  integration  testing  strategies  
are  top-down,  bottom-up,  mixed  (or  sand-
wiched),  and  the  big  bang.  They  focus  on  
different perspectives of the level at which 
SUT  elements  are  integrated.  Integration  
testing  is  a  continuous  activity  that  can  
be  performed  at  each  development  stage.  
It  may  target  different  aspects,  such  as  
interoperability (e.g., compatibility or con-
figuration)  of  the  SUT  elements  or  with  
the  external  environment.  External  inter-
faces  to  other  applications,  utilities,  hard-
ware devices or operating environments can 
also be considered.
2.1.3. System Testing 
[1*, c8, 2*, c8]
System  testing  concerns  testing  the  behavior  
of  the  SUT  (according  to  the  definition  of  
Section   1).   Effective   unit   and   integration   
testing  should  have  identified  many  SUT  
defects.  In  addition,  system  testing  is  usu-
ally   considered   appropriate   for   assessing   
non-functional  system  requirements,  such  as  
security,  privacy,  speed,  accuracy,  and  reli-
ability.  (See  Functional  and  Non-Functional  
Requirements  in  the  Software  Requirements  
KA  and  Software  Quality  Requirements  in  
the Software Quality KA.)
2.1.4. Acceptance Testing 
[1*, c1s7, 2*, c8s4]
Acceptance  testing  targets  the  deployment  of  a  
SUT. Its main goal is to verify that the SUT 
satisfies  the  requirements  and  the  end-users’  
expectations.  Generally,  it  is  run  by  or  with  
the end-users to perform those functions and 
tasks  for  which  the  software  was  built.  For  
example,  this  testing  activity  could  target  
usability  testing  or  operational  acceptance.  
Defining   acceptance   tests   before   imple-
menting  the  corresponding  functionality  is  
a  key  activity  of  the  acceptance  test-driven  
development   (ATDD).   (See   the   Software   
Requirements KA, Section 4.3.) 
2.2. Objectives of Testing 
[1*, c1s7]
Testing   is   conducted   considering   specific   
objectives,  which  are  stated  (more  or  less)  
explicitly  and  with  varying  degrees  of  preci-
sion. Stating the testing objectives in precise, 
quantitative terms supports measurement and 
control of the test process.
Testing  can  be  aimed  at  verifying  dif-
ferent  properties.  For  example,  test  cases  
can be designed to check that the functional 
specifications   are   correctly   implemented,   
which  is  variously  referred  to  in  the  liter-
ature  as  conformance  testing,  correctness  
testing or functional testing. However, sev-
eral  other  non-functional  properties  may  
be  tested  as  well,  including  performance,  
reliability,  and  usability.  (See  Models  and  
Quality   Characteristics   in   the   Software   
Qua lit y K A.)
Other important testing objectives include 
but  are  not  limited  to  reliability  measure-
ments,   identification   of   security   and   pri-
vacy vulnerabilities, and usability evaluation; 
different   approaches   would   be   necessary   
depending  on  the  objective.  Note  that,  in  
general, the test objectives vary with the test 
target; different purposes are addressed at dif-
ferent levels of testing.
The  subtopics  listed  below  are  those  most  
cited in the literature.
2.2.1. Conformance Testing
[1*, c10 s 4]
Conformance  testing  aims  to  verify  that  the  
SUT  conforms  to  standards,  rules,  specifi-
cations,  requirements,  design,  processes,  or  
practices. 

5-8   SWEBOK
®
 GUIDE V4.0
2.2.2 Compliance Testing
[1*, c1 2 s 3]
Compliance  testing  aims  to  demonstrate  the  
SUT’s   adherence   to   a   law   or   regulation.   
Usually,  compliance  testing  is  forced  by  an  
external regulatory body.
2.2.3. Installation Testing 
[1*, c1 2 s 2]
Often, after system and acceptance testing is 
completed, and the SUT has been installed in 
the  target  environment,  the  SUT  is  verified.  
Installation  testing  can  be  viewed  as  system  
testing conducted in the operational environ-
ment  of  hardware  configurations  and  other  
operational  constraints.  Installation  proce-
dures may also be verified.
2.2.4. Alpha and Beta Testing 
[1*, c13s7, c16s6, 2*, c8s4]
Before  the  SUT  is  released,  it  is  sometimes  
given  to  a  small,  selected  group  of  potential  
users  for  trial  use  (alpha testing)  and/or  to  a  
larger set of representative users (beta testing). 
These users report problems with the product. 
Alpha   testing   and   beta   testing   are   often   
uncontrolled and are not always referred to in 
a test plan.
2.2.5. Regression Testing 
[1*, c8s11, c13s3; 4, part 1, c5]
According  to  the  definition  reported  in  [5],  
regression  testing  is  the  “selective  retesting  of  
a  SUT  to  verify  that  modifications  have  not  
caused  unintended  effects  and  that  the  SUT  
still complies with its specified requirements.” 
In practice, the approach is designed to show 
that the SUT still passes previously passed tests 
in a test suite (in fact, it is sometimes referred 
to  as  non-regression testing).  In  some  cases,  a  
trade-off  must  be  made  between  the  assur-
ance  given  by  regression  testing  every  time  a  
change is made and the resources required to 
perform the regression tests. This can be quite 
time-consuming  because  of  the  many  tests  
that  might  be  executed.  Regression  testing  
can  be  conducted  at  each  test  level  described  
in  Section  2.1.  It  may  involve  functional  and  
non-functional   testing,   such   as   reliability,   
accessibility,  usability,  maintainability,  con-
version, migration, and compatibility testing.
Regression  testing  may  involve  selection  
(see  Section  1.2.2)  and  minimization  (see  
Section  1.2.3)  of  test  cases,  as  well  as  the  
adoption   of   prioritization   approaches   (see   
Section 2.2.6) to existing test suites.
Regression testing is a fundamental activity 
of  Agile,  DevOps,  test-driven  development  
(TDD),  and  Continuous  Development.  It  is  
usually performed after integration testing and 
before deployment to production or operation. 
2.2.6. Prioritization Testing 
[1*, c1 2 s7]
Test  case  prioritization  aims  to  schedule  test  
cases  to  increase  the  rate  and  likelihood  of  
fault  detection,  the  coverage  of  code  under  
test, and the SUT’s reliability. Typically, pri-
oritization  testing  relies  on  heuristics,  and  
its  performance  might  vary  according  to  the  
SUT, the environment, and the available test 
cases.   Among   the   different   prioritization   
proposals,  similarity-based  prioritization  is  
one  of  the  most  commonly  adopted.  In  this  
approach  to  prioritization,  test  cases  are  pri-
oritized  starting  from  those  most  dissimilar  
according to a predefined distance function.
2.2.7. Non-functional Testing 
[2*, c8]
Non-Functional  testing  targets  the  validation  
of  non-functional  aspects  (such  as  perfor-
mance, usability, or reliability), and it is per-
formed  at  all  test  levels.  At  the  state  of  the  
practice, there are hundreds of non-functional 
testing  techniques  that  include  but  are  not  
limited to the following: 
•    Performance     Testing     [4,     part     1]:     
Performance   testing   verifies   that   the   
software meets the specified performance 
requirements  and  assesses  performance  

SOFTWARE TESTING   5-9
characteristics      (e.g.,      capacity      and      
response time).
•    Load  Testing  [4,  part  1]:  Load  testing  
focuses on validating the SUT’s behavior 
under  load  pressure  conditions  to  dis-
cover  problems  (e.g.,  deadlocks,  racing,  
buffer  overflows  and  memory  leaks)  or  
reliability,  stability,  or  robustness  viola-
tions.  It  aims  to  assess  the  rate  at  which  
different  service  requests  are  submitted  
to the SUT.
•    Stress  Testing  [1*,  c8s8]:  Stress  testing  
aims  to  push  the  SUT  beyond  its  capa-
bilities by generating a load greater than 
what the system is expected to handle.
•    Volume   Testing   [4,   part   1]:   Volume   
testing   targets   the   assessment   of   the   
SUT’s internal storage limitations and its 
ability to exchange data and information.
•    Failover   Testing   [1*,   c17s2;   2*,   c8]:   
Failover   testing   validates   the   SUT’s   
ability  to  manage  heavy  loads  or  unex-
pected  failure  to  continue  typical  opera-
tions (e.g., by allocating extra resources). 
Failover  testing  is  also  connected  with  
recoverability validation.
•    Reliability   Testing   [1*,   c15;   2*,   c11]:   
Reliability  testing  evaluates  the  SUT’s  
reliability  by  identifying  and  correcting  
faults.  Reliability  testing  observes  the  
SUT  in  operation  or  exercises  the  SUT  
by  using  test  cases  according  to  statis-
tical  models  (operational  profiles)  of  the  
different  users’  behaviors.  Usually,  reli-
ability   is   assessed   through   reliability   
growth  models.  The  continuous  devel-
opment  processes  (such  as  DevOps)  are  
currently facilitating the adoption of reli-
ability testing in the various iterations for 
improving final SUT quality.
•    Compatibility Testing [4, part 1; 10, c3]: 
Compatibility  testing  is  used  to  verify  
whether the software can collaborate with 
different hardware and software facilities 
or with different versions or releases.
•    Scalability   Testing   [1*,   c8s7;   2*   c17]: 
Scalability   testing   assesses   the   soft-
ware’s  ability  to  scale  up  non-functional  
requirements  such  as  load,  number  of  
transactions,  volume  of  data.  It  could  
integrate  or  extend  load,  elasticity  and  
stress testing.
•    Elasticity  Testing  [17]:  Elasticity  testing  
assesses  the  ability  of  the  SUT  (such  as  
cloud  and  distributed  systems)  to  rap-
idly  expand  or  shrink  compute,  memory,  
and  storage  resources  without  compro-
mising  the  capacity  to  meet  peak  utili-
zation.  Some  elasticity  testing  objectives  
are  to  control  behaviors,  to  identify  the  
resources to be (un)allocated, and to coor-
dinate events in parallel.
•    Infrastructure   Testing   [8,   annex   H]:   
Infrastructure testing tests and validates 
infrastructure  components  to  reduce  the  
chances  of  downtime  and  improve  the  
performance of the IT infrastructure.
•    Back-to-Back   Testing   [5]:   ISO/IEC/
IEEE 24765 defines back-to-back testing 
as  “testing  in  which  two  or  more  vari-
ants  of  a  program  are  executed  with  
the  same  inputs,  the  outputs  are  com-
pared, and errors are analyzed in case of 
discrepancies.”
•    Recovery  Testing  [1*,  c14s2]:  Recovery  
testing  is  aimed  at  verifying  software  
restart capabilities after a system crash or 
other disaster.
2.2.8. Security Testing 
[2*, c13; 4, part 4, annex A]
Security  testing  focuses  on  validating  that  
the SUT is protected from external attacks. 
More  precisely,  it  verifies  the  confidenti-
ality,  integrity,  and  availability  of  the  sys-
tems and their data. Usually, security testing 
includes validation against misuse and abuse 
of the software or system (negative testing). 
(See   Security   Testing   in   the   Software   
Security KA.)
2.2.9. Privacy Testing 
[2*, c13, c14]
Privacy  testing  is  devoted  to  assessing  the  
security   and   privacy   of   users’   personal   
data  to  prevent  local  attacks.  It  specifically  

5-10   SWEBOK
®
 GUIDE V4.0
assesses   privacy   and   information-sharing   
policies,  as  well  as  the  validation  of  decen-
tralized management of users’ social profiles 
and  data  storage  solutions.  (See  Legal  Issue  
in   the Software  Engineering  Professional  
Practice K A.)
2.2.10. Interface and Application Program  
 Interface (API) Testing 
[2*, c8s1; 14*, c7s12; 4, part 5, c4, c7]
Interface defects are common in complex sys-
tems. Interface  testing  aims  to  verify  whether  
the components’ interface provide the correct 
exchange  of  data  and  control  information.  
Usually, the test cases are generated from the 
interface  specification.  A  specific  interface  
testing objective is to simulate the use of APIs 
by  end-user  applications.  That  involves  gen-
erating  parameters  of  the  API  calls,  setting  
conditions  of  the  external  environment,  and  
defining internal data that affect the API. 
2.2.11. Configuration Testing 
[1*, c8s5]
Where  the  SUT  is  built  to  serve  different  
users, configuration testing verifies the software 
under specified configurations.
2.2.12. Usability and Human-Computer  
 Interaction Testing 
[2* c8s4; 19*, c6; 4, part 4, annex A]
The  main  task  of  usability  and  human-com-
puter  interaction  testing  is  to  evaluate  how  
easy  it  is  for  end-users  to  learn  to  use  the  
software.  It  might  involve  testing  the  soft-
ware  functions  that  support  user  tasks,  the  
documentation that aids users, and the sys-
tem’s  ability  to  recover  from  user  errors.  
(See User-Centered Design in the Software 
Design K A.)
3. Test Techniques 
[1*, c1s15; 4, part 4]
Over  the  years,  different  testing  techniques  
have  been  developed  to  increase  the  SUT’s  
overall  quality  [4,  part  4].  These  techniques  
attempt to propose systematic procedures and 
approaches  for  generating  or  selecting  the  
most suitable test suites for detecting as many 
failures as possible.
Testing  techniques  can  be  classified  by  
considering   different   key   aspects   such   as   
specification,  structure,  and  experience  [4,  
part 4]. Additional classification sources can 
be  the  faults  to  be  discovered,  the  predicted  
use,  the  models,  the  nature  of  the  applica-
tion, or the derived knowledge. For instance, 
model-based testing [7; 4, part 1] refers to all 
the  testing  techniques  that  use  the  concept  
of  a  model  representing  behavioral  specifi-
cation,  the  SUT’s  structure,  or  the  available  
knowledge  and  experience.  However,  classi-
fication overlapping is possible, and one cate-
gory might deal with combining two or more 
techniques.
Alternative  classifications  that  rely  on  
the  degree  of  information  about  the  SUT  
are  available  in  the  literature.  Indeed,  in  
the   specification-based   techniques,   also   
known  as  black-box  techniques,  the  gen-
eration  of  test  cases  is  based  only  on  the  
SUT’s  input/output  behavior,  whereas  in  
the  structure-based,  also  called  white-box 
(or glass-box  or  clear-box),  techniques,  the  
test  cases  are  generated  using  the  infor-
mation   about   how   the   SUT   has   been   
designed or coded.
As   some   testing   techniques   are   used   
more  than  others,  the  remainder  of  the  sec-
tion presents the standard testing techniques 
and  those  commonly  adopted  at  the  state  of  
the practice.
3.1. Specification-Based Techniques
[1*, c6s2; 4, part 4]
The underlying idea of specification-based tech-
niques (sometimes also called domain testing 
techniques)  is  to  select  a  few  test  cases  from  
the input domain that can detect specific cat-
egories  of  faults  (also  called  domain  errors).  
These  techniques  check  whether  the  SUT  
can manage inputs within a certain range and 
return the required output.

SOFTWARE TESTING   5-11
3.1.1. Equivalence Partitioning 
[1*, c 9s 4]
Equivalence partitioning involves partitioning 
the input domain into a collection of subsets 
(or  equivalence  classes)  based  on  a  specified  
criterion  or  relation.  This  criterion  or  rela-
tion may be different computational results, a 
relation based on control flow or data flow, or 
a distinction made between valid inputs that 
are  accepted  and  processed  by  the  SUT  and  
invalid  inputs,  such  as  out-of-range  values,  
that  are  not  accepted  and  should  generate  
an error message or initiate error processing. 
A  representative  test  suite  (sometimes  con-
taining  only  one  test  case)  is  usually  taken  
from each equivalence class.
3.1.2. Bounday Value Analysis 
[1*, c9s5; 4, part 4]
Test  cases  are  chosen  on  or  near  the  bound-
aries of the input domain of variables, with the 
underlying rationale that many faults tend to 
concentrate near the extreme values of inputs. 
An  extension  of  this  technique  is  robustness 
testing, wherein test cases are also chosen out-
side the input domain of variables to test pro-
gram robustness in processing unexpected or 
erroneous inputs. 
3.1.3. Syntax Testing
[1*, c10s11, 2*, c5; 4, part 4] 
The Syntax Testing techniques, also known 
as   formal   specification-based   techniques,   
rely  on  the  SUT  specifications  in  a  formal  
language.   (See   Formal   Methods in   the   
Software Engineering Models and Methods 
KA.) This representation permits automatic 
derivation of functional test cases and, at the 
same  time,  provides  an  oracle  for  checking  
test results. 
3.1.4. Combinatorial Test Techniques 
[1*, c9s3; 4, part 4]
The  Combinatorial  Test  Techniques  system-
atically derive the test cases that cover specific 
parameters of values or conditions. According 
to  [4,  part  4],  the  commonly  used  combina-
torial  test  techniques  are  All  combinations  
Testing,   Pair-Wise   Testing,   Each   Choice   
Testing, and Base Choice Testing. All combi-
nations testing focuses on all the possible input 
combinations,  whereas  its  subset,  also  called  
t-wise testing, considers every possible combi-
nation of t input. In this case, more than one 
pair is derived (i.e., by including higher-level 
combinations).  Pair-wise  testing  is  a  specific  
combinatorial  testing  technique  where  test  
cases are derived by combining values of every 
pair of an input set. These techniques are also 
known as orthogonal array testing (OAT). 
3.1.5. Decision Table
[1*, c9s6; 1*, c13s6; 4, part 4]
Decision tables (or trees) represent logical rela-
tionships between conditions (roughly, inputs) 
and  actions  (roughly,  outputs).  Usually,  they  
are widely adopted for knowledge representa-
tion (e.g., machine learning (ML)). Test cases 
are   systematically   derived   by   considering   
every   possible   combination   of   conditions   
and   their   corresponding   resultant   actions.   
A  related  technique  is  cause-effect  graphing. 
Currently,  shift-left  development  processes  
are  taking  advantage  of  this  kind  of  testing  
technique because these techniques are useful 
for  documenting  the  test  results  and  factors  
that can affect them.
3.1.6. Cause-Effect Graphing
[1*, c1s6; 4, part 3, part 4]
Cause-effect  graphing  techniques  rely  on  log-
ical  networks  that  map  a  set  of  causes  to  a  
set  of  effects  by  systematically  exploring  the  
possible  combinations  of  input  conditions.  
They  identify  the  effects  and  link  the  effects  
to their causes through model graphs. Cause-
effect graphing techniques are used in testing 
because they allow specification analysis, the 
identification of the relevant input conditions 
or  causes,  the  consequent  transformations,  
and the output conditions.

5-12   SWEBOK
®
 GUIDE V4.0
3.1.7. State Transition Testing 
[1*, c10; 4, part 4]
Techniques  based  on  Finite-State  Machines  
(State   Transition   Testing   techniques   in   [4,   
part 4]) focus on representing the SUT with 
a  finite-state  machine.  In  this  case,  the  test  
suite  is  derived  to  cover  the  states  and  tran-
sitions according to a specific coverage level. 
3.1.8. Scenario-Based Testing 
[2*, c8s3, c19s3; 4, part 4; 7]
A model in this context is an abstract (formal) 
representation  of  the  SUT  or  its  software  
requirements.  (See  Modeling  in  the  Software  
Engineering   Models   and   Methods   KA.)   
Scenario-based testing is used to validate require-
ments,  check  their  consistency,  and  generate  
test  cases  focused  on  the  SUT’s  behavioral  
aspects. (See Types of Models in the Software 
Engineering  Models  and  Methods  KA.)  The  
key  components  of  scenario-based  testing  are  
the notation used to represent the model of the 
software or its requirements, workflow models 
or similar models, the test strategy or algorithm 
used  for  test  case  generation,  the  supporting  
infrastructure  for  the  test  execution,  and  the  
evaluation of test results compared to expected 
results. Because of the complexity of the tech-
niques,  scenario-based  testing  approaches  are  
often used with test automation harnesses. 
Among  scenario-based  testing,  workflow  
models can also be used to graphically represent 
the sequence of activities performed by humans 
and/or software applications. In this case, each 
sequence  of  actions  constitutes  one  workflow  
(also called a scenario). Usually, it is important 
to ensure that both typical and alternate work-
flows  are  also  tested.  For  example,  business  
process  testing  is  part  of  this  scenario-based  
technique. In this case, the special focus is on 
the roles in a workflow specification. 
3.1.9. Random Testing 
[1*, c9s7; 4, part 4]
In  this  approach,  test  cases  are  generated  
purely  at  random.  This  testing  falls  under  
the heading of input domain testing because 
the input domain must be known to be able 
to  pick  random  points  within  it.  Random 
testing provides a relatively simple approach 
to   test   automation.   Enhanced   forms   of   
random  testing  (such  as  adaptive  random  
testing)  have  been  proposed  in  which  other  
input  selection  criteria  direct  the  random  
input sampling.
Currently, under the name of fuzz testing, 
the  random  selection  of  invalid  and  unex-
pected inputs and data is extensively used in 
cybersecurity to find hackable software bugs, 
coding  errors,  and  security  loopholes.  (See  
also Sections 2.2.8 and 8.2.)
3.1.10. Evidence-Based  [10 , c 6 s 2]
Evidence-based  software  engineering  (EBSE),  
which  follows  a  rigorous  research  approach,  
is  the  best solution  for  a  practical  problem.  
EBSE includes the following phases: 
•    Identifying  the  evidence  and  forming  
a question
•    Tracking   down   the   best   evidence   to   
answer the question
•    Critically analyzing the evidence in light 
of  the  problem  that  the  evidence  should  
help solve.
•    EBSE  principles  can  also  be  applied  to  
the testing process. For that purpose, the 
widely  used  approaches  that  allow  iden-
tifying   and   aggregating   evidence   are   
systematic  mapping  studies  and  system-
atic reviews.
3.1.11. Forcing Exception 
[5] 
Test   cases   are   specifically   conceived   for   
checking  whether  the  SUT  can  manage  a  
predefined  set  of  exceptions/errors,  such  as  
data exception, operation exception, overflow 
exception, protection exception or underflow 
exception.  Testing  techniques  usually  focus  
on  negative  test  scenarios  (i.e.,  test  cases  
that are able to force the generation of error 
messages).

SOFTWARE TESTING   5-13
3.2. Structure-Based Test Techniques
[4, part 4] 
Structure-Based   Test   Techniques   (sometimes   
called code-based   test   techniques)   focus   on   
the  code  and  its  structure.  Structure-Based  
Test  Techniques  can  be  performed  at  dif-
ferent levels (such as code development, code 
inspection,  or  unit  testing)  and  can  include  
static  testing  (such  as  code  inspection,  code  
walkthrough,   and   code   review),   dynamic   
testing (like statement coverage, branch cov-
erage, and path coverage), or code complexity 
measurement (e.g., using techniques like cyc-
lomatic complexity [12]). 
3.2.1. Control Flow Testing 
[1*, c4; 4, part 4]
Control  flow  testing  covers  all  the  statements,  
branches,  decisions,  branch  conditions,  mod-
ified  condition  decision  coverage  (MC/DC),  
blocks of statements, or specific combinations 
of  statements  in  a  SUT.  The  strongest  of  the  
control  flow-based  criteria  is  path  testing,  
which  aims  to  execute  all  entry-to-exit  con-
trol flow paths in a SUT’s control flow graph. 
Because  exhaustive  path  testing  is  generally  
not feasible because of loops, other less strin-
gent  criteria  focus  on  coverage  of  paths  that  
limit  loop  iterations,  such  as  statement  cov-
erage, branch coverage, and condition/decision 
testing. The adequacy of such tests is measured 
in percentages; for example, when all branches 
have  been  executed  at  least  once  by  the  tests,  
100% branch coverage has been achieved.
3.2.2. Data Flow Testing 
[1*, c5; 4, part 4]
In data  flow  testing,  the  control  flow  graph  is  
annotated  with  information  about  how  the  
variables are defined, used, and killed (unde-
fined).  Commonly  adopted  data  flow  testing  
techniques  are  All-Definitions  Testing,  All-
C-Uses  Testing,  All-P-Uses  Testing,  All-
Uses Testing and All-DU-Paths Testing. The 
strongest data flow testing criterion is the All-
DU-Paths  Testing,  where  all  definition  and  
use  (DU)  paths  need  to  be  covered  [4,  part  
4].  This  is  because  it  requires  executing,  for  
each variable, every control flow path segment 
from  a  definition  of  that  variable  to  the  use  
of that definition. However, weaker strategies 
such as all-definitions and all-uses are used to 
reduce the number of paths required.
3.2.3. Reference Models for Structure-Based Test  
  Techniques  
[1*, c4]
Although  not  a  technique,  a  SUT’s  control  
structure can be graphically represented using 
a  flow  graph  to  visualize  structure-based  test  
techniques.  A  flow  graph  is  a  directed  graph,  
the  nodes  and  arcs  of  which  correspond  to  
program  elements.  (See  Graphs  and  Trees  
in  the  Mathematical  Foundations  KA.)  For  
instance,  nodes  may  represent  statements  or  
uninterrupted  sequences  of  statements,  and  
arcs  may  represent  the  transfer  of  control  
between nodes.
3.3. Experience-Based Techniques
[4, part 1, part 4]
The  generation  of  the  most  suitable  test  suite  
may depend on different factors, such as human 
knowledge of the SUT and its context and the 
tester’s  experience  and  intuition.  In  the  fol-
lowing section, the commonly adopted experi-
ence-based techniques are briefly introduced.
3.3.1. Error Guessing 
[1*, c9s8; 4, part 4]
In error  guessing,  software  engineers  design  
test  cases  specifically  to  anticipate  the  most  
plausible faults in each SUT. Good sources of 
information  are  the  history  of  faults  discov-
ered in earlier projects and the software engi-
neer’s expertise.
3.3.2. Exploratory Testing
[4, part 1]
Exploratory  testing  is  defined  as  simultaneous  
learning,  test  design  and  test  execution.  The  

5-14   SWEBOK
®
 GUIDE V4.0
test  cases  are  not  defined  in  advance  but  are  
dynamically  designed,  executed,  and  modi-
fied  according  to  the  collected  evidence  and  
test results, such as observed product behavior, 
peculiarities of the SUT, the domain and the 
environment, the failure process, the types of 
possible faults and failures, and the risk asso-
ciated with a particular product. Usually, the 
intuition,  knowledge,  and  expertise  of  the  
personnel in charge of performing the explor-
atory  testing  can  affect  the  testing  effective-
ness.  Exploratory  testing  is  widely  used  in  
shift-left  development  (such  as  Agile).  (See  
Section 5.4.2.) 
3.3.3. Further Experience-Based Techniques 
[4, part 4; 13]
At  the  state  of  the  practice,  experience-based 
techniques   may   include   further   approaches   
such as Ad Hoc-based, knowledge-based and 
ML-based testing techniques. 
Ad Hoc testing is a widely used technique in 
which  test  cases  are  derived  by  relying  on  the  
software  engineer’s  skill,  intuition,  and  expe-
rience  with  similar  programs.  It  can  be  useful  
for identifying test cases that are not easily gen-
erated by more formalized techniques. Typical 
Ad Hoc methodologies are the following: 
•    Monkey testing runs randomly generated 
test  cases  to  simulate  rundom  activities  
and cause the program to stop.
•    Pair  (Buddy)  testing  involves  two  indi-
viduals.  One  generates  and  runs  the  test  
cases;  the  other  observes  and  analyzes  
the  testing  process.  Pair  testing  allows  
for generating test cases with broader and 
better test coverage.
•    Gamification   aims   to   convert   testing   
tasks  to  components  of  gameplay.  By  
applying   specific   techniques   (such   as   
engaging  practitioners  or  crowdsourcing  
complex  testing  tasks),  gamification  can  
substantially   improve   software   testing   
practice and, consequently, SUT quality.
•    Quick testing, in which a very small test 
suite  is  selected  and  executed  to  swiftly  
identify critical issues in the SUT.  It aims 
to  enhances  the  probability  of  detecting  
faults early in the development process.
•    Smoke   testing   (also   known   as   Build   
Verification   Testing)   ensures   that   the   
SUT’s  core  functionalities  behave  prop-
erly.  It  also  guarantees  that  the  SUT  is  
operational  before  the  planned  testing  
begins.  In  addition,  smoke  testing  pre-
vents  failures  because  of  the  test  envi-
ronment    (e.g.,    because    artifacts    or    
packages  are  not  properly  built).  Smoke  
testing is also considered a special case of 
quick testing.
Knowledge-based  testing  and  ML-based  
testing  exploit  (formal  or  informal)  knowl-
edge about the SUT or derive it from obser-
vations  of  SUT  executions  for  defining  its  
behavioral   models   (such   as   ontologies   or   
decision  tables)  (see  Section  3.6.1),  rules,  
and  non-functional  properties.  In  addition,  
Knowledge-based   testing   and   ML-based   
testing  specify  the  testing  needs  and  iden-
tify  test  objectives  for  which  test  cases  are  
generated.
3.4. Fault-Based and Mutation Techniques 
[1*, c1s14, 1* c3s5; 5]
With different degrees of formalization, fault-
based testing techniques devise test cases spe-
cifically  to  reveal  likely  or  predefined  fault  
categories.  A  fault  model  can  be  introduced  
that  classifies  the  different  faults  to  better  
focus the test case generation or selection. In 
this context, a variety of platforms and devel-
opment  processes  (e.g.,  waterfall,  spiral  and  
Agile)  consider  the  orthogonal  defect  clas-
sification  (ODC)  a  valid  methodology  for  
collecting  semantic  information  about  the  
different  defects  and  reducing  the  time  and  
effort of the root cause analysis.
Mutation Testing was originally conceived as 
a technique to evaluate test suites (see Section 
4.2, Evaluation  of  the  Tests  Performed)  in  
which  a  mutant  is  a  slightly  modified  ver-
sion  of  the  SUT  (also  called  gold),  differing  
from  it  by  a  small  syntactic  change.  Every  
test  case  exercises  both  the  gold  version  and  

SOFTWARE TESTING   5-15
all generated mutants. If a test case succeeds 
in   identifying   the   difference   between   the   
gold  version  and  a  mutant,  the  latter  is  said  
to  be  “killed.”  The  underlying  assumption  of  
mutation  testing,  the  coupling  effect,  is  that  
more  complex  but  real  faults  will  be  found  
by  looking  for  simple  syntactic  faults.  For  
the  technique  to  be  effective,  many  mutants  
must be automatically generated and executed 
systematically  [6].  Mutation  testing  is  also  a  
testing  criterion  in  itself.  Test  cases  are  ran-
domly  generated  until  enough  mutants  have  
been  killed,  or  tests  are  specifically  designed  
to  kill  surviving  mutants.  In  the  latter  case,  
mutation testing can also be categorized as a 
structure-based  technique.  Mutation  testing  
has  been  used  effectively  for  generating  fuzz  
testing.  A  more  recent  application  of  the  
mutation  process  is  metamorphic  testing,  a  
technique  that  has  become  increasingly  pop-
ular in addressing some ML systems’ testing 
challenges.  In  this  case,  the  modifications  
(called  also  morph)  are  applied  to  the  inputs  
so  a  relationship  can  connect  the  previous  
input  (and  its  output)  to  the  new  morphed  
input (and its output).
3.5. Usage-Based Techniques 
[1*, c1 5s 5 ]
Usage-based  techniques usually rely on a usage 
model  or  profiles.  In  this  case,  the  testing  
environment  needs  to  represent  the  actual  
operational environment, and the sequence of 
test case execution should reproduce the SUT 
usage  by  the  target  stakeholder.  Statistical  
sampling  is  used  for  simulating  the  execu-
tion of many test cases. Thus, sometimes, the 
term random  testing  is  also  associated  with  
these    techniques.    Usage-based    statistical    
testing is applied more during the acceptance 
testing stage.
3.5.1. Operational Profile 
[1*, c15s5, 2*, c11]
Testing  based  on  operational  profiles  aims  at  
generating test cases that might estimate the 
reliability of the SUT or part of it. Therefore, 
the  goal  is  to  infer  from  the  observed  test  
results  the  future  reliability  of  the  software  
(when  it  is  in  use).  Because  the  established  
reliability  strictly  depends  on  the  operating  
profile, the main difficulty (and cost) in using 
this  testing  approach  comes  from  the  opera-
tional  profile  derivation.  Therefore,  one  pos-
sible  solution  is  to  assign  to  the  input  the  
probabilities or profiles according to their fre-
quency of occurrence in actual operation.
3.5.2. User Observation Heuristics
[19*, c5, c7; 4, part 4, annex A]
Specialized   heuristics,   also   called   usability 
inspection  methods,  are  applied  to  systemat-
ically  observe  system  use  under  controlled  
conditions to determine how well people can 
use  the  system  and  its  interfaces.  Usability  
heuristics   include   cognitive   walkthroughs,   
claims  analysis,  field  observations,  thinking  
aloud,  and  even  indirect  approaches  such  as  
user questionnaires and interviews. 
3.6. Techniques Based on the Nature of the 
Application
[2* c16, c17, c18, c20, c21; 14*, c4s8; 8] 
The  above  techniques  apply  to  all  kinds  of  
software. Additional test derivation and exe-
cution  techniques  are  based  on  the  nature  of  
the  software  being  tested.  Examples  are  the  
following: 
•    Object-oriented software 
•    Component-based software
•    Web-based software
•    Concurrent programs 
•    Protocol-based software
•    Communication systems
•    Real-time systems 
•    Safety-critical systems
•    Service-oriented software 
•    Open-source software 
•    Embedded software 
•    Cloud-based software
•    Blockchain-based software
•    Big data-based software
•    AI/ML/DL-based software

5-16   SWEBOK
®
 GUIDE V4.0
•    Mobile apps
•    Security and privacy-preserving software
In  some  cases,  standards  such  as  ISO/
IEC/IEEE  29119  [4,  part  4,  part  5]  pro-
vide examples and support for specifying test 
cases, automating their execution, and main-
taining the test suites, such as the case of the 
Keyword-Driven Testing [4, part 5].
3.7. Selecting and Combining Techniques 
[14*, c7s12; 10; 4, part 5] 
Combining  different  testing  techniques  has  
always been a well-grounded means to assure 
the required level of SUT quality. Currently, 
especially in shift-left developments, method-
ologies  for  adaptive  combinations  of  testing  
techniques  are  part  of  the  state  of  the  prac-
tice. The goal is to improve the effectiveness of 
testing processes by learning from experience 
and, at the same time, adapting the technique 
selection to the current testing session. 
3.7.1. Combining Functional and Structural
[1*, c9; 4, part 5]
Scenario-based    and    structure-based    test    
techniques  are  often  contrasted  as  functional 
vs. structural  testing.  These  two  approaches  
to  test  case  selection  are  nowadays  seen  as  
complements, as they use different sources of 
information  and  have  been  shown  to  high-
light  different  problems.  Depending  on  the  
different   organizational   constraints,   such   
as   budgetary   considerations,   they   could   
be combined.
3.7.2. Deterministic vs. Random 
[1*, c 9s 6]
Test  cases  can  be  selected  in  a  determin-
istic  way,  according  to  many  techniques,  or  
randomly  drawn  from  some  distribution  of  
inputs,  such  as  is  usually  done  in  reliability  
testing. Several analytical and empirical com-
parisons  have  been  conducted  to  analyze  the  
conditions   that   make   one   approach   more   
effective than the other.
3.8. Techniques Based on Derived Knowledge 
[2*, c19, c20; 14*, c7] 
Testing techniques can integrate evidence and 
knowledge  from  different  research  areas  and  
contexts. For this, approaches and methodol-
ogies are used to support testing activity and 
improve  its  effectiveness.  Currently,  innova-
tive approaches include using digital twins or 
simulation  methodologies  and  frameworks,  
exploiting  ML  and  gamification  facilities,  
and using (simulated) neuronal networks.
4. Test-Related Measures
[2*, c24s5; 14*, c10; 4, part 4]
Testing techniques are like tools that help in 
achieving specific test objectives. To evaluate 
whether  a  test  objective  is  reached,  well-de-
fined  measures  are  needed.  Measurement  is  
usually  considered  fundamental  to  quality  
analysis.  Measurement  may  also  be  used  to  
optimize  test  planning  and  execution.  Test  
management can use several different process 
measures  to  monitor  progress.  (See  Software  
Engineering  Measurement  in  the  Software  
Engineering  Management  KA  for  informa-
tion on measurement programs. See Software 
Measurement  in  the  Software  Engineering  
Process KA for information on measures.)
According  to  the  definition  in  [4,  part  4],  
testing techniques can be classified according 
to  the  degree  of  coverage  they  can  achieve.  
Coverage   may   vary   from   0%   to   100%,   
excluding  possible  infeasible  tests  (i.e.,  tests  
that cannot be executed). Thus, for each spec-
ification-based,  structure-based,  and  expe-
rience-based  test  technique,  the  associated  
coverage   measures   and   the   procedure   for   
evaluating that coverage must be determined. 
Examples  of  coverage  measures  could  be  the  
percentage  of  branches  covered  in  the  pro-
gram  flow  graph  or  the  percentage  of  func-
tional  requirements  exercised  among  those  
listed in the specifications document.
It  is  important  to  consider  that  moni-
toring facilities can dynamically compute the 
ratio between covered elements, and the total 
number may also be considered. Additionally, 

SOFTWARE TESTING   5-17
especially   in   the   case   of   structure-based   
testing  techniques,  appropriate  instrumenta-
tion of the SUT may also be necessary.
However, the proposed set of testing mea-
sures  can  also  be  classified  from  different  
viewpoints — from the point of view of those 
providing  and  allowing  an  evaluation  of  the  
SUT based on the observed test outputs and 
of  those  that  evaluate  the  thoroughness  or  
effectiveness of the executed test suites. 
4.1. Evaluation of the SUT 
[2*, c24s5]
Usually,   indicators   (i.e.,   measurable   infor-
mation)  can  be  used  to  determine  whether  a  
SUT is performing as expected and achieving 
its expected outcomes. The indicators, some-
times   known   as   key   performance   indica-
tors  (KPIs),  are  strongly  connected  with  the  
adopted  evaluation  measures,  methods,  data  
analysis and reporting.
4.1.1. SUT Measurements That Aid in Planning  
   and Designing Tests 
[14*, c10; 10, c6; 4, part 1, part 4] 
All  the  testing  measures  proposed  in  [4,  
part 4] can be used for planning and guiding 
testing  activities.  Additionally,  in  the  shift-
left  development  process,  specific  measures,  
such  as  deployment  frequency,  lead  time,  
mean time to recovery (MTTR), and change 
failure   rate,   are   also   commonly   adopted   
to  plan  and  manage  the  testing  activities  
and results. 
4.1.2. Fault Types, Classification and Statistics
 [1* c13s4, c13s5, c13s6]
The  testing  literature  is  rich  in  classifica-
tions  and  taxonomies  of  faults  that  can  be  
generic  or  specific  to  a  context  or  quality  
attributes  (such  as  the  usability  defect  clas-
sification, the taxonomy of HW/SW security 
and  privacy  vulnerabilities  and  attacks,  and  
the  classification  of  cybersecurity  risks).  To  
make  testing  more  effective,  it  is  important  
to know which types of faults may be found 
in  the  SUT  and  the  relative  frequency  with  
which these faults have occurred in the past. 
This  information  can  be  useful  in  making  
quality  predictions  and  in  process  improve-
ment  (See  Characterization  in  the  Software  
Quality K A).
4.1.3. Fault Density 
[1*, c13s4; 14*, c10s1]
Traditionally,   a   SUT   can   be   evaluated   
by  counting  discovered  faults  as  the  ratio  
between  the  number  of  faults  found  and  the  
SUT  size.  Because  of  the  semantics-based  
definition  of  faults,  additional  measurements  
can  be  considered,  such  as  fault  depth  (the  
minimal number of fault removals needed to 
make  a  SUT  correct)  and  fault  multiplicity  
(the  number  of  atomic  changes  needed  to  
repair a single fault). 
4.1.4. Life Test, Reliability Evaluation 
[1*, c15, 2*, c11; 14*, c1s3]
A statistical estimate of software reliability, 
which  can  be  obtained  by  observing  reli-
ability  achieved,  can  be  used  to  evaluate  a  
SUT  and  decide  whether  testing  can  be  
stopped or the SUT is mature enough to be 
a  candidate  for  the  next  shift-left  develop-
ment release. Reliability evaluation is taking 
a  pivotal  role  in  the  Cloud  (and  fog)  con-
te x t s [18].
On  the  one  hand,  validation  and  veri-
fication  proposals  are  focusing  on  main-
taining  the  high  level  of  reliability  and  
availability required by the cloud (fog) ser-
vices.  On  the  other,  testing  activities  are  
exploiting  the  computational  power  of  the  
cloud  (fog)  environment  to  speed  up  the  
reliability evaluation and drastically reduce 
its costs.
4.1.5. Reliability Growth Models 
[1*, c15, 2* c11s5]
Reliability    growth    models    predict    reli-
ability  based  on  observed  failures.  They  
assume,  in  general,  that  when  the  faults  

5-18   SWEBOK
®
 GUIDE V4.0
that caused the observed failures have been 
fixed  (although  some  models  also  accept  
imperfect  fixes),  the  product’s  reliability  
will  increase.  There  are  many  published  
reliability  growth  models.  Notably,  these  
models  are  divided  into  failure-count  and  
time-between-failure models.
4.2. Evaluation of the Tests Performed 
[4, part 4, c6]
The  behavior  of  SUT  is  generally  verified  
by  executing  test  suites,  which  are  pivotal  
in  finding  defects.  Therefore,  from  both  the  
researchers’  and  practitioners’  perspectives,  a  
fundamental part of software testing is com-
paring test suites. Usually, evaluating the test 
suites  means  comparing  techniques  for  test  
case  generation  that  produce  the  test  cases.  
Different  criteria  are  used  for  that  purpose,  
such  as  coverage  criteria  or  mutation  anal-
ysis criteria.
4.2.1. Fault Injection
[1*, c 2 s 5 ]
In fault  injection,  some  faults  are  artificially  
introduced   into   the   SUT   before   testing.   
When  a  test  suite  is  executed,  some  of  these  
injected  faults  are  revealed,  as  are,  possibly,  
some faults that were already there. In theory, 
depending on which and how many artificial 
faults are discovered, the testing effectiveness 
can be evaluated, and the remaining number 
of  genuine  faults  can  be  estimated.  In  prac-
tice,  statisticians  question  the  distribution  
and  representativeness  of  injected  faults  rel-
ative  to  genuine  faults  and  the  small  sample  
size  on  which  any  extrapolations  are  based.  
Some  also  argue  that  this  technique  should  
be  used  with  great  care  because  inserting  
faults into the SUT incurs the obvious risk of 
leaving them there.
4.2.2. Mutation Score 
[1*, c3s5; 6] 
In  mutation  testing,  the  test  suite  effective-
ness measure is calculated as the ratio of killed 
mutants to the number of generated mutants. 
The  higher  the  test  suite  effectiveness  value,  
the better, since it indicates a stronger ability 
to discover the most real injected faults. 
4.2.3. Comparison and Relative Effectiveness of  
  Different Techniques 
[1*, c1s7; 5; 9] 
Relative    effectiveness    compares    different    
testing techniques against a specific property, 
such as the number of tests needed to find the 
first failure, the ratio of the number of faults 
found  through  testing  to  all  the  faults  found  
during and after testing, and how much reli-
ability  was  improved.  Several  studies  have  
already   been   conducted   to   compare   dif-
ferent techniques analytically and empirically 
according to each notion of property (or effec-
tiveness) defined.
5. Test Process 
[4, part 1, part 2, part 3; 2* c8] 
Testing  concepts,  strategies,  techniques  and  
measures  need  to  be  integrated  into  a  defined  
and  controlled  test  planning  process  to  test  
output  evaluation.  The  test  process  supports  
testing and provides guidelines to those respon-
sible  for  different  testing  activities  to  ensure  
the test objectives are met cost-effectively.
As  described  in  [4,  part  2],  the  test  pro-
cess  is  a  multi-layered  process  activity  that  
includes  the  test  specification  at  the  organi-
zational,  management  and  dynamic  levels.  
The  organizational  test  process  defines  the  
steps for creating and maintaining test speci-
fications, such as organizational test policies, 
strategies,  processes,  procedures,  and  other  
assets [4, part 2].
The  test  management  process  defines  the  
steps  necessary  for  management:  planning,  
monitoring and control, and completion.
Finally,  the  dynamic  test  process  speci-
fies the steps for design and implementation, 
environment  setup  and  maintenance,  execu-
tion, and test incident reporting.
In  the  remainder  of  this  section,  some  
practical considerations about the test process 

SOFTWARE TESTING   5-19
specification, management, and execution, as 
well  as  a  summary  of  the  test  sub-processes  
and  activities  included  in  the  organizational,  
management and dynamic levels as in [4, part 
2], are provided.
5.1. Practical Considerations 
[4, part 1]
Testing processes should allow the automation 
of different testing phases and should rely on 
the  controllability,  traceability,  replicability,  
and  risk/cost  estimation  of  the  performed  
activities.  In  the  remainder  of  this  section,  
commonly  applied  test  steps  are  described,  
compatible with and applicable to all life cycle 
models.  (See  Software  Life  Cycles  in  the  
Software Engineering Process KA.)
5.1.1. Attitudes/Egoless Programming 
[1*, c16; 2*, c3]
An  important  element  of  successful  testing  
is  a  collaborative  attitude  toward  testing  and  
quality  assurance  (QA)  activities.  Managers  
have a key role in fostering a favorable recep-
tion  toward  failure  discovery  and  correction  
during  software  development  and  mainte-
nance.  For  instance,  in  shift-left  change  in  
development,  such  as  Agile,  communication  
and  collaboration  among  testers  and  devel-
opers  are  considered  vital  for  achieving  suc-
cessful testing results. 
5.1.2. Test Guides and Organizational Process 
[1*, c12s1, 2* c8; 4, part 2, part 3; 
14*, c7s3]
Various aims can guide the testing phases. For 
example,  risk-based  testing  uses  the  product  
risks to prioritize and focus the test strategy, 
and  scenario-based  testing  defines  test  cases  
based  on  specified  software  scenarios  and  
backlog  lists.  Usually,  the  organization  of  
the test process includes defining test policies 
(i.e., specifying the purpose, goals, and overall 
scope of testing) and test strategies (i.e., spec-
ifying  the  guidelines  about  how  testing  will  
be  carried  out).  For  instance,  in  shift-left  
developments,  a  test  strategy  should  include  
at least the following data: the purposes (e.g., 
defined  through  user  stories),  the  objectives  
(e.g.,  a  test  suite),  the  scope  (the  SUT),  and  
the environment and methods (e.g., how, and 
where the test suite is run).
5.1.3. Test Management and Dynamic Test  
  Processes
[1*, c12; 4, part 2, part 3, 14*, c7s3]
Test activities conducted at different levels (see 
Section  2,  Test  Levels)  should  be  organized  
— with people, tools, policies, and measures 
— into a well-defined process integral to the 
life  cycle.  Test  process  management  includes  
different subprocesses such as planning, mon-
itoring, control, and completion, whereas the 
Dynamic test process includes test design and 
implementation, test environment set-up and 
maintenance, test execution, and test incident 
reporting.
5.1.4. Test Documentation
[1*, c8s12; 14*, c7s8; 4, part 3] 
According  to  [4,  part  3],  documentation  is  
integral  to  the  formalization  of  the  test  pro-
cess.  Test  documents  can  be  classified  into  
three  hierarchical  categories:  organizational  
test  documentation,  test  management  docu-
mentation  and  dynamic  test  documentation.  
Organizational  test  documentation  includes  
the  information  necessary  for  documenting  
the  test  policy  and  the  organizational  test  
strategies.  Test  management  documentation  
includes  the  test  plan,  test  status  report  and  
test  completion  report.  Finally,  dynamic  test  
documentation  includes  the  following  docu-
ments: test specification (test design specifica-
tion, test case specification and test procedure 
specification),   test   data   requirements,   test   
environment requirements, test data readiness 
report, test environment readiness report, and 
test  execution  documentation  (such  as  actual  
results,  test  results,  test  execution  log  and  
incident report).
Test  documentation  should  be  produced  
and   continuously   updated   with   the   same   

5-20   SWEBOK
®
 GUIDE V4.0
quality  as  other  software  engineering  doc-
umentation.    Test    documentation    should    
also  be  under  the  control  of  software  con-
figuration  management.  (See  the  Software  
Configuration Management KA.) 
5.1.5. Test Team 
[1*, c16; 2* c23s5; 4, part 2, part 3]
Formalizing   the   testing   process   may   also   
involve  formalizing  the  testing  team’s  orga-
nization.  Considerations  of  cost,  schedule,  
maturity  levels  of  the  involved  organizations  
and criticality of the application can guide the 
decision. The testing team can be composed of 
members involved (or not) in the SUT devel-
opment  (i.e.,  having  or  not  having  an  unbi-
ased,  independent  perspective)  or  internal  
(or  external)  personnel.  Nowadays,  shift-left  
development  does  not  strongly  distinguish  
among testing team members because the test 
suite is defined and updated according to the 
SUT development and delivered code. 
5.1.6. Test Process Measures 
[1*, c18s3, 14*, c10; 4, part 1, part 
2, part 3] 
Managers   use   several   measures   for   the   
resources  spent  on  testing,  as  well  as  for  the  
relative fault-finding effectiveness of the var-
ious  test  phases,  to  control  and  improve  the  
testing process, as well as to provide informa-
tion  for  managing  process  risks.  Therefore,  
monitor   and   control   testing   must   define   
required data and information and state how 
to obtain them. The test measures may cover 
the  number  of  specified,  executed,  passed,  
and  failed  test  cases,  among  other  elements.  
These  measures  can  also  be  combined  with  
specific process metrics such as residual risk, 
cumulative defects open and closed, test case 
progress,   and   defect   detection   percentage.   
Evaluation of test phase reports can be com-
bined  with  root-cause  analysis  to  evaluate  
test  process  effectiveness  in  finding  faults  as  
early  as  possible.  Such  an  evaluation  can  be  
associated  with  risk  analysis.  Moreover,  the  
resources  deemed  worth  spending  on  testing  
should  be  commensurate  with  the  applica-
tion’s use and criticality. Different techniques 
have different costs and yield different confi-
dence levels in product reliability.
5.1.7. Test Monitoring and Control 
[4, part 1, part 2] 
Monitoring and Control comprise an important 
sub-process of the test management process as 
in  [4,  part  2],  useful  for  collecting  data  and  
information required during test management 
and assessment. Usually, monitoring and con-
trol  activities  are  executed  in  parallel  with  
the  test  execution,  and  sometimes,  data  col-
lected  might  prompt  revision  of  overall  pro-
cess planning. Monitoring assures that testing 
process  activities  comply  with  a  specific  test  
plan  to  trace  the  requirements  satisfaction  
and mitigate the identified risks satisfactorily. 
During  test  monitoring  and  control,  specific  
documentation (test reports) can regularly be 
produced  to  help  assess  and  document  the  
test activ it y.
5.1.8. Test Completion 
[14*, c7s11; 4, part 3]
A  decision  must  be  made  about  how  much  
testing  is  enough  and  when  a  test  stage  can  
be  completed.  Therefore,  the  purpose  of  Test 
Completion, a sub-process of the test manage-
ment process as in [4, part 2], is to ensure that 
test  requirements  are  satisfied  and  verified,  
test  reports  are  completed,  and  test  results  
are  communicated  to  relevant  stakeholders.  
Thoroughness measures, such as achieved code 
coverage or functional coverage, and estimates 
of fault density or operational reliability, pro-
vide  useful  support  but  are  not  sufficient  in  
themselves. The decision also involves consid-
erations about the costs and risks incurred by 
possible remaining failures, as opposed to the 
costs incurred by continuing to test (See Test 
Selection  and  Adequacy  Criteria  in  Section  
1.2, Key Issues.) As for the other activities, in 
this stage, specific documentation is produced 
(e.g.,  test  completion  report)  and  communi-
cated to the relevant stakeholders.

SOFTWARE TESTING   5-21
5.1.9. Test Reusability
[14*, c3; 9]
It is necessary to add complexity and time 
for test planning and design to achieve reus-
ability  of  the  testing  artifacts,  such  as  the  
test  case  or  execution  environment,  which  
is  desired  when  test  development  is  costly,  
time-consuming, and complex.
Test  reusability  collects  and  classifies  the  
testing knowledge (test cases and test results) 
to   make   this   information   searchable   and   
usable  for  creating  new  tests  or  re-executing  
an  existing  one.  Suitable  knowledge-based  
repositories  should  be  configured  and  man-
aged  to  test  reusability  so  changes  to  soft-
ware requirements or design can be reflected 
in changes to the tests.
Currently,  the  reusability  of  test  cases  is  
pivotal in feature-based or product-line devel-
opment  and  regression  testing.  Test  reus-
ability also relates to maintainability because 
reusability  can  reduce  the  cost  and  effort  
involved and improve a test’s effectiveness. 
5.2. Test Sub-Processes and Activities
[1*, c1s12; 1*, c12s9; 4, part 2]
In  the  remainder  of  this  section,  the  main  
testing activities and sub-processes are briefly 
introduced. 
5.2.1. Test Planning Process 
[1*, c12s1, c12s8; 11; 4, part 2] 
Like  all  other  aspects  of  project  manage-
ment,  testing  activities  must  be  planned.  
According to [4, part 2], key aspects of test 
planning  include  identification  and  coor-
dination   of   personnel,   identification   of   
the  test  objective  and  completion  criteria,  
definition  of  test  facilities  and  equipment,  
creation  and  maintenance  of  all  test-re-
lated documentation, and risk planning and 
management  for  possible  undesirable  out-
comes. These activities can be organized at 
three  different  levels:  (1)  process  manage-
ment  (i.e.,  identification  of  test  policies,  
strategies,  processes,  and  procedures),  (2)  
organizational  management  (i.e.,  definition  
of the test phase, test type and test objective), 
and (3) design and implementation (i.e., defi-
nition of the test environment, the test execu-
tion process and monitoring, the completion 
process, and reporting).
5.2.2. Test Design and Implementation
[1*, c12s1, c12s3; 11]
Generation  of  test  cases  is  based  on  the  
level  of  testing  to  be  performed  and  the  
chosen   testing   techniques.   According   to   
the dynamic test process, as described in [4, 
part 2], preconditions of the test case gener-
ation are the identification of test objectives 
and the selection of the appropriate testing/
demonstration  techniques.  Test  generation  
focuses on implementing and executing test 
cases.  It  often  relates  to  tooling  (i.e.,  using  
specific software, also called a test cases gen-
erator).  This  software  accepts  inputs  (such  
as  source  code,  test  criteria,  specifications,  
or data structure definitions) and uses them 
to  generate  the  test  suites.  Sometimes,  a  
test  case  generator  can  determine  expected  
results by using a specific oracle facility. This 
contributes to the full test automation of the 
overall testing process. 
5.2.3. Test Environment Set-up and  
   Maintenance   
[1*, c12s6; 2* c8s1; 14* c13s2; 4, part 2; 11]
According  to  the  dynamic  test  process,  as  
described  in  [4,  part  2],  test  environment  
development and setup involve identifying the 
testing infrastructure. This includes selecting 
or  developing  the  facilities,  hardware,  soft-
ware,  firmware,  and  procedures  to  conduct  
the  testing  activity.  The  testing  environment  
can  be  simulated,  controlled,  and  executed  
in  vitro  or  in  vivo.  Developing  the  test  envi-
ronment  also  involves  setting  up  monitoring  
and logging facilities useful for documenting 
the  testing  activities  and  assessing  the  result  
obtained.   The   testing   environment   should   
be  compatible  with  the  other  software  engi-
neering tools used. 

5-22   SWEBOK
®
 GUIDE V4.0
5.2.4. Controlled Experiments and Test  
   Execution 
[1*, c12s7, 14* c4s7, 14* c5s6; 4, part 2]
Execution  of  tests  should  embody  a  basic  
principle of scientific controlled experimenta-
tion — everything done during testing should 
be  performed  and  documented  specifically  
and clearly enough that another person could 
replicate  the  results.  Hence,  testing  should  
be  performed  following  documented  proce-
dures  using  a  clearly  defined  version  of  the  
SUT.  Especially  during  acceptance  testing,  
controlled  experiments  like  A/B  testing  can  
also  be  performed  to  statistically  evaluate  
user  preferences  between  different  versions  
of the SUT. 
5.2.5. Test Incident Reporting
[1*, c13s4, c13s9, c13s11; 2*, c8s3; 14*, 
c7s8; 4, part 3; 12]
According  to  the  dynamic  test  process,  as  
described  in  [4,  part  2],  testing  incidents  
and   reporting   focus   on   the   well-defined   
test  data  collection  process  (i.e.,  identifying  
when  a  test  was  conducted,  who  performed  
the  test,  what  software  configuration  was  
used,  and  other  relevant  identification  infor-
mation).  This  process  and  the  collected  evi-
dence   can   be   leveraged   for   accountability   
purposes.  Test  reporting  can  involve  suitable  
audit systems to identify unexpected or incor-
rect test results and record them in a problem 
reporting  system.  These  data  form  the  basis  
for  later  debugging  and  fixing  the  problems  
observed   as   failures   during   testing.   Also,   
anomalies  not  classified  as  faults  could  be  
documented if they later become more serious 
than first thought. Test reports are also inputs 
to  the  change  management  request  process.  
(See  Software  Configuration  Control in  the  
Software Configuration Management KA.) 
Hence,  the  Test  Incident  Reporting  pro-
cess   focuses   on   identifying   the   relevant   
stakeholders’  incidents  that  could  be  used  to  
determine  what  aspects  of  software  testing  
and  other  processes  need  improvement  and  
how effective previous approaches have been.
Part of the incident reporting is also eval-
uating  test  results  to  determine  whether  the  
testing  has  been  successful.  In  most  cases,  
“successful”  means  that  the  software  per-
formed  as  expected  and  did  not  have  any  
major  unexpected  outcomes.  Not  all  unex-
pected outcomes are necessarily faults; some-
times they are determined to be simply noise. 
Before a fault can be removed, an analysis and 
debugging effort is needed to isolate, identify, 
and describe it. When test results are particu-
larly important, a formal review board may be 
convened to evaluate them.
5.3. Staffing 
[1*, c16; 4, part 3]
According  to  [4,  part  3],  staffing  includes  
defining roles, activities, and responsibilities, 
specifying hiring needs, and defining training 
needs. Staffing affects project risk because the 
team’s expertise might undermine the ability 
to discover faults, to address changing require-
ments, to meet deadlines, and increase/reduce 
maintenance costs. 
The   roles,   activities   and   responsibilities   
definition  establishes  the  following  roles  and  
responsibilities:  the  activity  leader  and  sup-
porting  personnel,  the  test-related  roles  and  
their  corresponding  responsibilities,  and  the  
person responsible for providing the test item(s). 
Depending  on  the  development  lifecycle  
adopted,  typical  testing  roles  include  but  are  
not  limited  to  scrum  master/test  lead,  QA/
test analyst, test designer, test security/perfor-
mance engineer and consultant, test environ-
ment expert, test executor and test automation 
consultant or architect.
Hiring  needs  require  the  identification  of  
specific  requirements  for  which  additional  
testing personnel are needed to complete the 
testing process (as well as when that personnel 
is  needed  and  the  desired  skills).  Depending  
on  the  business  needs,  staffing  could  take  
different  forms,  from  internal  transfers  to  
external hires or even consultants and/or out-
sourced resources.
Finally,  the  training  needs  specification  
includes  the  definition  of  the  required  skill  

SOFTWARE TESTING   5-23
level. It also includes the specification of the 
training activities (such as classroom training, 
self-paced training, computer-based training, 
or mentoring) useful for providing the neces-
sary skills to the selected staff.
6. Software Testing in the Development 
Processes and the Application Domains
[2*, c8, c15; 14*, c4s8, c7]
Whatever  development  process  is  adopted,  
testing    remains    a    fundamental    activity.    
However,  specific  testing  activities  or  termi-
nologies could be used in some cases, such as 
the adopted development life cycle and/or the 
application domain 
6.1.  Testing Inside Software Development 
Processes 
[2*, c8; 14*, c7] 
In the remainder of this section, peculiarities 
of  testing  inside  the  different  development  
processes are provided.
6.1.1. Testing in Traditional Processes 
[1* c18; 14*, c7] 
There  are  a  variety  of  traditional  processes,  
essentially  based  on  the  SUT  development  
principles,  that  can  be  adopted  within  the  
organization. Sequential, V, spiral model and 
iterative  are  just  some  of  the  processes  com-
monly  applied.  (Software  Life  Cycles  in  the  
Software  Engineering  Process  KA  provides  
a  detailed  description  of  each.)  However,  in  
all  these  processes,  testing  is  just  one  per-
ceived  activity;  it  is  sometimes  performed  at  
the  end  of  the  process,  with  a  tangible  risk  
of  SUT  development  failure  in  case  of  devi-
ation  of  the  end-user  needs  or  assessment  
issues.  During  recent  years,  to  evaluate  and  
control the overall quality of the SUT, initia-
tives  such  as  test  maturity  model  integration  
(TMMi)  and  software  process  improvement  
(SPI) have been established. As a result, dif-
ferent existing frameworks have been updated 
or  improved  for  the  purpose,  such  as  soft-
ware   process   improvement   and   capability   
determination  (SPICE),  capability  maturity  
model integration (CMMI), and unified pro-
cess (UP). 
For  instance,  CMMI  is  one  of  the  most  
referenced  models;  it  can  guide  key  SUT  
stakeholders in gaining control of their devel-
opment  and  maintenance  processes.  It  is,  in  
fact,  a  well-defined  set  of  best  practices  in  
software  testing  that  improves  SUT  quality  
by increasing customer satisfaction.
Presented in the early 2000s, the UP model 
can  be  seen  as  a  predecessor  of  the  shift-left  
movement.  UP  encourages  testing  early  by  
offering   several   mechanisms   to   integrate   
testing more closely with the software devel-
opment effort, making testing a distinct disci-
pline. Furthermore, UP promotes an iterative 
development  approach  for  continuously  ver-
ifying  quality.  It  also  enables  use  cases  and  
risk  to  drive  SUT  development  and  allows  
strategic  change  management.  Indeed,  UP  
groups  the  SUT  increments  and  SUT  itera-
tions into four phases: inception, elaboration, 
construction, and transition.
Nowadays,  UP  can  be  considered  both  
Iterative  and  Agile  —  Iterative  because  all  
the core activities are repeated throughout the 
SUT development project, and Agile because 
the defined phases of the chosen lifecycle can 
be  repeated  until  the  SUT  meets  require-
ments  (both  functional  and  non-functional),  
achieves  the  defined  objectives,  and  guaran-
tees the target quality.
6.1.2. Testing in Line with Shift-Left Movement
[2*, c3, c8s2; 4, part 1; 10, c3, c5]
The shift-left  testing  movement  promotes  the  
adoption of testing in the early stages of soft-
ware development to detect and remove faults 
as  early  as  possible  to  increase  overall  SUT  
quality and reduce the cost and risks of testing 
activities.     Currently,     different     develop-
ment  life  cycles,  such  as  Agile,  DevOps  and  
TDD, belong to the shift-left movement. (See 
Agile  Methods  in  the  Software  Engineering  
Process K A.)
In  shift-left-based  development,  different  
testing aspects should be considered:

5-24   SWEBOK
®
 GUIDE V4.0
A. The  internal  code  quality:  Regression,  
prioritization, security, and privacy could 
be the primary objectives of the internal 
code  quality  (Section  2.2).  Usually,  unit  
testing  and  integration  testing  are  the  
targeted   levels   (Section   2.1),   whereas   
structure-based is the main testing tech-
nique (Section 3.2).
B. Business needs: Compliance and confor-
mance, usability, security, and privacy are 
just a subset of the possible objectives of 
the  business  needs  aspect  (Section  2.2).  
Concerning  this  aspect,  testing  focuses  
more  on  the  system  and  acceptance  test  
levels  and  on  end-user  expectations,  as  
well as usage-based (Section 3.5) and sce-
nario-based techniques (Section 3.1.8).
C. Perceived  quality:  Alpha,  beta,  instal-
lation,  usability,  security,  and  privacy  
could  be  the  primary  objectives  of  the  
internal  perceived  quality  (Section  2.2).  
Perceived  quality  usually  focuses  on  the  
acceptance   test   level   and   is   achieved   
by  applying  techniques  based  on  soft-
ware engineering’s intuition and experi-
ence  (Section  3.3)  and  usage-based  and  
fault-based techniques, such as mutation 
testing (Section 3.4).
D.   Quality  assurance:  Performance  installa-
tions,  security,  and  privacy  conformance  
and compliance are some main objectives of 
quality assurance (Section 2.2). This aspect 
may involve all testing levels, and the selec-
tion  of  the  testing  technique  depends  on  
the objective and the level chosen.
Here,  some  examples  of  testing  inside  the  
different  shift-left  movements  implementa-
tion are provided:
•    In  Agile  process  development,  testing  
activities involve all stakeholders (such as 
customers and team personnel) and target 
the identification of where improvements 
could  be  made  in  future  interactions.  
Managing  the  risk  of  regression  defects,  
meeting   changing   requirements,   and   
managing  their  impact  on  test  artifacts  
are  also  objectives  of  the  Agile  testing  
process. Typically, test automation is used 
to manage the regression risk, and explor-
atory  testing  may  be  used  to  manage  a  
lack of detailed requirements.
•    In  TDD,  the  test  cases  mainly  target  
the  software  requirements  specifications  
and  acceptance,  and  they  are  generated  
in  advance  of  the  code  being  written.  
The  tests  are  based  on  the  user  stories  
and  implemented  using  automated  com-
ponent  testing  tools.  Indeed,  TDD  is  a  
practice that requires defining and main-
taining unit tests and can help clarify the 
user  needs  and  software  requirements  
specifications.
•    In  testing  automated  builds  and  contin-
uous  integration  (for  instance,  DevOps),  
the SUT is continuously developed, inte-
grated,  delivered  and  monitored.  In  this  
process, regression testing is continuously 
performed  to  timely  identify  and  cor-
rect  development  and  integration  issues.  
Additionally,  quick  testing  techniques,  
such  as  smoke  testing,  are  commonly  
used  during  continuous  integration  to  
guarantee that the SUT is testable before 
it is released to the operational stage.
6.2. Testing in the Application Domains
[2*, c15; 14*, c4s8]
Usually, an application domain is strictly con-
nected  to  a  certain  reality.  Therefore,  testing  
approaches  could  be  tailored  to  the  needs  of  
the  domain  and  customized  to  the  adopted  
technologies.
Below,  we  provide  an  overview  of  dif-
ferent   aspects   and   solutions   for   software   
testing  applied  within  several  domain-spe-
cific environments:
•    Automotive  domain  testing:  Due  to  the  
complexity  of  automotive  systems,  this  
testing  involves  aspects  of  almost  every  
software  component  and  its  interaction  
with  hardware.  Security  testing,  simula-
tion  testing,  reliability/life  cycle  testing,  
integrated  systems  testing,  data  acquisi-
tion  and  signal  analysis  testing,  quality  

SOFTWARE TESTING   5-25
testing  and  inspection,  and  stress/strain  
testing are just some of the various testing 
performed  in  this  domain.  Several  sup-
porting  standards  are  currently  available  
to  guide  and  manage  automotive  testing  
according to the peculiarity, the compo-
nent,  or  the  quality  aspect  that  should  
be  assessed.  Autosar
2
  and  Automotive  
SPICE
3
 are examples.
•    Internet  of  things  (IoT)  domain  testing:  
This testing involves application develop-
ment,  device  management,  system  man-
agement,    heterogeneity    management,    
data  management,  and  tools  for  anal-
ysis,  deployment,  monitoring,  visualiza-
tion and research. Additionally, security, 
privacy,  communications  and  user/com-
ponent  interaction  should  be  considered  
in  the  quality  assessment.  For  example,  
guidelines  and  specific  conformance  test  
suites for cybersecurity assessment of the 
IoT  SUT  are  detailed  in  the  European  
Telecommunications  Standards  Institute  
(ETSI) standards.
4
 
•    Legal  domain  testing:  One  of  the  most  
important  aspects  in  the  legal  domain  
is  the  management  of  highly  sensitive  
users;   therefore,   security,   privacy   and   
trust are the most common areas of focus 
for  testing.  Additionally,  because  of  the  
copious  data  collected  and  exchanged,  
performance  testing  of  the  data  reposi-
tory,  testing  to  show  accurate  commu-
nication  and  integration  testing,  as  well  
as  consistency  and  compliance  testing,  
should also be done. Finally, because the 
legal  domain  is  characterized  by  specific  
nomenclature and jargon, involving legal 
domain  experts  in  test  case  generation  
is  common  practice  to  ensure  a  focus  on  
desired characteristics and quality.
2  https://www.autosar.org/
3  https://www.automotivespice.com/
4  https://www.etsi.org/
5  https://www.w3.org/2013/07/webmobile-ig-charter.html
6  www.astm.org.
7      https://www.hl7.org/
8      http://fhir.org/
•    Mobile  domain  testing:  This  testing  is  
usually   for   usability,   functional,   con-
figuration   and   consistency   assessment.   
Mobile-specific  aspects  such  as  screen  
resolution,   global   positioning   system   
(GPS),   operating   systems,   and   device   
manufacturers   should   also   be   consid-
ered  during  testing  activity.  Finally,  the  
type of mobile applications (native or web 
apps)  and  their  interactions  need  to  be  
tested.  For  example,  the  W3C  Web  and  
Mobile  Interest  Group
5
  provides  facil-
ities,  guidelines  and  ad  hoc  test  suites  
useful  for  developing  and  testing  web-
based content, applications and services. 
•    Avionics  domain  testing
6
:  Usually,  avi-
onics  systems  include  several  indepen-
dent  or  loosely  coupled  components  and  
commercial off-the-shelf products. Those 
forces   testing   to   include   very   general   
processes  and  approaches  applicable  at  
both  the  system  and  the  process  levels.  
Functional  and  non-functional,  integra-
tion,  communication  operational,  stress,  
safety,  and  security  testing  are  exam-
ples  of  possible  approaches.  As  in  other  
domains,    supporting    standards    such    
as    Aeronautical    Radio    Incorporated    
(ARINC)     Standards     and     ASTM     
F3153-15 can be used for reference.
•    Healthcare  domain  testing:  Healthcare  
domain   testing   should   ensure   quality   
in  areas  such  as  secure  and  reliable  data  
exchange,   stable   performance,   privacy,   
and safety. Interoperability, usability, per-
formance  and  compliance  with  industry  
regulations,  as  well  as  security  and  safety  
standards (such as the Health Level Seven 
(HL7),
7
  Fast  Healthcare  Interoperability  
Resources   (FHIR),
8
   Digital   Imaging   
and     Communications     in     Medicine     

5-26   SWEBOK
®
 GUIDE V4.0
(DICOM),
9
 Health Insurance Portability 
and  Accountability  Act  (HIPAA),
10
  and  
the  General  Data  Protection  Regulation  
(GDPR)
11
) should also be considered.
•    Embedded domain testing: Because soft-
ware  and  hardware  are  tightly  coupled  
in   embedded   systems,   testing   activity   
should  assess  functional  and  non-func-
tional  attributes  of  both  software  and  
hardware. 
•    Graphical  user  interface  (GUI)  testing:  
GUI  testing  involves  assessing  the  UI  
(user  interface)  (i.e.,  the  elements  of  the  
user objects that we can see). Thus, GUI 
testing targets the design pattern, images, 
alignment, spellings, and the overall look 
and  feel  of  the  UI.  Testing  approaches  
based   on   finite-state   machines,   goal-
driven  approaches,  approaches  based  on  
abstractions and model-based approaches 
can be considered. 
•    Gaming:  Gaming  applications  and  soft-
ware are currently a very active sector of 
software  production,  causing  increased  
demand  for  new  approaches  and  ways  
to   ensure   their   quality   and   security.   
Among  the  specific  testing  techniques,  
playtesting  is  one  of  the  most  adopted.  
In  this  case,  real  gamers  repeat  quality  
control  methods  at  many  points  of  the  
game  execution  or  design  process.  GUI  
testing,    functionality    testing,    secu-
rity  testing,  console  testing,  compliance  
testing and performance testing can also 
be considered.
•    Real-time   domain   testing:   Real-time   
testing   usually   focuses   on   assessing   
timing   constraints   and   deterministic   
behavior.  Usually,  unit,  integration  and  
system testing approaches can be adopted. 
Communication,  interaction  and  behav-
ioral testing can also be performed.
•    Service    oriented    architecture    (SOA)    
testing:   This   testing   focuses   mainly   
on    correctly    implementing    business    
9      https://www.dicomstandard.org/
10    https://www.hhs.gov/hipaa/.
11  https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32016R0679.
processes  and  involves  unit  and  integra-
tion testing approaches. Structure-based, 
specification-based  and  security  testing  
can be applied. The testing activity might 
vary according to the environment, orga-
nization  and  set  of  requirements  that  
should be satisfied.
•    Finance   domain   testing:   This   testing   
covers a wide range of aspects, from man-
aging  financial  requirements  to  assessing  
financial  applications  and  software  pro-
grams. As in other domains, domain-spe-
cific  knowledge  (such  as  that  held  by,  for  
example,  banks,  credit  unions,  insurance  
companies,  credit  card  companies,  con-
sumer finance businesses, investment funds 
and  stock  brokerages)  could  be  necessary  
to apply the testing process effectively and 
efficiently. Customer satisfaction, usability, 
security,  privacy,  third-party  component  
and   apps   integrations,   real-time   issues,   
and  performance  are  some  of  the  most  
important challenges in this domain.
7. Testing of and Testing Through 
Emerging Technologies 
In recent decades, software development was 
driven  by  emerging  trends  such  as  the  wide-
spread  diffusion  of  mobile  technology,  cloud  
infrastructures  adoption,  big  data  analysis  
and the software as a service paradigm, which 
highlighted  new  constraints  and  challenges  
for testing.
7.1. Testing of Emerging Technologies
•    Testing  artificial  intelligence  (AI),  ML/
deep  learning  (DL)  [13]:  AI,  ML  and  
DL   are   successfully   being   applied   in   
practice.  Sooner  or  later,  most  business  
applications  will  have  some  form  of  AI,  
ML or DL. Because of their peculiarities, 
testing  such  applications  is  challenging  
and might be very expensive. AI, ML or 

SOFTWARE TESTING   5-27
DL testing refers to any activity designed 
to reveal AI, ML or DL bugs. 
o Three main aspects should be consid-
ered  in  defining  bugs  and  testing  in  
this scenario: the required conditions 
(correctness, robustness, security, and 
privacy);  the  AI,  ML  or  DL  items  
(e.g.,  a  bug  might  exist  in  the  data,  
the  learning  program,  or  the  frame-
work  used);  and  the  involved  testing  
activities  (test  case  generation,  test  
oracle  identification  and  definition,  
and test case adequacy criteria).
o In all these applications, a prototype 
model is first generated based on his-
torical   data.   Then,   offline   testing,   
such   as   cross-validation,   is   con-
ducted  to  verify  that  the  generated  
model  satisfies  the  required  condi-
tions.  Usually,  after  deployment,  the  
model is used for prediction purposes 
by  generating  new  data.  Finally,  the  
generated  data  is  analyzed  through  
online  testing  to  evaluate  how  the  
model interacts with user behaviors.
•    Testing  blockchain  [15]:  The  commonly  
used   testing   techniques   for   validating   
blockchains  and  related  applications  such  
as  smart  contracts  are  stress  testing,  pen-
etration   testing   and   property   testing.   
However, depending on the specific situa-
tion, different aspects should be considered 
during  the  testing  of  a  blockchain-based  
SUT, such as the following:
•    Platform   type:   The   level   of   validation   
depends  on  the  type  of  platform  used  for  
implementation  —  public  or  private.  The  
latter requires a much greater testing effort.
•    Connection    with    other    applications:    
Integration  testing  should  be  performed  
to check consistency when the blockchain 
works with various applications.
•    Performance: Performance testing should 
be  conducted  when  performance  issues  
are a concern. Specific strategies to handle 
many  transactions  should  be  conceived  
to  guarantee  a  satisfactory  performance  
level.  Qualitative  and  quantitative  met-
rics,  such  as  average  transaction  valida-
tion  latency  and  security,  should  also  be  
considered.
•    Testing  the  cloud  [1*,  c10s10,  2*,  c18]:  
Testing the cloud validates the quality of 
applications and infrastructures deployed 
in  the  cloud  by  considering  both  func-
tional and non-functional properties. The 
focus  is  to  identify  problems  posed  by  
systems residing in the cloud. Therefore, 
testing  activities  use  techniques  to  val-
idate     cloud-based     services’     perfor-
mance, scalability, elasticity and security. 
Moreover,  testing  should  also  focus  on  
compatibility and interoperability among 
heterogeneous cloud resources when dif-
ferent  deployment  models  are  used  (e.g.,  
private, public or hybrid).
•    Testing concurrent and distributed appli-
cations  [1*,  c10s10,  2*,  c17]:  One  main  
aspect  of  testing  dynamic,  complex,  dis-
tributed   or   concurrent   applications   is   
dealing  with  multiple  operating  systems  
and  updates,  multiple  browser  platforms  
and versions, different types of hardware, 
and many users. For such testing, it’s dif-
ficult  to  use  testing  approaches  based  on  
the  classical  hierarchy  between  compo-
nents or systems; instead, solutions based 
on   input/output,   dependency   threads,   
or  dynamic  relations  often  work  better.  
Additionally, the possibility of continuous 
integration  and  deployment  of  the  dif-
ferent components forces the testing pro-
cess  to  include  approaches  for  managing  
continuous test operation, injection, mon-
itoring  and  reporting  according  to  the  
time,  bandwidth  usage,  throughput,  and  
adaptability  constraints.  Finally,  there  is  
still the need for solutions that allow the 
reusability  of  testing  knowledge,  archi-
tectures,  and  code  to  make  the  testing  
activity more effective and less expensive.
7.2. Testing Through Emerging Technologies
•    Testing through ML [13]: AI, ML or DL 
techniques are successfully used to reduce 

5-28   SWEBOK
®
 GUIDE V4.0
the effort involved in several activities in 
software  engineering  (such  as  behavior  
extraction, testing or bug fixing). These 
techniques   aid   both   researchers   and   
practitioners  in  adopting  and  identi-
fying   appropriate   methods   for   their   
desired applications. There is a growing 
interest  in  adopting  ML  techniques  in  
software  testing  because  most  software  
testing  issues  are  being  formulated  as  
ML learning problems. Indeed, AI, ML 
or  DL  is  intensively  used  in  almost  all  
software,  such  as  test  case  design,  the  
oracle problem, test case evaluation, test 
case  prioritization  and  refinement,  and  
mutation  testing  automation.  Indeed,  
they   can   reduce   maintenance   efforts   
and  improve  the  overall  SUT  quality  
because of their ability to analyze large 
amounts of data for classifying, triaging 
and  prioritizing  bugs  more  efficiently.  
From  a  DevOps  perspective,  AI,  ML  
and  DL  solutions  can  be  used  in  SUT  
automation   authoring   and   execution   
phases  of  test  cases,  as  well  as  in  the  
post-execution test analysis that identi-
fies trends, patterns and impact on SUT 
testing activity.
•    Testing     through     blockchain     [15]:     
Testing  becomes  complicated  when  dif-
ferent  teams,  domain  experts  and  users  
need  to  work  together  in  collaborative,  
large-scale  systems  and  complex  soft-
ware systems to achieve a common goal. 
This  is  mainly  because  of  the  time  con-
straint, data sharing policies, acceptance 
criteria  and  trusted  coordination  among  
the teams involved in the testing process. 
Blockchain technologies can be exploited 
to  improve  software  testing  efficiency  
and  avoid  using  centralized  authority  to  
manage  different  testing  activities.  This  
can  help  ensure  distributed  data  man-
agement, tamper resistance, auditability, 
and    automatic    requirement    compli-
ance  to  improve  the  quality  of  software  
testing  and  development.  Blockchain-
based  approaches  for  trusted  test  case  
repository  management  and  to  support  
test-based  software  and  security  testing  
are also considered.
•    Testing  through  the  cloud  [17]:  Testing  
through  the  cloud  refers  to  SUT  testing  
performed  by  leveraging  scalable  cloud  
technologies.  Usually,  the  cloud  is  used  
for testing purposes wherever large-scale 
simulations and elastic resources are nec-
essary. Indeed, this can affect cost reduc-
tion,  development,  and  maintenance  of  
the  testing  infrastructure  (scaffolding),  
and online validation of systems, such as 
ML-based SUT. A particular situation is 
the testing of the cloud through the cloud 
itself.  This  is  an  example  of  the  inter-
section  between  testing  of  and  testing  
through    emerging    technologies.    The    
applications and infrastructures deployed 
in the cloud can be tested, exploiting the 
cloud’s bandwidth.
•    Testing  through  simulation  [1*,  c3s9]:  
Simulation  is  an  important  technology  
for  testing  activity  because  it  represents  
a valid means for evaluating SUT execu-
tion  under  critical  situations  or  disasters  
or  assessing  specific  behaviors  or  recov-
ering  activities.  The  complexity  of  the  
testing approach might vary according to 
the  complexity  of  the  simulation  system  
adopted  and  might  involve  closed-loop  
testing; assessing the devices, communi-
cations, and interface; and use of real-time 
data  (e.g.,  voltage,  current  and  breaker  
status). Simulation testing can be applied 
to  each  development  level  and  might  
involve  mathematical,  formal  represen-
tation  of  the  real  system,  environment,  
network  conditions  and  control  devices.  
Simulation testing is currently adopted in 
many application domains. Especially in 
the  automotive  and  embedded  domain,  
among the different proposals, one of the 
emerging solutions for simulation testing 
is  hardware-in-the-loop  (HIL)  simula-
tion testing. In this case, real signals sent 
to the SUT to simulate reality and to test 
and design the iteration are continuously 
performed while the real-world system is 
being used. 

SOFTWARE TESTING   5-29
•    Testing   through   crowdsourcing   [16]:   
Crowdsourced   testing   (also   known   as   
crowdtesting) is an emerging approach for 
involving users and experts in the testing 
activity. Thus, crowdsourcing uses repre-
sent  the  dispersed,  temporary  workforce  
of  multiple  individual  testers.  Testing  
through  crowdsourcing  is  mainly  used  
for testing mobile applications because it 
ensures technology diversity and custom-
er-centric  validation.  However,  crowd-
testing  is  not  a  substitute  for  in-house  
SUT   validation.   It   represents   a   valid   
means  of  detecting  failures  and  issues  
because it involves many individuals (tes-
ters) in different locations, who are using 
different technologies in different condi-
tions  and  who  have  different  skills  and  
knowledge.
8. Software Testing Tools 
[1*, c12s11, 14*, c7]
Several testing tools focus on the SUT pecu-
liarities and needs. This section describes the 
main issues and challenges concerning testing 
tools  and  provides  an  overview  of  their  cur-
rently identified categories.
8.1. Testing Tool Support and Selection
[1*, c12s11, 14*, c7]
Testing  involves  many  labor-intensive  tasks  
since   it   involves   running   numerous   pro-
gram executions and handling a considerable 
amount   of   information.   Appropriate   tools   
can  alleviate  the  burden  of  tedious  clerical  
operations  and  make  them  less  error-prone.  
Sophisticated  tools  can  support  test  design  
and generation, making them more effective.
Guidance   to   managers   and   testers   on   
selecting   testing   tools   that   will   be   most   
useful  to  their  organization  and  processes  is  
an  important  topic,  as  tool  selection  greatly  
affects  testing  efficiency  and  effectiveness.  
Tool  selection  depends  on  diverse  factors,  
such   as   development   choices,   evaluation   
objectives and execution facilities. In general, 
there might not be a unique tool to satisfy spe-
cific needs, so a suite of selected tools could be 
appropriate.
8.2. Categories of Tools 
[1*, c1, c3, c4, c7, c8, c9, c12]
Several  classifications  of  testing  tools  mainly  
describe  their  functionalities,  such  as  the  
following:
• Test  harnesses  (drivers,  stubs)  [1*,  c3s9]  
provide   a   controlled   environment   in   
which tests can be launched and the test 
outputs can be logged. Drivers and stubs 
are provided to execute parts of a SUT to 
simulate calling and called modules.
• Test  generators  [1*,  c12s11]  assist  in  gen-
erating test cases. That generation can be 
random,  path-based,  model-based  or  a  
mix thereof.
• Capture/replay  tools  [1*,  c12s11]  automat-
ically re-execute or replay previously exe-
cuted tests that have recorded inputs and 
outputs (e.g., screens).
• Oracle/file   comparators/assertion   checking   
tools [1*, c9s7] assist in deciding whether a 
test outcome is successful.
• Coverage  analyzers  and  instrumenters  [1*,  
c4]  work  together.  Coverage  analyzers  
assess  which  and  how  many  entities  of  
the program flow graph have been exer-
cised  among  all  those  required  by  the  
selected test coverage criterion. The anal-
ysis  can  be  done  through  SUT  instru-
menters that insert recording probes into 
the code. 
• Tra c e r s  [1*,  c1s7]  record  the  history  of  a  
program’s execution paths.
• Regression testing tools [1*, c12s16] support 
the re-execution of a test suite after a sec-
tion of software has been modified. They 
can also help select a test subset according 
to the change made.
• Reliability evaluation tools [1*, c8] support 
test results analysis and graphical visual-
ization  to  assess  reliability-related  mea-
sures according to selected models. 
• Injection-based tools [1*, c3, c7s7] focus on 

5-30   SWEBOK
®
 GUIDE V4.0
introducing or reproducing specific prob-
lems  to  confirm  that  the  SUT  behaves  
suitably  under  the  corresponding  con-
dition.  That  can  involve  managing  some  
input  or  triggering  of  events.  Usually,  
two  categories  of  injection-based  tools  
are considered: attack injection and fault 
injection.
• Simulation-based tools [1*, c3s9] verify and 
validate selected properties. Usually, they 
exploit specific models to enable the auto-
mated  execution  of  scenarios  to  assess  
whether the SUT operates as expected or 
to predict how the SUT would respond to 
defined  inputs.  Typical  simulation-based  
tools  are  classified  into  tools  for  verifi-
cation,  tools  for  collaboration,  tools  for  
optimization, tools for testing automated 
systems and tools for evaluating software 
concepts. 
• Security   testing   tools   [1*,   c8s3,   c12s11]   
focus  on  specific  security  vulnerabilities.  
Among  these  are  tools  for  attack  injec-
tion, penetration testing and fuzz testing.
• Test management tools [1*, c12s11] include 
all  the  supporting  tools  that  assure  effi-
cient  and  effective  test  management  and  
data collection.
• Cross-browser testing tools [1*, c8s3] enable 
the  tester  to  quickly  build  and  run  user  
interface test cases across desktop, mobile 
and  web  applications  to  check  whether  
the SUT looks and works as expected on 
every device and browser.
• Load  testing  tools  [1*,  c3]  collect  valuable  
data  and  evidence  for  SUT  performance  
evaluations.
• Defect  tracking  tools  [1*,  c3]  help  keep  
track  of  detected  faults  during  the  SUT  
development projects. These tools behave 
as tracking systems and usually allow end 
users to enter fault reports directly.
• Mobile  testing  tools  [1*,  c8s3]  support  the  
implementation  and  testing  of  mobile  
apps by allowing several repeated UI tests 
over  the  application  platform,  develop-
ment on real mobile devices or emulators, 
testing  of  the  mobile  apps  on  real-time  
implementations  and  collection  of  data  
for specific QA measures.
• API  testing  tools  [1*,  c7s2]  check  whether  
the  applications  meet  functionality,  per-
formance, reliability, and security expec-
tations   throughout   the   automation   of   
specific API tests.
• CSS validator tools [1*, c7s2] validate cas-
cading  style  sheets  (CSS)  code  and  dis-
cover errors, issues and warnings that can 
be  fixed.  The  CSS  Validation  Service,  
provided  by  W3C  for  free,  is  one  of  the  
most used validators in practice that helps 
both  web  designers  and  web  developers  
check CSS.
• Web application testing tools [1*, c8s3], also 
referred  to  as  web  testing  tools,  support  
validating the functionality and the per-
formance of web-based SUTs before their 
deployment  into  production.  These  tools  
provide relevant insight and data for dif-
ferent  stakeholders,  such  as  developers,  
servers,  and  infrastructure  administra-
tors.  From  a  DevOps  perspective,  these  
tools address issues, or bugs before SUTs 
are available to end users.

SOFTWARE TESTING   5-31
MATRIX OF TOPICS VS. REFERENCE MATERIAL
1*2*14*19 *
1. Software Testing Fundamentalsc1, c2c8c7
1.1. Faults vs. Failuresc1s5c1c1s3
1.2. Key Issues
1.2.1. Test Case Creationc12s1, c12s3c8
1.2.2. Test Selection and Adequacy Criteriac1s14, 
c6s6, c12s7
c8
1.2.3. Prioritization/Minimization
1.2.4. Purpose of Testingc13s11, c11s4c8
1.2.5. Assessment and Certificationc7, c 2 5
1.2.6. Testing for Quality 
Improvement/Assurance
c16s2
1.2.7. The Oracle Problemc1s9, c9s7
1.2.8. Theoretical and Practical Limitationsc2s7
1.2.9. The Problem of Infeasible Pathsc4s7
1.2.10. Testabilityc17s2
1.2.11. Test Execution and Automation
1.2.12. Scalabilityc8s7
1.2.13. Test Effectivenessc1s1c8s1
1.2.14. Controllability, Replication and 
Generalization
c12s12
1.2.15. Offline vs. Online Testing
1.3. Relationship of Testing to Other Activities
2. Test Levelsc1s13c8s1
2.1. The Target of the Testc1s13c8s1
2.1.1. Unit Testingc3c8
2.1.2. Integration Testing c7c8
2.1.3. System Testingc8c8
2.1.4. Acceptance Testingc1s7c8s4
2.2. Objectives of Testingc1s7
2.2.1. Conformance Testingc10s4
2.2.2. Compliance Testingc12s3
2.2.3. Installation Testingc12s2
2.2.4. Alpha and Beta Testingc13s7, c16s6c8s4
2.2.5. Regression Testingc8s11, c13s3
2.2.6. Prioritization Testingc12s7
2.2.7. Non-functional testingc8s7, c8s8, 
c14s2 , 
c15, c17s2
c8, c 11, c17

5-32   SWEBOK
®
 GUIDE V4.0
2.2.8. Security Testingc13
2.2.9. Privacy Testingc13, c14
2.2.10. Interface and API Testingc8s1c7s12
2.2.11. Configuration Testingc8s5
2.2.12. Usability and Human-Computer 
Interaction Testing
c8s4c6
3 .   Te s t   Te c h n i q u e sc1s15
3.1. Specification-Based Techniquesc6s2
3.1.1. Equivalence Partitioningc9s4
3.1.2. Boundary Value Analysisc9s5
3.1.3. Syntax Testingc10s11c5
3.1.4. Combinatorial Test Techniquesc9s3
3.1.5. Decision Tablec9s6, c13s6 
3.1.6. Cause-Effect Graphingc1s6
3.1.7. State Transition Testingc10
3.1.8. Scenario Testingc8s3.2, c19s3.1
3.1.9. Random Testingc9s7
3.1.10. Evidence-Based
3.1.11. Forcing Exception
3.2. Structure-Based Test Techniques
3.2.1. Control Flow Testingc4
3.2.2. Data Flow Testingc5
3.2.3. Reference Models for Structure-Based 
Te s t   Te c h n i q u e s
c4
3.3. Experience-Based Techniques
3.3.1. Error Guessingc9s8
3.3.2. Exploratory Testing
3.3.3. Further Experience-Based Techniques
3.4. Fault-Based and Mutation Techniquesc1s14, c3s5
3.5. Usage-Based Techniquesc15s5
3.5.1. Operational Profile c15s5c11
3.5.2. User Observation Heuristicsc5, c7
3.6. Techniques Based on the Nature of the 
Application
c16, c17, 
c18, c20, c21
c4s8
3.7. Selecting and Combining Techniquesc7s12
3.7.1. Combining Functional and Structuralc9
3.7.2. Deterministic vs. Randomc9s6
3.8. Techniques Based on Derived Knowledgec19, c20c7
4. Test-Related Measuresc24s5c10
4.1. Evaluation of the SUTc24s5

SOFTWARE TESTING   5-33
4.1.1. SUT Measurements That Aid in Planning 
and Designing Tests
c10
4.1.2. Fault Types, Classification and Statisticsc13s4, 
c13s5, c13s6
4.1.3. Fault Densityc13s4c10s1
4.1.4. Life Test, Reliability Evaluationc15c11c1s3
4.1.5. Reliability Growth Modelsc15c11s5
4.2. Evaluation of the Tests Performed
4.2.1. Fault Injectionc2s5
4.2.2. Mutation Scorec3s5
4.2.3. Comparison and Relative Effectiveness of 
Different Techniques
c1s7
5. Test Processc8
5.1. Practical Considerations
5.1.1. Attitudes/Egoless Programmingc16c3
5.1.2. Test Guides and Organizational Processc12s1c8c7s3
5.1.3. Test Management and Dynamic 
Test Processes
c12c7s3
5.1.4. Test Documentationc8s12c7s8
5.1.5. Test Teamc16c23s5
5.1.6. Test Process Measuresc18s3c10
5.1.7. Test Monitoring and Control
5.1.8. Test Completionc7s11
5.1.9. Test Reusabilityc3
5.2. Test Sub-Processes and Activitiesc12s9, c1s12
5.2.1. Test Planning Processc12s1, c12s8
5.2.2. Test Design and Implementationc12s1, c12s3
5.2.3. Test Environment Set-up  
and Maintenance
c12s6c8s1c13s2
5.2.4. Controlled Experiments and 
Test Execution
c12s7c4 s7,  
c5s6
5.2.5. Test Incident Reportingc13s4, 
c13s9, c13s11
c8s3c7s8
5.3. Staffingc16
6. Software Testing in the Development 
Processes and the Application Domains
c8, c15c4s8, 
c7
6.1. Testing Inside Software 
Development Processes
c8c7
6.1.1. Testing in Traditional Processesc18c7
6.1.2. Testing in Line with Shift-
Left  Movement
c3, c8s2

5-34   SWEBOK
®
 GUIDE V4.0
6.2. Testing in the Application Domainsc15c4s8
7. Testing of and Testing Through Emerging 
Technologies
7.1. Testing of Emerging Technologiesc10s10c17, c18
7.2. Testing Through Emerging Technologiesc3s9
8. Software Testing Toolsc12s11c7
8.1. Testing Tool Support and Selectionc12s11c7
8.2. Categories of Toolsc1, c3, c4, c7, 
c8, c9, c12
REFERENCES
[1*] S. Naik and P. Tripathy, Software 
Testing and Quality Assurance: Theory and 
Practice, ed: Wiley, 2008, p. 648.
[2*] I. Sommerville, Software Engineering, 
10th ed., Addison-Wesley, 2016. 
[3] E.W. Dijkstra, Notes on Structured 
Programming, Technological University, 
Eindhoven, 1970.
[4] ISO/IEC/IEEE 29119 — System 
and software engineering — Software 
testing, ed. 2021.
[5]  ISO/IEC/IEEE, “ISO/IEC/IEEE 
24765:2017 Systems and Software 
Engineering — Vocabulary,” 
2nd ed. 2017.
[6] M. Papadakis, M. Kintis, J. Zhang, 
Y. Jia, Y. Le Traon, and M. Harman, 
Chapter Six — Mutation Testing 
Advances: An Analysis and Survey, 
Adv. Comput. 112, 2019: 275-378. 
[7] M. Utting, B. Legeard, F. Bouquet, E. 
Fourneret, F. Peureux, and A. Vernotte, 
Recent advances in model-based testing, 
Advances in Computers, 101, 2016, 
pp. 53-1 2 0 . 
[8]   IEEE Std 1012-2016, IEEE Standard 
for System, Software, and Hardware 
Verification, and Validation, ed. 2016.
[9] ISO/IEC 25010:2011, Systems and 
software engineering — Systems 
and Software Quality Requirements 
and Evaluation (SQuaRE) — 
System and Software Quality 
Models, ed. 2011.
[10] ISO/IEC/IEEE 32675:2022 
Information technology — DevOps — 
Building reliable and secure systems 
including application build, package and 
deployment.
[11] Software Engineering Competency 
Model (SWECOM), v1.0, 2014.
[12] ISO/IEC 20246:2017, “Software and 
systems engineering — Work product 
reviews”, ed, 2017, 42p
[13] V. Riccio, G. Jahangirova, A. Stocco, 
et al., Testing machine learning 
based systems: A systematic mapping, 
Empir Software Eng, 25, 2020, pp. 
5193-5254.
[14*] C.Y. Laporte, and A. April, Software 
Quality Assurance, IEEE Computer 
Society Press, 1st ed., 2018.
[15] S. Demi, R. Colomo-Palacios, and 
M. Sánchez-Gordón, Software 
Engineering Applications Enabled by 

SOFTWARE TESTING   5-35
Blockchain Technology: A Systematic 
Mapping Study, Applied Sciences, 11(7), 
2021, pp. 2960.
[16] K. Mao, L. Capra, M. Harman, and 
Y. Jia. A survey of the use of crowd-
sourcing in software engineering, 
Journal of Systems and Software, 126, 
2017, pp. 57-84.
[17] A. Bertolino, G.D. Angelis, M. 
Gallego, B. García, F. Gortázar, F. 
Lonetti, and E. Marchetti, A system-
atic review on cloud testing, ACM 
Computing Surveys (CSUR), 52(5), 
2019, pp. 1-42.
[18] R. Achary and P. Raj, Cloud Reliability 
Engineering: Technologies and Tools, CRC 
Press, 2021.
[19*] J.  Nielsen, Usability Engineering, 1st 
ed., Boston: Morgan Kaufmann, 1993.

6-1 
CHAPTER 06
Software Engineering 
Operations
ACRONYMS
APIApplication 
Programming Interface
ATDDAcceptance Test Driven 
Development
CDContinuous Delivery
CIContinuous Integration
CPUCentral Processing Unit
CONOPSConcepts of Operations
DBMSDatabase Management System
IaCInfrastructure as-Code
IaaSInfrastructure as a Service
ITInformation technology
ITILIT Infrastructure Library
KAKnowledge Area
KPIKey Performance indicator
MRModification request
MVPMinimum Viable Product 
PaaSPlatform as a Service
PRProblem Report
QAQuality Assurance
SaaSSoftware as a Service
SLAsService-Level Agreements
SRESite Reliability Engineering
TDDTest Driven Development
INTRODUCTION
Software  engineering  operations  refers  to  the  
set of activities and tasks necessary to deploy, 
operate  and  support  a  software  application  
or  system  while  preserving  its  integrity  and  
stability.  These  activities  include  the  deploy-
ment and configuration of the software in the 
targeted  operational  environments  and  the  
monitoring  and  management  of  the  applica-
tion while it is in use (until it is retired). Once 
the application is operational, software engi-
neering  operations  must  manage  any  defects  
that  are  uncovered,  any  changes  made  to  
the  system  software  environment  and  hard-
ware equipment over time, and any new user 
requirements that surface. 
Software engineering operations is an inte-
gral  part  of  system  and  software  life  cycle  
processes   [3].   The   Software   Engineering   
Operations  Knowledge  Area  (KA)  is  related  
to  all  other  aspects  of  software  engineering.  
Therefore,  this  KA  description  is  linked  to  
all  other  software  engineering  KAs  of  the  
SWEBOK  Guide,  particularly  the  Software  
Construction KA, which discusses preparing 
the  software  for  deployment,  including  inte-
grating, building, packaging and testing. 
Specialized software and information tech-
nology  (IT)  operations  engineers  have  tradi-
tionally provided and managed IT operations 
services.   Best   practices   in   software   engi-
neering  operations  were  initially  published  
by  the  IT  infrastructure  library  (ITIL)  and  
were  quickly  accepted  by  the  industry.  These  
practices  were  summarized  and  published  in  
the  Institute  of  Electrical  and  Electronics  
Engineers 20000 standard [1]. 
Historically, operations and computing cen-
ters  were  often  located  in  organizational  silos  
separate from software development activities. 
Progressive  organizations  now  co-locate  soft-
ware  development,  software  maintenance  and  
some  software  engineering  operations  activ-
ities  (often  provided  as  a  service  and  often  
coined  DevOps).  Benefits  of  this  approach  
are  the  elimination  of  the  organizational  silos  
that separated these software activities and the 

6-2   SWEBOK
®
 GUIDE V4.0
sharing  of  common  processes  and  tools.  The  
rising  popularity  and  growing  acceptance  of  
DevOps  practices  [2*]  and  related  standards  
[4],  including  an  ever-evolving  set  of  tools,  
reflect this trend. DevOps aims at automating 
and   continuously   evolving   software   engi-
neering  activities  to  ensure  high-quality  soft-
ware and to satisfy users who demand quicker 
turnaround from software engineers. 
In this context, the role of software engi-
neers involved in software engineering oper-
ations   has   significantly   evolved   over   the   
past  decade  with  the  emergence  of  practices  
like  infrastructure  as  code  (IaC),  Platform-
as-Code  (PaC),  Agile  infrastructure,  soft-
ware-defined     architectures/systems,     and     
the  availability  of  infrastructure  as  a  ser-
vice  (IaaS)  and  platform  as  a  service  (PaaS)  
solutions.  Tasks  traditionally  performed  by  
IT  infrastructure  engineers  are  increasingly  
automated  and  made  available  as  a  service,  
enabling  application  developers  to  perform  
software  engineering  operations  tasks  inde-
pendently as part of their daily project activ-
ities.  For  example,  application  developers  in  
many organizations can now directly use IaaS 
and  PaaS  to  deploy  applications  in  produc-
tion  environments  and  to  monitor  different  
aspects of those applications without directly 
involving operations engineers.
Having  end-to-end  resources  and  desired  
state  configuration  managed  like  code,  using  
practices such as IaC and PaC, provides value 
in  the  form  of  1)  improved  repeatability,  2)  
consistency/standardization,  3)  known  secu-
rity policies , 4) self-documentation (transpar-
ency), 5) single source of truth, 6) configuration 
control,  and  7)  scalability.  From  an  engi-
neering  perspective,  the  important  point  is  
that  nearly  anything  that  impacts  a  software  
product  directly  or  indirectly  should  be  con-
sidered for representation as code.
To perform software engineering operations 
tasks,  some  organizations  use  the  the  concept  
of  Platform  Engineering  and  Site  Reliability  
Engineering  (SRE)  [6]  to  increase  produc-
tivity and software quality. The role of platform 
engineering is to build and manage self-service 
platform capabilities that can be used by soft-
ware engineers to develop, deploy, and operate 
software   applications.   On   the   other   hand,   
the  role  of  SRE  is  to  monitor,  automate,  and  
improve  software  operations  with  respect  to  
non-functional  aspects,  including  availability,  
performance, latency, and security. SRE is also 
responsible  for  change  management,  emer-
gency response, capacity planning, and overall 
efficiency of software systems.
Although   many   organizations   still   use   
conventional    IT    operations    management    
Software Engineering
Operations
Software
Engineering
Operations
Fundamentals
Software
Engineering
Operations
Planning
Software
Engineering
Operations
Delivery
Software
Engineering
Operations
Control
Software
Engineering
Operations
Tools
Denition of
Software Engineering
Operations
Software Engineering
Operations Processes
Software Installation
Scripting and
Automating
Eective Testing and 
Troubleshooting
Performance, Reliability 
and Load Balancing
Operations Plan and
Supplier Management
Development 
and Operational 
Environment
Software Availability, 
Continuity and 
Service Levels
Software Capacity
Management
Software and Data 
Safety, Security, 
Integrity, Protection 
and Controls
Deployment/Release
Engineering
Rollback and
Data Migration
Change Management
Problem
Management
Incident 
Management 
Monitor, Measure 
Track and Review
Operations 
Support
Operations Service 
Reporting
Incident and 
Problem Prevention
Operational Risk 
Management
Automated 
Software
Engineering 
Operations
Software Engineering
Operations for
Very Small Entities
Containers 
and Incident
Visualization
Deployment
Automated Tests
Monitoring and 
Telemetry
Practical
Considerations
Figure 6.1. Breakdown of Topics for the Software Engineering Operations KA.

SOFTWARE ENGINEERING OPERATIONS   6-3
processes, this KA focuses mainly on the role 
of  software  engineers  in  operations  in  the  
emerging contexts of DevOps, IaC, PaC, and 
Agile infrastructure practices. 
In this context, we identify two main soft-
ware  engineering  roles  related  to  operations:  
Operations  engineer,  who  is  responsible  for  
developing operations services made available 
as  a  service  and  accessible  through  an  appli-
cation   programming   interface   (API),   and   
software  engineer,  who  can  use  the  resulting  
operations  services  (available  as  a  service)  to  
independently  deploy  and  manage  applica-
tions without directly involving IT operations 
specialists. 
BREAKDOWN OF TOPICS FOR 
SOF TWARE ENGINEERING 
OPERATIONS 
The  breakdown  of  topics  for  the  Software  
Engineering  Operations  KA  is  shown  in  
Figure 6.1.
1. Software Engineering Operations 
Fundamentals
This first section introduces the concepts and 
terminology that form an underlying basis for 
understanding the role and scope of software 
engineering operations.
1.1.  Definition of Software Engineering 
Operations [1, c3s3.3][3, c6s6.4.12]
In  this  Guide,  the  term  software  engineering  
operations refers to the knowledge, skills, pro-
cesses and tools used by software engineers or 
their  organization  to  ensure  that  a  software  
product,  including  IT  infrastructure,  system  
software,  and  application  software,  operates  
well during development, maintenance and in 
real conditions of operations. 
In  ISO/IEC/IEEE  12207  [3],  an  operator 
is  defined  as  an  “individual  or  organization  
that performs the operations of a system.” The 
SWEBOK  Guide  modifies  that  definition  for  
the  term  operations  engineer,  which  refers  to  
a  software  engineer  who  executes  software  
engineering operations processes. In this role, 
an operations engineer works closely with soft-
ware engineers to develop and offer operations 
services such as the following: 
•    Provisioning,    deploying    and    config-
uring, and supporting containers and vir-
tual servers,
•    Designing  and  offering  on-demand  ser-
vices (e.g., environment on demand, ver-
sioning, continuous integration (CI) and 
testing, deployment, and surveillance) for 
use by software engineering,
•    Monitoring  and  troubleshooting  system  
and   application   software   incidents   by   
running diagnostics, documenting prob-
lems  and  resolutions,  prioritizing  prob-
lems, and assessing impact of issues,
•    Performing,    automating    and    imple-
menting     appropriate     processes     for     
security,   data   protection   and   failover   
procedures,
•    Overseeing     capacity,     storage     plan-
ning  and  database  management  system  
(DBMS) performance,
•    Providing  documentation  and  technical  
specifications to IT staff for planning and 
implementing new or upgraded IT infra-
structure and system software.
ISO/IEC/IEEE   20000-1   describes   the   
need  to  develop  and  enhance  the  profes-
sional  competencies  of  operations  engineers.  
To  achieve  this  goal,  software  organizations  
should address the following:
•    Staff  recruitment:  To  validate  job  appli-
cants’        qualifications/competencies,        
including their professional certifications, 
and  to  identify  their  strengths,  weak-
nesses  and  potential  capabilities  against  
the  operations  engineer  job  description,  
core technologies and computer languages 
mastered and overall experience,
•    Resource   planning:   To   staff   new   or   
expanded engineering operations services, 
plan  the  use  of  new  technology,  plan  the  
assignment  of  service  management  staff  

6-4   SWEBOK
®
 GUIDE V4.0
to  development  project  teams,  develop  
succession  planning  and  other  staffing  
gaps created by staff turnover,
•    Resource    training    and    development:    
To  identify  training  and  development  
requirements  and  create  a  training  and  
development plan that meets them; also, 
to  provide  timely,  effective  delivery  of  
operations services. Operations engineers 
should be trained in the relevant aspects 
of service management (e.g., via training 
courses,     self-study,     mentoring     and     
on-the-job training), and their teamwork 
and leadership skills should be developed. 
A  chronological  training  record  should  
be  maintained  for  each  individual,  with  
descriptions of the training provided.
1.2.  Software  Engineering  Operations  Processes                               
 [2*, s1][3, c6s6.4.12]
ISO/IEC/IEEE 20000-1 is the reference stan-
dard that presents an overview of operations pro-
cesses.  It  specifies  requirements  for  the  design,  
transition,  delivery  and  improvement  of  opera-
tions  services.  The  ISO/IEC/IEEE  20000-1  
describes  five  main  operations  process  groups:  
service  delivery  processes,  release  processes,  
control processes, resolution processes and rela-
tionship  processes.  These  operations  processes  
are  further  categorized  as  technical  processes  
in ISO/IEC/IEEE 12207 [3]. Operations pro-
cesses, from the perspective of a software engi-
neer, contain the activities and tasks necessary 
to  deploy,  configure,  operate  and  support  an  
existing software system or product while pre-
serving its integrity. This international standard 
describes  four  main  operations  process  activi-
ties: 1) prepare for the operation: that requires 
to define an operation strategy; 2) perform the 
operation: which consist of operating and mon-
itoring;  3)  manage  the  results  of  operation:  
where  anomalies  are  recorded  and  addressed;  
and  finally  4)  support  the  customer:  which  
means to give assistance and consultation to any 
user of the operations services. 
Finally,  ISO/IEC/IEEE  32675  [4]  intro-
duces   a   number   of   software   engineering   
operations  activities  using  an  Agile  and  a  
minimum   viable   product   (MVP)   perspec-
tive.  This  standard  recognizes  the  influence  
of DevOps as a set of principles and practices 
that  enable  better  communication  and  collab-
oration  between  relevant  stakeholders  for  the  
•  Operations Plan and Supplier Management
•  Development and Operational Environment
•  Software CM, Build, Package and Deployment
•  Software Availability, Continuity and Service Levels
•  Software Capacity Management
•  Software Backup, Disaster Recovery and Failover
•  Software and Data Safety, Security, Integrity, Protection and Controls
•  Operational Testing, Verification and Acceptance
•  Development/Release Engineering
•  Rollback and Data Migration 
•  Problem Resolution
•  Incident and Change Management
•Monitor, Measure, Track and Review
•Service Support and Operations Service Desk
•Service Reporting
Operations Planning
Processes
Operations Delivery
Processes
Operations Control
Processes
Figure 6.2. Software Engineering Operations Processes and Activities

SOFTWARE ENGINEERING OPERATIONS   6-5
purpose  of  specifying,  developing,  continu-
ously  improving,  and  operating  software  and  
system  products  and  services.  These  processes  
and  activities  are  the  responsibility  of  opera-
tions engineers. 
For  the  purpose  of  the  SWEBOK  Guide, 
engineering   operations   activities   can   be   
grouped into three main operations processes 
(see Figure 6.2) that each contain a number of 
operations  activities,  which  are  described  in  
the following sections of this chapter:
•    Operations Planning (section 2),
•    Operations Delivery (section 3), 
•    Operations Control (section 4).
Each software engineering operations pro-
cess  includes  activities  performed  during  the  
pre delivery and post delivery stages of a soft-
ware  project.  Software  engineering  opera-
tions planning activities occur during the pre 
delivery stage. These activities are covered in 
this chapter.
1.3.  Software Installation  
 [1, c3, c6s2][2*, c3s3.1]
Before  a  software  application  or  update  can  
be  made  available  to  the  users  (i.e.  released  
in  production),  the  operations  engineer  must  
install the software as part of its deployment. 
To  install  the  software,  the  engineer  might  
have to uninstall previous versions, configure 
the  software  for  its  target  destination,  and  
create  the  necessary  directories,  registry  files  
and environment variables on the target des-
tination.  This  is  often  done  using  a  scripting  
language.  The  installation  of  the  software  to  
the  appropriate  locations  is  typically  done  
electronically,  but  in  the  case  of  embedded  
systems,  it  might  require  the  use  of  a  phys-
ical  medium.  Once  the  software  is  installed,  
a verification step is conducted to ensure that 
the operation succeeded.
1.4.  Scripting and Automating [2*, c9]
As  part  of  software  engineering  operations,  
repetitive  tasks  are  automated    to  reduce  
delays,  increase  quality,  and  ensure  a  con-
sistent  and  stable  operational  environment.  
This   is   typically   achieved   using   scripting   
languages,   which   are   basic   programming   
languages.   Automating   operations   enables   
a  quicker  reaction  in  case  of  a  failure  and,  
therefore, results in  less downtime and fewer 
severe  incidents,  as  alerts  are  sent  immedi-
ately.  Automating  such  tasks  is  also  a  good  
way to ensure standardization of operations in 
an  organization.  It  also  constitutes  the  basis  
for the development of operations made avail-
able as a service. Refer to section 6 for further 
discussion on operations tools.
1.5.  Ef﻿fective Testing and  
Troubleshooting [2*, c3]
Software  engineering  operations  is  respon-
sible for ensuring the stability of the system. 
For  this  purpose,  software  must  be  thor-
oughly  tested  before  it  is  released  (deployed  
in  production  and  made  available  to  users).  
Because  manual  testing  is  inefficient,  error-
prone and non-scalable, testing must be auto-
mated  as  much  as  possible  throughout  the  
entire  software  process.  Also,  because  the  
time  available  for  testing  is  limited,  regres-
sion  testing  and  test  coverage  strategies  (the  
selective  retesting  of  a  software  application,  
or  component,  to  verify  that  the  software  
to  be  deployed  will  not  cause  unintended  
effects)  play  an  important  role  in  software  
engineering operations. 
When errors are found (in production after 
the  software  is  released  or  during  internal  
testing  phases),  software  engineers  and  soft-
ware operations engineers need to troubleshoot 
hardware  and  software  incidents  by  running  
diagnostics,  documenting  problems  and  res-
olutions,  prioritizing  problems,  and  assessing  
the  impact  of  the  issues.  The  cost  —  in  both  
time  and  money  —  of  repeating  full  testing  
on  a  major  piece  of  software  is  significant.  
To  ensure  that  the  requested  problem  reports  
(PRs) are valid, the operations engineer should 
replicate  and  verify  problems  by  running  the  
appropriate  tests.  Testing  certain  aspects  of  
the software in production can be particularly 

6-6   SWEBOK
®
 GUIDE V4.0
challenging. For example, when software per-
forms critical functions, bringing it off-line to 
test  might  be  difficult.  Generally,  testing  the  
software  in  the  production  system  context  is  
challenging (sometimes impossible) and could 
require  the  use  of  testing  techniques  such  as  
canary testing and dark launches. The Software 
Testing  KA  provides  additional  information  
and references on testing.
1.6.  Performance, Reliability and  
Load Balancing [1, c6s6.2]
Software  operations  engineers  plan  for  per-
formance, reliability and load balancing early 
in  software  projects  to  ensure  they  meet  the  
project  requirements.  (See  section  1.2  to  1.7  
of  the  Software  Requirements  KA).  A  cur-
rent trend is for software engineers to design 
and  use  infrastructure/operations  services  to  
adjust dynamically (e.g. scalability) the infra-
structure  according  to  the  demand.  Using  
DevOps  practices  enables  operations  engi-
neers to anticipate these needs early and pro-
vide   infrastructure   services   that   software   
engineers  can  use  and  test  during  the  devel-
opment stages of a project. 
2. Software Engineering Operations 
Planning
This  topic  introduces  some  of  the  generally  
accepted  techniques  used  in  software  engi-
neering    operations    planning.    Operations    
engineers  must  deal  with  a  number  of  key  
issues to ensure software operates effectively. 
Operations  engineers  should  document  their  
software  engineering  operations  steps  and  
tools,  using  any  type,  form  or  medium  suit-
able for the purpose (e.g., Wikis, documents, 
and more). The following topics are typically 
considered suitable as evidence of well docu-
mented operations:
•    Policies and plans,
•    Service documentation,
•    Procedures,
•    Processes, and
•    Process control records.
2.1.  Operations Plan and Supplier Management
 [1, c4s4.1][3, c6s6.1]
Software   engineering   operations   planning   
should  comprise  part  of  the  process  of  trans-
lating  project  requirements  and  the  needs  of  
the  developers  and  maintainers  into  services,  
and it should provide a road map for directing 
progress. This process often involves the prod-
ucts  and  services  of  suppliers  that  must  be  
well  coordinated  to  ensure  quality  service.  
ISO/IEC/IEEE  20000-1  describes  planning  
activities,  as  well  as  ISO/IEC/IEEE  12207,  
which lists the activities operations engineers 
considers  from  human,  technical  and  system  
perspectives.
2.1.1. Operations Plan 
 [1, c4s4.1][3,c6s6.4.12.3a]
Whereas    software    development    typically    
lasts  from  some  months  to  a  few  years,  the  
operations  phase  usually  lasts  many  years.  
Therefore,  estimating  resources  is  a  key  ele-
ment  of  operations  planning.  Software  engi-
neering   operations   planning   should   begin   
with  the  decision  to  develop  a  new  software  
product  and  should  consider  its  maintenance  
and  operations  requirements  early.  A  concept  
document should be developed, followed by an 
operations and maintenance plan [1,c7s2], and 
both should address the following:
•    Scope  of  the  operations  and  software  
maintenance,
•    Adaptation  of  the  software  engineering  
operations process and tools,
•    Identification of the software engineering 
operations organization,
•    Estimate of software engineering opera-
tions and maintenance costs.
The  next  planning  step  suggest  to  develop  
a  software  engineering  operations  plan,  or  
concept  of  operations  (CONOPS).  This  plan  
should  be  prepared  during  software  develop-
ment and should specify how users will request 
software modifications and report problems or 
issues  when  the  software  will  be  operational.  

SOFTWARE ENGINEERING OPERATIONS   6-7
Software  engineering  operations  planning  is  
addressed  in  ISO/IEC/IEEE  12207  [3]  and  
ISO/IEC/IEEE 32675 [4]. The standards pro-
vide  guidelines  for  planning,  implementing,  
maintaining, automating and supporting pro-
duction software. Finally, at the highest plan-
ning  level,  the  operations  organization  must  
conduct business planning activities (e.g., bud-
getary, financial and human resources), just as 
all the other divisions of the organization (refer 
to  the  Software  Engineering  Management  
KA).  ISO/IEC/IEEE  20000-1  recommends  
that the operations plan address issues associ-
ated with a number of planning perspectives, 
including the following:
•    The  roles  and  responsibilities  for  imple-
menting,  operating  and  maintaining  the  
new or changed service,
•    Activities  to  be  performed  by  customers  
and suppliers,
•    Changes to the existing service manage-
ment framework and services,
•    Communication to the relevant parties,
•    New or changed contracts and agreements 
to align with changes in business needs,
•    Staffing and recruitment requirements,
•    Skills  and  training  requirements  (e.g.,  
users, technical support),
•    Processes,  measures,  methods  and  tools  
to be used in connection with the new or 
changed service,
•    Capacity management,
•    Financial management,
•    Budgets and timescales,
•    Service acceptance criteria, and
•    The  expected  outcomes  from  operating  
the  new  service,  expressed  in  measur-
able terms.
This   plan   ensures   that   an   operational   
strategy is defined, conditions for correct oper-
ations  are  identified  and  evaluated,  the  soft-
ware is tested at scale to operate in its intended 
environment,   and   surveillance   is   provided   
to  ensure  responsiveness  and  availability  of  
the  software  by  ensuring  constant  support.  
At  the  individual  request  level  (e.g.,  problem  
report  (PR)  or  modification  request  (MR))  
need  planning.  Once  individual  requests  are  
received  and  validated,  the  release  or  version  
planning   activity   requires   that   operations   
engineers perform the following tasks:
•    Identify  the  target  availability  dates  of  
individual requests,
•    Agree   on   the   content   of   subsequent   
releases or versions,
•    Identify  potential  conflicts  and  develop  
alternatives,
•    Assess  the  risk  of  a  given  release  and  
develop a rollback and data migration plan 
(see section 3.3) in case problems arise,
•    Inform all stakeholders.
2.1.2. Supplier Management 
 [1, c7s3][3, c6s6.1]
Supplier  management  ensures  that  the  orga-
nization’s suppliers and their performance are 
managed  appropriately  to  support  the  seam-
less provision of quality products and services. 
ISO/IEC/IEEE 12207 lists the activities that 
the operations engineer will perform to estab-
lish an agreement to acquire suppliers’ products 
and/or services. From an operations engineer’s 
perspective,  the  nature  of  the  relationship  
with  suppliers  and  the  approach  should  be  
determined by the nature of the products and 
services  needed  in  a  project.  Managing  sup-
pliers  of  services  related  to  operational  soft-
ware  includes  managing  out-sourced  services  
and cloud services, like IaaS and PaaS. 
2.2.  Development and Operational 
Environments [2*, c9]
The  overall  software  process  requires  the  use  
of  different  environments  at  different  stages.  
These are typically defined as the development 
environment,  the  testing  or  quality  assurance  
(QA)  environment,  the  preproduction  envi-
ronment,  and  the  production  environment.  
To  build  quality  into  the  product  and  reduce  
the  risks  associated  with  the  release  of  soft-
ware in the production environment (whether 
the  release  is  associated  with  new  function-
ality  or  software  defects),  engineers  must  

6-8   SWEBOK
®
 GUIDE V4.0
ensure that the different environments are all 
coherent and synchronized with the produc-
tion environment. 
For this reason, DevOps recommends that 
the creation of all the different environments 
be  automated  and  built  from  a  single  code  
repository. In mature DevOps organizations, 
the  creation  of  the  different  environments  is  
completely  automated  and  made  available  as  
a  service.  Also,  all  environments  need  to  be  
built from the same code source (single source 
of  truth)  to  ensure  that  all  the  environments  
are  synchronized  with  the  production  envi-
ronment  in  which  the  software  is  released.  
This leads to the concept of infrastructure as 
code (IaC).
2.3.  Software Availability, Continuity, and 
Service Levels [1, c6s6.3]
Service  availability  and  continuity  must  be  
managed to ensure that customer commitments 
are met. Because service availability and conti-
nuity are defined as nonfunctional requirements 
early  in  a  project  (see  the  Software  Quality  
KA),  operations  engineers  will  ensure  that  
the proper infrastructure is planned, designed, 
implemented  and  tested.  Software  availability  
is   measured   and   recorded,   and   unplanned   
nonavailability  is  investigated  and  appropriate  
actions  taken.  Service  reports  produce  avail-
ability and continuity indicators of operations 
services against service-level targets. 
The  service-level  management  process  moni-
tors the agreed software level of service, including 
workload    characteristics,    performance    and    
availability  trend  information  and  customer  
satisfaction analysis. Defining, agreeing to and 
documenting service-level agreements (SLAs) 
can  help  clarify  the  full  range  of  operations  
services  obligations  provided.  The  Software  
Maintenance  KA  provides  additional  infor-
mation and references about SLA’s.
2.4.   Software Capacity Management 
 [1, c6s6.5]
ISO/IEC/IEEE 20000-1 describes the need 
to  ensure  that  the  software  product  has  the  
capacity,  at  all  times,  to  meet  current  and  
future  agreed-upon  demands  created  by  the  
customer’s  business  needs.  The  current  and  
expected  business  requirements  for  services  
should  be  understood  in  terms  of  what  the  
business  needs  in  order  to  deliver  its  prod-
ucts or services to its customers. Business pre-
dictions  and  workload  estimates  should  be  
translated into specific requirements and doc-
umented. The reaction to variations in work-
load  or  environment  should  be  predictable;  
data on current and previous components, as 
well  as  resource  utilization  at  an  appropriate  
level, should be captured and analyzed to sup-
port the process.
Capacity  management  is  the  focal  point  
for  all  performance  and  capacity  issues.  The  
process  should  directly  support  the  develop-
ment  of  new  and  changed  services  by  sizing  
and modeling these services. A capacity plan 
documenting  the  actual  performance  of  the  
infrastructure and the expected requirements 
should be produced at a suitable frequency (at 
least annually), considering the rate of change 
in  services  and  service  volumes,  informa-
tion  in  the  change  management  reports,  and  
changing   customer   business   requirements.   
The  capacity  plan  should  document  costed  
options  for  meeting  business  requirements  
and  recommend  solutions  to  ensure  achieve-
ment of the agreed-upon service-level targets 
as  defined  in  the  SLA.  The  technical  infra-
structure and its current and projected capac-
ities  should  be  well  understood  to  ensure  
optimal software operations.
2.5.   Software Backup, Disaster Recovery, and 
Failover [1, c6s6.3.4]
ISO/IEC/IEEE  20000-1  also  proposes  that  
the   following   should   be   quickly   available   
following  a  major  service  failure  or  disaster  
to  ensure  continuity  planning  and  testing:  
backups  of  data,  documents  and  software,  
and any equipment or staff necessary for ser-
vice  restoration.  Backup  and  data  recovery  
are  important  activities;  successful  recovery  
is  especially  vital.  The  need  for  successful  
recovery  should  influence  which  backup  and  

SOFTWARE ENGINEERING OPERATIONS   6-9
recovery  methods  are  used  (full  or  incre-
mental),  how  frequently  restore  points  are  
established,  where  they  are  stored,  and  how  
long they are retained. 
Preparedness  and  regular  test  of  backup,  
disaster  recovery,  and  failover  should  be  con-
stantly  rehearsed  as  changes  to  the  produc-
tion  environment  are  made.  This  is  another  
essential activity that is triggered when outage 
assessments are done. Testing disaster recovery 
requires  stopping  the  service,  identifying  the  
checkpoint  state  and  triggering  the  failover  
process.  Software  engineers  should  under-
stand  that  failure  is  inevitable  and  that  auto-
mated  failover  daemons  can  reduce  recovery  
time  drastically.  To  achieve  this,  software  
applications  should  include  failure-handling  
logic;  this  must  be  planned  during  develop-
ment.  DevOps  can  help  organizations  that  
want to reduce failovers and disasters by auto-
mating and launching tests as often as possible 
to ensure readiness in case of a failure or cata-
strophic event.
2.6.   Software and Data Safety, Security, 
Integrity, Protection, and Controls 
 [1, c6.s6.6]
The   need   to   manage   information   secu-
rity  effectively  within  all  service  activities  is  
described  in  ISO/IEC/IEEE  20000-1.  This  
is done by conducting a software risk assess-
ment on the security and availability of infor-
mation. Operations engineers should strive to 
enforce the following controls:
a.    Senior  management  should  define  their  
information  security  policy,  communi-
cate  it  to  staff  and  customers,  and  act  to  
ensure its effective implementation,
b. Information  security  management  roles  
and  responsibilities  should  be  defined  
and allocated to post holders,
c.    A representative of the management team 
should be assigned the role of monitoring 
and  maintaining  the  effectiveness  of  the  
information security policy,
d.    Staff with significant security roles should 
receive information security training,
e.    All  staff  should  be  made  aware  of  the  
information security policy,
f.  Expert  help  on  risk  assessment  and  con-
trol implementation should be available,
g. Changes   should   not   compromise   the   
effective operation of controls, and
•    Information   security   incidents   should   
be  reported  following  incident  manage-
ment  procedures,  and  a  response  should  
be initiated.
In  line  with  the  evolution  of  DevOps,  
DevSecOps  is  promoting  the  integration  
of  security  early  and  throughout  the  soft-
ware  process,  which  includes  the  integra-
tion  of  different  security  mechanisms  and  
tools at the operations level. The goal is to 
automate  the  detection  and  correction  of  
security  issues  as  early  as  possible  in  the  
overall process.
3. Software Engineering Operations 
Delivery
This  topic  introduces  some  of  the  gener-
ally  accepted  processes  used  during  software  
engineering  operations    delivery  (ISO/IEC/
IEEE   20000-1):   SLA,   service   reporting,   
service  continuity,  availability  management,  
budgeting  and  accounting  for  IT  services,  
capacity management, and information secu-
rity management. 
3.1.   Operational Testing, Verification, and 
Acceptance [2*,c10] [3, c6s6.3.5.3d]
Software  engineers  plan  and  execute  soft-
ware  verification  as  early  as  possible,  using  
test-driven development (TDD) and accep-
tance   test-driven   development   (ATDD)   
techniques and tools that ensure that opera-
tional testing is ongoing during the develop-
ment of the software, not only at the end of 
a project. DevOps plays an important role in 
developing and automating software testing 
services  and  integrating  different  tools  to  
boost   software   productivity   and   quality.   
(See  TDD  and  ATDD  in  the  Software  
Testing KA.)

6-10   SWEBOK
®
 GUIDE V4.0
3.2.   Deployment/Release Engineering 
 [2*,c12][3,c6s6.3.5.3d]
A    software    operations    engineer’s    main    
responsibility  relates  to  the  deployment  and  
release  of  software  to  ensure  its  continued  
performance.  As  defined  in  [2*],  “deploy-
ment  is  the  installation  of  a  specified  ver-
sion of software to a given environment (e.g., 
deploying code into an integration test envi-
ronment  or  deploying  code  in  production),”  
whereas  “release  is  when  we  make  a  feature  
(or  set  of  features)  available  to  all  our  cus-
tomers  or  a  segment  of  customers  (e.g.,  we  
enable  the  feature  to  be  used  by  5%  of  our  
customer base).” Release processes include all 
the activities related to release management. 
ISO/IEC/IEEE  12207  [3]  lists  release  con-
trol activities and explains the need to iden-
tify  and  record  release  requests,  identify  the  
software  system  elements  in  a  release  fol-
lowed  by  approval,  and  track  the  releases  in  
their specified environments. 
DevOps  advocates  integrating  develop-
ment  and  operations  in  the  same  team  to  
improve   software   engineering   operations   
efficiency. In traditional software processes, 
when an application is ready for deployment, 
it is transferred from a development team to 
an  operations  team  that  is  responsible  for  
deployment, which is mostly done manually. 
This  results  in  processes  that  are  inefficient  
from both a time and a quality perspective. 
To improve the efficiency of the deployment 
process,  DevOps  calls  for  automating  the  
different deployment steps, including pack-
aging  the  code,  generating  configuration  
files, restarting the servers, configuring the 
servers  and  databases,  installing  the  soft-
ware on the different servers, launching the 
execution of the application, and executing 
smoke testing. 
Different    release    engineering    strate-
gies  can  be  used  to  reduce  the  risks  asso-
ciated     with     software     releases.     These     
strategies can be grouped into two main cat-
egories:   environment-based   release   strate-
gies and application-based release strategies. 
Environment-based  release  strategies  use  a  
staging  environment  to  support  the  release  
of  a  new  version  of  an  application.  In  other  
words,  the  basic  strategy  involves  deploying  
the new version of the application to a staging 
environment. Application-based release strat-
egies are based on the use of toggles (e.g., fea-
ture  toggles)  that  make  it  possible  to  enable  
or disable specific sections of the code (e.g., a 
feature) using configuration parameters.
Deployment  and  release  are  supported  
by  automation  techniques  and  tools.  The  
canary release testing technique is a partial 
and time-limited deployment of a change in 
a  service  and  an  evaluation  of  that  change.  
This  evaluation  helps  the  operations  engi-
neer   decide   whether   to   proceed   with   a   
complete  deployment.  Similarly,  tools  that  
manage the installation of new software typ-
ically observe the newly started server for a 
while, ensuring that the server doesn’t crash 
or  otherwise  misbehave.  The  same  tech-
nique is useful for observing recent changes; 
if  they  do  not  pass  the  validation  period,  
they  can  be  automatically  rolled  back.  The  
Software  Configuration  Management  KA  
provides more information about the release 
processes.  Once  the  application  platform  is  
deployed  in  the  targeted  production  envi-
ronment,  the  decision  to  make  it  available  
to  the  users  (release  it)  becomes  a  busi-
ness decision.
3.3.  Rollback and Data Migration 
 [2*, c12][3, c6s6.4.10.3]
Rollback  and  data  migration are terms used to 
describe the process of returning software and 
its  database  to  a  state  where  they  work  prop-
erly.  Software  engineers  ensure  that  when  
a  new  version  of  the  software  and  its  data-
bases  have  been  modified  and  deployed  to  
production,  they  can  easily  and  quickly  be  
rolled back in case the new version is causing 
defects or product degradation in production. 
This  means  a  planned  and  rehearsed  rollback  
is  done  before  a  new  version  of  the  software  
is  deployed  in  production.  DevOps  processes  
automate  this  process  to  make  it  faster;  in  
fact,  the  automated  surveillance  can  trigger  

SOFTWARE ENGINEERING OPERATIONS   6-11
rollback and data migration to a previous state 
so quickly that the end user doesn’t notice that 
there  was  a  problem.  Both  release  strategy  
categories  (described  in  section  3.2)  —  envi-
ronment-based  release  and  application-based  
release — can be used to support rollback.
3.4.  Change Management  [1, c9s9.2]
This   operations   process   ensures   that   all   
changes are assessed, approved, implemented 
and  reviewed  in  a  controlled  manner.  All  
change  requests  are  recorded  and  classified  
(e.g.,  emergency,  urgent,  major  and  minor).  
This  process  assesses  the  risk  of  a  change  
and  the  need  for  a  rollback  strategy  in  case  
of failure. Large systems might require that a 
change schedule be planned with the product 
manager and end users. 
Whereas  in  traditional  software  delivery  
processes  (or  software  life  cycle  models),  all  
changes  are  delivered  as  part  of  new  soft-
ware  releases  (containing  multiple  changes  
related  to  different  aspects  of  the  application  
or system) issued at fixed time intervals (e.g., 
every three months), DevOps aims to deliver 
small units of change (a single new function-
ality  or  service,  or  defect  fix,  rather  than  a  
new version of an application containing mul-
tiple changes) on demand and independently 
from  each  other.  For  this  purpose,  software  
applications   (or   services)   must   be   archi-
tected  to  enable  small,  independent  software  
deployments.
3.5.  Problem Management [1, c8s8.3]
The  objective  of  this  operations  process  is  to  
minimize disruption to the business through 
the  identification  and  analysis  of  the  cause  
of  software  and  system  incidents  and  prob-
lems. This approach may require the involve-
ment   of   a   multidisciplinary   team,   whose   
software  engineers  and  operations  engineers  
investigate,  for  example,  recurring  produc-
tion problems that might have an underlying 
cause  in  software  infrastructure  and  system  
components.  This  might  require  monitoring,  
logging  and  profiling  the  software  and  its  
infrastructure behavior.
4. Software Engineering Operations 
Control
This topic introduces some generally accepted 
techniques   used   in   software   engineering   
operations control.
4.1.  Incident Management [1, c8s8.2] 
Incident    management    is    the    process    of    
recording,  prioritizing  and  assessing  the  busi-
ness  impact,  resolution,  escalation  and  closure  
of  software  incidents.  The  modern  DevOps  
approach automates software surveillance using 
alerts and logs to prevent minor incidents from 
becoming   major   incidents.   When   an   inci-
dent  occurs,  proper  analysis  and/or  post  mor-
tems  must  be  conducted  to  find  the  source  of  
the incident and appropriate solutions must be 
implemented  to  prevent  similar  incidents  to  
happen again in the future.
4.2.  Monitor, Measure, Track, and Review   
 [2*, c14-15]
Software    engineering    operations    activi-
ties  monitor  capacity,  continuity  and  avail-
ability.  In  a  DevOps  mindset,  hope  should  
not be a strategy; instead, engineers should be 
informed about system quality and operational 
health  with  evidence,  such  as  the  following  
key performance indicators (KPI), which are 
available to stakeholders in real time:
•    Production    system’s    monitoring    and    
product telemetry,
•    Actionable     verification     and     valida-
tion  results  before  and  after  release  to  
production,
•    End-user activity and resource use,
•    Impact analysis results,
•    Inter-   and   intra-related   dependencies   
required for system operation,
•    Configuration    changes    unrelated    to    
approved deployment tasks, and
•    Security    and    resilience    performance    
capabilit y.

6-12   SWEBOK
®
 GUIDE V4.0
4.3.  Operations Support [1, c6, c14s5]
ISO/IEC/IEEE   12207   [3],   “ISO/IEC/
IEEE   20000-1   [1]   and   ISO/IEC/IEEE   
32675  [4]  identify  the  primary  software  
engineering  operations  activities  that  sup-
port   the   operations   processes   —   activi-
ties that operate the software product in its 
intended  environment  —  and  the  primary  
activities  that  provide  support  to  the  cus-
tomers of the software products. Operations 
support  activities  are  initiated  at  the  plan-
ning  stage  of  the  project  and  are  then  exe-
cuted,  which  often  requires  techniques  and  
tools  to  proactively  monitor  the  product  
and  services  and  react  quickly  to  events  
and  incidents.  Support  activities  are  often  
described in SLAs.
4.4.   Operations Service Reporting   
 [1,c6s6.2]
Service  reporting  aims  to  produce  agreed-
upon,  timely,  reliable  and  accurate  informa-
tion for decision-making. Each service report 
helps  demonstrate  how  an  operations  ser-
vice  has  performed  and  whether  it  has  met  
some stated and agreed-upon end-user objec-
tive.  Typical  service  reports  address  perfor-
mance  against  service-level  targets,  as  well  
as  security  breaches,  the  volume  of  transac-
tions and resource use, incidents and failures, 
trend  information,  and  satisfaction  analysis.  
Operations  engineers  need  to  establish  auto-
mated  systems  and  tools  for  measurement  to  
do the following:
•    Determine whether measures are already 
available  or  additional  instrumentation  
for   collection,   analysis   and   reporting   
is needed,
•    Select or develop a framework and tools to 
allow  coordination  of  measurement  col-
lection for analysis, reporting and control.
5. Practical Considerations
This topic introduces practical considerations 
for software engineering operations.
5.1.  Incident and Problem Prevention 
 [2*, c7]
The  overall  operations  process  needs  to  be  
automated as much as possible to prevent inci-
dents  and  problems,  and  automated  testing  
needs to be integrated throughout the process. 
Also,  product  telemetry  should  be  imple-
mented  with  proper  analytics  techniques  to  
detect problems as early as possible to prevent 
incidents.  For  this  purpose,  data  collected  
at  all  layers  of  the  product  stack  (including  
application  layer,  operating  system  layer  and  
infrastructure  layer)  must  be  collected  and  
analyzed.  Using  product  telemetry  not  only  
allows engineers to detect potential issues but 
also  provides  the  foundation  for  identifying  
the source of the problem.
5.2.   Operational Risk Management 
 [3, c6s6.4.12.3c4]
Operations engineers must manage a number 
of  risks.  IEEE  2675  [4]  defines  continuous  
risk management as a continuous process that 
can be automated to monitor operations con-
stantly for risks that can affect software avail-
ability,  scalability  and  security.  Operations  
engineers  can  take  measures  to  automate  
the alerts. To decide what events will trigger 
an  alert,  they  need  to  talk  with  product  
owners  and  software  engineers  to  establish  
an agreed-upon level of risk tolerance. Other 
perspectives  are  to  choose  the  deployment  
process that is appropriate for the risk profile 
of  a  given  service  and  the  risks  of  exposing  
private data.
5.3.  Automating Software Engineering 
Operations [2*, c8]
Automation has taken an important place in 
recent years in modern operations. Software 
engineers achieve the best results when cou-
pling applications and operations automation. 
Although  automation  primarily  focuses  on  
managing the life cycle of a system or infra-
structure  (e.g.,  user  account  creation,  envi-
ronments  and  server  provisioning,  runtime  

SOFTWARE ENGINEERING OPERATIONS   6-13
config changes), it can also be useful in other 
use  cases  where  services  can  be  developed  
to  help  software  engineers  deploy,  test  and  
debug  during  development.  Trends  in  oper-
ations automation aim to reduce complexity, 
accelerate   provisioning   of   infrastructure,   
offer operations services scripts to developers, 
define   applications,   automate   deployment   
and test workflows.
5.4.  Software Engineering Operations for Small 
Organizations
Very small organizations (organizations of up 
to  25  people)  have  difficulty  applying  stan-
dards  developed  by  and  for  large  organiza-
tions,  as  their  requirements  can  overwhelm  
the  capabilities  of  small  organizations.  This  
is  where  the  ISO/IEC  29110  series  of  stan-
dards  is  useful,  as  it  provides  standards  and  
guidelines adapted to very small organizations 
to  ensure  the  quality  of  their  software  engi-
neering  operations  [7].  Software  engineers  
should be aware that operations processes can 
be adapted to small organizations and that the 
ISO/IEC  CD  29110-5-5  is  currently  under  
development for this purpose.
6. Software Engineering Operations Tools 
 [1, c5s5g][2*, c12] 
This  topic  encompasses  tools  that  are  par-
ticularly important in software engineering 
operations for maximizing the efficient use 
of   personnel.   Automating   development,   
maintenance  and  operations-related  tasks  
saves  engineering  resources  and  improves  
quality   and   turnaround.   When   imple-
mented appropriately, such automated tasks 
are generally faster, easier and more reliable 
than they would be if they were attempted 
manually  by  software  engineers  and  oper-
ations  engineers.  DevOps  supports  such  
automation for integrating, building, pack-
aging,  configuring,  and  deploying  reliable  
and   secure   systems.   It   combines   devel-
opment,    maintenance,    and    operations    
resources  and  procedures  to  perform  CI,  
delivery, testing and deployment. 
Continuous   delivery   (CD)   is   a   software   
engineering   practice   that   uses   automated   
tools to provide frequent releases of new sys-
tems  (including  software)  to  staging  or  var-
ious   test   environments.   CD   continuously   
assembles  the  latest  code  and  configuration  
from the head into release candidates.
Continuous   testing   is   a   software   testing   
practice  that  involves  testing  the  software  at  
every  stage  of  the  software  development  life  
cycle. Continuous testing aims to evaluate the 
quality  of  software  at  every  step  of  the  CD  
process by testing early and often. Continuous 
testing involves various stakeholders, such as 
developers,  DevOps  personnel,  and  QA  and  
end-users.
Continuous deployment (aka CD) is an auto-
mated  process  of  deploying  changes  to  pro-
duction  by  verifying  intended  features  and  
validations  to  reduce  risk.  Jez  Humble  and  
David Farley [8] pointed out that “[t]he biggest 
risk  to  any  software  effort  is  that  you  end  up  
building  something  that  isn’t  useful.  The  ear-
lier and more frequently you get working soft-
ware in front of real users, the quicker you get 
feedback to find out how valuable it really is.”
6.1.  Containers and Virtualization  
Different   container/virtualization   technol-
ogies   and   management   tools   (also   called   
orchestrators)   are   available   to   operations   
engineers to improve the scalability of appli-
cations and standardize software deployment 
across multiple computer and server suppliers. 
[4, c6,s6.4.12] Operations engineers use their 
knowledge of the size and complexity of each 
project to identify the best tool for flexibility, 
security and monitoring.
6.2.  Deployment [2*, c12] 
Different  technologies  and  tools  can  be  used  
to  manage  software  deployments  in  different  
environments. [4, c5s5.1] Also, different tools 
are  usually  combined  to  cover  the  different  
phases  and  aspects  of  software  deployment,  
ranging from the specification of deployment 
and configuration using descriptor files to the 

6-14   SWEBOK
®
 GUIDE V4.0
automated  deployment  and  management  of  
production environment resources.
6.3.  Automated Test  [2*, c10]
To  enable  fast  and  constant  feedback  to  the  
developers,   testing   must   be   automated   as   
much  as  possible  throughout  the  entire  soft-
ware  delivery  process,  including  throughout  
development  and  operations.  For  this  pur-
pose,  a  testing  strategy  covering  the  different  
types of test (unit test, integration test, system 
test, user acceptance test) must be defined, and 
tools  to  support  and  automate  the  different  
testing  phases  must  be  selected.  The  automa-
tion of testing is critical to provide continuous 
feedback   to   software   engineers   developing   
code and thereby to improve software quality.
6.4.  Monitoring and Telemetry [2*, c14-15]
Monitoring  and  telemetry  are  key  aspects  
of   software   engineering   operations.   They   
collect data at all layers of the software system 
(including  application,  operating  system  and  
server)  and  extract  information  that  can  be  
used to analyze and monitor different aspects 
of  the  system  to  detect  issues  and  follow  
the  evolution  of  various  properties.  James  
Turnbull  [9]  describes  a  general  monitoring  
framework  architecture  used  by  engineering  
operations in many technology organizations. 
Implementing  monitoring  solutions  requires  
combining  different  techniques  and  tools  to  
collect  data  at  different  layers.  This  includes  
logs  at  the  application  level,  execution  traces  
at  the  operating  system  level  and  resource  
use information (like CPU and memory use) 
at  the  server  level.  Then,  based  on  the  col-
lected   data,   different   analytics   techniques   
(e.g., statistical analysis and machine learning 
techniques)  can  be  used  to  extract  relevant  
information. Finally, dashboards can be used 
to  visualize  the  extracted  information;  dif-
ferent dashboards can be developed to display 
relevant information to different stakeholders. 
MATRIX OF TOPICS VS. REFERENCE MATERIAL
ISO 20000-1  
[1] 
The DevOps  
Handbook [2*]ISO 12207 [3]
1. Software Engineering Operations 
Fundamentals
1.1. Definition of Software Engineering 
Operations 
c3s3.3c6s6.4.12
1.2. Software Engineering 
Operations Processes
s1c6 s6.4.12
1.3. Software Installationc3, c6s2c3s3.1
1.4. Scripting and Automatingc9
1.5. Ef﻿fective Testing and Troubleshootingc3
1.6. Performance, Reliability and 
Load Balancing
c6s6.2
2. Software Engineering 
Operations Planning
2.1. Operations Plan and Supplier 
Management
c4s4.1c6s6.1
2.2. Development and Operational 
Environments
c9

SOFTWARE ENGINEERING OPERATIONS   6-15
2.3. Software Availability, Continuity 
and Service Levels
c6s6.3
2.4. Software Capacity Managementc6s6.5
2.5. Software Backup, Disaster Recovery 
and Failover
c6s6.3.4
2.6. Software and Data Safety, Security, 
Integrity, Protection and Controls
c6s6.6
3. Software Engineering 
Operations Delivery
3.1. Operational Testing, Verification and 
Acceptance
c10c6s6.3.5.3d
3.2. Deployment/Release Engineeringc12
3.3. Rollback and
Data Migration
3.4. Change Managementc9s9.2
3.5. Problem Managementc8s8.3
4. Software Engineering 
Operations Control
4.1. Incident Managementc8s8.2
4.2. Monitor, Measure, Track and Review c14 -15
4.3. Operations Supportc6, c14s5
4.4. Operations Service Reportingc6s6.2
5. Practical Considerations 
5.1. Incident and Problem Preventionc7
5.2. Operational Risk Managementc6s6.4.12.3c4
5.3. Automating Software Engineering 
Operations
c8
5.4. Software Engineering Operations for 
Small Organizations
6. Software Engineering 
Operations Tools
c5s5gc12
6.1. Containers and Virtualization
6.2. Deploymentc12
6.3. Automated Testc10
6.4. Monitoring and Telemetryc14 -15
REFERENCES 
[1]   IEEE standard, ISO/IEC/IEEE 20000-
1:2013, Information technology — Service 
management — Part 1: Service management 
systems requirements, ed. IEEE, 2013.
[2*] G. Kim, J. Humble, J. Debois, J. 
Willis, and N. Forsgren, The DevOps 

6-16   SWEBOK
®
 GUIDE V4.0
Handbook: How to create world-class 
agility, reliability and security in tech-
nology organizations, 2nd ed., IT 
Revolution Press, 2021.
[3] IEEE standard, ISO/IEC/IEEE 
12207:2017, Systems and software 
engineering — Software Life Cycle 
Processes, ed. IEEE, 2017.
[4] IEEE standard, ISO/IEC/IEEE 
32675:2022, Information Technology 
— DevOps: Building Reliable and 
Secure Systems Including Application 
Build, Package and Deployment, ed. 
IEEE, 2022.
[5] ISO/IEC/IEEE, “ISO/IEC/IEEE 
24765:2017 Systems and Software 
Engineering — Vocabulary,” 2nd ed. 2017
[6] B. Beyer, C. Jones, J. Petoff, and N.R. 
Murphy, Site Reliability Engineering — 
How Google Runs Production Systems, 
O’Reilly Media, 2016. 
[7]  ISO/IEC CD 29110-5-5:2023, Systems 
and software engineering — Lifecycle 
profiles for Very Small Entities (VSEs), 
Part 5-5: Agile/DevOps guidelines.
[8]  J. Humble and D. Farley. Continuous 
delivery: reliable software releases through 
build, test, and deployment automation. 
Pearson Education, 2010.
[9]  J. Turnbull, The Art of Monitoring. James 
Tu r n b u l l ,   2 0 14 .

7-1 
CHAPTER 07
Software Maintenance
ACRONYMS
APIApplication Programming Interface
CIContinuous Integration
IECThe International Electrotechnical 
Commission
IEEEThe Institute of Electrical and 
Electronics Engineers
ISOInternational Organization for 
Standardization
KAKnowledge Area
LOCLines of Code
MRModification Request
PRProblem Report
SCMSoftware Configuration 
Management
SEESoftware Engineering Environment
SLAService-Level Agreement
SLIService-Level Indicators
SLOService-Level Objectives
SQASoftware Quality Assurance
V&V Verification and Validation
XaaSAnything as a Service
INTRODUCTION
Successful    software    development    efforts    
result in  the  delivery  of  a  software  product  
that  satisfies  user  requirements.  As  those  
requirements  and  other  factors  change,  the  
software product must evolve: Once the soft-
ware  is  in  operation,  defects  are  uncovered,  
operating   environments   change,   and   new   
user  requirements  surface.  The  maintenance  
phase of the life cycle begins after a warranty 
period  or  after  post-implementation  support  
delivery,   but   maintenance   activities   occur   
much earlier. 
Software  maintenance  is  an  integral  part  
of  a  software  life  cycle.  However,  it  has  not  
received   the   same   degree   of   attention   as   
the   other   software   engineering   activities. 
Historically,  software  development  has  had  
a much higher profile than software mainte-
nance. This is now changing as organizations 
strive to optimize their software engineering 
investment  by  ensuring  continuous  develop-
ment,  maintenance  and  operation,  progres-
sively   eliminating   the   organizational   silos   
among these  areas.  The  growing  acceptance  
of  DevOps  practices  and  tools  have  drawn  
further attention to the need to continuously 
evolve  software  while  ensuring  its  smooth  
operation to satisfy users, who are demanding 
quicker  turnaround  from  software  engineers  
than in the past. 
In  this  SWEBOK Guide,  software  main-
tenance  is  defined  as  the  totality  of  activi-
ties required to provide cost-effective support 
for  software  in  operation.  Activities  to  sup-
port software operation and maintenance are 
performed  during  the  pre  delivery  stage  and  
during  the  post  delivery  stage.  Pre  delivery 
activities  include  planning  for  post  delivery 
operations,  maintainability  and  determining 
the  logistics  support  needed  for  the  tran-
sition   from   development   to   maintenance. 
Postdelivery  activities  include  software  sur-
veillance,  modification,  training,  and  oper-
ating or interfacing with a help desk.
The Software Maintenance knowledge area 
(KA) is related to all other aspects of software 
engineering. Therefore, this KA description is 
linked to all other software engineering KAs 
in the Guide. 

7-2   SWEBOK
®
 GUIDE V4.0
BREAKDOWN OF TOPICS FOR 
SOFTWARE MAINTENANCE 
The  breakdown  of  topics  for  the  Software  
Maintenance KA is shown in Figure 7.1.
1. Software Maintenance Fundamentals
This section introduces the concepts and ter-
minology that form a basis for understanding 
the  role  and  scope  of  software  maintenance.  
Among  these  concepts  are  the  different  cat-
egories  of  software  maintenance.  Learning  
about  these  categories  is  critical  to  under-
standing  what  this  knowledge  area  encom-
passes and why it is so important.
1.1.  Definitions and Terminology 
 [1, s3.1][2*, c1s1.2, c2s2,2] 
The   purpose   of   software   maintenance   is   
defined in the international standard for soft-
ware   maintenance:   ISO/IEC/IEEE   14764   
[1].  In  the  context  of  software  engineering,  
software  maintenance  is  essentially  one  of  
many  technical  processes. The  objective  of  
software  maintenance  is  to  modify  existing  
software  while  preserving  its  integrity.  The  
international  standard  also  emphasizes  the  
importance of performing some maintenance 
activities before final delivery of the software 
(pre   delivery   activities).   Software   mainte-
nance  shares  knowledge  and  tools  with  soft-
ware development and software operation and 
also has its own processes and  techniques.
1.2.   Nature of Software Maintenance 
 [2*, c1s1.3]
Software   maintenance   sustains   the   soft-
ware product throughout its life cycle (from 
development  through  operations).  The  soft-
ware  is  monitored  for  capacity,  continuity  
and    availability.    Modification    requests    
(MRs)  and  incidents  or  problems  reports  
(PRs) are logged and tracked, the impact of 
proposed  changes  is  determined,  code  and  
other software artifacts are modified, testing 
is conducted, and a new version of the soft-
ware   product   is   released   into   operation. 
Also,  training  and  daily  ongoing  support  
are provided to users. A software maintainer 
is  defined  as  a  role  or  an  organization  that  
performs  software maintenance  activities.  
Software
Maintenance
Definitions and 
Terminology
Technical Issues
Management 
Issuess
Software 
Maintenance
Cost
Software 
Maintenance
Measurements
Nature of
Software 
Maintenance
Need of
Software 
Maintenance
Categories of
Software 
Maintenance
Evolution of
Software
Key Issues in
Software
Maintenance
Software
Maintenance
Fundamentals
Software
Maintenance
Processes
Software
Maintenance
Processes
Program
Comprehension
Software
Reengineering
Reverse
Engineering
CI/CD, Testing
and Deployment
Software
Maintenance
Activities 
and Tasks
Software
Maintenance
Techniques
Software
Maintenance
Tools
Figure 7.1. Breakdown of Topics for the Software Maintenance KA

SOFTWARE MAINTENANCE   7-3
In  this  KA,  the  term  sometimes  refers  to  
individuals who perform those activities, to 
contrast  their  role  with  the  software  devel-
oper’s role.
Maintainers can learn from the developers’ 
and  operators’  knowledge  of  the  software.  
Early  contact  with  the  developers  and  early  
involvement  by  the  maintainers  can  reduce  
the overall maintenance costs and efforts. An 
additional  challenge  is  created  when  main-
tainers join the project after the initial devel-
opers  have  left  or  are  no  longer  available.  
Maintainers  must  understand  and  use  soft-
ware  artifacts  from  development  (e.g.,  code,  
tests or documentation), support them imme-
diately, and progressively evolve and maintain 
them over time.
1.3.  Need for Software Maintenance  
 [2*, c1s1.5]
Software maintenance is needed to ensure that 
the software continues to satisfy user require-
ments  throughout  its  life  span.  Maintenance 
is necessary regardless of the type of software 
life cycle model used to develop it (e.g., water-
fall or Agile). Software products change as a 
result  of  both  corrective  and  non-corrective  
actions.  Software  maintenance  is  typically  
performed to do the following:
•    Correct faults and latent defects
•    Improve  the  design  or  performance  of  
operational software
•    Implement enhancements
•    Help   users   understand   the   software’s   
functionality
•    Adapt to changes in interfaced systems or 
infrastructure
•    Prevent security threats
•    Remediate    technical    obsolescence    of    
system or software elements
•    Retire the software
1.4.  Majority of Maintenance Costs 
 [2*, c4s4.3, c5s5.2]
It  is  generally  accepted  that  the  relative  cost  
of  error  fixing  increases  in  later  phases  of  
the   software   life   cycle.   Maintenance   also   
uses  a  significant  portion  of  the  total  finan-
cial  resources  attributed  throughout  the  life  
of a software. A common perception of soft-
ware maintenance is that it merely fixes faults. 
However,  studies  and  surveys  over  the  years  
have  indicated  that  most  software  mainte-
nance  —  over  80%  —  is  used  for  enhancing 
and   adapting   the   software [3].   Grouping   
enhancements   and   corrections   together   in   
management  reports  contributes  to  a  mis-
conception  that  corrections  cost  more  than  
they  really  do.  Understanding  the  categories  
of software maintenance helps us understand 
the  structure  of  software  maintenance  costs  
— that is, where most of that spending goes 
[7]. Also, understanding the factors that affect 
the maintainability of software can help orga-
nizations  contain  costs.  Environmental  fac-
tors  that  affect  software  maintenance  costs  
include the following:
•    Operating  environment  (hardware  and  
software).
•    Organizational      environment      (poli-
cies,  competition,  process,  product  and  
personnel).
1.5.  Evolution of Software  
 [2*, c3s3.5]
Software   maintenance   as   an   activity   that   
supports  the  evolution  of  software  was  first  
addressed   in   the   late   1960s.   Research,   by   
Lehman and others [8], over a period of twenty 
years  led  to  the  formulation  of  eight  laws  of  
software evolution: 
•    Continuing Change — Software must be 
continually  adapted,  or  it  becomes  pro-
gressively less satisfactory.
•    Increasing  Complexity  —  As  software 
evolves,  its  complexity  increases  unless  
work  is  done  to  maintain  or  reduce  that  
complexity.
•    Self-Regulation  —  The  program  evolu-
tion  process  is  self  regulating  with  close  
to  normal  distribution  of  measures  of  
product and process attributes.

7-4   SWEBOK
®
 GUIDE V4.0
•    Invariant   Work   Rate   —   The   average   
effective global activity rate in an evolving 
software  package  is  invariant  over  the  
product’s lifetime.
•    Conservation  of  Familiarity  —  As  soft-
ware  evolves,  all  associated  with  it  (e.g.,  
developers,   sales   personnel   and   users)   
must maintain mastery of its content and 
behavior to achieve satisfactory evolution. 
Excessive  growth  diminishes  that  mas-
tery. Hence, average incremental growth 
remains invariant as the system evolves.
•    Continuing  Growth  —  Functional  con-
tent  of  a  program  must  be  continually  
increased  to  maintain  user  satisfaction  
over its lifetime.
•    Declining Quality — The quality of soft-
ware will appear to be declining unless it 
is  rigorously  maintained  and  adapted  to  
changes in the operational environment.
•    Feedback  System  —  Software  evolution  
processes   constitute   multilevel,   multi-
loop,  multi-agent  feedback  systems  and  
must  be  treated  as  such  to  achieve  sig-
nificant   improvement   over   any   rea-
sonable base.
Key findings of Lehman’s research include 
a  proposal  that  maintenance  is  evolutionary  
development  and  that  maintenance  decisions  
are  aided  by  an  understanding  of  what  hap-
pens  to  software  over  time.  Another  way  to  
think  of  maintenance  is  as  continued  devel-
opment  that  accommodates  extra  inputs  (or  
constraints) — in other words, large software 
programs  are  never  complete  and  continue  
to  evolve.  As  they  evolve,  they  grow  more  
complex unless action is taken to reduce that 
complexity. 
1.6.  Categories of Software Maintenance 
 [1, s3.1.8][2*, c1s1.8, c3s3.3]
Five  categories  (types)  of  software  mainte-
nance  have  been  standardized  to  classify  a  
maintenance  request:  corrective,  preventive,  
adaptive,  additive  and  perfective.  ISO/IEC/
IEEE 14764 [1], regroups these maintenance 
categories  as  either  corrections  or  enhance-
ments, as shown in Figure 7.2. 
ISO/IEC/IEEE  14764  [1]  also  defines  a  
sixth category — emergency maintenance: 
•    Corrective maintenance: Reactive modi-
fication (or repairs) of a software product 
performed  after  delivery  to  correct  dis-
covered problems.
•    Preventive maintenance: Modification of 
a  software  product  after  delivery  to  cor-
rect latent faults in the software product 
before they occur in the live system. 
•    Adaptive maintenance: Modification of a 
software product performed after delivery 
to  keep  a  software  product  usable  in  an  
evolving  environment.  Adaptive  mainte-
nance  provides  enhancements  necessary  
to  accommodate  changes  in  the  environ-
ment in which a software product operates 
(e.g.,  an  upgrade  to  the  operating  system 
results in changes to the applications).
•    Additive     maintenance:     Modification     
of  a  software  product  performed  after  
delivery  to  add  functionality  or  features  
to  enhance  the  usage  of  the  product.  
Modification Request
Correction
CorrectivePreventiveAdaptiveAdditivePerfective
Enhancement
Figure 7.2. Software Maintenance Categories

SOFTWARE MAINTENANCE   7-5
Additive  maintenance  differs  from  per-
fective maintenance in that a) it provides 
additional  new  functions  or  features  to  
improve software usability, performance, 
maintainability or other software quality 
attributes, and b) it adds functionality or 
features  with  relatively  large  additions  
or  changes  for  improving  software  attri-
butes after delivery.
•    Perfective  maintenance:  Modification  of  
a  software  product  after  delivery  to  pro-
vide  enhancements  for  users,  improve-
ment  of  program  documentation,  and  
recoding   to   improve   software   perfor-
mance, maintainability, or other software 
attributes.
•    Emergency   maintenance:   Unscheduled   
modification  performed  to  temporarily  
keep  a  system  operational,  pending  cor-
rective maintenance.
2. Key Issues in Software Maintenance
A number of key issues must be dealt with to 
ensure the effective maintenance of software. 
Software  maintenance  provides  unique  tech-
nical  and  management  challenges  for  soft-
ware  engineers  (e.g.,the  challenge  of  finding  
a fault in large complex software developed by 
someone else.)
Similarly, in an Agile setting, maintainers 
and developers are constantly striving to make 
sure  that  clients  see  the  value  at  the  end  of  
each  iteration  so  maintenance  activities  have  
to compete with the development of new fea-
tures for client approval; Planning for a future 
release, which often includes coding the next 
release  while  sending  out  emergency  patches  
for the current release, also creates a challenge 
in  balancing  maintenance  and  development  
work.  The  following  section  presents  tech-
nical  and  management  issues  related  to  soft-
ware  maintenance.  They  are  grouped  under  
the following topics:
•    Technical issues.
•    Management issues.
•    Software maintenance costs.
•    Software maintenance measurement.
2.1.  Technical Issues
2.1.1 Limited Understanding 
 [2*, c6s6.9]
Limited  understanding  describes  a  software  
engineer’s  initial  comprehension  of  software  
someone  else  developed.  This  is  reflected  in  
how  quickly  a  software  engineer  can  under-
stand  where  to  change  or  correct  the  soft-
ware. Research suggests a significant portion 
of   total   maintenance   effort   is   devoted   to   
understanding  the  software  to  be  modified.  
Consequently,  the  topic  of  software  compre-
hension  is  of  great  interest  to  software  engi-
neers.  A  number  of  comprehension  factors  
have been identified: 1) domain knowledge; 2) 
programming  practices  (e.g.,  implementation  
issues); 3) documentation; and 4) organisation 
and  presentation  issues.  Comprehension  is  
more  difficult  in  text-oriented  representation  
(e.g., in source code), where it is often difficult 
to trace the evolution of software through its 
releases  or  versions  if  changes  are  not  docu-
mented  and  the  developers  are  not  available  
to  explain  them.  Thus,  software  engineers  
may  initially  have  a  limited  understanding  
of  the  software,  and  much  work  must  be  
done  to  remedy  this.  Various  techniques  can  
help  engineers  understand  existing  software,  
such as visualization and reverse engineering 
using   tool-based   graphical   representations   
of the code.
2.1.2 Testing 
 [1, s6.2][2*, c9, c13s13.4.4] 
Test planning and activities occur during MRs 
and PRs processing. The cost of repeating full 
testing on a major piece of software is signifi-
cant, in both time and effort. To ensure a soft-
ware modification is validated, the maintainer 
should replicate or verify changes by planning 
and  executing  the  appropriate  tests  —  for  
example,  regression  testing  is  important  in  
maintenance. Regression testing is the selec-
tive  retesting  of  software  or  a  component  to  
verify that the modifications have not caused 
unintended   effects.   Another   challenge   is   

7-6   SWEBOK
®
 GUIDE V4.0
finding  the  time  to  conduct  as  much  testing  
as  possible.  Coordinating  tests  can  be  chal-
lenging  for  maintenance  team  members  who  
are simultaneously working on different prob-
lems.  Bringing  software  offline  to  test  it  can  
be  difficult  if  the  software  performs  critical  
functions.  The  Software  Testing  KA  pro-
vides  additional  information  and  references  
on software testing and its subtopic on regres-
sion testing.
2.1.3 Impact Analysis 
 [1, s5.1.6][2*, c13s13.3] 
Impact analysis assesses the detailed effects 
of  proposed  changes  on  existing  software.  
Software  engineers  should  strive  to  con-
duct  the  analysis  as  cost-effectively  as  pos-
sible. Maintainers need detailed knowledge 
of the software’s structure and content. They 
use  that  knowledge  to  perform  the  impact  
analysis,  which  identifies  all  systems  and  
software products that would be affected by 
a  software  change  request  and  develops  an  
estimate  of  the  resources  needed  to  accom-
plish  the  change.  The  analysis  also  deter-
mines  the  risks  involved  in  making  the  
change. The   change   request   (originating   
from an MR or a PR), must first be analyzed 
and  translated  into  software  terms.  Impact  
analysis is performed after a change request 
enters   the   software   configuration   man-
agement  (SCM)  process.  ISO/IEC/IEEE 
1476 4   [1]  states  that  the  impact  analysis  
tasks do the following:
•    Develop     an     identification     scheme     
for MRs/PRs.
•    Develop  a  scheme  for  categorizing  and  
prioritizing MRs/PRs.
•    Determine the procedures for an operator 
to submit an MR/PR.
•    Identify the information needs and issues 
that must be tracked and reported to the 
users and identify the measures that pro-
vide feedback on those information needs 
and issues.
•    Determine how temporary work-arounds 
will be provided to the operators.
•    Track     the     work-around(s)     through     
to removal.
•    Determine what follow-up feedback will 
be provided to the users.
Software maintainers often use the severity 
of  a  PR  as  a  guide  when  deciding  how  and  
when to fix the problem. The maintainer con-
ducts  an  impact  analysis  that  identifies  the  
affected  components,  develops  several  poten-
tial   solutions,   and,   finally,   recommends   a   
course of action.
Impact  analyses  of  proposed  maintenance  
changes often consider various factors such as 
the maintenance category, the size of the mod-
ification, the cost involved, the testing needed 
to make the modification, and any impacts on 
performance,  safety  and  security.  Designing  
software with maintainability in mind greatly 
facilitates  impact  analysis.  More  information  
can  be  found  in  the  Software  Configuration  
Management KA.
2.1.4 Maintainability 
 [1, s8.8][2*, c12s12.5.5]
ISO/IEC/IEEE   14764   [1]   defines   main-
tainability  as  the  capability  of  the  software  
product  to  be  modified.  Modifications  can  
include  corrections,  improvements  or  adap-
tation of the software to changes in environ-
ment, as well as changes in requirements and 
functional specifications.
As  an  important  software  quality  char-
acteristic,  maintainability  should  be  speci-
fied, reviewed and controlled during software 
development   activities   in   order   to   reduce   
maintenance  costs.  When  these  activities  are  
carried  out  successfully,  the  software’s  main-
tainability   will   benefit.   Maintainability   is   
often difficult to achieve because it is often not 
a primary focus during software development. 
The  developers  are  typically  more  focused  on  
other  activities  and  might  not  pay  enough 
attention to   maintainability   requirements.   
This can result in bad architecturing, missing 
software documentation or test environments, 
which is a leading cause of difficulties in pro-
gram  comprehension  and  subsequent  impact  

SOFTWARE MAINTENANCE   7-7
analysis during maintenance. The presence of 
systematic  and  mature  software  development  
processes, techniques and tools helps enhance 
the maintainability of software. The Software 
Quality  KA  provides  additional  information  
and references on software maintainability.
Compromised    software    maintainability    
typically  increases  the  burden  on  software  
engineers  who  maintain  the  software  in  the  
future;  in  other  words,  it  creates  technical  
debt. Technical debt often accumulates when 
the need to quickly address corrective, emer-
gency,  and  additive  maintenance  tasks,  con-
strained  by  limited  time  and  understanding  
of the software, leads to compromises. These 
immediate  but  potentially  under-considered  
solutions, often not peer-reviewed, contribute 
to  the  accumulation  of  technical  debt.  This  
practice generally creates a technical debt that 
will take additional time and effort to address 
during   maintenance.   Specifically,   software   
engineers   must   investigate   three   areas   in   
depth when addressing technical debt:
1. Code  quality  versus  relevance:  Not  all  
technical debt is urgent.
2. Alignment   with   organizational   objec-
tives:  The  software  architecture  should  
reflect the organization’s goals. 
3. Process    loss:    Ensure    complementary    
skills of software engineers involved. 
2.2.  Management Issues
2.2.1. Alignment with Organizational 
Objectives 
 [1, s9.1.8][2*, c2s2.3.1.2, c3s3.4]
This  section  describes  how  to  optimizse  soft-
ware  maintenance  activities  and  economics  
to  be  aligned  with    organizational  objectives  
and  the  priorities  of  the  business,  customers  
and users.
In   many   organizations,   initial   software   
development  is  project-based,  with  a  defined  
time  scale  and  budget.  The  main  goal  is  to  
deliver  a  product  that  meets  user  needs  on  
time  and  within  budget.  In  contrast,  soft-
ware  maintenance  aims  to  extend  the  life  of  
software  and  keep  it  operational  for  as  long  
as  possible.  In  addition,  it  may  be  driven  by  
the  need  to  meet  user  demand  for  software  
updates and enhancements. 
In  both  cases,  the  economics  of  software  
maintenance is not as visible as those of soft-
ware   development.   At   the   organizational   
level,  it  may  be  seen  as  an  activity  that con-
sumes  significant  resources  with  no  clear,  
quantifiable  benefit  for  the  organization.  As 
a  consequence,  adding  new  features  is  often  
given higher priority than other maintenance 
activities (such as refactoring, security or per-
formance  improvement)  to  meet  the  goals  
and objectives of software customers, as well 
as  with  constraints  such  as  time  and  budget.  
However,  such  organizational  objectives  and  
constraints  must  be  balanced  with  software  
maintainability and engineering standards to 
avoid code decay and technical debt.
Applying product management approaches 
to  the  management  of  software  development  
and maintenance can help organizations:
•    Understand  the  total  cost  of  operational  
software over its full life cycle.
•    Compare the costs and benefits of devel-
oping   new   software   versus   enhancing   
existing software.
•    Resolve  staffing  and  skills  issues,  as  the  
same team can be responsible for mainte-
nance and development.
•    Focus  more  on  maintainability  require-
ments  from  the  start,  as  the  same  team  
has  responsibility  for  both  development  
and maintenance.
2.2.2. Staffing [1*, s6.4.13.3c] 
 [2*, c2s2.3.1.5, c10s10.4]
Although  maintenance  work  is  sometimes  
perceived as less engaging, this view overlooks 
the  critical  importance  of  software  main-
tainers. Given that maintenance constitutes a 
significant portion of software lifecycle activi-
ties, recognizing and valuing the contribution 
of maintainers is essential to boosting morale, 
performance,   and   reducing   staff   turnover.   

7-8   SWEBOK
®
 GUIDE V4.0
Organizations  need  to  design  development  
and  maintenance  teams  and  roles  carefully  
and provide professional development oppor-
tunities for their staff. 
2.2.3. Process [1*, s6][2*, c5] 
The  software  life  cycle  process  is  a  set  of  
activities, methods, practices and transforma-
tions that people use to develop and maintain 
software  and  its  associated  products.  At  the  
process  level,  software  maintenance  activ-
ities  share  much  in  common  with  software  
development  (e.g.,  SCM  is  a  crucial  activity  
in  both).  Maintenance  also  requires  several  
activities not found in software development. 
(Refer to section 3.2.)
2.2.4. Supplier Management 
 [1*, s6.1.2, s8.3, s8.8.2]
Supplier  management  ensures  that  the  orga-
nization’s suppliers and their performance are 
managed  appropriately  to  support  the  seam-
less provision of quality products and services 
when maintenance is contracted to suppliers. 
The  nature  of  the  organization’s  relation-
ship  with  suppliers  and  its  approach  to  sup-
plier  management  should  be  determined  by  
the  nature  of  these  products  and  services.  
Contractors  can  be  hired  to  conduct  main-
tenance  tasks  and  outsourcing  or  offshoring  
software  maintenance  is  a  major  industry.  
Outsourcing maintenance means substituting 
internal capability with an external supplier’s 
capability. Approaches to contracting mainte-
nance include the following:
•    Single source or partnership: A single sup-
plier provides all services, or an external 
service integrator manages the organiza-
tion’s relationship with all suppliers. 
•    Multi-sourcing:   Products   and   services   
are  provided  by  more  than  one  inde-
pendent  supplier.  These  are  combined  
into  a  single  (software-enabled)  service.  
Multi-sourcing  in  software  services  is  
increasingly   common,   enabled   by   the   
growth of “anything as a service” (XaaS), 
application     programming     interfaces     
(APIs), and data sources. 
Many  organizations  outsource  entire  port-
folios  of  software.  Typically,  these  portfolios  
include software that is not mission-critical, as 
organizations  do  not  want  to  lose  control  of  
the software used in their core business. One 
major challenge for outsourcers is determining 
the scope of the maintenance services required, 
the terms of a service-level agreement (SLA), 
and the contractual details. Outsourcers need 
to  invest  in  good  communication  infrastruc-
ture  and  an  efficient  help  desk  staffed  with  
people who can communicate effectively with 
customers and users [3]. Outsourcing requires 
a  significant  initial  investment  and  the  setup  
and review of software maintenance processes 
that require automation. 
2.2.5. Organizational Aspects of Maintenance  
 [1, s9.1.8][2*, c10]
Organizational     aspects     of     maintenance     
include   determining   which   teams   will   be   
responsible  for  software  maintenance.  When 
using  Agile  life  cycle  models,  the  developer  
also  conducts  maintenance  tasks,  acting  as  
both developer and maintainer. Other organi-
zations prefer that the team that develops the 
software does not necessarily maintain it once 
it  is  operational. In  deciding  where  the  soft-
ware  maintenance  function  will  be  located,  
software engineering organizations must con-
sider  each  alternative’s  advantages  and  disad-
vantages. There are a number of disadvantages 
to  having  the  developer  also  maintain  the  
software after it has been put into production, 
such as the risk that new development will be 
disrupted when the developers need to attend 
to failures and the potential loss of knowledge 
when developers leave the organization, since 
fewer  individuals  are  familiar  with  the  soft-
ware; this could also lead to lower-quality doc-
umentation, as fewer individuals are involved. 
However,   having   a   separate   maintenance   
function also has its challenges, as many soft-
ware engineers do not like limiting their work 
to  maintenance  and  may  be  more  likely  to  

SOFTWARE MAINTENANCE   7-9
leave for more interesting work. In addition, a 
handoff process must be put in place between 
developers and maintainers, which sometimes 
leads to friction between teams [3]. 
The   introduction   of   product   manage-
ment processes has encouraged a single-team 
approach,   particularly   for   developing   and   
maintaining  software  that  needs  to  respond  
rapidly to changes in customer and user needs. 
Because there are many pros and cons to each 
option, the decision should be made on a case-
by-case  basis.  What  is  important  is  that  the  
organization delegates the maintenance tasks 
to an experienced group or person and keeps 
quality documentation  on  maintenance  tasks  
and all changes made to the software, regard-
less of the organization’s structure. 
2.3.   Software Maintenance Costs 
Software engineers must understand the dif-
ferent   categories   of   software   maintenance   
described    in  1.6.  Presenting  costs  trends  by  
categories  of  Maintenance  can  show  cus-
tomers  where  maintenance  effort  is  spent  for  
each  system  supported  [7].  The  data  about  
maintenance  effort  by  category  can  be  also  
used to accurately estimate the cost of software 
maintenance. Cost estimation is an important 
aspect of planning software maintenance.
2.3.1.  Technical Debt Cost Estimation 
 [1, s6.1.7, s8.8.3.6][2*, c12.12.5]
Technical  debt  generally  makes  code  more  
expensive   to   maintain   than   it   has   to   be.   
Technical  debt  represents  the  effort  required  
to fix problems that remain in the code when 
an application is initially released by the devel-
opment  team.  Several  techniques  and  indica-
tors can help engineers measure technical debt, 
including, size, complexity and the number of 
engineering flaws and violations of good archi-
tectural  design  and  coding  practices  in  the  
source  code.  ISO/IEC/IEEE  14764  provides  
suggestions   for   improving   maintainability,   
including: ensuring legibility, pursuing struc-
tured code, reducing code complexity, provide 
accurate code comments, using identation and 
white space, eliminating language weaknesses 
and  compiler  dependent  constructs,  facilitate  
error-tracing,  ensure  traceability  of  code  to  
design, conduct inspections and code reviews. 
A software product needs to evolve, by adding 
new features and capabilities, and its codebase 
must remain maintainable, easily understood, 
and easy to further evolve. A common barrier 
to addressing technical debt — or, indeed, of 
implementing  any  potential  enhancement  —  
is  the  uncertain  reward  for  doing  so.  That’s  
why  it’s  so  important  for  organizations  to  
determine the following:
•    The quality of their current software. 
•    The current cost of their technical debt. 
•    The  potential  savings  from  investing  in  
quality enhancement.
•    The  impact  of  current  quality  issues  on  
their business.
Furthermore, technical debt is only one factor 
of  several  contributing  to  excess  unplanned  
work;  team  or  process  issues  may  also  need  to  
be understood and addressed. Modern tooling 
can help detect such issues, which means tech-
nical  debt  should  not  be  handled  in  isolation  
but through an examination of its root causes.
2.3.2.  Maintenance Cost Estimation  
 [1, s6.2.2, s9.1.4, s9.1.9-10] 
 [2*, c12s12.5.6]
An  estimate  of  software  maintenance  costs  
should be prepared early in the software plan-
ning process [1, c6s1.4]. The costs should be a 
function  of  the  scope  of  maintenance  activi-
ties.  ISO/IEC/IEEE  14764  [1,  c7s2.4]  iden-
tified various factors that should be included, 
such as the following:
•    Travel to user locations.
•    Training for maintainers as well as users.
•    Cost  and  annual  maintenance  for  the  
software engineering environment (SEE) 
and software testing.
•    Personnel costs (e.g., salaries, benefits).
•    Other resource costs, such as consumables.
•    Software license maintenance costs.

7-10   SWEBOK
®
 GUIDE V4.0
•    Product changes, program management.
•    Field service engineers.
•    Renting facilities for maintenance.
Moreover,  as  the  maintenance  and  devel-
opment efforts progress, the estimates should 
be  amended.  Historical  measurement  data  
should  be  used  as  inputs  to  estimate  main-
tenance  costs.  Additionally,  cost  estimates  
are  also  required  during  impact  analysis  of  
individual  MR  or  PR.  The  cost  estimating  
method  (e.g.,  parametric  model,  comparison  
to  analog  systems,  use  of  empirical  and  his-
torical data) should be described. Estimates of 
individual  MRs  or  PRs  typically  include  the  
estimated  effort  associated  with  executing  a  
change,  resource  estimates  and  an  estimated  
timeline for implementing the change. 
2.4.  Software Maintenance Measurement 
 [1, s6.1.7][2*, c12]
Measurable  software  maintenance  artifacts  
include maintenance processes, resources and 
products  [2*,  c12s12.3.1].  Measures  include  
size,  complexity,  quality,  understandability,  
maintainability and effort. One useful measure 
is the amount of effort (in terms of resources) 
expended for corrective, preventive, adaptive, 
additive and perfective maintenance. 
Complexity  and  technical  debt  measures 
of software can also be obtained using avail-
able  tools.  These  measures  constitute  a  good  
starting  point  for  the  measurement  of  soft-
ware  quality. Maintainers  should  determine  
which  measures  are  appropriate  for  a  spe-
cific  organization  based  on  that  organiza-
tion’s needs. Software measurement programs 
are  discussed  in  the  Software  Engineering  
Management KA.
The  software  quality  model  described  in  
the Software Quality KA describes software 
product and process measures specific to soft-
ware maintenance. Measurable characteristics 
of maintainability include the following:
•    Modularity measures the degree to which 
a system or software is composed of com-
ponents  that  are  independent,  such  that  
a change to one component has minimal 
impact on other components.
•    Reusability measures how well a compo-
nent can be reused.
•    Analyzability   measures   the   effort   or   
resources  the  maintainer  must  expend  
either  to  diagnose  deficiencies  or  causes  
of  failure  or  to  identify  components  to  
be modified.
•    Modifiability   measures   the   maintain-
er’s  effort  associated  with  implementing  
a  specified  modification  without  intro-
ducing   defects   or   degrading   existing   
product quality.
•    Testability   measures   the   effort   main-
tainers and users expend to test the mod-
ified software.
•    Supportability  measures  the  ease  with  
which  support  can  be  provided  for  the  
software,  encompassing  the  availability  
and accessibility of documentation, tools, 
and   assistance   for   addressing   issues,   
facilitating   effective   maintenance   and   
troubleshooting.
Other measures that software maintainers 
use include the following:
•    Reliability: The degree to which a system 
or  software  performs  specific  functions  
under  specified  conditions  for  a  spec-
ified   period,   including   the   following   
characteristics:
o Maturity:  How  well  a  system  or  soft-
ware can meet the need for reliability.
o Availability: Whether a system or soft-
ware is operational and accessible.
o Fault  tolerance:  How  well  a  system  or  
software  operates  despite  hardware  or  
software faults.
o Recoverability:  How  well  a  system  or  
software  can  recover  data  during  an  
interruption or failure.
•    Size   of   the   software   (e.g.,   functional   
size, LOC).
•    Number   of   maintenance   requests,   by   
time period.

SOFTWARE MAINTENANCE   7-11
•    Effort per maintenance request.
•    Software  characteristics  (e.g.,  platform,  
hardware,      programming      language,      
frameworks).
Maintenance  measures  may  be  collected,  
analyzed  and  trended  by  category  to  facil-
itate  improvement  and  to  provide  insight  
into  where  maintenance  costs  are  expended.  
The  degree  of  software  maintenance  effort  
expended  for  different  applications,  listed  
by  category,  is  valuable  business  informa-
tion  for  users  and  their  organizations.  It  
can also enable the organization to make an 
internal comparison of software maintenance 
profiles [7].
3. Software Maintenance Processes
In addition to standard software engineering 
processes  and  activities  described  in  ISO/
IEC/IEEE  14764  [1],  a  number  of  activities  
are unique to maintainers (refer to section 3.2).
3.1.  Software Maintenance Processes 
 [1, s5.2][2*, c5] 
Maintenance  processes  provide  needed  activ-
ities  and  detailed  inputs  and  outputs  to  those  
activities,   as   described   in   ISO/IEC/IEEE   
14764 [1]. Maintenance is one of the technical 
life  cycle  processes  presented  in  ISO/IEC/
IEEE 1 2 2 0 7 [10]. Figure 7.3 shows how main-
tenance  processes  connect  to  other  software  
engineering  processes,  which  interact  to  sup-
port operational software. The software main-
tenance processes includes the following:
•    Prepare for maintenance. 
•    Perform maintenance.
•    Perform logistics support.
•    Manage   results   of   maintenance   and   
logistics.
Recently, Agile methodologies, which pro-
mote  lightweight  processes,  have  also  been  
adapted  to  maintenance.  This  requirement  
has emerged from the ever-increasing demand 
for  fast  turnaround  of  maintenance  services.  
Improvement  to  the  software  maintenance  
processes  is  supported  by  software  mainte-
nance maturity models [3].
3.2.  Software  Maintenance  Activities  and  Tasks 
 [1, s6.1][2*, c6, c7] 
The maintenance process contains the activi-
ties and tasks necessary to operate and modify 
an existing software system while preserving 
its integrity. These activities and tasks are the 
responsibility  of  the  operator  and  the  main-
tainer.  As  already  noted,  many  maintenance  
activities  are  similar  to  those  of  software  
development.    Maintainers    perform    anal-
ysis,  design,  coding,  testing  and  documenta-
tion.  They  must  track  requirements  in  their  
activities  —  just  as  in  development  —  and  
update  documentation  as  baselines  change.  
Software Maintenance Process
Prepare for 
Maintenance
Perform
Logistic
Support
Manage Results 
of  Maintenance 
and Logistics
Disposal
Transition
Operation
Development
Perform 
Maintenance
Figure 7.3. Software Maintenance Processes (ISO/IEC/IEEE 14764) [1]

7-12   SWEBOK
®
 GUIDE V4.0
ISO/IEC/IEEE 14764   recommends   that   
when  a  maintainer  uses  a  development  pro-
cess, the process must be tailored to meet spe-
cific needs. 
However, there are a number of processes, 
activities and practices that are specialized to 
software maintenance:
•    Program  understanding:  This  comprises  
the  activities  needed  to  obtain  a  general  
knowledge  of  what  a  software  product  
does and how the parts work together.
•    Transition: This is a controlled and coor-
dinated   sequence   of   activities   during   
which  software  is  transferred  progres-
sively  from  the  developer  to  the  opera-
tions and maintenance team.
•    MR  acceptance/rejection:  Modifications  
requesting  work  greater  than  the  agreed  
size, level of effort, or level of complexity 
may   be   rejected   by   maintainers   and   
rerouted to a developer. 
•    Maintenance  help  desk:  The  help  desk  
is  an  end-user  and  maintenance-coordi-
nated  support  function  that  triggers  the  
assessment,  prioritization  and  costing  of  
MRs and incidents. 
•    Impact   analysis:   The   impact   analysis   
identifies   areas   impacted   by   a   poten-
tial change.
•    Maintenance     service-level     indicators     
(SLIs),  service-level  objectives  (SLOs),  
SLAs,  and  maintenance  software  and  
hardware  licenses  and  contracts:  These  
are  contractual  agreements  that  describe  
the   services   and   quality   objectives   of   
third parties.
3.2.1. Supporting and Monitoring Activities  
 [s6.4.13.3d5, s6.1.8][2*, c3s3.4]
Maintainers  may  also  perform  ongoing  sup-
port activities, such as documentation, SCM, 
verification  and  validation  (V&V),  problem  
resolution, software quality assurance (SQA), 
reviews, vulnerability assessments, and audits. 
Another  important  management  of  mainte-
nance  results  activity  is  that  of  monitoring 
customer satisfaction.
3.2.2. Planning Activities 
 [1, s6.1.3, s8.7.2][2*, c10]
An  important  activity  for  software  main-
tenance  is  planning,  and  this  process  must  
address  the  issues  associated  with  a  number  
of    planning    perspectives,    including    the    
following:
•    Business planning (organizational level)
•    Maintenance planning (transition level).
•    Release/version planning (software level).
•    MR planning (at individual request level).
At the individual request level, planning is 
carried  out  during  the  impact  analysis.  (See  
section  2.1.3,  Impact  Analysis.)  The  release/
version  planning  activity  requires  that  the  
maintainer do the following:
•    Collect  the  dates  of  availability  of  indi-
vidual requests.
•    Agree with users on the content of sub-
sequent releases/versions.
•    Identify  potential  conflicts  and  develop  
alternatives.
•    Assess   the   risk   of   a   given   release   
and  develop  a  back-out  plan  in  case  
problems arise
•    Inform all stakeholders.
Whereas   software   development   projects   
have  a  typical  duration  of  months  to  a  few  
years, the maintenance phase usually lasts until 
the software is retired by the disposal process. 
Estimating resources is a key element of main-
tenance planning. Software maintenance plan-
ning should begin with the decision to develop 
a  new  software  product  and  should  consider  
quality objectives. A concept document should 
be developed, followed by a maintenance plan, 
and these should address the following:
•    Scope of software maintenance.
•    Adaptation  of  the  software  maintenance  
processes and tools.
•    Identification  of  the  software  mainte-
nance organization.
•    Estimate of software maintenance costs.

SOFTWARE MAINTENANCE   7-13
A  software  maintenance  plan  should  be  
prepared  during  software  development  and  
should  specify  how  users  will  request  mod-
ifications and   report   problems   or   issues.   
Software  maintenance  planning  is  addressed  
in ISO/IEC/IEEE  14764  [1].  Finally,  at  the  
highest level of management, the maintenance 
organization  must  conduct  software  mainte-
nance business planning activities (e.g., com-
munications, budgetary, financial and human 
resources activities). [2*, c10]
3.2.3. Configuration Management 
 [1, s6.1.3c, s6.4.13.3d4][2*, c11s11.3] 
ISO/IEC/IEEE  14764  [1]  describes  SCM  
as  an  enabling  system  or  service  to  support  
the  maintenance  process.  SCM  procedures  
should  provide  for  the  verification,  valida-
tion and audit of each step required to iden-
tify,  authorize,  implement  and  release  the  
software  product  and  its  IT  assets  under-
going change. 
It  is  not  sufficient  to  track  MRs  or  PRs  
only.   Any   change   made   to   the   software   
product   and   its   underlying   infrastructure   
must be controlled. This control is established 
by  implementing  and  enforcing  an  approved  
SCM process. The SCM KA discusses SCM 
in more detail as well as the process by which 
change requests are submitted, evaluated and 
approved.  SCM  for  software  maintenance  
differs  from  SCM  for  software  development  
in the number of small changes that must be 
controlled  in  the  operational  environment. 
The  SCM  process  is  implemented  by  devel-
oping and following an SCM plan and oper-
ating  procedures.  Maintainers  participate  in  
configuration  control  boards  to  determine  
the  content  of  the  next  release  or  version  in  
production.
3.2.4. Software Quality 
 [1, s6.1.6, s8.7.2][2*, c13s13.4]
It  is  not  sufficient  to  simply  hope  that  soft-
ware maintenance will produce higher quality 
software.  Maintainers  should  have  an  effec-
tive  quality  program.  They  must  implement  
processes to support the continuous improve-
ment of software maintenance processes. The 
activities   and   techniques   for   SQA,   V&V,   
reviews,  and  audits  must  be  selected  in  con-
cert  with  all  the  other  processes  to  achieve  
the  desired  level  of  quality.  It  is  also  recom-
mended  that  both  software  operations  and  
maintenance adapt and use the output of the 
software development process, its techniques 
and deliverables (e.g., test tools and documen-
tation),  and  test  results.  More  details  about  
software quality can be found in the Software 
Quality KA.
4. Software Maintenance Techniques
This topic introduces generally accepted tech-
niques used in software maintenance.
4.1.  Program Comprehension 
 [2*, c6, c14s14.5]
Maintainers spend considerable time reading 
and   understanding   programs   in   order   to   
implement  changes.  Code  browsers  are  key  
tools for program comprehension and are used 
to  organize  and  present  source  code.  Clear  
and concise documentation also aids program 
comprehension.
4.2.   Software Reengineering 
                                                                                                                      [2*, c7]
Software reengineering refers to the examina-
tion and alteration of software to reconstitute 
it  in  a  new  form.  It  includes  the  subsequent  
implementation  of  the  new  form.  It  is  often  
undertaken  not  to  improve  maintainability  
but to replace aging legacy software. 
Refactoring  is  a  reengineering  technique  
that  aims  to  reorganize  a  program  without  
changing  its  behavior.  Refactoring  seeks  to  
improve the internal structure and the main-
tainability   of   software.   Refactoring   tech-
niques   can   be   used   during   maintenance   
activities  to  reduce  the  technical  debt  of  the  
codebase before and after code changes.
In the context of Agile software develop-
ment, the incremental nature of continuous 

7-14   SWEBOK
®
 GUIDE V4.0
integration  (CI)  often  requires  the  code  to  
be  continuously  refactored  to  augment  its  
quality  and  reliability.  Hence,  continuous  
refactoring  supports  the  volatile  software  
life cycle by providing better ways to reduce 
and manage the growing complexity of soft-
ware   systems   while   improving   developer   
productivity.
4.3.  Reverse Engineering 
 [2*, c7, c14s14.5]
Reverse  engineering  is  the  process  of  ana-
lyzing  software  to  identify  the  software’s  
components   and   their   interrelationships   
and  creating  representations  of  the  soft-
ware  in  another  form  or  at  higher  levels  of  
abstraction.  Reverse  engineering  is  passive;  
it does not change the software or result in 
new  software.  Reverse  engineering  efforts  
typically produce  graphical  representations  
of different software artifacts, such  as  call  
graphs and control flow graphs from source 
code.  Types  of  reverse  engineering  include  
the following:
•    Re-documentation.
•    Design recover y. 
•    Data  reverse  engineering  —  recovering  
logical schemata from physical databases.
Tools  are  key  for  reverse  engineering  and  
related  tasks  such  as  re-documentation  and  
design   recovery.   Software   visualization   is   
a common reverse   engineering   technique   
that  helps  maintainers  explore,  analyze  and  
understand the structure of software systems 
as  well  as  their  evolution.  Software  visual-
ization comprises visually encoding and ana-
lyzing  software  systems,  including  software  
maintenance  practices,  evolution,  structure  
and  software  runtime  behavior  using  infor-
mation  visualization,  computer  graphics  and  
human-computer     interaction.     Generally,     
software  visualization  tools  are  accompanied  
by  various  quality  assurance  features,  such  
as  quality  metrics  calculation,  technical  debt  
estimation, and bad design and coding prac-
tices (code smells) detection. 
4.4.  Continuous Integration, Delivery, Testing 
and Deployment [1, s6.4.13.3 Note 1]
Automating    development,    operation    and    
maintenance-related   tasks   saves   engineering   
resources.  When  implemented  appropriately,  
such automated tasks are generally faster, easier 
and  more  reliable  than  they  would  be  if  per-
formed  manually.  ISO14764  states  that  auto-
mation includes distribution and installation of 
software.[1, s6.4.13.3 Note 1]. DevOps supports 
such automation while building, packaging and 
deploying reliable and secure systems. DevOps 
combines  development,  operations,  and  main-
tenance  resources  and  procedures  to  perform  
CI, delivery, testing and deployment. [9]
CI  is  a  software  engineering  practice  that  
continually merges artifacts, including source 
code updates from all members of a team, into 
a shared mainline for evolving and testing the 
developed  system.  With  CI,  the  members  of  
a team can integrate their changes frequently, 
and  each  integration  can  be  verified  by  an  
automated  build  (including  testing)  to  detect  
integration  errors  as  quickly  as  possible.  The  
fundamental  goal  of  CI  is  to  automatically  
catch  problematic  changes  as  early  as  pos-
sible. CI helps guarantee the working state of 
a software system at various points from build 
to  release,  thereby  improving  confidence  and  
quality  in  software  products  and  improving  
productivity  in  teams.  Specifically,  CI  auto-
mates  the  build  and  release  processes  with  
continuous build, continuous delivery, contin-
uous  testing  and  continuous  deployment.  [6,  
c23, c24].
Continuous   delivery   is   a   software   engi-
neering practice that enables frequent releases 
of new systems (including software) to staging 
or  various  test  environments  through  the  use  
of automated tools. Continuous delivery con-
tinuously assembles the latest code and config-
uration to create release candidates. 
Continuous testing is a software testing prac-
tice that involves testing the software at every 
stage  of  the  software  development  life  cycle.  
The  goal  of  continuous  testing  is  to  evaluate  
the  quality  of  software  at  every  step  of  the  
continuous  delivery  process  by  testing  early  

SOFTWARE MAINTENANCE   7-15
and  often.  Continuous  testing  involves  var-
ious  stakeholders  such  as  developers,  main-
tainers,   DevOps,   SQA,   and   operational   
systems teams.
Continuous deployment is an automated pro-
cess  of  deploying  changes  to  production  by  
verifying intended features and validations to 
reduce  risk.  As  Martin  Fowler,  in  the  book  
Continuous Delivery, pointed out, “The biggest 
risk  to  any  software  effort  is  that  you  end  up  
building something that isn’t useful. The ear-
lier and more frequently you get working soft-
ware in front of real users, the quicker you get 
feedback to find out how valuable it really is.”
4.5.  Visualizing Maintenance
Maintaining  a  clear  understanding  of  soft-
ware  systems’  evolving  structures  and  depen-
dencies  presents  a  challenge.  Visualization  is  
a valuable supporter in software maintenance 
management,  offering  a  visual  representation  
of  the  software’s  components  and  helping  it  
make informed decisions. With the increasing 
size and complexity of software systems, visual 
representations  can  support  software  mainte-
nance by enabling dependency analysis, tracing 
a  software  evolution  history,  visualizing  soft-
ware  runtime  dynamics,  and  providing  com-
plementary     documentation.     Visualization     
represents  an  active  research  area  that  syner-
gizes  computational  capabilities  with  human  
pattern  detection  abilities.  It  produces  visual  
representations designed to enhance the main-
tenance  team’s  cognitive  performance  when  
faced with complex data analysis.
5. Software Maintenance Tools 
  [1, c6s4][2*, c14] 
This  topic  encompasses  tools  that  are  par-
ticularly  important  in  software  maintenance  
where  existing  software  is  being  modified.  
Maintenance   tools   are   interrelated   with   
development  and  operations  tools.  Together,  
they  are  part  of  the  SEE.  The  following  are  
examples of maintenance tools:
•    Configuration   management,   code   ver-
sioning and code review tools,
•    software testing tools,
•    Software   quality   assessment   tools   (to   
assess technical debt and code quality). 
•    Program  slicers,  which  select  only  the  
parts of a program affected by a change.
•    Static    analyzers,    which    allow    gen-
eral   viewing   and   summaries   of   pro-
gram content.
•    Dynamic   analyzers,   which   allow   the   
maintainer to trace the execution path of 
a program.
•    Data  flow  analyzers,  which  allow  the  
maintainer to track all possible data flows 
of a program.
•    Cross-referencers, which generate indexes 
of program components.
•    Dependency analyzers, which help main-
tainers analyze and understand the inter-
relationships    among    components    of    
a program.
•    Remote   Access   tools,   enabling   main-
tainers to diagnose and modify user sys-
tems remotely, crucial for real-time issue 
resolution   and   seamless   modifications   
across environments.
Reverse engineering tools support the pro-
cess  by  working  backward  from  an  existing  
product  to  create  artifacts  such  as  specifica-
tion and design descriptions, which can then 
be  transformed  to  generate  a  new  product  
from  an  old  one.  Maintainers  also  use  soft-
ware  tests,  SCM,  software  documentation  
and software measurement tools.

7-16   SWEBOK
®
 GUIDE V4.0
MATRIX OF TOPICS VS. REFERENCE MATERIAL
ISO/IEC/IEEE 
1476 4 2 0 2 2 [1] 
Grubb and 
Takang 2003 [2*]
1. Software Maintenance Fundamentals
1.1. Definitions and Terminologys3.1c1s1.2, c2s2.2
1.2. Nature of Software Maintenancec1s1.3
1.3. Need for Software Maintenancec1s1.5
1.4. Majority of Maintenance Costsc4s4.3, c5s5.2
1.5. Evolution of Softwarec3s3.5
1.6. Categories of Software Maintenance s3.1.8c1s1.8, c3s3.3
2. Key Issues in Software Maintenance
2.1. Technical Issues
2.1.1. Limited Understandingc6s6.9
2.1.2. Testings6.2c9, c13s13.4.4
2.1.3. Impact Analysiss5.1.6c13s13.3
2.1.4. Maintainabilitys8.8c12s12.5.5
2.2. Management Issues
2.2.1. Alignment with Organizational Objectivess9.1.8c2s2.3.1.2, c3s3.4
2.2.2. Staffings6.4.13.3cc2s2.3.1.5, c10s10.4
2.2.3. Processs6c5
2.2.4. Supplier Managements6.1.2, s8.3, s8.8.2
2.2.5. Organizational Aspects of Maintenances9.1.8c10
2.3. Maintenance Costs 
2.3.1. Technical Debt Cost Estimations6.1.7, s8.8.3.6c12s12.5
2.3.2. Maintenance Costs Estimation s6.2.2, 
s9.1.4, s9.1.9-10
c12s12.5.6
2.4. Software Maintenance Measurements6.1.7c12
3. Software Maintenance Process
3.1. Software Maintenance Processes s5.2c5
3.2. Software Maintenance Activities and Taskss6.1c6, c7
3.2.1. Supporting and Monitoring Activitiess6.4.13.3d5, s6.1.8c3s3.4
3.2.2. Planning Activitiess6.1.3, s8.7.2c10
3.2.3. Software Configuration Managements6.1.3c, s6.4.13.3d4c11s11.3
3.2.4. Software Qualitys6.1.6, s8.7.2c13s13.4
4. Software Maintenance Techniques 
4.1. Program Comprehensionc6,c14s14.5
4.2. Software Reengineeringc7
4.3. Reverse Engineeringc7, c14s14.5

SOFTWARE MAINTENANCE   7-17
4.4. Continuous Integration, Delivery, Testing and 
Deployment
s6.4.13.3 Note 1
4.5. Visualizing Maintenance
5. Software Maintenance Tools s4c14
FURTHER READINGS
A. April and A. Abran, Software Maintenance 
Management:    Evaluation    and    Continuous    
Improvement [3].
This book explores the domain of contin-
uous  software  maintenance  processes.  It  
provides  road  maps  for  improving  soft-
ware  maintenance  processes  in  organiza-
tions.  It  describes  software  maintenance  
practices   organized   by   maturity   levels,   
which  allow  for  benchmarking  and  con-
tinuous  improvement.  Goals  for  each  key  
practice  area  are  provided,  and  the  pro-
cess model presented is fully aligned with 
the  architecture  and  framework  of  inter-
national  standards  ISO12207,  ISO14764  
and ISO15504, as well as  models such as 
ITIL and CoBIT.
IEEE  std  2675-2021,  IEEE  Standard  for  
DevOps: Building  Reliable  and  Secure  Systems  
Including    Application    Build,    Package    and    
Deployment [5].
Technical  principles  and  processes  to  build,  
package,  and  deploy  systems  and  applica-
tions  in  a  reliable  and  secure  way  are  speci-
fied.  Establishing  effective  compliance  and  
information  technology  (IT)  controls  is  the  
focus.  DevOps  principles  presented  include  
mission  first,  customer  focus,  shift-left,  con-
tinuous  everything,  and  systems  thinking.  
How  stakeholders,  including  developers  and  
operations staff, can collaborate and commu-
nicate  effectively  is  described.  The  process  
outcomes  and  activities  herein  are  aligned  
with  the  process  model  specified  in  ISO/
IEC/IEEE 12207:2017 and ISO/IEC/IEEE 
15288:2015.
REFERENCES 
[1] IEEE standard, ISO/IEC/IEEE 
14764 IEEE Std. 14764:2022, Software 
Engineering — Software Life Cycle 
Processes — Maintenance, third ed: 
2022 01, 39p.
[2*] P. Grubb and A.A. Takang, Software 
Maintenance: Concepts and Practice, 2nd 
ed. River Edge, NJ: World Scientific 
Publishing, 2003.
[3] A. April and A. Abran, Software 
Maintenance Management: Evaluation 
and Continuous Improvement. Wiley-
IEEE Computer Society Press, 2008.
[4] C. Seybold and R. Keller, Aligning 
Software Maintenance to the Offshore 
Reality, 12th European Conference 
on Software Maintenance and 
Reengineering. April 1-4, 2008, 
Athens, Greece, DOI:10.1109/
CSMR.2008.4493298.
[5] IEEE standard, IEEE Std. 2675-
2021, IEEE Standard for DevOps: 
Building Reliable and Secure Systems 
Including Application Build, Package and 
Deployment, ed: IEEE. 2021.
[6]  W. Titus, T. Manshreck, and H. 
Wright. Software engineering at Google: 
Lessons learned from programming over 
time. O’Reilly Media, 2020.
[7]   A. Abran and H. Nguyenkim, 
Measurement of the maintenance pro-
cess from a demand-based perspec-
tive, Journal of Software Maintenance: 

7-18   SWEBOK
®
 GUIDE V4.0
Research and Practice, Vol. 5 Issue 2: 
63-90, 1993.
[8]   “Laws of software evolution revisited.” 
European workshop on software process 
technology. Berlin, Heidelberg: Springer 
Berlin Heidelberg, 1996”
[9] J. Humble and D. Fairley, Continuous 
Delivery: Reliable Software Releases 
through Build, Test, and Deployment 
Automation, Addison-Wesley, 2010.
[10] ISO/IEC/IEEE 12207:2017 Systems 
and software engineering — Software life 
cycle processes, 2 017.

8-1 
CHAPTER 08
Software Configuration 
Management
ACRONYMS
CCBConfiguration Control Board
CI Configuration Item
CMConfiguration Management
FCAFunctional Configuration Audit
PCAPhysical Configuration Audit
QAQuality Assurance
SCCBSoftware Configuration 
Control Board
SCISoftware Configuration Item
SCMSoftware Configuration Management
SCMPSoftware Configuration 
Management Plan
SCRSoftware Change Request
SCSASoftware Configuration Status 
Accounting
CMMISoftware Engineering Institute’s 
Capability Maturity Model 
Integration
SLCPSoftware Life Cycle Process
SQASoftware Quality Assurance
V&VVerification And Validation
KAKnowledge Area
MBXModel Based Experience
SBOMSoftware Bill Of Materials
CRChange Request
VDDVersion Description Document
CMDBConfiguration 
Management Database
INTRODUCTION
Software  configuration  management  (SCM)  
is formally defined as “the process of applying 
configuration management [CM] throughout 
the  software  life  cycle  to  ensure  the  com-
pleteness  and  correctness  of  CIs  [configura-
tion items],” with CM defined as “a discipline 
applying  technical  and  administrative  direc-
tion and surveillance to identify and document 
the  functional  and  physical  characteristics  of  
a configuration item, control changes to those 
characteristics, record and report change pro-
cessing and implementation status, and verify 
compliance  with  specified  requirements”  [1].  
SCM is a software life cycle process (SLCP) 
that   supports   project   management,   devel-
opment  and  maintenance  activities,  quality  
assurance  (QA)  activities,  and  the  customers  
and users of the end product. 
The  concepts  of  CM  apply  to  all  items  
controlled,  although  some  differences  exist  
between  implementing  hardware  CM  and  
implementing   software   CM.   CM   applies   
equally  to  iterative  and  incremental  software  
development methodology.
SCM  is  closely  related  to  software  quality  
assurance  (SQA).  As  defined  in  the  Software  
Quality  knowledge  area  (KA),  SQA  processes  
ensure  that  the  software  products  and  pro-
cesses in the project life cycle conform to their 
specified  requirements  by  requiring  software  
engineers  to  plan,  enact  and  perform  a  set  of  
activities that demonstrate that those specifica-
tions  are  built  into  the  software.  SCM  activi-
ties support these SQA goals through software 
configuration  activities  (presented  later  in  this  
chapter). The configuration audit activity can be 
described as a review of CIs and is closely related 
to the reviews defined in the quality plan. 
The  SCM  activities  should  operationalize  
SCM  process  management  and  planning,  soft-
ware configuration identification, software con-
figuration change control, software configuration 

8-2   SWEBOK
®
 GUIDE V4.0
status  accounting  (SCSA),  software  configura-
tion auditing, and software release management 
and delivery. This operationalization:
1. Determines what is expected to be under 
control during project development
2. Identifies and records who developed what 
CI as well as when and where it is allocated
3. Allows controlled changes
4. Tracks    CIs’    relationships    to    show    
how  changes  that  affect  one  CI  might  
affect other CIs
5. Keeps CI versions under control
6. Ensures that the quality of the CIs delivered 
meets the requirements for intended use
The  SCM  KA  is  related  to  all  other  KAs  
because SCM’s object is the artifact produced 
and   used   throughout   the   software   engi-
neering process.
BREAKDOWN OF TOPICS FOR 
SOFTWARE CONFIGURATION 
MANAGEMENT
Figure 8.1 shows the breakdown of topics for 
the SCM KA.
1. Management of the SCM Process  
 [2*, c6, c7]
SCM controls the evolution and integrity of 
a product by identifying its elements (known 
as  CIs);  managing  and  controlling  change;  
and  verifying,  recording  and  reporting  on  
configuration  information.  From  the  soft-
ware  engineer’s  perspective,  SCM  facilitates  
development   and   change   implementation   
activities.  Successful  SCM  implementation  
requires  careful  planning  and  management,  
which  requires  a  strong  understanding  of  
the  organizational  context  for,  and  the  con-
straints  placed  on,  the  design  and  imple-
mentation  of  the  SCM  process.  The  SCM  
plan  can  be  developed  once  for  the  organi-
zation and then adjusted as needed for indi-
vidual projects.
1.1 Organizational Context for SCM  
 [2*, c6, ann. D] [3*, Introduction]  
 [4*, c25]
To  plan  an  SCM  process  for  a  project,  it  is  
necessary  to  understand  the  organizational  
context  and  the  relationships  among  orga-
nizational  elements.  SCM  interacts  not  just  
Software Configuration 
Management
Organizational
Context for SCM
Constraints and
Guidance for the
SCM Process
Planning for SCM
Identifying Items
to be Controlled
Requesting, Evaluating
and Approving
Software Changes
Software
Configuration Status
Information
Software
Configuration Status
Reporting
Software Functional
Configuration Audit
Software Physical
Configuration Audit
In-process Audits
of a Software
Baseline
Software Building
Software Release
Management
Implementing
Software Changes
Deviations and
Waivers
Software
Configuration
Control Board
Software Change
Request Process
Software Change
Request Forms
Definition
Configuration 
Item Identifiers 
and Attributes
Baselines 
Identification
Baseline Attributes
Relationships Scheme
Definition
Software Libraries
Software
Configuration
Software
Configuration
Item
SCM Organization
and Responsibilities
SCM Resources 
and Schedules
Tool Selection and
Implementation
Vendor/
Subcontractor
Control
Interface Control
SCM Plan
Surveillance of
Software Configuration
Management SCM 
Measures and Measurement
In-Process Audits of SCM
Management of
the SCM Process
Software
Configuration
Identification
Software
Configuration
Change Control
Software
Configuration
Status Accounting
Software
Configuration
Auditing
Software Release
Management
 and Delivery
Software
Configuration
Management Tools
Figure 8.1. Breakdown of Topics for the Software Configuration Management KA.

SOFTWARE CONFIGURATION MANAGEMENT   8-3
with the particular project but also with sev-
eral other areas of the organization. 
The   organizational   elements   responsible   
for   software   engineering   supporting   pro-
cesses  might  be  structured  in  various  ways.  
The   overall   responsibility   for   SCM   often   
rests  with  a  distinct  part  of  the  organization  
or  with  a  designated  individual.  However,  
responsibility  for  certain  SCM  tasks  might  
be assigned to other parts of the organization 
(such as the development division). 
Software  is  frequently  developed  as  part  
of  a  larger  system  containing  hardware  and  
firmware  elements.  In  this  case,  SCM  activ-
ities take place in parallel with hardware and 
firmware  CM  activities  and  must  be  con-
sistent   with   system-level   CM.   Note   that   
firmware  contains  hardware  and  software;  
therefore,  both  hardware  and  software  CM  
concepts apply.
SCM  might  interface  with  an  organiza-
tion’s  QA  activity  on  issues  such  as  records  
management    and    nonconforming    items.    
Regarding the former, project records subject 
to  provisions  of  the  organization’s  QA  pro-
gram might also be under SCM control. The 
QA team is usually responsible for managing 
nonconforming items. However, SCM might 
assist with tracking and reporting on software 
configuration items (SCIs) in this category.
Perhaps  the  closest  relationship  is  with  
the  software  development  and  maintenance  
organizations.  It  is  within  this  context  that  
many  of  the  software  configuration  control  
tasks  are  conducted.  Frequently,  the  same  
tools support development, maintenance, and 
SCM purposes.
1.2 Constraints and Guidance for the  
SCM Process  
 [2*, c6, ann. D, ann. E] [3*,  
 c2, c5] [5, c19s2.2] 
Constraints   affecting,   and   guidance   for,   
the  SCM  process  come  from  many  sources.  
Policies and procedures set forth at corporate 
or other organizational levels might influence 
or prescribe the design and implementation of 
the  SCM  process  for  a  project.  In  addition,  
the  contract  between  the  acquirer  and  the  
supplier  might  contain  provisions  affecting  
the  SCM  process  (e.g.,  certain  configura-
tion audits might be required, or the contract 
might  specify  that  certain  items  be  placed  
under CM). When the software to be devel-
oped could affect public safety, external regu-
latory bodies may impose constraints. Finally, 
the  SLCP  chosen  for  a  software  project  and  
the  level  of  formalism  selected  for  imple-
mentation  will  also  affect  SLCP  design  and  
implementation. 
Software  engineers  can  also  find  guid-
ance   for   designing   and   implementing   an   
SCM  process  in  “best  practice,”  as  reflected  
in  the  software  engineering  standards  issued  
by  the  various  standards  organizations.  (See  
Appendix B for more information about these 
standards.)
1.3 Planning for SCM  
 [2*, c6, ann. D, ann. E] [3*, c23]  
 [4*, c25]
SCM  process  planning  for  a  project  should  
be consistent with the organizational context, 
applicable   constraints,   commonly   accepted   
guidance  and  the  nature  of  the  project  (e.g.,  
size, safety criticality and security). The major 
activities covered in the plan are software con-
figuration  identification,  software  configura-
tion  control,  SCSA,  software  configuration  
auditing,  and  software  release  management  
and delivery. In addition, issues such as orga-
nization  and  responsibilities,  resources  and  
schedules,   tool   selection   and   implementa-
tion,  vendor  and  subcontractor  control,  and  
interface control are typically considered. The 
planning  activity’s  results  are  recorded  in  an  
SCM plan (SCMP), which is subject to SQA 
review and audit.
Branching  and  merging  strategies  should  
be   carefully   planned   and   communicated   
because  they  affect  many  SCM  activities.  
SCM  defines  a  branch  as  a  set  of  evolving  
source  file  versions  [1].  Merging  consists  of  
combining  different  changes  to  the  same  file  
[1].  This  typically  occurs  when  more  than  
one  person  changes  a  CI.  There  are  many  

8-4   SWEBOK
®
 GUIDE V4.0
branching and merging strategies in common 
use.  (See  the  Further  Readings  section  for  
additional discussion.)
The software development life cycle model 
chosen  (see  Software  Life  Cycle  Models  in  
the  Software  Engineering  Process  KA)  also  
affects  SCM  activities,  and  SCM  planning  
should consider this. For instance, many soft-
ware development approaches use continuous 
integration,  which  is  characterized  by  fre-
quent build-test-deploy cycles. Clearly, SCM 
activities must be planned accordingly. 
1.3.1  SCM Organization and Responsibilities 
 [2*, ann. Ds5-6] [3*, c10-11] [4*, c25] 
Organizational  roles  must  be  clearly  identi-
fied to prevent confusion about who will per-
form  specific  SCM  activities  or  tasks.  These  
responsibilities must also be assigned to orga-
nizational entities; this can be made clear by 
the  responsible  individual’s  title  or  by  des-
ignating  the  organizational  division  or  sec-
tion in addition to the individual responsible 
within that section. The overall authority and 
reporting  channels  for  SCM  should  also  be  
identified,  although  this  might  be  accom-
plished at the project management or the QA 
planning stage.
1.3.2   SCM Resources and Schedules 
 [2*, ann. Ds8] [3*, c23]
Planning  for  SCM  identifies  the  resources  
—  including  staff  and  tools  —  involved  in  
carrying  out  SCM  activities  and  tasks.  It  
also   identifies   the   necessary   sequences   of   
SCM  tasks  and  establishes  each  task’s  place  
in  the  project  schedule  and  its  position  rela-
tive  to  milestones  established  at  the  project  
management  planning  stage.  Any  training  
requirements for implementing the plans and 
training new staff members are also specified.
1.3.3   Tool Selection and Implementation 
 [3*, c26s2, c26s6]
As  in  any  area  of  software  engineering,  the  
selection  and  implementation  of  SCM  tools  
should  be  carefully  planned.  The  following  
questions should be considered:
•    Organization: What motivates tool acqui-
sition from an organizational perspective?
•    Tools:  Can  we  use  commercial  tools,  or  
do we need to develop our own tools spe-
cifically for this project?
•    Environment:    What    constraints    are    
imposed by the organization and its tech-
nical context?
•    Legacy:  How  will  projects  use  (or  not  
use) the new tools?
•    Financing:  Who  will  pay  for  the  tools’  
acquisition,  maintenance,  training  and  
customization?
•    Scope: How will the new tools be deployed 
— for instance, through the entire orga-
nization or only on specific projects?
•    Ownership: Who is responsible for intro-
ducing new tools?
•    Future: What is the plan for the tools’ use 
in the future?
•    Change: How adaptable are the tools?
•    Branching  and  merging:  Are  the  tools’  
capabilities   compatible   with   planned   
branching and merging strategies?
•    Integration:  Do  the  various  SCM  tools  
integrate  among  themselves?  Do  they  
integrate  with  other  tools  in  use  in  the  
organization?
•    Migration: Can the repository maintained 
by  the  version  control  tool  be  ported  to  
another  version  control  tool  while  main-
taining  the  complete  history  of  the  CIs  
it contains?
SCM  requires  a  set  of  tools  instead  of  
a  single  tool.  Such  tool  sets  are  sometimes  
called workbenches.  As  part  of  the  tool  selec-
tion planning effort, the team must determine 
whether  the  SCM  workbench  will  be  open 
(tools from different suppliers will be used in 
different SCM process activities) or integrated 
(elements  of  the  workbench  are  designed  to  
work together).
Organization size and the type of projects 
involved  may  also  affect  tool  selection.  (See  
SCM Tools, section 7 of this document) 

SOFTWARE CONFIGURATION MANAGEMENT   8-5
1.3.4   Vendor/Subcontractor Control  
 [2*, c13] [3*, c13s9-c14s2] 
A software project might acquire or use pur-
chased software products, such as compilers or 
other tools. SCM planning considers whether 
and  how  these  items  will  be  managed  with  
configuration control (e.g., integrated into the 
project libraries) and how changes or updates 
will be evaluated and managed.
Similar   considerations   apply   to   subcon-
tracted software. When a project uses subcon-
tracted software, both the SCM requirements 
to  be  imposed  on  the  subcontractor’s  SCM  
process and the means for monitoring compli-
ance need to be established. The latter includes 
determining what SCM information must be 
available for effective compliance monitoring.
1.3.5   Interface Control  
 [2*, c12] [3*, c23s4]
When a software item interfaces with another 
software  or  with  a  hardware  item,  a  change  
to  either  item  can  affect  the  other.  Planning  
for the SCM process considers how the inter-
facing items will be identified and how changes 
to the items will be managed and communi-
cated. The SCM role may be part of a larger, 
system-level process for interface specification 
and control involving interface specifications, 
interface  control  plans  and  interface  control  
documents.  In  this  case,  SCM  planning  for  
interface  control  takes  place  within  the  con-
text of the system-level process.
1.4 SCM Plan 
 [2*, ann. D] [3*, c23]
The  results  of  SCM  planning  for  a  given  
project  are  recorded  in  an  SCMP,  a  “living  
document”  that  serves  as  a  reference  for  the  
SCM   process.   The   SCMP   is   maintained   
(updated  and  approved)  as  necessary  during  
the software life cycle. For teams to implement 
an SCMP, they’ll typically need to develop a 
number  of  more  detailed,  subordinate  pro-
cedures  to  define  how  specific  requirements  
will be met  during day-to-day activities (e.g., 
which branching strategies will be used, how 
frequently builds will occur, how often auto-
mated tests of all kinds will be run).
Guidance  on  creating  and  maintaining  an  
SCMP,  based  on  the  information  produced  
by  the  planning  activity,  is  available  from  a  
number  of  sources,  such  as  [2*].  This  refer-
ence provides requirements for information to 
be contained in an SCMP. An SCMP should 
include the following sections: 
•    Introduction (purpose, scope, terms used)
•    SCM Management (organization, respon-
sibilities,  authorities,  applicable  policies,  
directives, procedures)
•    SCM  Activities  (configuration  identifi-
cation, configuration control, etc.)
•    SCM Schedules (coordination with other 
project activities)
•    SCM Resources (tools, physical resources 
and human resources)
•    SCMP Maintenance
1.5 Monitoring of Software Configuration 
Management  
 [3*, c11s3]
After   the   SCM   process   has   been   imple-
mented,  some  surveillance  may  be  necessary  
to ensure that the SCMP provisions are prop-
erly  carried  out.  The  plan  is  likely  to  include  
specific  SQA  requirements  to  ensure  com-
pliance  with  specified  SCM  processes  and  
procedures.  The  person  responsible  for  SCM  
ensures  that  those  with  the  assigned  respon-
sibility  perform  the  defined  SCM  tasks  cor-
rectly.   As   part   of   a   compliance   auditing   
activity,  the  SQA  authority  might  also  per-
form this surveillance.
Using  integrated  SCM  tools  with  pro-
cess  control  capability  can  make  the  surveil-
lance task easier. Some tools facilitate process 
compliance   while   providing   flexibility   for   
the  software  engineer  to  adapt  procedures.  
Other tools enforce a specific process, leaving 
the  software  engineer  with  less  flexibility.  
Surveillance  requirements  and  the  level  of  
flexibility  provided  to  the  software  engineer  
are important considerations in tool selection.

8-6   SWEBOK
®
 GUIDE V4.0
1.5.1 SCM Measures and Measurement  
 [3*, c9s2, c25s2-s3]
SCM  measures  can  be  designed  to  provide  
specific information on the evolving product, 
but  they  can  also  provide  insight  into  how  
well  the  SCM  process  functions  and  iden-
tify opportunities for process improvement. 
SCM process measurements enable teams to 
monitor the effectiveness of SCM activities 
on  an  ongoing  basis.  These  measurements  
are   useful   in   characterizing   the   current   
state of the process and providing a basis for 
comparison  over  time.  Measurement  anal-
ysis  may  produce  insights  that  lead  to  pro-
cess   changes   and   corresponding   updates   
to the SCMP.
Software  libraries  and  the  various  SCM  
tool capabilities enable teams to extract useful 
information  about  SCM  process  characteris-
tics (as well as project and management infor-
mation).  For  example,  information  about  the  
time  required  to  accomplish  various  types  of  
changes would be useful in evaluating criteria 
for  determining  what  levels  of  authority  are  
optimal  for  authorizing  certain  changes  and  
in  estimating  the  resources  needed  to  make  
future changes.
Care must be taken to keep the surveillance 
focused on the insights that can be gained from 
the  measurements,  not  on  the  measurements  
themselves.   Software   process   and   product   
measurement   is   further   discussed   in   the   
Software Engineering Process KA. Software 
measurement  programs  are  described  in  the  
Software Engineering Management KA.
1.5.2 In-Process Audits of SCM
[3 *,   c1s1]
Audits can be carried out during the software 
engineering  process  to  investigate  the  status  
of specific configuration elements or to assess 
the SCM process implementation. In-process 
SCM auditing provides a more formal mech-
anism  for  monitoring  selected  aspects  of  the  
process  and  may  be  coordinated  with  the  
SQA  function.  (See  Software  Configuration  
Auditing.)
2. Software Configuration Identification 
 [2 *, c8]
Software  configuration  identification  identi-
fies  items  to  be  controlled,  establishes  iden-
tification  schemes  for  the  items  and  their  
versions,  and  establishes  the  tools  and  tech-
niques to be used in acquiring and managing 
controlled  items.  These  activities  provide  the  
basis for other SCM activities.
2.1 Identifying Items to Be Controlled  
 [2*, c8s2.2]
A  first  step  in  controlling  change  is  identi-
fying the software items to be controlled. This 
involves understanding the software configu-
ration  within  the  context  of  the  system  con-
figuration,  selecting  SCIs  and  developing  a  
strategy for labeling software items.
2.1.1. Software Configuration
Software configuration  is  the  functional  and  
physical  characteristics  of  hardware  or  soft-
ware as set forth in technical documentation 
or achieved in a product. It can be viewed as 
part of an overall system configuration.
2.1.2 Software Configuration Item  
 [2*, c8s2.1] [3*, c9]
A  CI  is  an  item  or  aggregation  of  hardware,  
software or both, designed to be managed as 
a  single  entity.  An  SCI  is  a  software  entity  
that  has  been  established  as  a  CI  [1].  The  
SCM  controls  various  items  in  addition  to  
the code itself. Software items with potential 
to  become  SCIs  include  plans,  specifications  
and design documentation, testing materials, 
software  tools,  source  and  executable  code,  
code libraries, data and data dictionaries, and 
documentation for installation, maintenance, 
operations and software use. 
Selecting  SCIs  is  an  important  process  in  
which  a  balance  must  be  achieved  between  
providing  adequate  visibility  for  project  con-
trol  purposes  and  providing  a  manageable  
number of controlled items. 

SOFTWARE CONFIGURATION MANAGEMENT   8-7
2.2 Configuration Item Identifiers and 
Attributes 
 [2*, c8s2.3, c8s2.4] [3*, c9]
Status  accounting  activity  (explained  later)  
gathers  information  about  CIs  while  they  
are  developed.  The  CIs’  scheme  is  defined  
in  order  to  establish  what  information  must  
be gathered and tracked for each CI. Unique 
identifiers and versions are tracked.
An   example   scheme   may   include   the   
following: 
CI name
CI unique identifier
CI description
CI date(s) 
CI type
CI owner
The  CI’s  unique  Identifier  can  use  sig-
nificant  or  nonsignificant  codification.  An  
example  of  significant  codification  could  be  
XX-YY,  where  XX  is  the  iteration  abbrevia-
tion (in case of using an iterative development 
method) and YY is the CI abbreviation.
2.3 Baseline Identification 
 [2*, c8s2.5.4, c8s2.5.5, c8s2.5.6]
A  software  baseline  is  a  formally  approved  
version of a CI (regardless of media type) that 
is  formally  designated  and  fixed  at  a  specific  
time during the CI’s life cycle. The term also 
refers  to  a  particular version  of  an  agreed-
upon SCI. The baseline can be changed only 
through  formal  change  control  procedures.  
A baseline, with all approved changes to the 
baseline, represents the current approved con-
figuration. A baseline consists of one or more 
related CIs.
2.4 Baseline Attributes 
 [2*, c8s2.5.4]
Baseline  attributes  are  used  in  the  status  
accounting  activity  and  specify  information  
about the baseline established.
Example  baseline  attributes  may  include  
the following:
Baseline name
Baseline unique identifier
Baseline description
Baseline date of creation
Baseline CIs
2.5 Relationships Scheme Definition 
 [3*, c7s4]
Relationships     provide     the     connections     
required  to  create  and  sustain  structure.  The  
ability to communicate intent and manage the 
results are significantly enhanced when effec-
tive  relationships  (structuring)  are  in  place  
(e.g.,  model-based  experience  (MBX)  plat-
forms).  Relationship  information  exchange  
and  interoperability  are  needed  to  support  
the  applicable  relationship  types.  The  status  
accounting activity is responsible for gathering 
information about relationships among CIs.
Common  types  of  relationships  can  be  
described according to the following schemes: 
Dependencies: CI-1 and CI-2 depend mutu-
ally on each other.
Example: CI-1 depends on C1-2, and vice 
versa, for instance a class model depends on a 
sequence diagram, because any change on any 
of both types of models, affect the other. 
CI-1 C odeCI-2 CodeDate
Derivation:  One  CI  derives  from  another,  
typically   in   a   sequential   relationship,   not   
because of a lack of resources to handle both 
CIs  but  because  of  a  constraint  that  requires  
that,  for  instance,  CI-1  is  completed  before  
CI-2 is developed. 
Example: CI-1 derives from CI-2. 
CI-1 C odeCI-2 CodeDate
Succession: Software items evolve as a soft-
ware  project  proceeds.  A  software  item  ver-
sion  is  an  identified  instance  of  an  item.  It  
can  be  thought  of  as  a  state  of  an  evolving  
item. This is what the succession relationship 

8-8   SWEBOK
®
 GUIDE V4.0
reflects, and it is reflexive in that each CI has 
this  relationship  with  itself.  The  first  succes-
sion  comes  up  the  first  time  a  CI  is  created.  
Each  time  it  is  changed,  a  new  succession  
comes  up,  and  tracking  these  successions  is  
the way to track CI versions. 
Example: CI versions along a timeline.
CI CodeCurrent VersionNext VersionDate
Variants   are   program   versions   resulting   
from   engineered   alternative   options.   This   
type  of  relationship  is  not  as  common  as  the  
type of relationships described above because 
it is more expensive to maintain. 
The decision on what relationships to track 
throughout  the  project  is  important  because  
tracking some relationships can require extra 
work. On the other hand, tracking such rela-
tionships  can  facilitate  decisions  on  change  
requests (CRs) for a CI.
Relationships  between  CIs  can  be  tracked  
in  a  Software  Bill  of  Materials  (SBOM).  
An  SBOM  is  a  formal  record  containing  
the  details  and  supply  chain  relationships  
of  the  CIs  used  in  building  software.  CIs  
in  an  SBOM  are  frequently  referred  to  as 
components. Components can be source code, 
libraries,  modules  and  other  artifacts;  they  
can  be  open  source  or  proprietary,  free  or  
paid; and the data can be widely available or 
access-restricted. 
A   simple   example   of   the   relationships   
among  three  CIs  in  an  SBOM,  called  CI-1,  
CI-2 and CI-3, is illustrated in Figure 8.2.
2.6 Software Libraries  
 [2*, c8s2.5] [3*, c1s3]
A software library is a controlled collection of 
source  code,  scripts,  object  code,  documen-
tation   and   related   artifacts.   Requirements   
and  test  cases  are  stored  in  a  repository  and  
should  be  linked  with  the  code  baselines  
developed. Source code is stored in a version 
control  system,  which  provides  traceability  
and   security   for   the   baselines   developed.   
Multiple  development  streams  are  supported  
in version control systems linked to the binary 
objects  (e.g.,  object  code)  derived  during  the  
build  process.  These  binary  objects  are  typi-
cally  stored  in  a  repository  that  should  con-
tain cryptographic hashes used to perform the 
physical configuration audit (PCA). 
Successions Records: According to the scheme defined for succession relationships, the next table gives the date when each CI was 
created (three first rows), and the fourth row indicates a change made on the CI-1 on 10/05/2021, where the current version was 1 
and created new version is 2.
Derivation Record: According to the scheme defined for derivation, CI-3 derives from CI-1 and 
this relationship came up the day CI-3 was created.
Dependency Record: According to the scheme defined for dependencies CI-1 and CI-2 have a 
dependency relationship created the day CI-2 was developed.
CI-1 – 1 10/01/2021
CI-2 – 1 10/04/2021
CI-3 – 1 10/03/2021
CI-1 1 2 10/05/2021
CI-1 CI-2 10/04/2021
CI-3 CI-1 10/03/2021
CI-1
CI-2CI-3
succession
succession
succession
dependency
derivation
Figure 8.2. Example of reported relationships

SOFTWARE CONFIGURATION MANAGEMENT   8-9
The  definitive  media  library    contains  the  
release  baseline(s)  of  the  artifacts  that  can  
be  deployed  to  the  test,  stage  and  produc-
tion systems. 
The  release  management  process  depends  
on these software libraries to manage the arti-
facts deployed. In terms of access control and 
the backup facilities, security is a key aspect of 
library management.
3. Software Configuration Change Control  
 [2*, c9] [3*,c8] [4*, c25s3] [5, c11.s3.3]
Software configuration change control is con-
cerned  with  changes  required  to  CIs  during  
the  software  life  cycle.  It  covers  the  pro-
cess  for  determining  what  changes  to  make,  
the  authority  for  approving  certain  changes,  
support   for   implementing   those   changes,   
and  the  concept  of  formal  deviations  from  
project  requirements  as  well  as  waivers  of  
them.  Information  derived  from  these  activ-
ities is useful in measuring change traffic and 
breakage, as well as aspects of rework.
Given  that  change  to  CIs  can  follow  spe-
cific rules depending on the industrial sector, 
area,  company,  etc.,  it  is  very  important  to  
identify  those  rules  in  the  context  of  the  
software  project  for  which  the  SCM  pro-
cess is being developed and to adhere strictly 
to  those  rules.  The  rest  of  this  section  can  
be  useful  when  no  specific  rules  regarding  
change  control  exist  in  the  company  or  the  
industrial  sector  where  the  software  project  
under development is allocated.
3.1 Requesting, Evaluating, and Approving 
Software Changes  
 [2*, c9s2.4] [3*, c11s1] [4*, c25s3]
The  first  step  in  managing  changes  to  con-
trolled items is determining what changes to 
make.  The  software  change  request  (SCR)  
process  (Figure  8.3)  provides  formal  pro-
cedures  for  submitting  and  recording  CRs;  
evaluating the potential cost and impact of a 
proposed  change;  and  accepting,  modifying,  
deferring  or  rejecting  the  proposed  change.  
A  CR  is  a  request  to  expand  or  reduce  the  
project   scope;   modify   policies,   processes,   
plans or procedures; modify costs or budgets; 
modify implemented code; or revise schedules 
[1]. Requests for changes to SCIs may be orig-
inated by anyone at any point in the software 
life cycle and may include a suggested solution 
and requested priority. One source of a CR is 
the initiation of corrective action in response 
to problem reports. Regardless of the source, 
the  type  of  change  (e.g.,  defect  or  enhance-
ment) is usually recorded on the SCR.
“Emergency Path”
usually also exists
Changes can be
implemented with 
change process
performed afterward
Incomplete
Complete
Approved
Rejected
Inform
Requester
Assign
to Software
Engineer
Schedule, 
Design, Test,
Complete Change
CCB
Review
Preliminary
Investigation
Need for
Change
Change
identied for
controlled item
SCR Generated
or Upgraded
SCR
Evaluated
Figure 8.3. Flow of a Change Control Process

8-10   SWEBOK
®
 GUIDE V4.0
Recording of the SCR enables the software 
engineers to track defects and collect change 
activity measurements by change type. Once 
an  SCR  is  received,  a  technical  evaluation  
(also  known  as  an  impact  analysis)  is  per-
formed to determine the extent of the modifi-
cations necessary should the CR be accepted. 
A  good  understanding  of  the  relationships  
among   software   (and,   possibly,   hardware)   
items  is  important  for  this  task.  The  infor-
mation  recorded  about  the  CIs’  relationships  
could be useful for making decisions affecting 
any  CI,  given  the  potential  impact  on  other  
CIs. Finally, an established authority — com-
mensurate with the affected baseline, the SCI 
involved and the nature of the change — will 
evaluate  the  CR’s  technical  and  managerial  
aspects and accept, modify, reject or defer the 
proposed change. 
3.1.1 Software Configuration Control Board  
 [2*, c9s2.2] [3*, c11s1] [4*, c25s3]
The  authority  for  accepting  or  rejecting  pro-
posed changes rests with an entity known as a 
configuration control board (CCB). In smaller 
projects,  this  authority  may  reside  with  the  
leader  or  an  assigned  individual  rather  than  
a  multi-person  board.  There  can  be  multiple  
levels  of  change  authority  depending  on  a  
variety of criteria — such as the criticality of 
the  item  involved,  the  nature  of  the  change  
(e.g.,  impact  on  budget  and  schedule),  or  
where the project is in the life cycle. The com-
position of the CCBs used for a system varies 
depending on these criteria (but an SCM rep-
resentative is always present). All stakeholders 
appropriate to the CCB level are represented. 
When  a  CCB’s  scope  of  authority  is  limited  
to software, the board is known as a Software 
Configuration     Control     Board     (SCCB).     
The  CCB’s  activities  are  subject  to  software  
quality audits or reviews.
3.1.2 Software Change Request Process  
 [3*, c1s4, c8s4] [4*, c25s3]
An  effective  SCR  process  requires  the  use  
of   supporting   tools   and   procedures   for   
originating CRs, enforcing the change process 
flow, capturing CCB decisions and reporting 
change process information. Linking this tool 
capability with the problem-reporting system 
can facilitate the problem resolution tracking 
and how quickly solutions are developed. 
3.1.3 Software Change Request Forms 
Definition 
 [2*, c9s2.3, c9s2.5]  
 [3*, c8s4] [4*, c25s3]
A CR application must include the following:
•    A  CR  form,  which  must  describe  the  
request and give the rationale for it
•    A change certification form (necessary if 
the CR is granted)
These  forms  can  be  managed  through  the  
corresponding  supporting  tool,  but  humans  
are responsible for designing the forms. 
3.2 Implementing Software Changes  
 [4*, c 25s3]
Approved  SCRs  are  implemented  using  the  
defined software procedures per the applicable 
schedule  requirements.  Because  a  number  of  
approved SCRs might be implemented simul-
taneously,  a  means  for  tracking  which  SCRs  
are incorporated into particular software ver-
sions and baselines must be provided. At the 
end of the change process, completed changes 
may  undergo  configuration  audits  and  soft-
ware   quality   verification,   which   includes   
ensuring  that  only  approved  changes  have  
been made. The SCR process typically docu-
ments the change’s SCM and other approval 
information. 
Changes may be supported by source code 
version control tools. These tools allow a team 
of  software  engineers,  or  a  single  software  
engineer,  to  track  and  document  changes  to  
the  source  code.  These  tools  provide  a  single  
repository for storing the source code, so they 
can prevent more than one software engineer 
from  editing  the  same  module  at  the  same  
time, and they record all changes made to the 

SOFTWARE CONFIGURATION MANAGEMENT   8-11
source  code.  Software  engineers  check  mod-
ules out of the repository, make changes, doc-
ument the changes, and then save the edited 
modules in the repository. If needed, changes 
can  also  be  discarded,  restoring  a  previous  
baseline.  More  powerful  tools  can  support  
parallel development and geographically dis-
tributed environments. These tools may mani-
fest as separate, specialized applications under 
an  independent  SCM  group’s  control.  They  
may  also  appear  as  an  integrated  part  of  the  
software  engineering  environment.  Finally,  
they  may  be  as  elementary  as  a  rudimentary  
change  control  system  that  is  provided  with  
an operating system.
3.3 Deviations and Waivers  
 [1, c3]
The  constraints  imposed  on  a  software  engi-
neering  effort  or  the  specifications  produced  
during the development activities might con-
tain  provisions  that  those  working  on  the  
project  find  cannot  be  satisfied  at  the  desig-
nated  point  in  the  life  cycle.  A  deviation  is  
a  written  authorization  granted  before  the  
manufacture of an item to depart from a par-
ticular performance or design requirement for 
a specific number of units or a specific period 
of  time.  A  waiver  is  a  written  authorization  
to  allow  a  CI  or  other  designated  item  in  
response to an issue found during production 
or after the project is submitted for inspection 
to  depart  from  specified  requirements  when  
the  CI  or  project  is  nevertheless  considered  
suitable for use, either as it is or after rework 
via  an  approved  method.  In  these  cases,  a  
formal  process  is  used  to  gain  approval  for  
deviations from or waivers of the provisions. 
4. Software Configuration Status 
Accounting 
 [2*, c10] [3*, c9] [5, c11s3.4]
SCSA  is  an  activity  of  CM  consisting  of  
recording and reporting information needed to 
manage  a  configuration  effectively  regarding  
CIs,  baselines  and  relationships  among  CIs.  
This  activity  must  be  done  by  following  the  
logical schemes defined in the activity config-
uration  identification  for  CIs,  baselines  and  
relationships for gathering information.
4.1 Software Configuration Status Information 
 [2*, c10s2.1]
The  SCSA  activity  designs  and  operates  a  
system  for  capturing,  verifying,  validating  
and  reporting  necessary  information  as  the  
life  cycle  proceeds.  As  in  any  information  
system,  the  configuration  status  information  
to be managed for the evolving configurations 
must be identified, collected and maintained. 
In  addition,  the  information  itself  should  be  
secured  where  relevant.  SCSA  information  
and measurements are needed to support the 
SCM  process  and  to  meet  the  configuration  
status  reporting  needs  of  management,  soft-
ware  engineering,  security,  performance  and  
other related activities. 
The types of information available include 
but are not limited to the following:
•    Ongoing   and   approved   configuration   
identification
•    Current implementation status of changes
•    Impacted CIs and related systems
•    Deviations and waivers
•    Verification     and     validation     (V&V)     
activities
Automated  tools  support  SCSA  as  tasks  
are performed, and reporting is available in a 
user-friendly format. 
4.2 Software Configuration Status Reporting 
 [2*, c10s2.4] [3*, c1s5, c9s1]
Reported  information  can  be  used  by  var-
ious  organizational  and  project  elements  —  
including  the  development  team,  operations,  
security, the maintenance team, project man-
agement,  software  quality  activities  teams  
and  others.  Reporting  can  take  many  forms:  
automated  reports,  ad  hoc  queries  to  answer  
specific  questions,  and  regular  production  of  
predesigned  reports,  including  those  devel-
oped  to  meet  security,  legal  or  regulatory  

8-12   SWEBOK
®
 GUIDE V4.0
requirements.  In  other  words,  information  
produced  by  the  SCSA  activity  throughout  
the  life  cycle  can  be  used  to  satisfy  QA  and  
security  and  to  provide  evidence  of  compli-
ance  with  regulations,  governance  require-
ments, etc.
In  addition  to  reporting  the  configura-
tion’s current status, the information obtained 
by  the  SCSA  can  serve  as  a  basis  for  various  
measurements. 
Modern  SCM  includes  a  wider  scope  of  
information, including but not limited to the 
following: 
•    Indicators    of    integrity    (e.g.,    MAC    
(Message  Authentication  Code)  SHA1  
(Secure      Hash      Algorithm),      MD5      
(Message Digest))
•    Indicators  of  security  status  (e.g.,  gover-
nance risk and compliance) 
•    Evidence of V&V activities (e.g., require-
ments completion)
•    Baseline status
•    The number of CRs per SCI 
•    The       average       time       needed       to       
implement a CR 
5. Software Configuration Auditing 
 [2*, c11] [5, c11s3.5]
A software audit is an independent examina-
tion  of  a  work  product  or  set  of  work  prod-
ucts  to  assess  technical,  security,  legal  and  
regulatory   compliance   with   specifications,   
standards,  contractual  agreements  or  other  
criteria  [1].  Audits  are  conducted  according  
to  a  well-defined  process  comprising  various  
auditor   roles   and   responsibilities.   Because   
of  this  complexity,  each  audit  must  be  care-
fully planned. An audit can require a number 
of individuals to perform various tasks over a 
fairly  short  time.  Tools  to  support  the  plan-
ning and conduct of an audit can greatly facil-
itate the process.
Software   configuration   auditing   deter-
mines  the  extent  to  which  an  item  satis-
fies  requirements  for  functional  and  physical  
characteristics.  Informal  audits  can  be  con-
ducted  at  key  points  in  the  life  cycle.  Two  
types  of  formal  audits  might  be  required  by  
the  governing  contract  (e.g.,  a  contract  cov-
ering critical software): the functional config-
uration audit (FCA) and the PCA. Successful 
completion of these audits can be a prerequi-
site for establishing the product baseline. 
5.1 Software Functional Configuration Audit  
 [2*, c11s2.1]
The  software  FCA  ensures  that  the  audited  
software item is consistent with its governing 
specifications.  The  software  V&V  activities’  
output  (see  Verification  and  Validation  in  
the  Software  Quality  KA)  is  a  key  input  to  
this audit.
5.2 Software Physical Configuration Audit  
 [2*, c11s2.2]
The  software  PCA  ensures  that  the  design  
and  reference  documentation  are  consistent  
with the as-built software product.
5.3 In-Process Audits of a Software Baseline 
 [2*, c11s2.3]
Audits can be carried out during the develop-
ment process to investigate the status of specific 
configuration  elements.  In-process  audits  can  
be  applied  to  all  baseline  items  to  ensure  that  
performance  is  consistent  with  specifications  
or that evolving documentation continues to be 
consistent with the developing baseline item. 
This  task  applies  to  every  single  CI  to  be  
approved  as  part  of  a  baseline.  The  audit  
consists  of  reviewing  the  CI  to  determine  
whether it satisfies requirements. How to con-
duct the review and the expected result must 
be described in the quality plan or if there is 
no quality plan, defined for the software con-
figuration auditing activity. 
Continuous  reviews  of  CIs  identified  in  
the configuration identification activities help 
verify conformance to governance and regula-
tory requirements. 
Configuration  auditing  reviews  take  place  
throughout  project  development,  whenever  a  
CI must be reviewed.

SOFTWARE CONFIGURATION MANAGEMENT   8-13
6. Software Release Management and 
Delivery 
 [2*, c14] [3*, c8s2] [4*, c25s4]
In   this   context,   release refers   to   distrib-
uting  software  and  related  artifacts  outside  
the  development  activity,  including  internal  
releases and distribution to customers. When 
different versions of a software item are avail-
able for delivery (such as versions for different 
platforms  or  versions  with  varying  capabili-
ties),  re-creating  specific  versions  and  pack-
aging the correct materials for version delivery 
are frequently necessary. The software library 
is a key element in accomplishing release and 
delivery tasks.
6.1 Software Building [4*, c 25s2]
Software building constructs the correct ver-
sions  of  SCIs,  using  the  appropriate  config-
uration  data,  into  a  software  package  for  
delivery to a customer or other recipient such 
as  a  team  performing  testing.  For  systems  
with  hardware  or  firmware,  the  executable  
program  is  delivered  to  the  system-building  
activity.  Build  instructions  help  ensure  that  
the  proper  build  steps  are  taken  in  the  cor-
rect  sequence.  In  addition  to  building  soft-
ware  for  new  releases,  SCM  must  usually  
be  able  to  reproduce  previous  releases  for  
recovery,  testing,  maintenance  or  additional  
release purposes.
Software  is  built  using  supporting  tools,  
such  as  compilers.  For  example,  if  it  is  nec-
essary to rebuild an exact copy of a previously 
built  SCI,  supporting  tools  and  associated  
build  instructions  must  be  under  SCM  con-
trol  to  ensure  the  availability  of  the  correct  
versions of the tools. 
Tool capability is useful for selecting the 
correct versions of software items for a target 
environment  and  automating  the  process  
of  building  the  software  from  the  selected  
version  and  configuration  data.  This  tool  
capability   is   necessary   for   projects   with   
parallel  or  distributed  development  envi-
ronments. Most software engineering envi-
ronments provide this capability. However, 
these tools vary in complexity; some require 
the  software  engineer  to  learn  a  special-
ized scripting language, while others use a 
more graphics-oriented approach that hides 
much  of  the  complexity  of  an  “intelligent”  
build facility.
The  build  process  and  products  are  often  
subject    to    software    quality    verification.    
Outputs of the build process might be needed 
for future reference. They may become records 
of quality, security, or compliance with orga-
nizational  or  regulatory  requirements.  The  
SBOM  listing  the  artifacts  included  in  the  
build is an important CM output.
In     continuous     integration,     software     
building   is   performed   automatically   when   
changes  to  CIs  are  committed  to  a  source  
control  repository.  Tools  running  on  a  local  
or  cloud-based  server  monitor  the  project’s  
source control system and initiate a pipeline of 
steps to be undertaken every time a change is 
committed to a particular branch or area of the 
source code repository. The tool is configured 
to retrieve a fresh copy of the complete source 
code for the project and execute the necessary 
commands to compile and link the code. This 
configuration is often combined with steps to 
validate coding standards via automated static 
analysis,  execute  unit  tests  and  determine  
code coverage metrics, or extract documenta-
tion from the source code.  The resulting arti-
facts  are  then  deployed  through  the  Release  
Management process.
6.2 Software Release Management 
 [4*, c 25s2]
Software  release  management  encompasses  
the  identification,  packaging  and  delivery  of  
the  elements  of  a  product  (e.g.,  an  execut-
able  program,  documentation,  release  notes,  
or  configuration  data).  Given  that  product  
changes  can  occur  continually,  one  concern  
for release management is determining when 
to  issue  a  release.  The  severity  of  the  prob-
lems  addressed  by  the  release  and  measure-
ments  of  the  fault  densities  of  prior  releases  
affect this decision. The packaging task iden-
tifies which product items are to be delivered 

8-14   SWEBOK
®
 GUIDE V4.0
and then selects the correct variants of those 
items,  given  the  product’s  intended  applica-
tion. The information documenting the phys-
ical contents of a release is known as a version 
description  document  (VDD).  The  release  
notes describe new capabilities, known prob-
lems and platform requirements necessary for 
proper  product  operation.  The  package  to  be  
released also contains installation or upgrade 
instructions.  The  latter  can  be  complicated  
because  some  users  might  have  versions  that  
are several releases old. In some cases, release 
management might be necessary to track the 
product’s  distribution  to  various  customers  
or  target  systems  (e.g.,  when  the  supplier  
was  required  to  notify  a  customer  of  newly  
reported  problems).  Finally,  a  mechanism  to  
help  ensure  the  released  item’s  integrity  can  
be  implemented  (e.g.,  by  including  a  digital  
signat ure).
 A tool capability is needed for supporting 
these   release   management   functions.   For   
example,  a  connection  with  the  tool  capa-
bility  supporting  the  CR  process  is  useful  to  
map  release  contents  to  the  SCRs  that  have  
been received. This tool capability might also 
maintain  information  on  various  target  plat-
forms and customer environments.
In  continuous  delivery,  a  pipeline  is  estab-
lished   to   build   software   continuously,   as   
described in the previous section. The resulting 
artifacts  from  the  build  process  include  exe-
cutable code and libraries, which can then be 
combined  into  an  installation  package  and  
deployed into an environment for verification 
or production use. 
7. Software Configuration Management 
Tools 
 [3 *, c 2 6 s1]
Many tools can assist with CM at many levels. 
The scope of these tools varies depending on 
who uses the tools. CM is most effective when 
integrated with other processes and by exten-
sion with other existing tools. The selection of 
CM tool can be made depending on the scope 
that the tool is going to have.
Overview of tools:
•    The  configuration  management  system  
(CMS) provides enabling technology and 
logic to facilitate CM activities. 
•    Version  control  stores  the  source  code,  
configuration files and related artifacts.
•    Build automation (pipeline) is established 
to enable continuous delivery.
•    A repository stores binaries that are cre-
ated  during  the  build  process  to  extract  
the  latest  build  artifacts  and  redeploy  
them  as  required  —  used  in  the  release  
verification process.
•    Configuration    management    database    
(CMDB) or similar persistence store.
•    Change control tools.
•    Release/deployment tools.
The  CMS  supports  the  unique  identifica-
tion of artifacts. Both individual artifacts and 
collections  are  specified  in  CM  systems  and  
related repositories. Structuring creates a log-
ical relationship between artifacts. Validation 
and   release   establish   the   artifacts’   integ-
rity,  as  part  of  the  release  management  pro-
cess. Baselines are identified where stability is 
intended. For example, interface management 
is identified and controlled, making it part of 
the  baseline  process.  Change  management,  
including   variants   and   nonconformances,   
is  reviewed  and  approved,  and  its  imple-
mentation  is  planned.  Verification  and  audit  
activities are performed as part of the identi-
fication, change and release management pro-
cess.  Status  and  performance  accounting  are  
recorded as events occur and are made avail-
able through the CMS.
Individual  support  tools  are  typically  suffi-
cient  for  small  organizations  or  development  
groups that do not issue variants of their soft-
ware  products  or  face  other  complex  SCM  
requirements.  The  following  are  examples  of  
these tools:
•    Version  control  tools:  These  tools  track,  
document and store individual CIs such as 
source code and external documentation.
•    Build  handling  tools:  In  their  simplest  
form, such tools compile and link an exe-
cutable  version  of  the  software.  More  

SOFTWARE CONFIGURATION MANAGEMENT   8-15
advanced building tools extract the latest 
version  from  the  version  control  soft-
ware, perform quality checks, run regres-
sion  tests,  and  produce  various  forms  of  
reports, among other tasks.
•    Change  control  tools:  These  tools  pri-
marily  support  the  control  of  CRs  and  
event    notifications    (e.g.,    CR    status    
changes, milestones reached).
Project-related   support   tools   mainly   sup-
port   workspace   management   for   develop-
ment   teams   and   integrators.   In   addition,   
they   can   support   distributed   development   
environments.  Such  tools  are  appropriate  for  
medium-to-large organizations that use vari-
ants  of  their  software  products  and  parallel  
development  and  do  not  have  certification  
requirements.
Companywide-process    support    tools    can    
automate  portions  of  a  companywide  pro-
cess,  providing  support  for  workflow  man-
agement,  roles  and  responsibilities.  They  can  
handle many items, large volumes of data, and 
numerous  life  cycles.  In  addition,  such  tools  
add to project-related support by supporting a 
more  formal  development  process,  including  
certification requirements.
MATRIX OF TOPICS VS. REFERENCE MATERIAL
Topic
IEEE 828-2012[2*]Hass 2003 [3*]Sommer ville 2016[4*]
1. Management of the SCM Processc6, c7
1.1. Organizational Context for SCMc6, ann.D Introductionc25
1.2. Constraints and Guidance for the SCM Process
c6, ann.D,  
ann.E
c2,c5
1.3. Planning for SCM
c6, ann.D,  
ann.E
c23c25
1.3.1. SCM Organization and Responsibilitiesann.Ds5-6c10 -11c25
1.3.2. SCM Resources and Schedulesann.Ds8c23
1.3.3. Tool Selection and Implementationc26s2, s6
1.3.4. Vendor/Subcontractor Controlc13c13s9-c14s2
1.3.5. Interface Controlc12c23s4
1.4. SCM Plan
ann.Dc23
1.5. Surveillance of Software Configuration 
Management
c11s3
1.5.1. SCM Measures and Measurementc9s2; c25s2-s3
1.5.2. In-Process Audits of SCMc1s1
2. Software Configuration Identificationc8
2.1. Identifying Items to Be Controlledc8s2.2c1s2
2.1.1. Software Configuration

8-16   SWEBOK
®
 GUIDE V4.0
2.1.2. Software Configuration Itemc8s2.1c9
2.2. Configuration Item Identifiers and Attributes
c8s2.3 c8s2.4
c9
2.3. Baseline Identification
c8s2.5.4
c8s2.5.5 c8s2.5.6
2.4. Baseline Attributesc8s2.5.4
2.5. Relationships Scheme Definitionc7s4
2.6. Software Librariesc8s2.5
c1s3
3. Software Configuration Change Controlc9c8c25s3
3.1. Requesting, Evaluating and Approving 
Software Changes
c9s2.4c11s1c25s3
3.1.1. Software Configuration Control Boardc9s2.2c11s1c25s3
3.1.2. Software Change Request Processc1s4, c8s4c25s3
3.1.3. Software Change Request Forms Definitionc9s2.3 c9s2.5c8s4c25s3
3.2. Implementing Software Changesc25s3
3.3. Deviations and Waivers
4. Software Configuration Status Accountingc10c9
4.1. Software Configuration Status Informationc10s2.1
4.2. Software Configuration Status Reportingc10s2.4c1s5; c9s1
5. Software Configuration Auditingc11
5.1. Software Functional Configuration Auditc11s2.1
5.2. Software Physical Configuration Auditc11s2.2
5.3. In-Process Audits of a Software Baselinec11s2.3
6. Software Release Management 
and Delivery
c14c8s2c25s4
6.1. Software Building
c25s2
6.2. Software Release Management
c25s2
7. Software Configuration Management Toolsc26s1
FURTHER READINGS
S.P.   Berczuk   and   B.   Appleton,   Software 
Configuration  Management  Patterns:  Effective  
Te a m w o rk, Practical Integration [6].
This  book  expresses  useful  SCM  practices  
and strategies as patterns. The patterns can be 
implemented using various tools, but they are 
expressed in a tool-agnostic fashion.
CMMI for Development, Version 2.0 - 2.1, pp. 
66 – 8 0 [7].
This model presents a collection of best prac-
tices  to  help  software  development  organi-
zations  improve  their  processes.  At  maturity  
level 2, it suggests CM activities.
B. Aiello and L. A. Sachs, Configuration man-
agement best practices: Practical methods that 

SOFTWARE CONFIGURATION MANAGEMENT   8-17
work in the real world (1st edition), 2011 [8].
This book presents the seven types of change 
control (Chapter 4, Section 3).
REFERENCES 
[1]   ISO/IEC/IEEE, “ISO/IEC/IEEE 
24765:2017 Systems and Software 
Engineering — Vocabulary,” 
2nd ed. 2017.
[2*] IEEE. IEEE Standard 828-
2012, Standard for Configuration 
Management in Systems and Software 
Engineering, 2012.
[3*] A.M.J. Hass. Configuration Management 
Principles and Practices, 1st ed. Boston: 
Addison-Wesley, 2003.
[4*] I. Sommerville, Software Engineering, 
10th ed. Global ed. Pearson, 2016.
[5] J.W. Moore, The Road Map to Software 
Engineering: A Standards-Based Guide, 
1st ed. Hoboken, NJ: Wiley-IEEE 
Computer Society Press, 2006.
[6]   S.P. Berczuk and B. Appleton, 
Software Configuration Management 
Patterns: Effective Teamwork, 
Practical Integration: Addison-Wesley 
Professional, 2003.
[7] CMMI for development, Ve r s ion   2 . 0 ,  
CMMI Institute, 2018.
[8]   B. Aiello and L.A. Sachs, Configuration 
management best practices: Practical 
methods that work in the real world (1st 
edition), 2011.

9-1 
CHAPTER 09
Software Engineering 
Management
ACRONYMS
PMBOK
®
  
Guide 
Guide to the Project Management 
Body of Knowledge
SDLCSoftware development life cycle
SEMSoftware engineering 
management
SQASoftware quality assurance
SWXSoftware Extension to the 
PMBOK
®
 Guide 
WBSWork breakdown structure
PSMPractical Software and Systems 
Measurement
MBSEModel-Based System Engineering
INTRODUCTION
Software  engineering  management  (SEM)  
can be defined as a collection of work activi-
ties involved with planning, estimating, mea-
suring, controlling, coordinating, leading and 
managing risk factors for a software project to 
help  ensure  that  software  products  and  soft-
ware  engineering  services  are  delivered  effi-
ciently,  effectively  and  to  the  stakeholders’  
benefit  [3].  Although  project  management  
and   measurement   management   are   often   
seen  as  separate  areas,  and  each  possesses  
many unique attributes, the close relationship 
between  the  two  has  led  to  their  combined  
treatment in this knowledge area (KA). 
In  one  sense,   it   should   be   possible   to   
manage a software engineering project in the 
same  way  other  complex  endeavors  are  man-
aged,  using  models,  technical  processes  and  
problem-solving  styles  as  other  engineering  
projects do. However, software engineers use 
different process models, technical processes, 
and  problem-solving  styles  than  other  engi-
neers,  making  these  choices  based  on  their  
education  and  experience  and  on  the  differ-
ences  between  physical  and  software  attri-
butes.  Software  system  elements  are  logical  
constructions  expressed  in  algorithmic  form,  
while  physical  system  elements  are  realized  
in mechanical, electrical, chemical, biological 
and  other  physical  media.  Software  is  intan-
gible because it has no physical properties and 
is malleable because of the relative ease with 
which  code  can  be  modified.  Obtaining  the  
desired  effect  by  modifying  software  code  
might  not  be  easy,  but  code  modifications,  
per se, are straightforward compared with the 
modification  of  physical  elements  that  have  
already been constructed [12].
As  software  and  software-embedded  sys-
tems become bigger, more complex, and more 
intertwined,  software  engineering  manage-
ment  and  engineering  roles  are  evolving  in  
response   [10],   because   skilled   individuals   
must actively develop and maintain these sys-
tems.  Consider  the  following:  hardware  is  
different from software (and not all software 
is  the  same).  Hardware  can  be  developed,  
procured, and maintained in a linear fashion. 
Software is an enduring capability that must 
be   supported   and   continuously   improved   
throughout  its  life  cycle  [13].  Furthermore,  
the  malleable  nature  of  software  allows  iter-
ation among and interleaving of the develop-
ment phases (to a much greater degree than is 
possible when developing physical artifacts).
Software is made by people and for people, 
so  digital  talent  matters.  Software  projects  
are increasingly important, and their ongoing 
success  largely  depends  on  people  with  the  
right skills, knowledge and abilities. This fact 

9-2   SWEBOK
®
 GUIDE V4.0
is essentially actual and necessary but not suf-
ficient.  Other  human  factors  may  affect  the  
project’s  success.  During  the  software  devel-
opment  lifecycle,  it  is  impossible  to  separate  
the  human  factors  from  the  technical  ones.  
Therefore,   people   management   activities,   
such as team and teamwork, leadership, com-
munication,  and  coordination  activities,  are  
important to project success.
Software reuse can be a key factor in main-
taining   and   improving   productivity   and   
competitiveness.
Factors  such  as  cultural  differences  and  
diverse   attitudes   may   affect   the   develop-
ment team. A significant number of software 
projects  failed  due  to  social  issues.  A  “high  
quality”   developer   can   produce   inappro-
priate  or  poor  quality  products  that  require  
rework if presented with poor requirements or 
communication.
Other issues can complicate effective man-
agement of software projects and software life 
cycle processes, including the following:
•    Clients often do not know what is needed 
or what is feasible.
•    Increased  understanding  and  changing  
conditions  will  likely  generate  new  or  
changed software requirements.
•    Clients often do not appreciate the com-
plexities   inherent   in   software   engi-
neering,     particularly     regarding     the     
impact of changing requirements.
•    As a result of changing requirements and 
software  malleability,  software  is  often  
built  iteratively  rather  than  as  a  linear  
sequence of phases.
•    Software is nominally an enduring capa-
bility that must be supported and contin-
uously improved throughout its lifecycle. 
•    Software construction differs from hard-
ware  implementation  in  that  design  is  
usually   part   of   software   construction,   
whereas  in  hardware-oriented  systems,  
design  precedes  hardware  implementa-
tion to “get it right” prior to procurement 
or fabrication of hardware
 
[1 2].
•    Software engineering necessarily incorpo-
rates creativity and discipline. Maintaining 
an appropriate balance between the two is 
sometimes difficult [5].
•    The development of software capabilities 
often  involves  a  high  degree  of  novelty  
and complexity.
•    Typically, the underlying technology has 
a high rate of change.
•    Computer  software  has  become  a  key  
component   of   most   modern   systems.   
Software  has  been  elevated  to  a  highly  
prominent  role  because  of  its  flexibility  
and  relatively  low  replication  cost  com-
pared with hardware.
•    A significant number of software projects 
failed due to human issues. Physical mea-
surement  units  such  as  the  length  and  
weight measures are challenging to apply 
to  the  software.  This  difficulty  impacts  
how  to  plan,  monitor,  and  control  soft-
ware development projects. 
•    Software  rework  to  remove  faults  and  
respond to change. 
•    Speed and cycle time are important met-
rics   for   managing   software.   Software   
capabilities    are    often    delivered    at    
increasing  speed  to  satisfy  business  and  
mission needs [13].
SEM activities occur on three levels: orga-
nizational  and  infrastructure  management,  
project management, and management of the 
measurement program. The last two are cov-
ered in detail in this KA description. This fact 
does not diminish the importance of organiza-
tional  and  infrastructure  management  issues  
but rather points out that software organiza-
tional  engineering  managers  should  be  con-
versant  with  the  project  management  and  
software  measurement  knowledge  described  
in  this  KA.  They  should  also  possess  some  
target  domain  knowledge.  Likewise,  it  also  
helps  for  managers  of  complex  projects  and  
programs where software is part of the system 
architecture  to  know  what  issues  software  
engineering  processes  (versus  other  types  of  
engineering processes)  introduce  into  project  
management and project measurement. 
Other   aspects   of   organizational   man-
agement  affect  software  engineering  —  for  

SOFTWARE ENGINEERING MANAGEMENT   9-3
example,  organizational  policies  and  proce-
dures that provide the framework for software 
engineering  projects.  These  policies  and  pro-
cedures  might  need  to  be  adjusted  for  effec-
tive  software  development  and  maintenance  
requirements.   In   addition,   several   policies   
specific  to  software  engineering  might  need  
to  be  in  place  or  established  for  the  effective  
management  of  software  engineering  at  the  
organizational level. For example, policies are 
usually  necessary  to  establish  specific  organi-
zation-wide  processes  or  procedures  for  soft-
ware engineering tasks such as software design, 
software construction, estimating, monitoring 
and reporting. Such policies are important for 
effective  long-term  management  of  software  
engineering  projects  across  an  organization  
(e.g.,  one  such  policy  could  establish  a  con-
sistent basis for analyzing past project perfor-
mance and implementing improvements).
Another   important   aspect   of   organiza-
tional  management  is  the  use  of  personnel  
management   policies   and   procedures   for   
hiring,  training  and  mentoring  —  not  only  
for  a  project’s  success,  but  also  for  the  orga-
nization’s  long-term  success.  Given  the  pro-
jected  scarcity  of  skilled  software  engineers,  
it is important to provide an environment that 
attracts  and  retains  good  talent.  Software  
engineering   personnel   can   present   unique   
training   or   personnel   management   chal-
lenges (e.g., maintaining currency in a context 
where  the  underlying  technology  undergoes  
rapid and continuous change) as part of career 
development. 
Communication management is also often 
mentioned  as  an  overlooked  but  important  
aspect  of  success  in  a  field  where  a  pre-
cise  understanding  of  user  needs,  software  
requirements  and  software  designs  is  nec-
essary.    Furthermore,    portfolio    manage-
ment  is  desirable,  which  provides  an  overall  
view  of  software  under  development  in  var-
ious  projects  and  programs  (integrated  proj-
ects)  of  planned  software,  and  of  software  
already in use in an organization. Also, soft-
ware reuse can be a key factor in maintaining 
and improving productivity and competitive-
ness. Effective reuse requires a strategic vision 
that reflects the advantages and disadvantages 
of reuse. 
Software  engineers  should  have  a  sound  
understanding of the aspects of management 
that are unique to software projects, and they 
should also have some knowledge of the more 
general   aspects   of   management   discussed   
in  this  KA  (even  in  the  first  few  years  after  
graduation).
Certain  attributes  of  organizational  cul-
ture  and  behavior,  as  well  as  management  of  
functional areas of the enterprise outside the 
immediate  software  engineering  realm,  can  
influence   an   organization’s   software   engi-
neering  processes,  albeit  indirectly.  Software  
projects  are  often  targeted  at  changing  the  
way people work — but culture change is dif-
ficult,  complicated  and  unlikely  to  succeed  
without  a  significant  effort.  For  this  reason,  
leadership  is  an  important  attribute  for  pro-
gram  managers,  as  they  often  need  to  lead  
the  charge  for  digital  transformation.  They  
might need to galvanize their teams and other 
stakeholders to bring their very best to every 
project pursuing major change.
Extensive  information  concerning  project  
management  can  be  found  in  the  Guide  to  
the   Project   Management   Body   of   Knowledge   
(PMBOK
® 
Guide fifth edition) and the Software 
Extension  to  the  PMBOK
® 
Guide (SWX)  [1,  
2].  Each  of  these  guides  includes  10  project  
management  KAs:  project  integration  man-
agement,  project  scope  management,  project  
time/schedule management, project cost man-
agement, project quality management, project 
resource/human management,  project  com-
munications  management,  project  risk  man-
agement,  project  procurement  management  
and  project  stakeholder  management.  Each  
KA has direct relevance to this SEM KA. 
Additional information is also provided in this 
KA’s references and list of Further Readings.
This   SEM KA   discusses   the   software   
project  management  processes  shown  as  the  
first  five  topics  in  Figure  9-1  (Initiation  and  
Scope Definition, Software Project Planning, 
Software   Project   Enactment,   Review   and   
Evaluation,   Closure),   as   well   as   Software   
Engineering  Measurement  (the  sixth  topic  

9-4   SWEBOK
®
 GUIDE V4.0
shown in the figure) and Software Engineering 
Management Tools (the seventh topic). 
Unfortunately,  a  common  perception  of  
the  software  industry  is  that  software  prod-
ucts often are delivered late, are over budget, 
are   of   poor   quality   and   have   incomplete   
functionality.  Measurement-informed  man-
agement — a basic principle of any true engi-
neering  discipline  (see  Measurement  in  the  
Engineering  Foundations  KA)  —  can  help  
improve  perception  and  reality.  In  essence,  
management  without  measurement  (qualita-
tive and quantitative) suggests a lack of disci-
pline, and measurement without management 
suggests  a  lack  of  purpose  or  context.  To  be  
effective,  software  engineers  must  use  both  
measurement and management.
The   following   working   definitions   are   
adopted here:
• Management is a system of processes and 
controls required to achieve the strategic 
objectives set by the organization. 
• Measurement refers   to   the   assignment   
of  values  and  labels  to  software  engi-
neering   work   products,   processes   and   
resources,  plus  the  models  derived  from  
them,  whether  these  models  are  devel-
oped using statistical or other techniques 
[3*, c7, c8].
The  software  engineering  project  manage-
ment  sections  in  this  KA  use  the  Software  
Engineering Measurement section extensively.
This  KA  is  closely  related  to  others  in  the  
SWEBOK  Guide;  reading  the  following  KA  
descriptions  will  be  particularly  helpful  in  
understanding this one: 
•    The Engineering Foundations KA describes 
some  general  measurement  concepts  that  
directly apply to the Software Engineering 
Measurement  section  of  this  KA.  In  addi-
tion,   the   concepts   and   techniques   pre-
sented in the Statistical Analysis section of 
the  Engineering  Foundations  KA  apply  
directly to many topics in this KA.
•    The Software Requirements KA describes 
activities    that    should    be    performed    
during  the  project’s  Initiation  and  Scope  
Definition phase.
•    The Software Configuration Management 
KA deals with the identification, control, 
status  accounting  and  auditing  of  soft-
ware  configurations,  along  with  software  
release   management   and   delivery   and   
software configuration management tools. 
•    The  Software  Engineering  Process  KA  
describes  software  life  cycle  models  and  
the  relationships  between  processes  and  
work products.
Software Engineering 
Management
Initiation 
and Scope 
Definition
Software 
Engineering
Measurement
Determination 
and Negotiation 
of Requirements
Feasibility
Analysis
Process for the
Review and 
Revision of
Requirements
Process
Planning
Determine
Deliverables
Effort, 
Schedule,
and Cost 
Estimation
Implementation
of Plans
Software 
Acquisition 
and Supplier 
Contract
Management
Implementation 
of Measurement
Process
Monitor Process
Control Process
Reporting
Determine
Satisfaction of
Requirements
Reviewing
and Evaluating
Performance
Determine
Closure
Closure
Activities
Establish 
and Sustain
Measurement
Commitment
Plan the 
Measurement
Process
Perform the 
Measurement
Process
Evaluate
Measurement
Software 
Project 
Planning
Software 
Project 
Enactment
Software
Review and 
Evaluation
Closure
Software 
Engineering
Management 
Tools
Figure 9.1. Breakdown of Topics for the Software Engineering Management KA

SOFTWARE ENGINEERING MANAGEMENT   9-5
•    The   Software   Quality   KA   emphasizes   
quality as a management goal and as an aim 
of many software engineering activities.
•    The   Software   Engineering   Economics   
KA  discusses  how  to  make  software-re-
lated decisions in a business context. 
BREAKDOWN OF TOPICS FOR 
SOF TWARE ENGINEERING 
MANAGEMENT 
Because most software development life cycle 
(SDLC) models require similar activities that 
may  be  executed  in  different  ways,  the  topic 
breakdown,  shown  in  Figure  9-1,  is  activi-
ty-based.  The  top-level  elements  shown  in  
the  figure  are  activities  that  are  usually  per-
formed when a software development project 
is being managed, regardless of which SDLC 
model is being used (see Software Life Cycle 
Models in the Software Engineering Process 
KA).  This  breakdown  does  not  recommend  
a  specific  life  cycle  model.  However,  it  is  
important  to  note  the  choice  of  the  SDLC  
can  have  a  impact  on  program  activities  to  
accommodate changing requirements.
Delivery speed, continuous adaptation and 
frequent  modular  upgrades  to  deliver  new  
capabilities  are  often  key  business  differenti-
ators and project management imperative [11, 
13].  These  imperatives  should  be  balanced  
with risk management activities.
Several  software  life  cycle  process  models  
have been and are being developed to shorten 
development  cycles  in  response  to  changing  
business  needs,  specifically,  changing  soft-
ware   requirements.   Most   of   these   pro-
cesses  involve  Agile  SDLC  approaches  [14].  
The  Agile  approach  assumes  that  teams  can  
develop    high-quality,    adaptive    software    
using  continuous  design  improvement  prin-
ciples  and  testing  based  on  rapid  feedback  
and  change.  In  comparison,  the  traditional  
approach assumes that software-intensive sys-
tems are fully specifiable and predictable and 
can  be  built  through  meticulous  and  exten-
sive  planning.  The  management  style  asso-
ciated  with  the  Agile  approach  emphasizes  
leadership and collaboration at the team level, 
whereas  the  management  style  of  the  highly  
predictive   approach   is   more   formal   (top-
down). Many Agile approaches integrate dif-
ferent management approaches.
 
For  example,  Dev/Sec/Ops  is  a  culture  
and  an  Agile  approach  to  modern  software  
delivery that aligns development (Dev), secu-
rity (Sec) and operations (Ops) groups into an 
integrated team focused on continuous, incre-
mental delivery of capabilities. The main char-
acteristic of Dev/Sec/Ops is that this approach 
automates, continuously monitors and applies 
security at all phases of the software life cycle: 
plan,   develop,   build,   test,   release,   deliver,   
deploy,  operate  and  monitor.  In  Dev/Sec/
Ops,  testing  and  security  are  shifted  to  the  
left through automated unit, functional, inte-
gration  and  security  testing.  This  is  a  key  
Dev/Sec/Ops  differentiator;  security/quality  
assurance   (QA)   and   other   nonfunctional   
and   functional   capabilities   are   tested   and   
built  simultaneously  [11,  14].  Whereas  Dev/
Sec/Ops  encompasses  the  culture  and  pro-
cesses  that  enable  rapid,  continual  delivery  
of   cyber-resilient   systems,   complex   soft-
ware-embedded  systems  can  have  additional  
demands  that  must  also  be  integrated  into  
the  Dev/Sec/Ops  culture  and  processes,  such  
as  safety.  Elevating  these  demands  to  be  on  
par  with  Dev/Sec/Ops  highlights  the  impor-
tance of incorporating quality into all program 
aspects.  The  complexity  of  the  end-to-end  
DevSecOps tools and of using emerging tech-
nologies such as artificial intelligence (AI) and 
machine learning (ML) to leverage those tools 
adds  another  dimension  [15].  For  example,  
Agile and DevOps approaches are reasonably 
well-established, but in case of AI-based soft-
ware, new SLDCs maybe required to manage 
the complexity brought by AI to the software.
It  is  important  to  understand  the  differ-
ence  between  phases  and  activities  and  why  
an  activities  breakdown  is  used.  The  Project  
Management   Institute   (PMI)   describes   a   
phase this way:  “The completion and approval 
of  one  or  more  deliverables  characterizes  a  
project  phase.” A deliverable  is  a  measurable,  
verifiable work product such as a specification, 

9-6   SWEBOK
®
 GUIDE V4.0
feasibility study report, detailed design docu-
ment or working prototype. Some deliverables 
correspond to part of the project management 
process,  whereas  others  are  the  end  products  
or components of the end products for which 
the  project  was  conceived.  The  deliverables,  
and  hence  the  phases,  are  part  of  a  generally  
sequential  process  designed  to  ensure  proper  
control of the project and to attain the desired 
product or service, which is the project’s objec-
tive. From a project management perspective, 
phases help accomplish project objectives and 
maintain control over the project. 
The  activity-based  breakdown  in  Figure  
9-1  shows  what  happens  but  does  not  imply  
when,  how  or  how  many  times  each  activity  
occurs. The seven topics are the following:
•    Initiation  and  Scope  Definition,  which  
deals  with  the  decision  to  embark  on  a  
software engineering project
•    Software     Project     Planning,     which     
addresses the activities undertaken to pre-
pare  for  a  successful  software  engineering  
project from the management perspective
•    Software Project Enactment, which deals 
with  generally  accepted  SEM  activities  
that occur during a software engineering 
project’s execution
•    Review and Evaluation, which deals with 
ensuring  that  technical,  schedule,  cost  
and   quality   engineering   activities   are   
satisfactory 
•    Closure,  which  addresses  the  activities  
accomplished to complete a project
•    Software    Engineering    Measurement,    
which  deals  with  the  effective  develop-
ment  and  implementation  of  measure-
ment  programs  in  software  engineering  
organizations
•    Software     Engineering     Management     
Tools,  which  describes  the  selection  and  
use  of  tools  for  managing  a  software  
engineering project
1. Initiation and Scope Definition 
Project  initiation  focuses  on  reviewing  the  
software  requirements  and  determining  the  
need, scope, feasibility, and authorization for 
a software project Once project feasibility has 
been  established,  the  remaining  tasks  in  this  
section  are  specifying  the  software  require-
ments and selecting the processes for require-
ments revision and review. 
1.1.  Determination and Negotiation of 
Requirements  [3*, c3]
Determining   and   negotiating   the   project   
requirements  are  the  overarching  goals  of  
the  tasks  undertaken  during  this  phase  (see  
the Software Architecture KA and Software 
Requirements KA). Activities should include 
software  requirements  review  (e.g.,  elicita-
tion,  analysis,  specification,  and  validation).  
Methods  and  techniques  should  be  selected  
and  applied  considering  the  various  stake-
holder perspectives. Requirements provide the 
basis for all that follows on a software project 
and are captured in a Project Charter or other 
high-level project initiation document. 
1.2.  Feasibility Analysis  [4*, c5]
The  purpose  of  the  feasibility  analysis  is  to  
develop  a  clear  description  of  project  objec-
tives and to evaluate alternative approaches to 
determine whether the proposed project solu-
tion is the best approach, given the constraints 
of technology, resources, finances and changes 
to ethical, environmental, and socio-technical 
considerations. An initial project and product 
scope  statement,  project  deliverables,  project  
duration  constraints,  and  an  estimation  of  
resources needed should be prepared.
Resources (which can be internal or external 
to  the  organization)  include  infrastructure,  
support,  and  people  with  the  necessary  core  
competencies.  The  feasibility  analysis  often  
requires  estimations  of  effort  and  cost  based  
on  appropriate  methods.  (See  Section  2.3,  
Effort, Schedule and Cost Estimation.) 
An   initial   work   breakdown   structure   
(WBS)  and  context  diagram  may  be  devel-
oped during the project’s Initiation and Scope 
Definition  phase  activities.  Breaking  work  
into  smaller  tasks  is  a  common  productivity  

SOFTWARE ENGINEERING MANAGEMENT   9-7
technique  that  makes  the  work  more  man-
ageable   and   approachable.   As   the   project   
tool  that  uses  this  technique,  WBS  is  an  
important   project   management   document.   
While  a  WBS  can  be  used  to  organize  cost  
and  schedule  tracking,  the  WBS  does  not  
itself  include  cost  and  schedule  baselines.    
Schedules  are  developed  as  part  of  the  next  
activity, project planning (section 2).
An  engineering  context  diagram  defines  
the  boundary  between  the  system  (or  a  part  
of  the  system)  and  its  environment,  showing  
the entities interacting with it. This document 
is  important  in  defining  management  and  
technical  interfaces  and  trade-offs  that  must  
be considered [1]. While engineers are devel-
oping the WBS, they should consider all con-
figuration items as tasks to have under control.
1.3.  Process for the Review and Revision of 
Requirements  [3*, c3]
Given  the  inevitability  of  change,  stake-
holders  should  agree  on  how  requirements  
and scope will be reviewed and revised (e.g., 
change  management  and  trade-off  proce-
dures,  iterative  cycle  retrospectives).  (See  
the Requirements KA.)  This indicates that 
scope  and  requirements  will  not  be  “set  in  
stone”  but  can  and  should  be  revisited  at  
predetermined points as the project unfolds 
(for example, at the time when backlog pri-
orities  are  created  or  at  milestone  reviews).  
If  changes  are  accepted,  then  forward  or  
backward traceability analysis and risk anal-
ysis  should  be  used  to  ascertain  the  impact  
of  those  changes.  For  example,  backward  
traceability  may  link  the  test  script  to  its  
associated   requirement   and   design.   This   
link  helps  monitor  the  status  of  require-
ments  satisfaction  and  helps  make  deci-
sions to stop testing. It also helps in making 
tradeoffs     regarding     requirements     and     
design. (See Section 2.5, Risk Management, 
and Software Configuration Control in the 
Software Configuration Management KA.) 
A managed-change approach can also form 
the basis for evaluating success during closure 
of  an  incremental  cycle  or  an  entire  project,  
based on changes that occurred along the way. 
(See Topic 5, Closure).
2. Software Project Planning
A key step in software project planning should 
be selecting an appropriate SDLC model and, 
perhaps,  tailoring  it  based  on  project  scope,  
software   requirements   and   a   risk   assess-
ment.  The  SWX  [2] states  that  project  life  
cycles occupy a continuum from predictive to 
adaptive.  Factors  that  characterize  the  posi-
tions  of  software  project  life  cycles  within  
the  continuum  include  (but  are  not  limited  
to)  the  various  ways  requirements  and  plans  
are handled, how risk and cost are managed, 
and key stakeholder involvement. Highly pre-
dictive software project life cycles emphasize 
requirements specification and detailed plan-
ning during the project’s initiation and plan-
ning phases. Detailed plans based on a known 
architecture, requirements and constraints are 
used  to  reduce  risk  and  cost.  Milestones  are  
planned,  versus  continuous  key  stakeholder  
involvement. Highly adaptive software project 
life  cycles,  on  the  other  hand,  are  character-
ized by progressive requirements specification 
based  on  short  iterative  development  cycles.  
Risk and cost are reduced by progressive evo-
lution  of  initial  plans,  and  key  stakeholders  
are continuously involved [2].
Other   factors   to   consider   include   the   
nature   of   the   application   domain,   func-
tional and technical complexity, and software 
quality  requirements.  (See  Software  Quality  
Requirements in the Software Qua lit y K A.) 
In  all  SDLCs,  risk  assessment  should  be  
an  element  of  initial  project  planning,  and  
the “risk profile” of the project should be dis-
cussed  and  accepted  by  all  relevant  stake-
holders.    Software    quality    management    
processes (see Software Quality Management 
Processes   in   the   Software   Quality   KA)   
should  be  planned  along  with  project  plan-
ning.    This  planning  should  establish  proce-
dures and responsibilities for software quality 
assurance   (SQA),   verification   and   valida-
tion,  reviews,  and  audits.  (See  the  Software  
Quality  KA.)  Processes  and  responsibilities  

9-8   SWEBOK
®
 GUIDE V4.0
for ongoing review and revision of the project 
plan and related plans should also be clearly 
stated and agreed upon.
2.1.  Process Planning 
  [3*, c3, c4, c5], [5*, c1]
SDLC  models  span  a  continuum  from  pre-
dictive to adaptive. (See Software Life Cycle 
Models in the Software Engineering Process 
KA.) Predictive SDLCs are characterized by 
the  development  of  detailed  software  archi-
tecture  and  software  requirements,  detailed  
project   planning,   and   minimal   planning   
for   iteration   among   development   phases.   
Adaptive  SDLCs  are  designed  to  accommo-
date   emergent   software   requirements   and   
iterative  adjustment  of  plans.  A  highly  pre-
dictive  SDLC  executes  the  first  five  pro-
cesses listed in Figure 9-1 in a linear sequence 
with  revisions  to  earlier  phases  only  as  nec-
essary.  Adaptive  SDLCs  are  characterized  
by  iterative  development  cycles.  SDLCs  in  
the  midrange  of  the  SDLC  continuum  pro-
duce  increments  of  functionality  on  either  a  
preplanned  schedule  (on  the  predictive  side  
of  the  continuum)  or  as  the  products  of  fre-
quently  updated  development  cycles  (on  the  
adaptive side of the continuum).
Well-known  SDLCs  include  the  water-
fall, incremental and spiral models, plus var-
ious  Agile  software  development  approaches  
[2, 11] [3*, c2]. 
Relevant    methods    (see    the    Software    
Engineering  Models  and  Methods  KA)  and  
tools  should  be  selected  as  part  of  planning.  
Automated tools that will be used throughout 
the  project  should  also  be  planned  for  and  
acquired.   Tools   might   include   those   for   
project   scheduling,   software   requirements,   
software design, software construction, soft-
ware   maintenance,   software   configuration   
management,  software  engineering  process  
and software quality, among others. Many of 
these tools should be selected based primarily 
on  the  technical  considerations  discussed  in  
other  KAs,  but  some  of  those  concerns  are  
closely  related  to  the  management  consider-
ations discussed in this chapter. 
2.2. Determine Deliverables 
 [3*, c4, c5, c6]
Each  project  activity’s  work  product(s)  (e.g.,  
software    architecture    design    documents,    
inspection reports, tested software) should be 
identified and characterized. Opportunities to 
reuse software components from previous proj-
ects or to use off-the-shelf software products 
should  be  evaluated.  Software  procurement  
and  use  of  third  parties  to  develop  delivera-
bles should be planned and suppliers selected. 
(See  Section  3.2,  Software  Acquisition  and  
Supplier Contract Management.) 
2.3. Effort, Schedule, and Cost Estimation
The topic of estimation in general is addressed 
in the Software Engineering Economics KA. 
Questions  like  “What  is  estimation?”  and  
“Why  do  we  estimate?”  are  addressed  there.  
This  section  addresses  management-specific  
estimation topics.
Estimating costs for software projects is an 
error-prone process. The effort required for any 
given software project depends almost entirely 
on  human  elements:  individuals’  experience  
and  capabilities,  team  members’  interactions,  
and  the  culture  of  the  software  development  
environment. Dynamic environmental factors, 
such  as  rapid  technology  evolution,  changing  
and emergent requirements, and the intangible 
nature of the product, also significantly affect 
cost management. Estimating costs when this 
much  variability  exists  is  difficult  even  when  
significant   historical   data   exists.   Software   
project managers should use multiple estima-
tion approaches and then reconcile the differ-
ences among the estimates [3, 10, 11].
When data is available, the estimated range 
of  effort  required  for  a  project,  or  parts  of  a  
project, can be determined using a calibrated 
estimation model based on historical size and 
effort  data.  It  is  best  to  also  use  bottom-up  
estimation   techniques   based   on   estimates   
from those who will accomplish the work and 
historical  data  based  on  similar  projects
 
[2]. 
Task  dependencies  can  be  established,  and  
potential  opportunities  for  completing  tasks  

SOFTWARE ENGINEERING MANAGEMENT   9-9
concurrently  and  sequentially  can  be  identi-
fied  and  documented,  using  a  Gantt  chart,  
for  example.  In  predictive  SDLC  projects,  
the expected schedule of tasks, with projected 
start  times,  durations  and  end  times,  is  typ-
ically  produced  during  planning.  In  adaptive  
SDLC  projects,  an  overall  estimate  of  effort  
and  schedule  is  typically  developed  from  the  
initial understanding of the requirements, or, 
alternatively, constraints on overall effort and 
schedule may be specified and used to deter-
mine an initial estimate of the number of iter-
ative cycles and estimates of effort and other 
resources allocated to each cycle. 
Resource     requirements     (for     example,     
people   and   tools   needed)   can   usually   be   
translated  into  cost  estimates.  The  estima-
tion  of  effort,  schedule  and  cost  is  an  itera-
tive  activity  that  should  be  negotiated  and  
revised   among   affected   stakeholders   until   
consensus  is  reached  on  resources  and  time  
available   for   project   completion.   Program   
managers  often  use  a  model  that  links  four  
association  role  types:  responsible,  account-
able,  consulted,  and  informed  (i.e.,  RACI)  to  
facilitate  this  process.  Responsible  roles  pro-
duce   deliverables;   accountable   roles   check   
the   deliverables;   consulted   roles   advise   on   
tasks;  and  informed  roles  are  kept  informed  
throughout these processes.  Project managers 
should constantly monitor stakeholder require-
ments  and  changes  as  they  evolve  to  analyze  
their impact on the project cost and schedule. 
This  is  usually  more  important  in  Agile  soft-
ware  development  projects,  where  stakeholder  
requirements  are  dynamic  because  changes  
might occur rapidly as the project progresses.
2.4. Resource Allocation  [3*, c5, c10, c11]
Equipment,  facilities  and  people  should  be  
allocated  to  the  identified  tasks,  including  
allocating responsibilities for completing var-
ious project elements and the overall project. 
A  matrix  that  shows  who  is  responsible  for,  
accountable for, consulted about and informed 
about  each  task  can  be  used.  Resource  allo-
cation  is  based  on  and  constrained  by  the  
availability  of  resources  and  their  optimal  
use,  and  by  issues  relating  to  personnel  (e.g.,  
productivity  of  individuals  and  teams,  team  
dynamics, and team structures). 
2.5. Risk Management  [3*, c9] [5*, c5]
Risk  and  uncertainty  are  related  but  distinct  
concepts.  Uncertainty  results  from  a  lack  of  
information.  Risk  is  effect  of  uncertainty  on  
objectives that has negative (threats) or positive 
(opportunities) consequences on objectives.
Risk  management  entails  identifying  risk  
factors,  analyzing  probability  and  potential  
impact  of  each  risk  factor,  prioritizing  risk  
factors,  and  developing  risk  mitigation  strat-
egies  to  reduce  the  probability  of  a  negative  
event and to minimize the negative impact if 
a  risk  factor  becomes  a  problem.  Risk  man-
agement  data  can  be  used  to  represent  the  
project  risk  profile;  this  data  is  often  part  of  
a  risk  register.  A  risk  register  is  a  document  
used as a risk management tool. It can be used 
to  fulfill  regulatory  compliance,  serving  as  a  
repository for all risks identified and for addi-
tional  information  about  each  risk  [2].  Risk  
assessment  methods  (e.g.,  expert  judgment,  
historical  data,  decision  trees  and  process  
simulations)  can  sometimes  be  used  to  iden-
tify and evaluate risk factors. 
Project  abandonment  conditions  can  also  
be determined with all relevant stakeholders. 
Software-unique aspects of risk, such as soft-
ware  engineers’  tendency  to  add  unneeded  
features  or  the  risks  related  to  software’s  
intangible  nature,  can  influence  risk  man-
agement   for   software   projects.   Particular   
attention  should  be  paid  to  managing  risks  
related to software quality requirements such 
as  safety  or  security  [11].  (See  the  Software  
Quality  KA.)  Risk  management  should  be  
done  not  only  at  the  beginning  of  a  project,  
but  also  at  periodic  intervals  throughout  the  
project life cycle.
2.6. Quality Management  
 [3*, c4] [4*, c2]
According  to  the  PMBOK®  Guide,  Project  
quality management includes the performing 

9-10   SWEBOK
®
 GUIDE V4.0
organization’s  processes  and  activities  that  
determine  quality  policies,  objectives  and  
responsibilities  so  the  project  will  satisfy  
the needs for which it was undertaken. This 
section  discusses  additional  considerations  
for  managing  software  project  quality  [1].  
Software  quality  requirements  for  a  soft-
ware project and the associated work prod-
ucts   should   be   identified,   perhaps   both   
quantitatively   and   qualitatively.   Quality   
attributes  of  software  include  but  are  not  
limited to safety, security, reliability, avail-
ability, performance, ease of use and ease of 
modification. SWX Section 1.9 lists quality 
attributes  that  are  important  for  software  
users  (e.g.,  efficiency,  safety,  security,  reli-
ability,  availability)  and  quality  attributes  
that  are  important  to  software  developers  
and   maintainers   (e.g.,   maintainability   is   
important  to  those  who  provide  sustain-
ment  services)  [1].  ISO/IEC  25000  series  
of   standards   provides   extensive   lists   of   
software  quality  attributes  that  align  with  
different stakeholder needs [2]. This align-
ment  is  consistent  with  ISO/IEC/IEEE  
15939  and  practical  software  and  systems  
measurement (PSM) [2, 9.11].
Large portions of system functionality 
are shifting from hardware to software to 
capitalize on the increased f lexibility and 
speed  of  component  delivery  that  soft-
ware  can  provide.  However,  with  these  
benefits  come  other  challenges  —  for  
example,  the  need  for  increased  man-
agement   of   software   quality   require-
ments   (e.g.,   cybersecurity)   throughout   
the SDLC [11]. Thresholds for acceptable 
quality  measurements  should  be  set  for  
each  software  quality  requirement  based  
on stakeholder  needs  and  expectations.  
Procedures concerned with ongoing SQA 
and    quality    improvement    throughout    
the  development  process  and  with  veri-
fying and validating the deliverable soft-
ware  product  should  also  be  specified  
during  quality  planning  (e.g.,  technical  
reviews  and  inspections  or  demonstra-
tions  of  completed  functionality).  (See  
the Software Quality KA.) 
2.7. Plan Management  [3*, c4]
Except  for  older  predictive  programs,  doc-
umenting  and  managing  formal  plans  are  
becoming less emphasized in managing most 
software  projects.  (e.g.,  documentation  plans  
are rarely used, especially when Model-Based 
Systems  Engineering  (MBSE)  is  used  for  
product data). The said, where they are used, 
plans  should  be  developed  and  managed  for  
software  projects  when  change  is  expected.  
The magnitude of the planning effort and the 
plan’s  content  should  be  determined  partly  
by  the  risk  of  not  developing  the  plan.  The  
management of the project plan should itself 
be  planned.  Plans  and  processes  selected  for  
software  development  should  be  systemat-
ically   monitored,   reviewed,   reported   and,   
when  appropriate,  revised.  Plans  associated  
with  supporting  processes  (e.g.,  documenta-
tion,   software   configuration   management,   
and problem resolution) also should be man-
aged.  Reporting,  monitoring  and  controlling  
a project should fit within the selected SDLC 
and  the  realities  of  the  project.  Plans  should  
account  for  the  various  artifacts  that  will  be  
used to manage the project.
Project  managers  of  predictive  life  cycle  
software  projects  put  substantial  effort  into  
up-front development of the project plan and 
integration   of   subsidiary   plans   developed   
by  support  personnel  from  other  organiza-
tional units (e.g., estimation specialists in the 
Project Management Office (PMO)). 
In  other  types  of  programs  (e.g.,  adap-
tive  programs)  where  formal  plans  are  not  
usually  used,  the  emphasis  should  be  on  
selecting  and  retaining  project  information  
useful in project control and future projects, 
and establishing strategy, policies, and pro-
cedures. For example, in adaptive programs, 
managers  will  usually  spend  less  effort  up  
front on developing detailed scope, cost and 
schedule plans. But significant effort is typ-
ically  spent  defining  monitor  and  control  
processes, such as requirements traceability, 
to  ensure  coordination  among  the  project  
members or teams as the emerging plans are 
implemented [2]. 

SOFTWARE ENGINEERING MANAGEMENT   9-11
3. Software Project Execution
During   software   project   enactment   (also   
known  as  project  execution),  plans  are  imple-
mented,  and  the  processes  embodied  in  the  
plans  are  enacted.  Throughout,  there  should  
be a focus on adherence to the selected SDLC 
processes, with an overriding expectation that 
adherence  will  satisfy  stakeholder  require-
ments  and  achieve  the  project’s  objectives.  
Fundamental  to  enactment  are  the  ongoing  
management  activities  of  monitoring,  con-
trolling and reporting.
3.1.   Implementation of Plans  [4*, c2]
Project activities should follow the project plan 
and  supporting  plans.  Project  activities  use  
resources (personnel, technology and funding) 
and generate work products (software design, 
software code and software test cases).
3.2.   Software Acquisition and Supplier 
Contract Management  [3*, c3, c4]
Software  acquisition  and  supplier  contract  
management  concern  issues  involved  in  con-
tracting   with   customers   of   the   software   
development  organization  who  acquire  the  
deliverable  work  products  and  with  suppliers  
who  supply  products  or  services  to  the  soft-
ware engineering organization. 
Software  acquisition  is  common  practice  
in software development projects, with inte-
grated  development  environments  (IDEs)  
and   package   libraries   allowing   software   
engineers  to  acquire  third-party  libraries  
with  minimal  steps,  facilitating  the  assess-
ment    of    risk,    legality    and    suitability.    
However,  software  is  no  longer  exclusively  
acquired  as  a  shrink-wrapped  product  via  
a  complex  supply  chain  process  and  pur-
chasing  route.  The  ease  of  acquiring  soft-
ware   has   resulted   in   a   common   attack   
surface  and  led  to  security  vulnerabilities.  
Organizations  should  consider  introducing  
technical or procedural controls to minimize 
risk potentially exposed by unfiltered access 
to external library repositories.
The  different  software  acquisition  classes  
include   commercial   off-the-shelf   (COTS)   
software  —  an  existing  product  acquired  “as  
is” from another software vendor, with appli-
cable license terms; software developed exclu-
sively  for  the  organization  by  another  party  
—  typically  contracted  and  sometimes  a  cus-
tomization  of  COTS  software;  open  source  
software — nominally free, although the orga-
nization  may  purchase  enhanced  support  or  
maintenance  and  must  review  the  license  for  
restrictions  on  use;  customer  loaned  software  
—  typically  to  provide  simulation  or  integra-
tion with another system element; software as 
a service (SaaS) — which might include soft-
ware the organization rents to fulfill a partic-
ular need (for example, a cloud-based hosting, 
source control or development environment).
Software  projects  typically  use  different  
acquisition approaches to obtain the necessary 
software components. However, regardless of 
how  the  software  components  are  obtained,  
the following activities should be performed: 
verifying  that  each  component  is  complete,  
correct  and  consistent  concerning  the  archi-
tectural design and software requirements for 
that component; integrating the components; 
verifying  that  the  integrated  components  are  
correct,  complete  and  consistent  concerning  
the  architectural  design  and  the  software  
requirements;  and  validating  that  the  inte-
grated components will satisfy their intended 
purpose  when  used  in  their  intended  oper-
ating environment.
Different    acquisition    approaches    (for    
obtaining  software  components)  require  dif-
ferent  approaches  to  managing  the  project.  
For  example,  custom  development  requires  
detailed  planning  for  the  numbers  and  skills  
of  the  software  developers,  organizing  the  
development team(s), allocating requirements 
to the teams, specifying project metrics to be 
collected,  monitoring  progress,  and  applying  
corrective  actions  when  actual  progress  does  
not  agree  with  planned  progress.  Licensing  
components   involves   evaluating   candidate   
components;   selecting   appropriate   compo-
nents; and negotiating terms, conditions, and 
delivery dates for the selected components. 

9-12   SWEBOK
®
 GUIDE V4.0
This  might  involve  selecting  appropriate  
contracts, such as fixed price, time-and-mate-
rials, cost plus fixed fee, and cost-plus incentive 
fee. Agreements with customers and suppliers 
typically  specify  the  scope  of  work  and  the  
deliverables.  The  agreements  can  also  include  
special  clauses,  such  as  clauses  establishing  
penalties  for  late  delivery  or  no  delivery,  and  
intellectual  property  agreements  that  specify  
what  the  suppliers  are  providing  and  what  
the  acquirer  is  paying  for,  plus  what  will  be  
delivered  to  and  owned  by  the  acquirer.  For 
software  developed  by  suppliers  (both  those  
internal to and those external to the software 
development  organization),  agreements  com-
monly establish software quality requirements.
In   software   contracting   with   suppliers,   
data  set  acquisition  is  usually  important.  It  
includes   the   process   of   obtaining   specific   
datasets  from  external  vendors  or  partners  
as  part  of  a  software  development  project  or  
service  agreement.  This  can  occur  in  various  
scenarios, such as: date licensing agreements, 
data  provisioning,  custom  data  acquisition  
and data integration services.
After the agreement has been put in place, 
executing   the   project   in   compliance   with   
the  terms  of  the  agreement  should  be  man-
aged.  (See  Chapter  12,  Software  Extension  
to   the   PMBOK
® 
Guide (SWX),   Software   
Procurement  Management,  for  more  infor-
mation on this topic [2].) 
3.3.   Implementation of Measurement Process 
 [3*, c7]
The  measurement  process  should  be  enacted  
during  the  software  project  to  ensure  that  
relevant  and  useful  data  is  collected.  (See  
Sections 6.2, Plan the Measurement Process, 
and 6.3, Perform the Measurement Process.)
3.4.   Monitor Process  [3*, c8]
Adherence  to  the  scope,  project  plan  and  
related  plans  should  be  assessed  continually  
and  at  predetermined  intervals.  Outputs  and  
completion  criteria  for  each  task  should  also  
be assessed. Deliverables should be evaluated 
for their required characteristics (for example, 
via  inspections  or  by  demonstrating  working  
functionality).  Effort  expenditure,  schedule  
adherence,  costs  to  date,  and  resource  use  
should  be  analyzed.  The  project  risk  pro-
file   (see   Section   2.5,   Risk Management) 
should  be  revisited,  and  adherence  to  soft-
ware  quality  requirements  should  be  evalu-
ated  (see  Software  Quality  Requirements  in  
the Software Quality KA). 
Measurement   data   should   be   analyzed.   
(See  Statistical  Analysis  in  the  Engineering  
Foundations  KA.)  Variance  analysis  should  
be conducted to determine deviation of actual 
from expected outcomes and values. This anal-
ysis  might  examine  cost  overruns,  schedule  
slippage or other measures. Outlier identifica-
tion and analysis of quality and other measure-
ment  data  should  be  performed  (e.g.,  defect  
analysis). (See Software Quality Measurement 
in the Software Quality KA.) Risk exposures 
should be recalculated. (See Section 2.5, Risk 
Management.)   These   activities   can   enable   
problem detection and exception identification 
based on thresholds that have been exceeded. 
Outcomes  should  be  reported  as  necessary  
or  when  thresholds  have  been  exceeded.  For  
example, the timely identification, mitigation, 
and resolution of software security vulnerabil-
ities and weaknesses that exceed expectations 
can affect the system’s security posture [11].
3.5.   Control Process  [3*, c7, c8]
Project monitoring activities provide the basis 
for making decisions. Where appropriate, and 
when  the  probability  and  impact  of  risk  fac-
tors are understood, changes can be made to 
the  project.  This  may  take  the  form  of  cor-
rective action (e.g., retesting certain software 
components).  It  might  involve  incorporating  
additional  actions  (e.g.,  deciding  to  use  pro-
totyping  to  assist  in  software  requirements  
validation;  see  Prototyping  in  the  Software  
Requirements   KA).   It   might   also   entail   
revising  the  project  plan  and  other  project  
documents  (e.g.,  the  software  requirements  
specification)  to  accommodate  unanticipated  
events and their implications.

SOFTWARE ENGINEERING MANAGEMENT   9-13
In   some   instances,   the   control   process   
might  lead  to  abandonment  of  the  project.  
In  all  cases,  the  software  development  team  
should adhere to software configuration con-
trol  and  software  configuration  management  
procedures. (See the Software Configuration 
Management KA.) Decisions should be doc-
umented  and  communicated  to  all  relevant  
parties, plans should be revisited and revised 
when  necessary,  and  relevant  data  should  
be  recorded.  (See  Section  6.3,  Perform  the  
Measurement Process.) 
3.6.   Reporting  [3*, c11]
Progress  to  date  should  be  reported at  spec-
ified and agreed-upon times both within the 
organization  (e.g.,  to  a  project  steering  com-
mittee) and to external stakeholders (e.g., cli-
ents  or  users).  Reports  should  focus  on  the  
information   needs   of   the   target   audience   
as  opposed  to  the  detailed  status  reporting  
within the project team. 
4. Software Review and Evaluation
At prespecified times and as needed, overall 
progress  toward  the  stated  objectives  and  
satisfaction  of  stakeholder  (user  and  cus-
tomer)  requirements  should  be  evaluated.  
Similarly, assessments of the effectiveness of 
the software process, the personnel involved, 
and the tools and methods used should also 
be   undertaken   regularly   and   as   circum-
stances demand.
4.1.   Determining Satisfaction of Requirements 
 [4*, c8]
Achieving  stakeholder  satisfaction  is  a  prin-
cipal  goal  of  the  software  engineering  man-
ager.  Progress  toward  this  goal  should  be  
assessed   periodically.   Progress   should   be   
assessed   upon   achieving   a   major   project   
milestone  (e.g.,  completing  software  design  
architecture  or  completing  a  software  tech-
nical  review)  or  upon  completion  of  an  iter-
ative   development   cycle   that   results   in   a   
product  increment.  Variances  from  software  
requirements should be identified, and appro-
priate actions should be taken.
As in the control process activity above (see 
Section  3.5,  Control  Process),  software  con-
figuration control and software configuration 
management  procedures  should  be  followed  
(see the Software Configuration Management 
KA).  Decisions  should  be  documented  and  
communicated  to  all  relevant  parties;  plans  
should  be  revisited  and  revised  as  neces-
sary;  and  relevant  data  should  be  recorded  
(see  Section  6.3,  Perform  the  Measurement  
Process). 
4.2.   Reviewing and Evaluating Performance 
 [3*, c8, c10]
Periodic performance reviews for project per-
sonnel can provide insight into the likelihood 
of adherence to plans and processes and pos-
sible  areas  of  difficulty  (e.g.,  team  member  
conflicts).  The  various  project  methods,  tools  
and techniques should be evaluated for effec-
tiveness  and  appropriateness.  The  project’s  
process   should   also   be   systematically   and   
periodically assessed for relevance, utility and 
efficacy.  Where  appropriate,  project  changes  
should be made and managed. 
5. Closure
An  entire  project,  a  major  project  phase  or  
an  iterative  development  cycle  reaches  clo-
sure  when  all  the  plans  and  processes  have  
been  enacted  and  completed.  The  criteria  for  
project, phase or iteration success should then 
be  evaluated.  Once  closure  has  been  estab-
lished,   archival,   retrospective   and   process   
improvement activities can be performed.
5.1.   Determining Closure  [1, s3.7, s4.6]
Closure  occurs  when  the  specified  tasks  for  
a  project,  a  phase  or  an  iteration  have  been  
completed  and  satisfactory  achievement  of  
the  completion  criteria  has  been  confirmed.  
Software  requirements  can  be  confirmed  as  
satisfied  or  not,  and  the  degree  of  achieving  
the  objectives  can  be  determined.  Closure  

9-14   SWEBOK
®
 GUIDE V4.0
processes   should   involve   relevant   stake-
holders  and  document  relevant  stakeholders’  
acceptance;  any  known  problems  should  be  
documented. 
5.2.   Closure Activities  [2, s3.7, s4.8]
After  closure  has  been  confirmed,  project  
materials  should  be  archived  in  accordance  
with    stakeholder    agreed-upon    rules    for    
archival  methods,  location  and  duration  —  
possibly   including   destruction   of   sensitive   
information,  software  and  the  medium  on  
which copies are resident. For example, these 
rules could require that during closure, all data 
is  removed  and  destroyed  from  any  devices  
that   contain   relevant   information   before   
physical disposal of the devices (e.g., the hard 
drives  of  personal  computers,  servers,  main-
frames,  personal  digital  assistants  (PDAs),  
routers,  firewalls,  switches,  tapes,  diskettes,  
CDs,  DVDs,  cell  phones,  printers,  universal  
serial bus (USB) data storage devices). 
The  organization’s  measurement  database  
should be updated with relevant project data. 
A  project,  phase  or  iteration  retrospective  
analysis  should  be  undertaken  so  that  issues,  
problems,  risks  and  opportunities  encoun-
tered  can  be  analyzed.  (See  Topic  4,  Review  
and  Evaluation.)  Lessons  learned  should  be  
drawn from the project and fed into organiza-
tional learning and improvement endeavors. 
6. Software Engineering Measurement 
The importance of software engineering mea-
surement  for  good  management  and  engi-
neering   practices   is   widely   acknowledged.   
(See    Measurement    in    the    Engineering    
Foundations  KA.)  Effective  software  engi-
neering   measurement   has   become   one   of   
the  cornerstones  of  organizational  maturity.  
Measurement  can  be  applied  to  organiza-
tions,  projects,  processes  and  work  products.  
This  section  focuses  on  applying  measure-
ment  at  the  levels  of  projects,  processes  and  
work products.
1  These two chapters can be downloaded free of charge from http://www.psmsc.com/PSMBook.asp.
This    section    follows    ISO/IEC/IEEE    
15939  standard  [6],  which  describes  a  pro-
cess  to  define  the  activities  and  tasks  neces-
sary  to  implement  a  software  measurement  
process.  The  standard  also  includes  a  mea-
surement  information  model.  This  model  in  
the  PSM  Continuous  Iterative  Development  
Measurement Framework report is also elab-
orated for SDLC approaches [9].
6.1.   Establish and Sustain Measurement 
Commitment  [7*, c1, c2]
1
•    Establish   measurement   requirements.   
Each  measurement  endeavor  should  be  
guided by organizational objectives and 
driven by a set of measurement require-
ments  established  by  the  organization  
and  the  project  (e.g.,  an  organizational  
objective might be first to market).
•    Establish  the  scope  of  measurement.  
The  project  team  should  establish  the  
organizational unit to which each mea-
surement  requirement  is  to  be  applied.  
This   might   be   a   functional   area,   a   
single  project,  a  single  site  or  an  entire  
enterprise.  The  temporal  scope  of  the  
measurement effort should also be con-
sidered because the time series of some 
measurements  might  be  required  (e.g.,  
to  calibrate  estimation  models).  (See  
Section  2.3,  Effort,  Schedule  and  Cost  
Estimation.) 
•    Establish   the   team’s   commitment   to   
measurement.  The  commitment  should  
be  formally  established,  communicated  
and supported by resources.
•    Commit   measurement   resources. An 
organization’s   commitment   to   mea-
surement  is  an  essential  factor  for  suc-
cess, as evidenced by the assignment of 
resources  for  implementing  the  mea-
surement  process.  Assigning  resources  
includes  allocation  of  responsibility  for  
the  various  tasks  of  the  measurement  
process  (such  as  analyst  and  librarian).  
Adequate  funding,  training,  tools  and  

SOFTWARE ENGINEERING MANAGEMENT   9-15
support  to  conduct  the  process  should  
also be allocated. 
6.2.   Plan the Measurement Process  
 [7*, c1, c2]
1
•    Characterize the organizational unit. The 
organizational  unit  provides  the  context  
for  measurement,  so  the  organizational  
context  should  be  explicit,  including  the  
organization’s  constraints  on  the  mea-
surement  process.  The  characterization  
can  be  stated  in  terms  of  organizational  
processes,   application   domains,   tech-
nology,   organizational   interfaces   and   
organizational structure.
•     Identify information needs. Information 
needs  are  based  on  the  organizational  
unit’s goals, constraints, risks, and prob-
lems and  may  be  derived  from  business,  
organizational, regulatory and/or product 
objectives.  Stakeholders  should  identify,  
prioritize,  document,  communicate  and  
review these needs. 
•    Select  measures.  Select candidate  mea-
sures, with clear links to the information 
needs. Select measures based on the pri-
orities of the information needs and other 
criteria such as cost of collection; degree 
of  process  disruption  during  collection;  
ease   of   obtaining   accurate,   consistent   
data;  and  ease  of  analysis  and  reporting. 
Internal    quality    characteristics    (see    
Models  and  Quality  Characteristics  in  
the  Software  Quality  KA)  are  often  not  
contained  in  the  contractually  binding  
software  requirements.  Therefore,  con-
sider  measuring  the  software’s  internal  
quality  to  provide  an  early  indicator  of  
potential issues that might affect external 
stakeholders.
•    Define   data   collection,   analysis   and   
reporting  procedures.  This  encompasses  
collection    procedures    and    schedules,    
storage,  verification,  analysis,  reporting  
and data configuration management.
•    Select  criteria  for  evaluating  the  infor-
mation    products. The    organizational    
unit’s  technical  and  business  objectives  
influence evaluation criteria. Information 
products  include  those  associated  with  
the  product  produced  and  those  associ-
ated  with  the  processes  used  to  manage  
and measure the project.
•    Provide resources for measurement tasks. 
The    appropriate    stakeholders    should    
review   and   approve   the   measurement   
plan  to  include  all  data  collection  pro-
cedures;  storage,  analysis,  and  reporting  
procedures;   evaluation   criteria;   sched-
ules;   and   responsibilities.   Criteria   for   
reviewing these artifacts should be estab-
lished  at  the  organizational  unit  level  or  
higher and should be used as the basis for 
these  reviews.  Such  criteria  should  con-
sider experience, resource availability and 
potential  disruptions  to  projects  when  
changes  from  current  practices  are  pro-
posed.  Approval  demonstrates  commit-
ment to the measurement process.
o Identify  resources  to  be  made  avail-
able for implementing the planned and 
approved measurement tasks. Resource 
availability may be staged in cases where 
changes  are  piloted  before  widespread  
deployment.   Consider   the   resources   
necessary for successful deployment of 
new procedures or measures.
o Acquire  and  deploy  supporting  tech-
nologies.    This    includes    evaluating    
available     supporting     technologies,     
selecting  the  most  appropriate  tech-
nologies,  acquiring  those  technologies  
and deploying those technologies.
6.3.   Perform the Measurement Process  
 [7*, c1, c2]
Integrate  measurement  procedures  with  rel-
evant  software  processes.  The  measurement  
procedures,  such  as  data  collection,  should  
be integrated into the software processes they 
measure. This might involve changing current 
software processes to accommodate data col-
lection  or  generation  activities.  It  might  also  
involve  analyzing  current  software  processes  
to  minimize  additional  effort  and  evaluating  

9-16   SWEBOK
®
 GUIDE V4.0
the effect on employees to ensure acceptance 
of   the   measurement   procedures.   Consider   
morale  issues  and  other  human  factors.  In  
addition, communicate the measurement pro-
cedures to those providing the data. Training 
and support might also be needed. Data anal-
ysis  and  reporting  procedures  are  typically  
integrated  similarly  into  organizational  and  
project processes.
Collect  data.  Measurement  data  should  be  
collected  and  analyzed.  Data  should  be  col-
lected,   verified   and   stored.   Collection   can   
sometimes   be   automated   by   using   SEM   
tools   (see   Topic   7,   Software   Engineering   
Management   Tools)   to   analyze   data   and   
develop   reports. Data   may   be   aggregated,   
transformed or recorded as part of the analysis, 
using a degree of rigor appropriate to the nature 
of  the  data  and  the  information  needs.  This  
analysis typically produces graphs, numbers or 
other  indicators  that  inform  conclusions  and  
recommendations  to  present  to  stakeholders.  
(See  Statistical  Analysis  in  the  Engineering  
Foundations KA.) The results and conclusions 
are  reviewed  using  the  organization’s  formal  
or  informal  process.  Data  providers  and  mea-
surement users should participate in reviewing 
the data to ensure it is meaningful and accurate 
and can result in reasonable actions.
Communicate    results.    Document    and    
communicate  information  products  to  users  
and stakeholders.
6.4.   Evaluate Measurement  [7*, c1, c2]
Evaluate  information  products  and  the  mea-
surement  process  against  specified  evalua-
tion  criteria,  and  determine  the  strengths  
and  weaknesses  of  the  information  products  
or process. An internal process or an external 
audit  can  be  used  to  perform  the  evaluation,  
including  feedback  from  measurement  users.  
Record   lessons   learned   in   an   appropriate   
database. 
Identify   potential   improvements.   Such   
improvements might be changes in the format 
of  indicators,  changes  in  units  measured  or  
reclassification   of   measurement   categories.   
Determine   potential   improvements’   costs   
and benefits, and report appropriate improve-
ment actions. 
Communicate  proposed  improvements  to  
the  measurement  process  owner  and  stake-
holders  for  review  and  approval.  Also,  com-
municate  the  lack  of  potential  improvements  
if the analysis fails to identify any.
7.  Software Engineering Management 
Tools  [3*, c5, c6, c7]
SEM  tools  are  often  used  to  provide  visibility  
and control of SEM processes. Some tools are 
automated, whereas others are manually imple-
mented.  In  addition,  there  has  been  a  recent  
trend toward using integrated suites of software 
engineering tools throughout a project to plan, 
collect  and  record,  monitor  and  control,  and  
report  project  and  product  information.  Tools  
can be divided into the following categories: 
Project  planning  and  tracking  tools.  Project  
planning  and  tracking  tools  can  be  used  to  
estimate project effort and cost and to prepare 
project  schedules.  For  example,  some  proj-
ects  use  automated  estimation  tools  that  use  
a software product’s estimated size and other 
characteristics  as  input  and  then  estimate  
the  required  total  effort,  schedule  and  cost.  
Planning tools also include automated sched-
uling tools that analyze the WBS tasks, their 
estimated  durations,  their  precedence  rela-
tionships  and  the  resources  assigned  to  each  
task to produce a Gantt chart. 
Tracking tools can be used to track project 
milestones, regularly scheduled project status 
meetings, scheduled iteration cycles, product 
demonstrations and action items.
Risk management tools. Risk management 
tools  (see  Section  2.5,  Risk  Management) 
can be used to track risk identification, anal-
ysis and monitoring. These tools include sim-
ulation or decision trees to analyze the effect 
of  costs  versus  payoffs  and  subjective  esti-
mates of the probabilities of risk events. For 
example, Monte Carlo simulation tools can 
be used to produce probability distributions 
of  effort,  schedule  and  risk  by  algorithmi-
cally  combining  multiple  input  probability  
distributions.

SOFTWARE ENGINEERING MANAGEMENT   9-17
Communication tools. Communication tools 
can help provide timely and consistent infor-
mation  to  relevant  stakeholders  involved  in  
a  project.  Examples  of  such  tools  are  email  
notifications  and  broadcasts  to  team  mem-
bers  and  stakeholders;  regular  communica-
tions of meeting minutes; and charts showing 
progress,  backlogs,  and  maintenance  request  
resolutions. 
Measurement tools. Measurement tools sup-
port  activities  related  to  the  software  mea-
surement  program.  (See  Topic  6,  Software  
Engineering  Measurement.)  There  are  few  
completely   automated   tools   in   this   cate-
gory.  Measurement  tools  to  gather,  analyze  
and  report  project  measurement  data  may  be  
based  on  spreadsheets  developed  by  project  
team members or organizational employees.
MATRIX OF TOPICS VS. REFERENCE MATERIAL
Fa irley 2 0 0 9 
[3*]
Sommerville 
2011 [4*]
Boehm and 
Turner 2003 [5*]
McGarry et 
al. 2001 [7*]
1. Initiation and Scope 
Definition
1.1. Determination and 
Negotiation of Requirements
c3
1.2. Feasibility Analysisc4
1.3. Process for the Review and 
Revision of Requirements
c3
2. Software 
Project Planning
2.1. Process Planningc2, c3, c4, c5c1
2.2. Determine Deliverablesc4, c5, c6
2.3. Effort, Schedule and Cost 
Estimation
c6
2.4. Resource Allocationc5, c10, c11
2.5. Risk Managementc9 c5
2.6. Quality Managementc4c24
2.7. Plan Managementc4
3. Software 
Project Enactment
3.1. Implementation of Plansc2
3.2. Software Acquisition and 
Supplier Contract Management
c3, c4
3.3. Implementation of 
Measurement Process
c7
3.4. Monitor Process c8
3.5. Control Processc7, c 8
3.6. Reportingc11
4. Review and Evaluation
4.1. Determining Satisfaction 
of Requirements

9-18   SWEBOK
®
 GUIDE V4.0
4.2. Reviewing and 
Evaluating Performance
c8, c10
5. Closure
5.1. Determining Closure
5.2. Closure Activities
6. Software Engineering 
Measurement
6.1. Establish and Sustain 
Measurement Commitment
c1, c2
6.2. Plan the 
Measurement Process
c1, c2
6.3. Perform the 
Measurement Process
c1, c2
6.4. Evaluate Measurementc1, c2
7. Software Engineering 
Management Tools
c5, c6, c7
FURTHER READINGS
A  Guide  to  the  Project  Management  Body  of  
Knowledge (PMBOK
®
 Guide)   [1].
The PMBOK
®
  Guide  provides  guidelines  for  
managing   individual   projects   and   defines   
project  management-related  concepts.  It  also  
describes  the  project  management  life  cycle  
and  its  related  processes,  and  the  project  life  
cycle. It is a globally recognized guide for the 
project management profession.
Software  Extension  to  the  Project  Management  
Body of Knowledge (PMBOK®) Guide [2].
SWX  provides  adaptations  of  and  extensions  
to  the  generic  practices  of  project  manage-
ment documented in the PMBOK® Guide for 
managing software projects. The primary con-
tribution  of  this  extension  to  the  PMBOK® 
Guide  is  a  description  of  processes  for  man-
aging adaptive life cycle software projects.
IEEE Standard Adoption of ISO/IEC 15939 [6].
This  international  standard  identifies  a  pro-
cess  that  supports  defining  suitable  measures  
to address specific information needs. It iden-
tifies the activities and tasks necessary to suc-
cessfully  identify,  define,  select,  apply  and  
improve measurement within an overall project 
or organizational measurement structure.
J.  McDonald,  Managing  the  Development  of  
Software Intensive Systems, Wiley, 2010 [8].
This textbook introduces project management 
for  beginning  software  and  hardware  devel-
opers, plus unique advanced material for expe-
rienced  project  managers.  Case  studies  are  
included for planning and managing verifica-
tion and validation for large software projects 
and complex software and hardware systems, 
as well as inspection results and testing met-
rics to monitor project status.
REFERENCES
[1] Project Management Institute, A 
Guide to the Project Management Body 
of Knowledge (PMBOK® Guide), 6th 
ed., Newton Square, PA: Project 
Management Institute, 2017.

SOFTWARE ENGINEERING MANAGEMENT   9-19
[2] Software Extension to the Project 
Management Body of Knowledge 
(PMBOK® Guide), Fifth Edition, 
Project Management Institute, 2013.
[3*] R. E. Fairley, Managing and Leading 
Software Projects. Hoboken, NJ: Wiley 
IEEE Computer Society Press, 2009.
[4*] I. Sommerville, Software Engineering, 
10th ed., New York: Addison-
Wesley, 2015.
[5*] B. Boehm and R. Turner, Balancing 
Agility and Discipline: A Guide for 
the Perplexed. Boston: Addison-
Wesley, 2003.
[6]   IEEE,   IEEE Standard Adoption of ISO/
IEC 15939: 2007 Systems and Software 
Engineering Measurement Process, ed: 
IEEE, 2017.
[7*] J. McGarry et al., Practical Software 
Measurement: Objective Information 
for Decision Makers, Addison-Wesley 
Professional, 2001.
[8] J. McDonald, Managing the 
Development of Software-Intensive 
Systems. Hoboken, NJ: John Wiley and 
Sons, Inc., 2010.
[9]  Practical Software and Systems 
Measurement Continuous Iterative 
Development Measurement Framework 
Parts 1-3: Concepts, Definitions, 
Principles, and Measures, Version 2.1,  
15 April 2021. 
[10] S. Sheard, M. Bouyaud, M. Osaisai, 
J. Siviy, and K. Nidiffer, “Book Club” 
Guides a Working Group to Create 
INCOSE System-Software Interface 
Products, INSIGHT, Volume 24, 
Issue 2, 2021.
[11] K. Nidiffer, C. Woody, and T.A. 
Chick, Program Manager’s Guidebook 
for Software Assurance, Special Report, 
CMU/SEI-2018-SR-025, Software 
Solutions and CERT Divisions, 
Software Engineering Institute/
Carnegie Mellon University, 
August 2018.
[12] R.E.  Fairley, Systems Engineering of 
Software-Enabled Systems, ISBN 978-1-
119-53501-0, 2019. 
[13] Defense Innovation Board, Software Is 
Never Done: Refactoring the Acquisition 
Code for Competitive Advantage Defense, 
v3.3, March 12, 2019.
[14] “DevOps: Building Reliable and Secure 
Systems Including Application Build, 
Package, and Deployment,” IEEE 
Standard, 2675-2021, 2021.
[15] M. Chemuturi and T. Cagley, Mastering 
Software Project Management: Best 
Practices, Tools and Techniques, J. Ross 
Publishing, July 2010.

10-1 
CHAPTER 10
Software Engineering Process
ACRONYMS
BPMNBusiness Process Modeling Notation
CASEComputer-Aided Software 
Engineering
CMMCapability Maturity Model
CMMICapability Maturity Model 
Integration
GQMGoal-Question-Metric
IDEF0Integration Definition
KAKnowledge Area
PDCAPlan-Do-Check-Act
SLCMSoftware Life Cycle Model
SLCPSoftware Life Cycle Process
UMLUnified Modeling Language
INTRODUCTION TO THE KA 
This  chapter  considers  the  software  engi-
neering  process  from  several  perspectives:  
concepts,  life  cycles,  and  software  engi-
neering  process  assessment.  The  software  
engineering    community    has    been    very    
active   concerning   the   standardization   of   
many  of  the  aspects  of  the  software  engi-
neering process.
BREAKDOWN OF TOPICS FOR 
THE SOF TWARE ENGINEERING 
PROCESS KA
The   topic   breakdown   for   the   Software   
Engineering    Process    KA    is    shown    in    
Figure 10.1.
1. Software Engineering Process 
Fundamentals
1.1 Introduction  [1*,c5],[13]
Software engineering processes involve work 
activities software engineers conduct to build 
and  operate  software.  When  the  discipline  
of  software  engineering  emerged,  scientists,  
engineers  and  technicians  had  to  look  at  
existing  disciplines  to  understand  the  scope  
of the software engineering process. An engi-
neering process consists of a set of interrelated 
activities  that  transform  one  or  more  inputs  
into  outputs  while  consuming  resources  to  
accomplish  the  transformation.  As  part  of  
engineering,  software  engineering  uses  pro-
cesses similar to those of other types of engi-
neering. As engineers create devices or other 
products, they progress through various steps, 
expending  significant  design  effort,  relying  
on a vast trove of knowledge as they do so, at 
the time that they gain knowledge, i.e. learn, 
about the process they are performing and the 
product they are creating.
Beginning in the 1960s and continuing in 
the  1970s,  engineering  design  and  manufac-
turing provided a baseline — a foundation — 
for what would later become a new discipline. 
In those years, it was agreed that the process 
of  building  software  would  be  decomposed  
into  processes  that  could  include  design  and  
manufacturing,  and  later,  operations.  Some  
of the processes needed to construct software 
systems fit into the design class, and others fit 
into the manufacturing class. Today, the soft-
ware engineering community is still learning 
and,   therefore,   still   improving   the   soft-
ware  engineering  process.  Currently,  a  wide  
consensus   exists   concerning   that   building   

10-2   SWEBOK
®
 GUIDE V4.0
software  systems  requires  lots  of  design  and  
learning  effort  focused  on  the  product  under  
construction,  and  on  the  process.  As  it  will  
be discussed below, no ideal process, or set of 
processes  exists:    software  processes  must  be  
selected,  adapted,  and  applied  as  appropriate  
for each project and each organizational con-
text.  It  is  essential  that  the  software  engi-
neering process management is supported by 
empirical measurement.
The  concept  of  a  project  emerges  as  an  
“endeavor  with  defined  start  and  finish  cri-
teria undertaken to create a product or service 
in  accordance  with  specified  resources  and  
requirements”  [1]  or  a  “temporary  endeavor  
undertaken  to  create  a  unique  product,  ser-
vice, or result” [13]. It is a concept of the man-
agement  discipline  linked  to  clear  objectives  
and  bound  by  a  limited  time  frame,  as  dis-
cussed  in  knowledge  area  (KA)  9,  Software  
Engineering   Management.   Software   engi-
neering processes are usually performed in the 
context of projects.
Many  of  the  processes  of  the  more  con-
ventional  engineering  disciplines  (e.g.,  elec-
trical    or    chemical)    include    design    and    
manufacturing,  where  manufacturing  pro-
duces multiple units of a system (e.g., a chem-
ical reactor). This is not the case for software 
systems,  though  manufacturing  is  useful  to  
describe the need to build the many software 
units  that  comprise  a  software  system.  In  
electrical  or  chemical  engineering,  the  oper-
ation  of  the  engineering  systems  transforms  
(raw)  materials,  energy  and  physical  entities  
into other forms of material or energy. For the 
software  engineering  discipline,  an  analogy  
for  this  operation  could  be  the  execution  of  
a  software  unit  (the  output  from  a  software  
engineering  set  of  processes)  that  transforms  
one kind of data into another. 
In  the  rest  of  the  section,  the  term  process 
will denote work activities, not the execution 
of software. 
The   Software   Engineering   Process   KA 
is  closely  related  to  most  of  the  SWEBOK  
Software Engineering 
Process
Software Engineering 
Process Fundamentals
Introduction
Software Engineering 
Process Definition
Life Cycle Definition, Process 
Cathegories and Terminology
Rationale for Life Cycles
e Concepts of Process 
Models and Life Cycle Models
Some Paradigm for Development 
Life Cycle Models
Development Life Cycle 
Models and eir Engineering 
Dimension
e Management of SLCPs
Software Engineering Process
Management
Software Life Cycle Adaptation
Practical Considerations
Software Process Infrastructure, 
Tools, Methods
Software Engineering Process 
Monitoring and the Relation 
to the Software Product
Overview of Sotware Process
Assesment and Improvement
Global-Question-Metric (GQM)
Framework-Based-Method
Process Assesment and 
Improvement in Agile
Life Cycles
Software Process Assesment 
and Improvement
Figure 10.1. Breakdown of Topics for the Software Engineering Process KA

SOFTWARE ENGINEERING PROCESS   10-3
KAs     and     the     Software     Engineering     
Management,  Software  Engineering  Models  
and  Methods,  Software  Quality,  Software  
Architecture, and Software Testing KAs. The 
Measurement  and  Root  Cause  Analysis  sec-
tions in  the  Engineering  Foundations  KA  is  
also closely related.
1.2 Software Engineering Process Definition 
 [1*,c5][2] [7][14][20]
A process is a “set of interrelated or interacting 
activities  that  transforms  inputs  into  outputs”,  
where activity is a “set of cohesive tasks of a pro-
cess,”  and  a  task  is  a  “required,  recommended,  
or permissible action, intended to contribute to 
the  achievement  of  one  or  more  outcomes  of  
a  process”  [1].  According  to  [2],  a  process  is  a  
“predetermined  course  of  events  defined  by  its  
purpose  or  by  its  effect,  achieved  under  given  
conditions.” A third definition, following [7], is 
a  “system  of  activities,  which  use  resources  to  
transform  inputs  into  outputs.”  And  a  fourth  
one is a “set of interrelated or interacting activ-
ities  which  transforms  inputs  into  outputs  to  
deliver  an  intended  result”  [20].  That  is,  the  
description of a process includes required inputs, 
transforming activities, and the outputs gener-
ated.  These  definitions  address  any  processes  
that are applied to the software part of software 
systems.  Software  systems  also  include  hard-
ware, and they also involve people and manual 
procedures.  The  output  of  one  process  can  be  
an  input  to  another  process.    Processes  may  
include controls (e.g. directives and constraints)  
and enabling mechanisms (e.g. tools, technolo-
gies  or  resources  such  as  workforce  and  infra-
structure)  associated with the processes [14].
2. Life Cycles
1
2.1.  Life Cycle Definition, Process Categories, 
and Terminology 
 [1*,c5-6][3*,c2][8*,c1-3][13]
A life cycle, according to [1], is the “evolution 
of a system, product, service, project or other 
1  Lifecycle, life-cycle and life cycle are different spellings. Merriam-Webster prefers the spelling “life cycle”.
human-made entity from conception through 
retirement.”   In   software   engineering,   life   
cycles help convey information about software 
systems,  the  “system[s]  for  which  software  is  
of  primary  importance  to  the  stakeholders”  
[1]. The concept of life cycles was put in place 
because  simply  identifying  and  defining  the  
processes  required  to  produce  software  did  
not  adequately  describe  all  the  complexity  
of  software  systems.  It  was  also  necessary  to  
define life cycles, which include a number of 
processes and constraints [8].
In software engineering, development refers 
to  a  crucial  stage  of  a  system,  product,  ser-
vice  or  project  life  cycle:  that  of  building  (or  
changing)  a  software  system  according  to  
the  stakeholders’  needs.  From  a  production/
industrial  management  perspective,  software  
systems  are  referred  to  as  products.  In  this  
context, the term software product development 
lifecycle makes sense. 
Product  life  cycle  can  be  defined  as  the  
“series  of  phases  that  represent  the  evolution  
of  a  product,  from  concept  through  delivery,  
growth,  maturity,  to  retirement”  [13].  This  
definition  is  not  specific  to  software  sys-
tems  but  applies  to  all  products  more  gener-
ally. Likewise, the life cycle concept, which is 
linked to the product concept, is not specific 
to software engineering.
Software  systems  contain  software  units  
that are an “atomic-level software component 
of the software architecture that can be sub-
jected to stand-alone testing.” (See the Testing 
KA.) The life cycle of a software system (and 
keep  in  mind  that  software  engineering  uses  
an  interdisciplinary  approach)  comprises  all  
the  processes,  activities  and  tasks  from  the  
ideation of the software system to the retire-
ment  of  the  system,  including  production,  
operation  and  evolution,  as  well  as  acquisi-
tion, when needed, and supply. Likewise, we 
can  look  at  the  life  cycle  of  an  element  of  a  
software  system  (a  software  unit).  A  soft-
ware  system  life  cycle  will  consider  both  the  
business and the technical needs of the stake-
holders  and  the  system’s  ability  to  produce,  

10-4   SWEBOK
®
 GUIDE V4.0
as  the  outcome  of  the  different  software  life  
cycle processes (SLCPs) performed by a team, 
a product that meets the stakeholders’ needs, 
with the required quality level for its users and 
for all the different stakeholders. 
The  following  paragraphs  enumerate  the  
process   categories,   as   enumerated   in   [1].   
These  process  categories  reflect  the  multiple  
perspectives  involved  in  producing  a  soft-
ware system: (1) technical processes including 
engineering  practices  to  build,  make,  evolve,  
operate   and   retire   software   products;   (2)   
technical  management  processes  that  cover  
planning  and  control,  as  well  as  configura-
tion  management,  risk  management,  infor-
mation  management  and  quality  assurance;  
(3)  organizational  project-enabling  processes  
that  support  life  cycle  model  and  infrastruc-
ture   management,   portfolio   management,   
and human resources, knowledge and quality 
management;  and  finally  (4)  agreement  pro-
cesses,  which  are  essential  to  support  collec-
tive  decision-making,  as  well  as  acquisition  
and supply processes.
A    breakdown    of    these    processes    is    
as follows:
1. Technical processes
a) Business or mission analysis process
b)  Stakeholder  needs  and  requirements  
definition process
c) System/software requirements defini-
tion process
d) Architecture definition process
e) Design definition process
f ) System analysis process
g) Implementation process
h) Integration process
i) Verification process
j) Transition process
k)  Validation process
l) Operation process
m) Maintenance process
n)    Disposal process
2. Technical management processes
a) Project planning process
b) Project assessment and control process
c) Decision management process
d) Risk management process
e) Configuration management process
f ) Information management process
g) Measurement process
h) Quality assurance process
3. Organizational project-enabling processes
a) Life cycle model management process
b) Infrastructure management process
c) Portfolio management process
d) Human resource management process
e) Quality management process
f ) Knowledge management process
4. Agreement processes 
a) Acquisition process
b) Supply processes
2.2. Rationale for Life Cycles [8*,c2-3][12]
Creating,   operating   and   retiring   software   
products require a number of processes, with 
their  activities  and  tasks,  and  a  number  of  
constraints. As noted above, software systems 
involve people and manual procedures, as well 
as software and hardware. Defining software 
processes, following [12], requires specifying 
inputs  and  outputs.  Inputs  from  processes  
are, very often, outputs from other processes. 
Therefore,  life  cycle  processes  are  interre-
lated  processes;  that  is,  each  individual  pro-
cess  (its  inputs  and  outputs)  may  depend  on  
other processes. The interrelated nature of the 
processes involved make the overall software 
engineering process highly complex. 
The  specification  of  life  cycles  is  a  pow-
erful  tool  for  implementing  an  engineering  
approach   to   the   creation,   operation   and   
retirement  of  software  systems.  A  life  cycle  
should be defined following engineering prin-
ciples  that  guide  engineering  as  a  discipline  
[8].  The  specification  of  a  life  cycle  includes  
the  specification  of  every  process  and  the  
associated  constraints.  The  process  specifica-
tion should be useful to humans so that they 
can communicate with one another using this 
specification.  The  specification  should  be  easy  
to  understand  and  correct  because  life  cycle  
specifications  are  the  basis  for  technical  and  

SOFTWARE ENGINEERING PROCESS   10-5
engineering  management,  including  coordina-
tion  and  agreement,  measurement,  assessment  
and improvement, and quality management.
2.3.  The Concepts of Process Models and Life 
Cycle Models [3*,c2][10*,c2][c2]
Section 2.1 provides a number of software life 
cycle  definitions.  In  reference  [2],  a  new  defi-
nition introduces the concept of a standard as a 
commonly accepted guiding document, stating 
that a “project-specific sequence of activities ... 
is  created  by  mapping  the  activities  of  a  stan-
dard  onto  a  selected  software  life  cycle  model  
(SLCM).” That is, a life cycle is created in con-
formance with the life cycle model. 
Examples of well-known life cycle models 
for  product  development  are,  among  others,  
the  waterfall  model,  the  V-model,  the  incre-
mental model, the spiral model and the Agile 
model [2,3, 10]. 
2.4.  Some Paradigms for Development Life 
Cycle Models [3*,c2-3][8*,c2-3] 
                        [9*,c1][10*,c1][2][11][12]
Each  software  system  has  its  own  features  
reflecting the stakeholders’ needs, both busi-
ness  and  technical.  A  suitable  life  cycle  will  
consider  all  these  needs.  As  explained  in  
Section  2.3,  a  software  life  cycle  will  be  
defined in conformance with (partially or fully 
conforming to) an SLCM. Some authors use 
the  term  “development”  to  refer  to  SLCM,  
e.g. “iterative development” instead of “itera-
tive (software) life cycle model”. Types of life 
cycles are described below. 
Predictive  life  cycles  are  “a  form  of  project  
life cycle in which the project scope, time, and 
cost are determined in the early phase of the life 
cycle” [13]. Predictive life cycles assume that the 
set of requirements that will be implemented is 
a  closed  set  that  will  not  undergo  substantive  
change unless a force majeure occurs. 
An iterative life cycle is “a project life cycle 
where  the  project  scope  is  generally  deter-
mined  early  in  the  project  life  cycle,  but  
time  and  cost  estimates  are  routinely  mod-
ified  as  the  project  team  understanding  of  
the  product  increases.  Iterations  develop  the  
product  through  a  series  of  repeated  cycles,  
while increments successively add to the func-
tionality of the product” [3, 8, 13]. The itera-
tions duration is defined for each project. The 
method  chosen  (see  KA  11)  would  prescribe  
the role and size of iterations. 
In  an  evolutionary  life  cycle,  a  product  
or  service  changes  over  its  lifetime.  It  may  
happen  because  requirements  and  customer  
needs change, but it also may happen because 
requirements are introduced into the product 
in successive steps and not as a complete and 
atomic  set  [3,  8].  “Successive  steps”  is  a  syn-
onym for “iterations.”
An incremental  life  cycle  is  “an  adaptive  
project  life  cycle  in  which  the  deliverable  is  
produced  through  a  series  of  iterations  that  
successively add functionality within a prede-
termined time frame. The deliverable contains 
the  necessary  and  sufficient  capability  to  be  
considered complete only after the final itera-
tion” [3, 8, 13]. Incremental life cycles are not 
always predictive, but they can be. Incremental 
development is a “software development tech-
nique   in   which   requirements   definition,   
design, implementation, and testing occur in 
an overlapping, iterative (rather than sequen-
tial)  manner,  resulting  in  incremental  com-
pletion of the overall software product” [2]. 
Continuous development refers to software 
engineering  practices  that  allow  for  frequent  
releases   of   new   systems   (including   soft-
ware) to staging or various test environments 
through the use of automated tools [8, 9, 11].
A  life  cycle  can  enforce  a  rule  that  the  
requirements     specifications     cannot     be     
changed  once  the  requirements  process  has  
been finalized and the customer has agreed to 
the specifications. This happens, for example, 
in  predictive  life  cycles.  On  the  other  hand,  
when the life cycle does not preclude changes 
in the requirements specifications, even after 
the  customer  has  agreed  to  them  and  signed  
off  on  them,  and  in  practice,  allows  them  
to  change  at  any  point  [upon  negotiation  of  
interested parts], then the life cycle is said to 
be open to change. Being open to change is one 
of the claims of Agile development [9, 10].

10-6   SWEBOK
®
 GUIDE V4.0
2.5.  Development Life Cycle Models and Their 
Engineering Dimension [3*,c2][8*,c2-3]
 [9*,c1][10*,c1][2] [11] [16]  
 [17] [18] [19][25][26][27]
Several  life  cycle  models  have  become  well  
known   with   the   development   of   software   
engineering  since  its  inception.  One  model,  
which  became  popular  early  in  the  history  of  
the discipline, is the waterfall model [3], that 
falls  into  the  category  of  predictive,  described  
previously.  The  waterfall  model  approach  for  
product development uses a number of phases, 
including  requirements,  preliminary  design,  
detailed design, coding and testing. It imple-
ments a very strict process, in which one phase 
cannot be started until the previous one is fin-
ished. The waterfall model was useful because 
it introduced a systematization in the develop-
ment of software systems and, therefore, what 
could be referred to as an engineering approach 
to software product development. Many vari-
ants  or  extensions,  such  as  the  V-model  [3],  
with many different names and nuances, have 
been  introduced  in  the  history  of  software  
engineering. The waterfall model was an early 
attempt to address the so-called software crisis 
[3].  The  waterfall  model  is  document-driven.  
Reference  [2]  defines  the  waterfall  model  as  
the  “model  of  the  software  development  pro-
cess  in  which  the  constituent  activities,  typ-
ically  a  concept  phase,  requirements  phase,  
design   phase,   implementation   phase,   test   
phase,  and  installation  and  checkout  phase,  
are  performed  in  that  order,  possibly  with  
overlap but with little or no iteration.”
The  waterfall  model  is  clearly  an  example  
of  a  predictive  life  cycle.  Some  other  para-
digms, such as the incremental life cycle, also 
attempted  to  address  the  “software  crisis.”  In  
this  model  (see  Section  2.4),  different  phases  
occur in an overlapping rather than sequential 
manner. An incremental life cycle can also be 
a  predictive  life  cycle.  This  would  mean  that  
the requirements are defined and closed before 
any  other  development  phase  is  started.  The  
spiral  model,  introduced  by  Boehm,  is  evolu-
tionary  and  risk-driven,  as  opposed  to  docu-
ment- or code-driven [3]. Reference [2] defines 
the  spiral  model  as  a  “model  of  the  software  
development  process  in  which  the  constit-
uent  activities,  typically  requirements  anal-
ysis,  preliminary  and  detailed  design,  coding,  
integration,  and  testing,  are  performed  itera-
tively until the software is complete.” Another 
popular  model  is  rapid  prototyping,  a  “type  
of  prototyping  in  which  emphasis  is  placed  
on  developing  prototypes  early  in  the  devel-
opment  process  to  permit  early  feedback  and  
analysis in support of the development process” 
[2]. The unified process, also known as  unified 
software  development  process,  is  an  iterative  
and  incremental  software  development  pro-
cess framework [25]. From the unified process, 
the  rational  unified  process  (RUP®)  is  docu-
mented in [26], and the OpenUP, managed by 
the Eclipse Foundation [27].
The Agile Manifesto [16] effected a disrup-
tion  in  the  software  engineering  community  
by  creating  an  abrupt  change  of  mindset.  The  
difference  was  that  Agile  Manifesto  signato-
ries claimed that the process should be open to 
change  —  requirements  could  be  modified  at  
any  stage  of  the  development  process  if  users’  
needs  changed.  Communication  and  mutual  
trust  between  team/customer  were  essential.  
Signatories claimed that team communication, 
often  face-to-face,  and  communication  with  
the customer were key. Nevertheless, the Agile 
Manifesto  does  not  say  that  documents  (e.g.  
to define requirements) are not needed, docu-
ments are needed [9, 10]. Signatories also advo-
cated for small software incremental deliveries, 
as opposed to projects that applied the waterfall 
model with a single software delivery at the end 
of the project after months or years of working. 
Agile  makes  a  clear  distinction  between,  on  
the one side, values and principles (e.g., always 
delivering value to the customer or a commit-
ment to technical excellence) and, on the other, 
practices  (peer  programming,  sprint  planning  
or retrospective). The Agile mindset [10] is dif-
ferent from the predictive mindset. The Agile 
mindset  is  based  on  a  number  of  values  and  
principles  (e.g.,  the  importance  of  communi-
cation,  being  open  to  change  or  commitment  
to  technical  excellence  and  always  delivering  
value to the customer); this focus differentiates 

SOFTWARE ENGINEERING PROCESS   10-7
Agile  from  the  predictive  mindset,  which  is  
more focused on committing to the implemen-
tation of the requirements specifications. Agile  
helps address complexity [8, 10].
Several misconceptions arose around Agile, 
and  some  still  remain.  One  is  that  Agile  is  a  
method  in  itself,  which  it  is  not.  Another  is  
that  Agile  is  “faster”  than  waterfall  because  
you need not produce any document. A third 
one is that Agile has a  limited or unstructured 
set of methods/practices; a chart that enumer-
ates  several  commonly  used  Agile  methods  
and  practices  can  be  found,  for  example,  in  
[18].  Several  Agile  methods  became  popular,  
like Extreme Programming for product devel-
opment,  Scrum  for  project  management  and  
others. Even considering the ever rising pop-
ularity of the Agile life cycle model to address 
complex  projects,  scaling  up  Agile  for  large  
projects and portfolios is still challenging. The 
perception  today  is  that  the  Agile  Manifesto  
meant  a  significant  disruption;  nevertheless,  
it  is  already  20  years  old,  and  some  authors  
think  that  some  of  its  principles  might  need  
be updated, informed by the experience devel-
opers have obtained in the past 20 years [17].
The application of Agile practices has tran-
scended the software engineering process, and 
the  terms  business  agility  and  Agile  organiza-
tions are now very common [19]. From a soft-
ware engineering point of view, Agile created 
an  opportunity  for  the  industry  to  achieve  a  
reengineering and a better alignment of soft-
ware engineering processes and business stra-
tegic  processes  in  organizations.  The  use  of  
an  Agile  approach  by  business  processes  is  a  
common scenario; this is reflected in the prin-
ciples of DevOps [11], for example, explained 
later  in  this  section,  and  process  assessment  
and improvement in Section 3.
The  need  to  provide  more  frequent  releases,  
the fact that users’ needs and technological life 
cycles  change  more  frequently,  together  with  
the  required  alignment  of  the  organizations’  
strategic plans with the organizations’ IT opera-
tions, has led to the creation of DevOps, defined 
as  a  “set  of  principles  and  practices  which  
enable better communication and collaboration 
between relevant stakeholders for the purpose of 
specifying,  developing,  and  operating  software  
and  systems  products  and  services,  and  con-
tinuous  improvements  in  all  aspects  of  the  life  
cycle” [11]. The ability to provide more releases 
more frequently, once adequate process manage-
ment  has  been  defined,  has  become  an  advan-
tage that makes companies more competitive.
In  the  history  of  software  engineering,  
there has been a lot of controversy over soft-
ware  life  cycle  models  —  for  example,  as  
seen  in  debate  over  the  merits  of  the  water-
fall model versus the Agile model of software 
development  (See  Section  2).  This  contro-
versy  should  be  understood  from  a  historical  
perspective;  new  approaches  have  been  dis-
ruptive  or  considered  disruptive,  and  there  
has been a lack of empirical measures to sup-
port  evidence-based  discussions  about  soft-
ware  engineering.  This  situation  has  been  
changing slowly but steadily. Using empirical 
measures as the basis for making decisions is 
an  essential  element  of  software  engineering  
[4,  8].  See  also  KA  9,  Software  Engineering  
Management., and KA 12, Software Quality.
2.6. The Management of SLCPs [14]
The life cycle for any software system contains 
a  number  of  stages.  According  to  [14],  these  
stages are the following:
1. Concept:   At   this   stage,   stakeholders’   
needs will be identified, concepts will be 
explored, and solutions will be proposed.
2. Development:   At   this   stage,   require-
ments  representing  the  users’  needs  will  
be refined, solutions will be created, sys-
tems  built,  and  all  undergo  the  needed  
verification and validation processes.
3. Production:  This  stage  will  have  a  dif-
ferent scope depending on the character-
istics of the software system under focus. 
Generally  speaking,  it  will  include  the  
production and testing of the system.
4. Utilization:  At  this  stage,  the  system  
operates to satisfy users’ needs.
5. Support:  At  this  stage,  developers  pro-
vide the required actions to achieve a sat-
isfactory operation.

10-8   SWEBOK
®
 GUIDE V4.0
6. Retirement:  At  this  stage,  the  team  fol-
lows established procedures to dispose of 
the system.
The stages are not supposed to be sequen-
tial,  by  any  means.  Actually,  the  specifica-
tion of the life cycle for a software system will 
include  the  transitions  between  these  stages.  
It should be clear that these stages have been 
identified for a general life cycle. Specific life 
cycles  will  have  specific  stages,  meaningful  
to  a  particular  project’s  stakeholders;  these  
stages will fit into these general stages.
2.7. Software Engineering Process Management 
 [1*,c5][2]
Process management is defined as “direction, 
control,  and  coordination  of  work  performed  
to  develop  a  product  or  perform  a  service”  
[2]. Several  management  levels  govern  the  
software  engineering  process,  as  explained  
in  reference  [1],  see  also  KA  9,  Software  
Engineering Management. The lowest level is 
the technical processes; the second is the tech-
nical  management  level,  which  will  include  
project management processes. The third level 
is  the  (executive)  management  level,  focused  
on  organizational  enabling  processes,  such  
as  knowledge  management,  life  cycle  model  
management, or portfolio management. 
2.8. Software Life Cycle Adaptation 
 [5] [14] [23][29]
Each software system has its differential char-
acteristics.  These  differential  characteristics,  
together with the stakeholders’ needs, lead to 
specific life cycles. This adaptation will include 
identifying  all  the  relevant  characteristics,  
selecting  the  appropriate  standards  or  docu-
ments internal to an organization, selecting a 
development strategy/life cycle model, stages, 
and processes, and documenting the decisions 
and rationale. The adaptation will not require 
keeping  the  names  provided  in  Section  2,  
or  including  them  all  [5,  14,  23].  The  ISO/
IEC   29110   series,   Systems   and   Software   
Engineering  Standards  and  Guides  for  Very  
Small  Entities  (VSEs)  [29],  is  an  example  of  
a series derived from ISO/IEC/IEEE 12207. 
2.9. Practical Considerations [8*,c2-3]
Defining a life cycle process includes the spec-
ification  of  the  four  categories  presented  in  
Section  2.  This  means  addressing  technical  
processes (definition of the processes that will 
be   required),   organizational   processes   (this   
includes  human  resources,  among  other  pro-
cesses), technical management processes (how 
processes  are  related,  how  they  are  monitored  
and managed), and agreement processes.
The  discipline  of  software  engineering  has  
been  evolving  since  its  conception  for  several  
reasons.  The  community  has  never  stopped  
learning,  while  the  complexity  of  the  prod-
ucts   has   been   ever-increasing.   Defining   a   
software  life  cycle  for  the  development  of  a  
product  requires  considering  the  characteris-
tics  of  the  product  (e.g.,  stakeholders’  needs,  
product size or complexity) and others external 
to  the  product,  such  as  the  stakeholders’  char-
acteristics. Something that the community has 
learned  is  that  estimations  and  measurements  
are  essential.  Wrong  or  uncertain  estimations  
in the context of a life cycle will lead to failure. 
Accurate estimations are not easy to produce. [8]
A  current  trend  in  software  engineering  
is  a  focus  on  continuous  delivery,  supported  
by  realistic  process  and  product  estimations  
and  measurements.  A  helpful  lesson  engi-
neers have learned is that working with large 
processes  without  producing  any  delivera-
bles along the way increases uncertainty. (See 
DevOps  in  Section  2.5.)  The  Agile  mindset  
has  contributed  to  this  and  has  helped  engi-
neers recognize the importance of communi-
cation in the process. [8]
When a project process is defined in confor-
mity with a life cycle, it is important to make 
sure  that  it  will  be  possible  to  have  metrics/
measure definitions that will result in realistic 
process  (and  product)  estimations  and  mea-
surements  throughout  project  definition  and  
execution, and to define the level of precision 
and uncertainty; project process (and product) 
measurements should always provide accurate 

SOFTWARE ENGINEERING PROCESS   10-9
information  about  what  is  happening  (the  
status of the process and the product) while the 
life cycle process is executed. If we are uncer-
tain  about  the  accuracy  of  estimations  and  
measurements,  the  project  might  not  be  suc-
cessful.  In  this  case,  a  reflection  should  take  
place  on  the  overall  approach.  Historically,  
a  lot  of  polemics  have  grown  about  the  pre-
dictive  life  cycle  versus  the  Agile  life  cycle.  
In  software  engineering,  discussions  should  
always  be  supported  by  realistic  process  and  
product estimations and measurements, which 
can accurately reduce the level of uncertainty. 
2.10. Software Process Infrastructure, Tools, 
Methods [3*,c2][8*,c2-3][2]
Several  notations  have  been  used  for  defining  
software processes, including natural language, 
specifying  textual  lists  of  constituent  activi-
ties and tasks, data-flow diagrams, state charts, 
integration definition (IDEF0), Petri nets, and 
unified modeling language (UML) activity dia-
grams, and business process modeling notation 
(BPMN) [2, 3]. Software process infrastructure 
includes tools to support the definition of these 
processes (e.g., a BPMN toolkit) but mainly to 
support  all  specific  processes  (testing  or  con-
figuration   management).   Process   definitions   
will often include methods and formalism (e.g., 
Rational Unified Process or extreme program-
ming)  [3].  Tools  will,  ideally,  have  to  support  
these methods and, as important, be integrated 
with  them.  Therefore,  it  is  not  enough  that  a  
tool supports testing. Once a code unit has been 
successfully  tested,  for  example,  this  becomes  
useful  information  that  should  be  recorded  so  
that  the  rest  of  the  team  can  be  aware  of  this  
fact.  This  means  that  the  configuration  man-
agement tool and the testing tool will have to be 
integrated [3, 8]. The term software engineering 
environment,  representing  a  set  of  integrated  
tools, is sometimes used. The term CASE (com-
puter-aided software engineering) was popular 
in  the  1980s  and  1990s.  Somehow,  the  power  
tools of the 1980s and 1990s were oversold as a 
cure for the software crisis. In any case, today, 
the automation of some processes (e.g., config-
uration management, or at least version control; 
testing; ticket management) is seen as essential 
for the implementation of successful life cycles. 
You can also read KA 11, Software Engineering 
Models and Methods.
2.11.  Software Engineering Process Monitoring 
and its Relationship with the Software 
Product [1*,c5-6][3*,c2][4*c4-10]
                                                   [8*c2-3]
Developers  must  monitor  the  software  engi-
neering process execution, assess whether the 
process  objectives  are  met,  and  assess  risks.  
This  process  monitoring  is  part  of  software  
engineering  process  assessment  (see  Section  
3)  and  part  of  the  Software  Engineering  
Management KA [1, 3, 4, 8]. 
Empirical methods support process assess-
ment  and  improvement  as  well  as  product  
assessment and improvement. The goal of pro-
cess execution is to obtain products that meet 
stakeholders’ needs. While this area is focused 
on  the  software  engineering  process,  process  
monitoring requires assessing both process and 
product, using a joint, more holistic approach.
3. Software Process Assessment and 
Improvement
3.1.  Overview of Software Process Assessment 
and Improvement [4*,c4][15][24]
The  idea  that  any  executed  process  can  be  
improved was present in the classic Shewhart-
Deming   plan-do-check-act   (PDCA)   par-
adigm   [15,   24],   which   was   already   being   
discussed  and  applied  in  the  1950s,  and  its  
foundations  can  be  found  centuries  earlier.  
For  the  software  engineering  process,  several  
approaches have been developed. 
The  PDCA  paradigm  is  an  opportunity  to  
meet  a  widely  recognized  need  —  the  need  
for   empirical   evidence   to   make   decisions.   
Such  decisions  include  choosing  a  life  cycle,  
deciding  how  to  assess  a  process  or  deciding  
how   to   improve   a   process,   among   others.   
Getting  empirical  evidence  across  the  execu-
tion of a software engineering process is essen-
tial for the success of the process execution. [4]

10-10   SWEBOK
®
 GUIDE V4.0
3.2. Goal-Question-Metric (GQM) [21]
The  GQM  approach  [21]  is  based  on  Basili’s  
Quality   Improvement   Paradigm.   Both   are   
based  on  setting  goals  that  can  be  measured,  
changing something, and then evaluating the 
effect  of  the  change.  When  the  evaluation  is  
positive, an improvement has occurred. 
3.3 Framework-Based Methods 
 [4*,c4-10][6][22]
Some assessment methods are based on frame-
works  that  use  a  process  reference  model  and  
an assessment reference model — for example, 
CMM® (capability maturity model), CMMI® 
[4, 22], and the ISO/IEC 33000 [4, 6] series, 
also known as SPICE. 
The  ISO/IEC  33000  framework  includes  
a  process  reference  framework  and  a  pro-
cess  assessment  model.  The  ISO/IEC  33000  
framework revises the ISO/IEC 15504 series 
of    International    Standards,    providing    a    
framework for the assessment of (1) the pro-
cess  quality  characteristics,  one  of  which  is  
process  capability,  together  with  (2)  organi-
zational maturity. This framework covers pro-
cesses for the development, maintenance and 
use  of  systems  across  the  information  tech-
nology  domain,  as  well  as  processes  for  the  
design,  transition,  delivery  and  improvement  
of services. The concept of seeking continuous 
improvement underlies the assessment.
This series has developed several groups of 
standards addressing, as well as core elements, 
basic   requirements   for   performing   process   
assessments,  process  models  and  the  process  
measurement  framework;  guidance  on  how  
to  perform  assessments;  measurement  frame-
works for the assessment of process capability 
and  organizational  maturity;  process  refer-
ence models for special cases such as safety or 
high maturity; process assessment models for 
SLCPs,  system  life  cycle  process  IT  service  
management,  safety  and  high  maturity;  and  
organizational maturity models.
The process reference model is defined as a 
“model comprising definitions of processes in 
a domain of application described in terms of 
process purpose and outcomes, together with 
an  architecture  describing  the  relationships  
between  the  processes.”  The  process  assess-
ment model is defined as a “model suitable for 
the  purpose  of  assessing  a  specified  process  
quality  characteristic,  based  on  one  or  more  
process reference models.” [6]
3.4. Process assessment and improvement in Agile 
 [9*,c11][28]
Agile  methods  (e.g.,  the  scrum  project  man-
agement  method)  introduce  what  they  call  
retrospectives  at  the  end  of  each  iteration.  The  
objective  of  the  retrospective  is  to  analyze  
what  went  well  and  what  did  not  go  well,  to  
understand why, and to set a number of actions 
for learning and improvement. In the end, the 
team is in a continuous learning loop [9]. This 
practice, with different names and scopes was 
not new in software engineering [28].
MATRIX OF TOPICS VS. REFERENCE MATERIAL
ISO/IEC/I 
 
EEE 12207 [1*]Sommerville 
 
[3*]Laporte et al. [4*]Fa rley [8 *]Shore et al [9*]PM I [10 *]
Others
1. Software Engineering Process 
Fundamentals
1.1 Introductionc5[13]
1.2 Software Engineering Process 
Definition
c5[2] [7][14][20]

SOFTWARE ENGINEERING PROCESS   10-11
2. Life Cycles
2.1 Life cycle definition, process 
categories and terminology
c5-6c2c1-3[13]
2.2 Rationale for life cyclesc2-3[1 2]
2.3 The concept of process models and 
life cycles models
c2c2 [2]
2.4 Some paradigms for 
development life cycle models
c2-3c2-3c1c1[2] [11] [13]
2.5 Development life cycle models 
and their engineering dimension
c2c2-3c1c1[2] [11] [16] 
[17] [18] [19] 
[25] [26] [27]
2.6 The management of SLCPs[14]
2.7 Software engineering process 
management
c5[2]
2.8 Software life cycle adaptation[5] [14] [23] [29]
2.9 Practical considerations
2.10 Software process infrastructure, 
tools, methods
c2c2-3[2]
2.11 Software engineering process 
monitoring
c5-6c2c4 -10c2-3
3. Software Process Assessment 
and Improvement
c4 -10
3.1 Overview of software process 
assessment and improvement
c4[1 5 ] [2 4]
3.2 Goal-question metric (GQM)[21]
3.3 Framework-based methodsc4 -10[6] [22]
3.4 Process Assessment and 
improvement in Agile
c11[28]
REFERENCES
[1] ISO/IEC/IEEE 12207:2017 Systems 
and software engineering — Software 
life cycle processes.
[2]   ISO/IEC/IEEE, “ISO/IEC/IEEE 
24765:2017 Systems and Software 
Engineering — Vocabulary,” 2nd ed. 2017.
[3] I. Sommerville, Software Engineering. 
10th ed. 2016.
[4] C. Y. Laporte and A. April, Software 
Quality Assurance, IEEE Computer 
Society Press, 1st ed., 2018.
[5] Project Management Institute, Software 
Extension to the PMBOK® Guide — 
Fifth Edition, 2013.
[6] ISO/IEC 33001:2015 Information 
technology — Process assessment — 
Concepts and terminology.
[7]   ISO/IEC 25000:2014 Systems and 
software engineering — Systems and 
software product quality requirements 
and evaluation (SQuaRE) — Guide 
to SQuaRE.
[8]  D. Farley, Modern Software Engineering: 
Doing What Works to Build Better 

10-12   SWEBOK
®
 GUIDE V4.0
Software Faster. Addison-Wesley 
Professional, December 2021.
[9] J. Shore and S. Warden, The Art of Agile 
Development, O’Reilly Media, 2nd ed. 
October 2021.
[10]  Project Management Institute, Agile 
Practice Guide. Project Management 
Institute and Agile Alliance. 
September 2017.
[11] ISO/IEC/IEEE Std 32675:2022 
Information technology — DevOps — 
Building reliable and secure systems 
including application build, package and 
deployment.
[12] ISO/IEC/IEEE 24774:2021 Systems 
and software engineering — Life cycle 
management — Specification for pro-
cess description.
[13] Project Management Institute, A 
Guide to the Project Management Body 
of Knowledge (PMBOK® Guide) — 
Sixth Edition.
[14] ISO/IEC/IEEE 24748-1:2018(E) 
Systems and software engineering 
— Life cycle management — Part 1: 
Guidelines for life cycle management.
[15] W.A. Shewhart and W.E. Deming, 
Statistical Method from the Viewpoint 
of Quality Control. Dover, New 
Yo r k ,   19 8 6 .
[16] “The Agile Manifesto.” https://
agilemanifesto.org. [Accessed 
March 5, 2022].
[17] S. McConnell, More Effective Agile: A 
Roadmap for Software Leaders, 2019.
[18] “Subway Map to Agile Practices.” Agile 
Alliance. https://www.agilealliance.org 
/agile101/subway-map-to-agile 
-practices/. [Accessed March 5, 2022].
[19] J. Eckstein and J. Buck, Company-wide 
Agility with Beyond Budgeting, Open 
Space & Sociocracy: Survive & Thrive on 
Disruption, 2021.
[20] ISO/IEC TR 29110-5-3:2018 Systems 
and software engineering — Lifecycle 
profiles for very small entities (VSEs) — 
Part 5-3: Service delivery guidelines.
[21] N. Fenton and J. Bieman, Software 
Metrics, 3rd ed. CRC Press, 2014.
[22] CMMI Institute — CMMI V2.0. 
https://cmmiinstitute.com/cmmi.
[Accessed 5 March 2022].
[23] ISO/IEC/IEEE 24748-3:2020. Part 3: 
Guidelines for the application of ISO/
IEC/IEEE 12207 (software life cycle 
processes).
[24] D.R. Kiran, Total Quality manage-
ment. Elsevier, 2017.
[25] J. Rumbaugh, G. Booch, I. Jacobson. 
The Unified Software Development 
Process, 1999
[26] P.  Kruchten. The Rational Unified 
Process: An Introduction. 3rd Ed. 2004
[27] The Eclipse Foundation https://www.
eclipse.org/org/foundation/ [Accessed 
25 April 2024].
[28] T. Dingsøyr, Postmortem reviews: pur-
pose and approaches in software engi-
neering, Information and Software 
Technology, Volume 47, Issue 5, 2005, 
Pages 293-303.
[29] ISO/IEC TR 29110-1:2016 Systems 
and software engineering Lifecycle pro-
files for Very Small Entities (VSEs) 
Part 1: Overview

11-1 
CHAPTER 11
Software Engineering Models 
and Methods
ACRONYMS
3GL3rd Generation Language    
BNFBackus-Naur Form
FDDFeature-Driven Development
IDE
Integrated Development 
Environment
PBIProduct Backlog Item
RADRapid Application Development
UMLUnified Modeling Language
XPeXtreme Programming
INTRODUCTION
Software  engineering  models  and  methods  
impose  structure  on  software  engineering  to  
make it systematic, repeatable and ultimately 
more  success-oriented.  Models  provide  an  
approach  to  problem-solving,  a  notation  and  
procedures  for  model  construction  and  anal-
ysis. Methods provide an approach to the sys-
tematic   specification,   design,   construction,   
testing  and  verification  of  the  end-item  soft-
ware and associated work products.
Software engineering models and methods 
vary  widely  in  scope  —  from  addressing  a  
single software life cycle phase to covering the 
complete software life cycle. This knowledge 
area  (KA)  focuses  on  models  and  methods  
that  encompass  multiple  software  life  cycle  
phases regardless of the type of life cycle pro-
cess models such as iterative models and agile 
ones, since other KAs cover methods specific 
to single life cycle phases.
BREAKDOWN OF TOPICS FOR 
SOF TWARE ENGINEERING 
MODELS AND METHODS
This chapter on software engineering models 
and   methods   is   divided   into   four   main   
topic areas: 
1. Modeling discusses the general practice of 
modeling and presents topics in modeling 
principles,  properties  and  expression  of  
models,   modeling   syntax,   semantics,   
and pragmatics, as well as preconditions, 
postconditions, and invariants.
2. Types  of  Models  briefly  discusses  models  
and  aggregation  of  submodels  and  pro-
vides   general   characteristics   of   model   
types  commonly  found  in  the  software  
engineering practice.
3. Analysis of Models presents common anal-
ysis techniques used in modeling to verify 
completeness,   consistency,   correctness,   
traceability and interaction.
4. Software   Engineering   Methods   presents   
a  summary  of  commonly  used  software  
engineering   methods.   The   discussion   
guides the reader through a summary of 
heuristic methods, formal methods, pro-
totyping and Agile methods.
The  breakdown  of  topics  for  the  Software  
Engineering  Models  and  Methods  KA  is  
shown in Figure 11.1.
1. Modeling
Modeling of software is becoming a pervasive 
technique  to  help  software  engineers  under-
stand,   engineer   and   communicate   aspects   
of  the  software  to  appropriate  stakeholders.  

11-2   SWEBOK
®
 GUIDE V4.0
Stakeholders are those people or parties with a 
stated or implied interest in the software (e.g., 
users, buyers, suppliers, architects, certifying 
authorities,  evaluators,  developers,  software  
engineers). 
Although  there  are  many  modeling  lan-
guages,  notations,  techniques  and  tools  in  
the  literature  and  in  practice,  some  general,  
unifying concepts apply to them all. The fol-
lowing sections provide background on these 
general concepts.
1.1. Modeling Principles 
  [1*, c2s2, c5s1, c5s2, 2*, c2s2, 3*, c5s0]
Modeling   provides   the   software   engineer   
with  an  organized  and  systematic  approach  
for  representing  significant  aspects  of  the  
software    under    study,    facilitating    deci-
sion-making about the software or elements, 
and  communicating  those  significant  deci-
sions  to  others  in  the  stakeholder  commu-
nities.  Three  general  principles  guide  such  
modeling activities:
• Model the essentials: Good models do not 
usually  represent  every  aspect  or  fea-
ture of the software under every possible 
condition.  Modeling  typically  involves  
only  those  aspects  or  features  that  pose  
specific  questions,  abstracting  away  any  
nonessential  information.  This  approach  
keeps models manageable and useful.
• Provide   perspective:   Modeling   provides   
views  of  the  software  under  study  using  
defined  rules  for  expressing  the  model  
within each view. This perspective-driven 
approach  provides  dimensionality  to  the  
model  (e.g.,  providing  a  structural  view,  
a  behavioral  view,  a  temporal  view,  an  
organizational  view  and/or  other  views  
if relevant). Organizing information into 
views   focuses   the   software   modeling   
efforts  on  specific  concerns  relevant  to  
that view using the appropriate notation, 
vocabulary, methods and tools.
• Enable effective communications: Modeling 
uses  the  application  domain  vocabulary  
of  the  software,  a  modeling  language  
and semantic expression (in other words, 
meaning  within  context).  When  used  
rigorously   and   systematically,   mod-
eling  results  in  a  reporting  approach  
that   facilitates   effective   communica-
tion  of  software  information  to  project  
stakeholders. 
Software
Engineering Models
and Methods
Modeling
Types of Models
Analysis of
Models 
Software
Engineering
Methods  
Modeling
Principles
Properties and
Expression of
Models
Syntax,
Semantics and
Pragmatics
Preconditions,
Postconditions
and Invariants     
Behavioral
Modeling
Structure
Modeling
Analyzing for
Completeness
Analyzing for
Consistency
Analyzing for
Correctness
Analyzing for
Traceability
Analyzing for
Interaction
Heuristic
Methods
Formal
Methods
Prototyping
Methods
Agile
Methods
Figure 11.1. Breakdown of Topics for the Software Engineering Models and Methods KA

SOFTWARE ENGINEERING MODELS AND METHODS   11-3
A  model  is  an  abstraction  or  simplification  
of a system. A consequence of using abstrac-
tion  is  that,  because  no  single  abstraction  
completely  describes  a  software  component,  
the software model comprises an aggregation 
of  abstractions,  which,  when  taken  together,  
describe   selected   aspects,   perspectives   or   
views — only those that are needed to make 
informed decisions and respond to the reasons 
for creating the model in the first place. This 
simplification points to assumptions about the 
context within which the model is placed that 
should  also  be  captured  in  the  model.  Then,  
when the model is reused, these assumptions 
can  be  validated  first  to  establish  the  rele-
vancy of the reused model within its new use 
and context.
1.2. Properties and Expression of Models  
 [1*, c5s2, c5s3, 3*, c4s1.1p7, c4s6p3,  
                                                     c5s0p3]
Properties  of  models  are  those  distinguishing  
features  of  a  particular  model  that  charac-
terize  its  completeness,  consistency  and  cor-
rectness within the chosen modeling notation 
and tooling. Properties of models include the 
following:
• Completeness  — the  degree  to  which  all  
requirements have been implemented and 
verified within the model
• Consistency  —  the  degree  to  which  the  
model  contains  no  conflicting  require-
ments,  assertions,  constraints,  functions  
or component descriptions
• Correctness  — the  degree  to  which  the  
model   satisfies   its   requirements   and   
design specifications and is free of defects
Models are constructed to represent objects 
needed for target domains and their behaviors 
to  answer  specific  questions  about  how  the  
software is expected to operate. Interrogating 
the  models  —  through  exploration,  simula-
tion or review — might expose areas of uncer-
tainty  within  the  model  and  the  software  to  
which  the  model  refers.  These  uncertain-
ties  or  unanswered  questions  regarding  the  
requirements,  design  and/or  implementation  
can then be handled appropriately.
The primary expression element of a model 
is  an  entity.  An  entity  may  represent  concrete  
artifacts  (e.g.,  processors,  sensors  or  robots)  
or  abstract  artifacts  (e.g.,  software  modules  
or  communication  protocols).  Model  entities  
are  connected  to  other  entities  using  relations  
(lines  or  textual  operators  on  target  entities).  
Expression  of  model  entities  may  be  accom-
plished  using  textual  or  graphical  modeling  
languages; both modeling language types con-
nect  model  entities  through  specific  language  
constructs.  The  meaning  of  an  entity  may  
be  represented  by  its  shape,  its  textual  attri-
butes  or  both.  Generally,  textual  information  
adheres  to  language-specific  syntactic  struc-
ture. The precise meanings related to the mod-
eling  of  context,  structure  or  behavior  using  
these  entities  and  relations  are  dependent  on  
the  modeling  language  used,  the  design  rigor  
applied  to  the  modeling  effort,  the  specific  
view being constructed and the entity to which 
the specific notation element may be attached. 
Multiple views of the model may be required to 
capture the needed semantics of the software.
When using automation-supported models, 
models may be checked for completeness and 
consistency.  The  usefulness  of  these  checks  
depends  greatly  on  the  level  of  semantic  and  
syntactic rigor applied to the modeling effort 
and on explicit tool support. Correctness can 
be checked through model simulation, execu-
tion or review.
1.3. Syntax, Semantics, and Pragmatics  
 [2*, c2s2.2.2p6, 3*, c5s0]
Models can be surprisingly deceptive. The fact 
that  a  model  is  an  abstraction  with  missing  
information  can  give  people  the  illusion  that  
they completely understand the software after 
studying  a  single  model.  A  complete  model 
(“complete”  being  relative  to  the  modeling  
effort) may be a union of multiple submodels 
and any special function models. Examination 
of  and  decision-making  regarding  a  single  
model  within  this  collection  of  submodels  
may be problematic.

11-4   SWEBOK
®
 GUIDE V4.0
Understanding   the   precise   meanings   of   
modeling  constructs  can  also  be  difficult.  
Syntactic and semantic rules define modeling 
languages.  For  textual  languages,  syntax  is  
defined using a notation grammar that defines 
valid  language  constructs  (e.g.,  Backus-Naur  
form (BNF)). For graphical languages, syntax 
is defined using graphical models called meta-
models.  As  with  BNF,  metamodels  define  a  
graphical  modeling  language’s  valid  syntac-
tical  constructs.  In  addition,  the  metamodel  
defines how these constructs can be composed 
to produce valid models.
Semantics  for  modeling  languages  specify  
the  meaning  attached  to  the  entities  and  
relations   captured   within   the   model.   For   
example, a simple diagram of two boxes con-
nected  by  a  line  is  open  to  various  interpre-
tations. Knowing that the diagram on which 
the  boxes  are  placed  and  connected  is  an  
object  diagram  or  an  activity  diagram  can  
assist in interpreting this model. 
As  a  practical  matter,  the  semantics  of  
a  specific  software  model  are  usually  fairly  
clear  due  to  the  model’s  use  of  a  modeling  
language,  the  way  that  modeling  language  
expresses  entities  and  relations  within  that  
model,  the  experience  and  skill  of  the  mod-
elers, and the context within which the mod-
eling  has  been  undertaken  and  represented.  
Meaning is communicated through the model 
even  in  the  presence  of  incomplete  informa-
tion through abstraction. Pragmatics explains 
how  meaning  is  embodied  in  the  model  and  
its context and how it is communicated effec-
tively to other software engineers.
However,  there  are  still  instances  where  
caution  is  needed  regarding  modeling  and  
semantics.   For   example,   any   model   parts   
imported from another model or library must 
be  examined  for  semantic  assumptions  that  
conflict   with   the   new   modeling   environ-
ment;  these  conflicts  might  not  be  obvious.  
The model should be checked for documented 
assumptions.  Although  the  imported  mod-
eling syntax might be the same, it might mean 
something quite different in the new environ-
ment, which is a different context. Also, con-
sider  that  as  software  matures  and  changes  
are  made,  semantic  discord  can  be  intro-
duced,  leading  to  errors.  With  many  soft-
ware  engineers  working  on  part  of  a  model  
over time, and with tool updates and perhaps 
new requirements, there are opportunities for 
portions of the model to represent something 
different from the original author’s intent and 
initial model context.
1.4. Preconditions, Postconditions, and Invariants 
 [2*, c4s4, 4*, c10s4p2, c10s5p2p4]
When    modeling    functions    or    methods,    
the  software  engineer  typically  starts  with  
assumptions about the software’s state before, 
during and after the function or method exe-
cutes.  These  assumptions  are  essential  to  the  
correct  operation  of  the  function  or  method  
and  are  grouped,  for  discussion,  as  a  set  of  
preconditions, postconditions and invariants. 
• Preconditions are conditions that must be 
satisfied before execution of the function 
or method. If these preconditions do not 
hold  before  execution  of  the  function  or  
method,  the  function  or  method  might  
produce erroneous results.
• Postconditions  are  conditions  guaranteed  
to  be  true  after  the  function  or  method  
has  executed  successfully.  Typically,  the  
postconditions  represent  how  the  soft-
ware’s state has changed, how parameters 
passed  to  the  function  or  method  have  
changed, how data values have changed, 
or how the return value has been affected.
• Invariants are conditions within the oper-
ational environment that persist (in other 
words,  do  not  change)  before  and  after  
execution  of  the  function  or  method.  
These  invariants  are  relevant  and  neces-
sary  to  the  software  and  to  the  correct  
operation of the function or method.
2. Types of Models
A  typical  model  consists  of  an  aggregation  
of  submodels.  Each  submodel  is  a  partial  
description  and  is  created  for  a  specific  pur-
pose. A submodel may comprise one or more 

SOFTWARE ENGINEERING MODELS AND METHODS   11-5
diagrams.  The  collection  of  submodels  may  
use  multiple  modeling  languages  or  a  single  
modeling  language.  The  unified  modeling  
language  (UML)  recognizes  a  rich  collec-
tion  of  modeling  diagrams.  These  diagrams,  
along with the modeling language constructs, 
are used in two common model types: struc-
tural  models  and  behavioral  models.  (See  
Section  1.1.)  Depending  on  modeling  lan-
guages,  there  can  be  other  types  of  models.  
For instance, the systems modeling language 
(SysML) provides two other types of models: 
requirements models and parametric models.
2.1. Structural Modeling 
 [1*, c7s2.2, c7s2.5, c7s3.1, c7s3.2, 3*, c5s3, 
 c8s1, 4*, c4, 17]
Structural   models   illustrate   the   software’s   
physical  or  logical  composition  of  software  
from  its  various  component  parts.  Structural 
modeling   establishes   the   defined   boundary   
between  the  software  being  implemented  or  
modeled and the environment in which it is to 
operate. Some common structural constructs 
used in structural modeling are composition, 
decomposition,  generalization,  and  special-
ization  of  entities;  identification  of  relevant  
relations and cardinality between entities; and 
the  definition  of  process  or  functional  inter-
faces.  Structure  diagrams  provided  by  the  
UML  for  structural  modeling  include  class,  
component,  object,  deployment,  and  pack-
aging diagrams.
  Information  modeling  is  a  kind  of  struc-
tural   modeling   and   focuses   on   data   and   
other  information.  An  information  model  is  
an  abstract  representation  that  identifies  and  
defines  a  set  of  concepts,  properties,  relations  
and constraints on data entities. The semantic 
or conceptual information model is often used 
to provide some formalism and context to the 
software as viewed from the problem perspec-
tive,  without  concern  for  how  this  model  is  
mapped to the implementation of the software. 
The semantic or conceptual information model 
is an abstraction and, as such, includes only the 
concepts,  properties,  relations  and  constraints  
needed  to  conceptualize  a  real-world  view  of  
the  information.  Subsequent  transformations  
of  the  semantic  or  conceptual  information  
model  become  logical  and  then  physical  data  
models as implemented in the software.
2.2. Behavioral Modeling  
 [1*, c7s2.1, c7s2.3, c7s2.4, 2*, c9s2, 3*, 
  c5s4, 8, c1s5.4]
Behavioral  models  identify  and  define  soft-
ware  functions.  Behavioral  models  generally  
take  three  basic  forms:  state  machines,  con-
trol-flow models and data-flow models. State 
machines  provide  a  model  that  represents  
the software as a collection of defined states, 
events  and  transitions.  The  software  tran-
sitions  from  one  state  to  the  next  through  a  
guarded  or  unguarded  triggering  event  that  
occurs in the modeled environment. Control-
flow models depict how a sequence of events 
causes  processes  to  be  activated  or  deacti-
vated.  Data-flow  models  represent  data-flow  
behavior  as  a  sequence  of  steps  where  data  
moves  through  processes  toward  data  stores  
or  data  sinks.  These  models  are  described  in  
the  way  of  event-triggered,  time  concepts  
(i.e.,  logical,  physical,  discrete,  continuous,  
relative,  or  absolute  time),  or  combinations  
thereof. Behavioral diagrams provided by the 
UML  for  behavioral  modeling  include  use  
case,  activity,  state  machine,  and  interaction  
(sequence, communication, timing, and inter-
action overview) diagrams.
3. Analysis of Models
The  development  of  models  allows  the  soft-
ware  engineer  to  study,  reason  about  and  
understand    software    structure,    function,    
operational  use  and  assembly  considerations.  
Analysis  of  constructed  models  is  needed  to  
ensure  that  the  models  are  complete,  con-
sistent   and   correct   enough   to   serve   their   
intended purpose for the stakeholders.
The following sections briefly describe the 
analysis  techniques  generally  used  to  ensure  
that the software engineer and other relevant 
stakeholders  gain  appropriate  value  from  the  
development and use of models.

11-6   SWEBOK
®
 GUIDE V4.0
3.1. Analyzing for Completeness  
 [3*, c4s1.1p7, c4s6, 5*, pp8-11]
To  ensure  software  fully  meets  the  needs  of  
the  stakeholders,  completeness  —  from  the  
requirements elicitation process to code imple-
mentation  —  is  critical.  Completeness  is  the  
degree to which all specified requirements have 
been implemented and verified. Engineers can 
check models for completeness with a modeling 
tool  that  uses  structural  analysis  and  state-
space reachability analysis (which ensure some 
set of correct inputs reach all paths in the state 
models). Models may also be checked manually 
for  completeness  by  using  inspections  or  other  
review  techniques.  (See  the  Software  Quality  
KA.)  Errors  and  warnings  generated  by  these  
analysis tools and found by inspection or review 
indicate  that  corrective  actions  are  probably  
needed to ensure model completeness.
3.2. Analyzing for Consistency  
 [3*, c4s1.1p7, c4s6, 5*, pp8-11]
Consistency  is  the  degree  to  which  models  
contain  no  conflicting  requirements,  asser-
tions,  constraints,  functions  or  component  
descriptions.  Typically,  consistency  checking  
is accomplished with the modeling tool using 
an  automated  analysis  function.  Models  may  
also   be   checked   manually   for   consistency   
using inspections or other review techniques. 
(See the Software Quality KA.) As with com-
pleteness,  errors  and  warnings  generated  by  
these analysis tools and found by inspection or 
review indicate the need for corrective action.
3.3. Analyzing for Correctness  [5*, pp8-11]
Correctness  is  the  degree  to  which  a  model  
satisfies  its  software  requirements  and  soft-
ware  design  specifications,  is  free  of  defects,  
and  ultimately  meets  the  stakeholders’  needs.  
Analyzing  for  correctness  includes  verifying  
the  model’s  syntactic  correctness  (that  is,  cor-
rect  use  of  the  modeling  language  grammar  
and  constructs)  and  semantic  correctness  (that  
is,  use  of  the  modeling  language  constructs  to  
correctly  represent  the  meaning  of  that  which  
is being modeled). To analyze a model for syn-
tactic and semantic correctness, one analyzes it 
— either automatically (e.g., using the modeling 
tool  to  check  for  model  syntactic  correctness)  
or manually (using inspections or other review 
techniques)  —  searching  for  possible  defects  
and then removing or repairing the confirmed 
defects before the software is released for use.
3.4. Analyzing for Traceability  
 [3*, c4s7.1, c4s7.2]
Developing  software  typically  involves  using,  
creating  and  modifying  many  work  products  
such as planning documents, process specifica-
tions, software requirements, diagrams, designs 
and  pseudo-code,  handwritten  and  tool-gen-
erated  code,  manual  and  automated  test  cases  
and  reports,  and  files  and  data.  These  work  
products  may  share  various  dependency  rela-
tionships (e.g., uses, implements and tests). As 
software is developed, managed, maintained or 
extended, these traceability relationships must 
be  mapped  and  controlled  to  demonstrate  the  
software  requirements’  consistency  with  the  
software  model  (see  Requirements  Tracing  in  
the Software Requirements KA) and the many 
work  products.  Use  of  traceability  typically  
improves  the  management  of  software  work  
products  and  software  process  quality  and  
assures  stakeholders  that  all  requirements  are  
satisfied.  Traceability  enables  change  analysis  
once  the  software  is  developed  and  released  
because  relationships  to  software  work  prod-
ucts  can  easily  be  traversed  to  assess  change  
impact. Modeling tools typically help automat-
ically  or  manually  specify  and  manage  trace-
ability links among requirements, design, code 
and/or test entities that might be represented in 
the models and other software work products. 
(For more information on traceability, see the 
Software Configuration Management KA.)
3.5. Analyzing for Interaction  
 [2*, c10, c11, 3*, c29s1.1, c29s5, 4*, c5]
Interaction analysis focuses on the communica-
tions or control-flow relations between entities 
used to accomplish a specific task or function 

SOFTWARE ENGINEERING MODELS AND METHODS   11-7
within   the   software   model.   This   analysis   
examines  the  dynamic  behavior  of  the  inter-
actions  among  the  software  model’s  different  
parts, including other software layers (such as 
the  operating  system,  middleware  and  appli-
cations). Examining interactions between the 
computer  software  application  and  the  user  
interface  software  might  also  be  important  
for  some  software  applications.  Some  soft-
ware modeling environments provide simula-
tion facilities to study aspects of the dynamic 
behavior   of   modeled   software.   Stepping   
through  the  simulation  allows  the  software  
engineer to review the interaction design and 
verify that the software’s different parts work 
together to provide the intended functions.
4. Software Engineering Methods
Software  engineering  methods  provide  an  
organized  and  systematic  approach  to  devel-
oping  software  for  a  target  computer.  There  
are numerous methods from which to choose, 
and the software engineer needs to choose an 
appropriate  method  or  methods  for  the  soft-
ware  development  task  at  hand.  This  choice  
can  dramatically  affect  the  success  of  the  
project.  When  software  engineers,  working  
with people who have the right skill sets and 
the right tools, use these software engineering 
methods,  they  can  visualize  the  software’s  
details and ultimately transform the represen-
tation into a working set of code and data.
Selected   software   engineering   methods   
are discussed below. The topic areas are orga-
nized into discussions of Heuristic Methods, 
Formal  Methods,  Prototyping  Methods  and  
Agile Methods.
4.1. Heuristic Methods  [1*, c13, c15, c16, 3*, 
c2s2.2, c7s1, c5, 8,  pp.xiii-xvii  9, c2s2, 11, 
 c1, 12, c1s1, 19, pp.220-242]
Heuristic  methods  are  experience-based  soft-
ware engineering methods that are fairly widely 
practiced  in  the  software  industry.  This  topic  
area contains five broad discussion categories: 
structured  analysis  and  design  methods,  data  
modeling  methods,  object-oriented  analysis  
and design methods, aspect-oriented develop-
ment  methods,  and  model-driven  and  mod-
el-based development methods.
• Structured   analysis   and   design   methods: 
These   methods   develop   the   software   
model  primarily  from  a  functional  or  
behavioral  viewpoint.  It  starts  from  a  
high-level view of the software (including 
data  and  control  elements).  It  then  pro-
gressively   decomposes   or   refines   the   
model  components  through  increasingly  
detailed  designs.  The  detailed  designs  
eventually  converge  to  specific  software  
details   or   specifications   that   must   be   
coded  (by  hand,  automatically  generated  
or both), built, tested and verified.
• Data  modeling  methods:  The  data  model  
is constructed from the viewpoint of the 
data or information used. Data tables and 
relationships define the data models. This 
data  modeling  method  is  used  primarily  
to  define  and  analyze  data  requirements  
supporting   database   designs   or   data   
repositories  typically  found  in  business  
software, where data is actively managed 
as a business systems resource or asset. 
• Object-oriented  analysis  and  design  methods: 
The object-oriented model is represented as 
a collection of objects that encapsulate data 
and  relationships  and  interact  with  other  
objects  through  methods.  Objects  may  be  
real-world  items  or  virtual  items.  These  
methods  build  models  using  diagrams  to  
constitute  selected  views  of  the  software.  
Progressive refinement of the models leads 
to  a  detailed  design.  The  detailed  design  
is   then   either   evolved   through   succes-
sive  iterations  or  transformed  (using  some  
mechanism) into the implementation view 
of  the  model,  where  the  code  and  pack-
aging for eventual software product release 
and  deployment  are  expressed.  Popular  
object-oriented approaches include Unified 
Process  (UP)  and  specific  implementa-
tions  of  UP,  such  as  Rational  Unified  
Process (RUP). (See Software Design KA, 
Model-Based Requirements and Software 
Requirements KA.)

11-8   SWEBOK
®
 GUIDE V4.0
• Aspect-Oriented Development Methods: The 
aspect-oriented approach aims to separate 
crosscutting concerns from non-crosscut-
ting  ones  in  the  system  and  keeps  them  
encapsulated  throughout  the  entire  life  
cycle to solve their scattering and tangling 
problem. Aspect is the unit of modularity 
to  encapsulate  crosscutting  concerns.  At  
the  software  level,  there  is  a  “weaver”  
that  is  in  charge  of  joining  the  portions  
of   functionality   (advices)   encapsulated   
in  the  incumbencies  at  certain  points  of  
base  behavior  (join  points),  according  to  
well-defined predicates (pointcuts).
• Model-Driven          and          Model-Based          
Development    Methods:    Model-Driven    
Development   (MDD)   is   an   approach   
using   models   as   primary   artifacts   of   
the  development  process.  In  MDD,  usu-
ally  the  implementation  or  other  models  
are  (semi)automatically  transformed  from  
the  models.  Model-Based  Development  
(MBD) uses models to analyze the system, 
where  models  are  not  necessarily  the  pri-
mary  artifacts.  Some  literature  refers  to  
MBD  as  the  acronym  for  Model-Based  
Design.  Model-Based  Design  is  a  mod-
el-centric   approach   to   developing   con-
trol,  signal  processing,  communications,  
and   other   dynamic   systems,   focusing   
on  executable  specification  and  simula-
tion.  See  Software  Design  KA.  Model-
Driven  Requirements  and  Model-Based  
Requirements apply the same mentality to 
specification of software requirements, see 
the  Software  Requirements  KA  for  more  
information on this topic. MDD/MBD is a 
prerequisite to Model-Based Architecture, 
see    the    Software    Architecture    KA.    
Sometimes,  test  cases  are  generated  from  
models, see the Software Testing KA.
4.2. Formal Methods  
 [1*, c18, 3*, c27, 5*, pp8-24, 10, pp.xi-xiv]
Formal   methods   are   software   engineering   
methods   that   apply   rigorous,   mathemati-
cally based notation and language to specify, 
develop  and  verify  the  software.  Through  
use  of  a  specification  language,  the  software  
model can be systematically checked for con-
sistency  (or  lack  of  ambiguity),  complete-
ness,  and  correctness,  either  automatically  
or  semiautomatically.  This  topic  is  related  to  
the  Formal  Analysis  section  in  the  Software  
Requirements KA. 
This  section  addresses  specification  lan-
guages,  program  refinement  and  derivation,  
formal   verification,   logical   inference,   and   
lightweight formal methods.
• Specification  languages: Specification  lan-
guages  provide  the  mathematical  basis  
for  a  formal  method.  Specification  lan-
guages  are  formal,  higher-level  computer  
languages  (not  a  classic  3rd-generation  
language  (3GL)  programming  language)  
used  during  the  software  specification,  
requirements analysis and/or design stages 
to describe specific input/output behavior. 
Specification  languages  are  not  directly  
executable  languages.  Instead,  they  typ-
ically  comprise  a  notation  and  syntax,  
semantics for the use of the notation, and 
a set of allowed relations for objects. 
• Program     refinement     and     derivation: 
Program refinement creates a lower-level 
(or  more  detailed)  specification  using  a  
series  of  transformations.  Through  suc-
cessive   transformations,   the   software   
engineer  derives  an  executable  represen-
tation  of  a  program.  Specifications  may  
be refined, adding details until the model 
can  be  formulated  in  a  3GL  program-
ming  language  or  in  an  executable  por-
tion of the chosen specification language. 
This   specification   refinement   is   made   
possible  by  defining  specifications  with  
precise semantic properties. For example, 
the  specifications  must  set  out  not  only  
the   relationships   between   entities   but   
also the exact runtime meanings of those 
relationships and operations.
• Formal  verification:  Model  checking  is  a  
formal  verification  method.  It  typically  
involves  performing  a  state-space  explo-
ration  or  reachability  analysis  to  demon-
strate that the represented software design 

SOFTWARE ENGINEERING MODELS AND METHODS   11-9
has or preserves certain model properties 
of interest. An example of model checking 
is an analysis that verifies correct program 
behavior under all possible interleaving of 
event or message arrivals. Formal verifica-
tion requires a rigorously specified model 
of  the  software  and  its  operational  envi-
ronment. This model often takes the form 
of a finite-state machine or other formally 
defined automaton.
• Logical  inference:  Logical  inference  is  a  
method  of  designing  software  that  spec-
ifies   preconditions   and   postconditions   
around   each   significant   design   block.   
Using mathematical logic, it develops the 
proof  that  those  preconditions  and  post-
conditions  must  hold  under  all  inputs.  
This  allows  the  software  engineer  to  pre-
dict   software   behavior   without   having   
to   execute   the   software.   Some   inte-
grated development environments (IDEs) 
include ways to represent these proofs and 
the design or code.
• Lightweight  Formal  Methods:  Lightweight  
formal      methods      are      lightweight      
approaches     that     balance     practical     
usability  and  rigorous  verification.  For  
instance, Alloy takes from formal specifi-
cation the idea of a precise and expressive 
notation based on a tiny core of simple and 
robust  concepts,  but  it  replaces  conven-
tional analysis based on theorem proving 
with a fully automatic analysis that gives 
immediate   feedback.   Unlike   theorem   
proving, this analysis is not “complete”: it 
examines only a finite space of cases.
4.3. Prototyping Methods  
 [1*, c12s2, 3*, c2s3.1, 6*, c7s3p5]
Software prototyping  is  an  activity  that  gen-
erally  creates  incomplete  or  minimally  func-
tional   versions   of   a   software   application,   
usually  for  trying  out  specific  new  features;  
soliciting  feedback  on  software  requirements  
or  user  interfaces;  further  exploring  software  
requirements,   software   design,   or   imple-
mentation  options;  or  gaining  some  other  
useful insight into the software. The software 
engineer   selects   a   prototyping   method   to   
first  understand  the  least  understood  soft-
ware  aspects  or  components.  This  approach  
contrasts   with   other   software   engineering   
methods that usually begin development with 
the  best-understood  portions  first.  Typically,  
the prototype does not become the final soft-
ware  product  without  extensive  development  
rework or refactoring.
This  section  briefly  discusses  prototyping  
styles, targets and evaluation techniques.
• Prototyping    style:    Prototyping    styles    
describe the various approaches to devel-
oping  prototypes.  A  prototype  can  be  
developed  as  throwaway  code  or  a  paper  
product,  as  an  evolution  of  a  working  
design,  or  as  an  executable  specification.  
Different prototyping life cycle processes 
are typically used for each style. The style 
chosen is based on the type of results the 
project  needs,  the  quality  of  the  results  
needed and the results’ urgency.
• Prototyping target: The prototyping target 
is the specific product served by the pro-
totyping effort. Examples of prototyping 
targets  are  a  requirements  specification,  
an  architectural  design  element  or  com-
ponent, an algorithm, and a human-ma-
chine user interface.
• Prototyping   evaluation   techniques:   The   
software engineer or other project stake-
holders may use or evaluate the prototype 
in  many  ways,  driven  primarily  by  the  
underlying  reasons  that  led  to  prototype  
development.  Prototypes  may  be  evalu-
ated  or  tested  against  the  implemented  
software  or  target  requirements  (e.g.,  a  
requirements  prototype).  The  prototype  
might  also  serve  as  a  model  for  future  
software  development  (e.g.,  as  in  a  user  
interface specification).
4.4. Agile Methods  
 [3*, c3, 6*, c7s3p7, 7*, c6, App. A,  
 13, 14, 15, 16, 18]
Agile methods were developed in the 1990s to 
reduce the apparent large overhead associated 

11-10   SWEBOK
®
 GUIDE V4.0
with  heavyweight,  plan-based  methods  used  
in large-scale software development projects. 
Agile   methods   are   considered   lightweight   
because  of  their  short,  iterative  development  
cycles, self-organizing teams, simpler designs, 
code   refactoring,   test-driven   development,   
frequent customer involvement and emphasis 
on  creating  a  demonstrable  working  product  
with each development cycle. Agile methods 
can  be  seen  as  an  application  of  the  Deming  
improvement   cycle   of   Plan-Do-Check-Act   
(PDCA)    to    software    engineering.    For    
example,  EVO,  which  is  one  of  the  earliest  
agile methods, is known as a practical way to 
implement the PDCA cycle incrementally.
Many Agile methods are available in the lit-
erature. Some more popular approaches, dis-
cussed  here  briefly,  include  rapid  application  
development  (RAD),  eXtreme  programming  
(XP),   Scrum,   feature-driven   development   
(FDD), and Lean software development.
• R AD: RAD methods are used primarily 
in data-intensive, business systems appli-
cation   development.   RAD   is   enabled   
by   special-purpose   database   develop-
ment tools used by software engineers to 
quickly  develop,  test  and  deploy  new  or  
modified business applications.
• XP:  This  approach  uses  stories  or  sce-
narios  for  requirements,  develops  tests  
first, has direct customer involvement on 
the  team  (typically  defining  acceptance  
tests),  uses  pair  programming,  and  pro-
vides  continuous  code  refactoring  and  
integration.  Stories  are  decomposed  into  
tasks,  prioritized,  estimated,  developed  
and  tested.  Each  software  increment  is  
tested with automated and manual tests. 
An increment may be released frequently, 
such as every couple of weeks.
• Scrum:   This   Agile   approach   is   more   
project   management-friendly   than   the   
others.  The  Scrum  master  manages  the  
activities  within  the  project  increment.  
Each increment is called a sprint and lasts 
no more than 30 days. The product owner 
determines   which   items   go   into   the   
product backlog and developed a product 
backlog  item  (PBI)  list.  The  tasks  from  
this  list  are  identified,  defined,  priori-
tized and estimated. A working version of 
the software is tested and released in each 
increment. Daily Scrum meetings ensure 
work is managed according to the plan.
• FDD: This is a model-driven, short, iter-
ative   software   development   approach   
using  a  five-phase  process:  (1)  develop  a  
product  model  to  scope  the  breadth  of  
the  domain,  (2)  create  the  list  of  needs  
or features, (3) build the feature develop-
ment  plan,  (4)  develop  designs  for  itera-
tion-specific  features,  and  (5)  code,  test,  
and  then  integrate  the  features.  FDD  is  
similar to an incremental software devel-
opment  approach.  It  is  similar  to  XP,  
except  that  code  ownership  is  assigned  
to  individuals  rather  than  to  the  team.  
In addition, FDD emphasizes an overall 
architectural  approach  to  the  software,  
which  promotes  building  features  cor-
rectly  the  first  time  rather  than  rely  on  
continual refactoring.
•    Lean: This is an application of lean man-
ufacturing  principles  adapted  from  the  
Toyota  Production  System  to  software  
development.  The  approach  adopts  the  
strategy  of  making  a  Minimum  Viable  
Product,  in  which  a  team  releases  the  
simplest version of its product. The team 
learns  feedback  from  users  and  iterates  
based  on  the  feedback.  The  concept  of  
Lean  is  to  optimize  the  entire  develop-
ment process, rather than optimizing the 
individual development process. By over-
looking  the  entire  value  flow,  including  
design,  manufacturing,  sales,  and  ser-
vice  delivery,  this  approach  optimizes  
the flow to quickly deliver the service to 
users. Kanban is also lightweight process 
that applies many of the Lean. However, 
they  are  some  fundamental  differences  
because    Kanban    supports    managing    
workflow and visualization.
There  are  many  more  variations  of  Agile  
methods  in  the  literature  and  in  practice.  
There will always be a place for heavyweight, 

SOFTWARE ENGINEERING MODELS AND METHODS   11-11
plan-based  software  engineering  methods  as  
well as places where Agile methods shine. In 
addition, new methods are arising from com-
binations  of  Agile  and  plan-based  methods:  
Practitioners are defining these new methods 
to  balance  features  from  heavyweight  and  
lightweight   methods   based   primarily   on   
organizational  business  needs.  These  busi-
ness  needs,  as  typically  identified  by  project  
stakeholders,  should  and  do  drive  the  choice  
of software engineering method.
Large-scale and enterprise agile approaches 
reflect  recent  efforts  to  manage  many  agile  
teams and apply agile principles and practices 
across  the  enterprise  while  keeping  promises  
of agile development methodologies (see agile 
models in Software Engineering Process KA).
Agile methodology leads to shorter release 
cycles. Then, Release engineering contributes 
lightweight release cycle.  Release engineering 
is  a  sub-discipline  in  software  engineering  
concerned  with  the  compilation,  assembly,  
and delivery of source code into finished prod-
ucts or other software components. The trend 
cycle in Agile would be Integration, Building, 
and Testing that Release Engineering focuses 
on.  DevOps  is  often  conflated  with  agile  
and  continuous  deployment  approaches  of  
software  development.  To  avoid  conflating,  
release  management  acts  as  a  method  for  
filling  the  collaboration  gap  between  devel-
opment  and  operations.  Release  managers  
need to monitor the development process and 
the promotion schedule for each release. The 
key to managing software releases in DevOps 
that keeps pace with deployment schedules is 
through automated management tools such as 
a continuous integration (CI) system.
MATRIX OF TOPICS VS. REFERENCE MATERIAL
Budgen 2021 [1*]Mellor and Balcer 2002 [2*]Sommerville 2011 [3*]Page-Jones 1999 [4*]Wing 1990 [5*]Brookshear 2008 [6*]{Brookshear, 2008, Computer Science: An Overview}Boehm and Turner 2003 [7*]
1. Modeling
1.1. Modeling  
Principles
c3s3, c3s5, 
c4s2, c7s1,  
c7s2
c2s2c5s0
1.2. Properties  
and Expression  
of Models
c7s2 , c7s3c4s1.1p7,  
c4s6p3,  
c5s0p3
1.3. Syntax,  
Semantics and 
Pragmatics
c2s2.2.2p6c5s0
1.4. Preconditions, 
Postconditions and 
Invariants
c4s4c10s4p2,  
c10s5p2p4

11-12   SWEBOK
®
 GUIDE V4.0
2. Types of  
Models
2.1. Structural  
Modeling
c9s5, c10s5c8s1, c5s3c4
2.2. Behavioral  
Modeling
c9s3, c10s6c9s2c5s4
3. Analysis  
of Models
3.1. Analyzing for 
Completeness
c4s1.1p7,  
c4s6
pp8-11
3.2. Analyzing for 
Consistency
c4s1.1p7,  
c4s6
pp8-11
3.3. Analyzing for 
Correctness 
pp8-11
3.4. Traceabilityc4 s7.1, c4 s7. 2
3.5. Interaction  
Analysis
c10, c11c29s1.1,  
c29s5
c5
4. Software 
Engineering  
Methods
4.1. Heuristic  
Methods
c13c2s2.2, 
c7s1, c 5s4.1
4.2. Formal  
Methods
c18s2c27pp8-24
4.3. Prototyping  
Methods
c14s1, c14s2,  
c14s3
c2s3.1c7s3p5
4.4. Agile  
Methods
c14s5, c14s6c3c7s3p7c6,  
app. 
A
REFERENCES 
[1*]  D Budgen, Software Design: Creating 
Solutions for Ill-Structured Problems, 3rd 
Edition, CRC Press, 2021.
[2*] S.J. Mellor and M.J. Balcer, Executable 
UML: A Foundation for Model-Driven 
Architecture, 1st ed. Boston: Addison-
Wesley, 2002.
[3*]  I. Sommerville, Software Engineering, 9th 
ed. New York: Addison-Wesley, 2011.
[4*] M. Page-Jones, Fundamentals of Object-
Oriented Design in UML, 1st ed. 
Reading, MA: Addison-Wesley, 1999.
[5*] J.M. Wing, “A Specifier’s Introduction 
to Formal Methods,” Computer, vol. 23, 
pp. 8, 10-23, 1990.
[6*] J.G. Brookshear, Computer Science: An 
Overview, 10th ed. Boston: Addison-
Wesley, 2008.
[7*] B. Boehm and R. Turner, Balancing 
Agility and Discipline: A Guide for 
the Perplexed. Boston: Addison-
Wesley, 2003.
[8] B. Selic and S. Gerard, Modeling and 
Analysis of Real-Time and Embedded 

SOFTWARE ENGINEERING MODELS AND METHODS   11-13
Systems with UML and MARTE: 
Developing Cyber-Physical Systems, 
Morgan Kaufmann, 2013.
[9] M. Brambilla, J. Cabot, and M. 
Wimmer, Model-Driven Software 
Engineering in Practice, Morgan & 
Claypool Publishers, 2017.
[10] D. Jackson, Software Abstractions, 
revised edition, The MIT Press, 2016.
[11] R. Aarenstrup, Managing Model-
Based Design, CreateSpace Independent 
Publishing Platform, 2015.
[12] C.  Larman, Applying UML and 
Patterns: An Introduction to Object-
oriented Analysis and Design and Iterative 
Development, Germany: Prentice Hall 
PTR, 2005.
[13] M. Poppendieck and T. Poppendieck, 
Lean Software Development: An 
Agile Toolkit, Addison-Wesley 
Professional, 2003.
[14] T. Ohno, Toyota Production System: 
Beyond Large-Scale Production, Taylor & 
Francis Distribution, 2021
[15] D.J.  Anderson, Kanban: Successful 
Evolutionary Change for Your Technology 
Business, Blue Hole Press; Blue Book ed. 
edition, 2010.
[16] J. Goodpasture, Project management the 
agile way: Making it work in the enter-
prise, J. Ross Publishing, 2010.
[17] ISO/IEC 19505-1:2012, Information 
technology — Object Management 
Group Unified Modeling Language 
(OMG UML) — Part 1: Infrastructure.
[18] ISO/IEC/IEEE 32675:2022, 
Information technology — DevOps — 
Building reliable and secure systems 
including application build, package and 
deployment.
[19] G. Kiczales, J. Lamping, A. Mendhekar, 
C. Maeda, C. Lopes, J. M. Loingtier, 
and J. Irwin, Aspect-oriented pro-
gramming, ECOOP’97, LNCS, Vol. 
1 2 41, 19 9 7.

12-1 
CHAPTER 12
Software Quality
ACRONYMS
CI/CDContinuous Integration/
Continuous Delivery
CoSQCost of Software Quality
COTSCommercial Off-The-Shelf
FMEAFailure Mode and Effects Analysis
F TAFault Tree Analysis
IV&VIndependent Verification and 
Validation
PDCAPlan-Do-Check-Act
PSPPersonal Software Process
QFDQuality Function Deployment
RCARoot Cause Analysis
SCMSoftware Configuration 
Management
SQASoftware Quality Assurance
SQAPSoftware Quality Assurance Plan
SQCSoftware Quality Control
SQMSoftware Quality Management
V&VVerification and Validation
INTRODUCTION
What  is  software  quality,  and  why  is  it  so  
important  that  it  is  included  in  many  knowl-
edge areas (KAs) of the SWEBOK Guide? One 
reason is that the term software quality is over-
loaded. Software quality may refer to the desir-
able characteristics of software products, to the 
extent  to  which  a  particular  software  product  
has   those   characteristics   (software   product   
quality),  and  to  the  processes,  tools  and  tech-
niques  used  to  achieve  those  characteristics  
(software  process  quality).  Over  the  years,  
authors and organizations have defined the term 
quality differently. Phil Crosby defined quality 
as  “conformance  to  requirements”  [2].  Watts  
Humphrey referred to it as “achieving excellent 
levels of “fitness for use” [3]. Meanwhile, IBM 
coined   the   phrase   “market-driven   quality,”   
where  the  “customer  is  the  final  arbiter”  [4].  
Finally,  fitness  for  purpose  is  also  a  term  that  
refers to software qualit. Fitness for purpose is 
the  suitability  of  a  product,  system,  or  service  
for use by the intended users, for the intended 
use,  in  the  intended  situations,  and  intended  
environmental conditions.
More  recently,  software  (product)  quality  
has  been  defined  as  the  “capability  of  a  soft-
ware  product  to  satisfy  stated  and  implied  
needs  under  specified  conditions”  [4]  and  as  
“the degree to which a software product meets 
established   requirements;   however,   quality   
depends  upon  the  degree  to  which  those  
established requirements accurately represent 
stakeholder  needs,  wants,  and  expectations”  
[6].  Both  definitions  embrace  the  premise  of  
conformance  to  requirements.  Neither  refers  
to  different  types  of  requirements  (require-
ments categorized according to functionality, 
reliability, performance, dependability, or any 
other  characteristic).  Significantly,  however,  
these definitions emphasize that quality is an 
important characteristic of requirements.
These   definitions   also   illustrate   another   
reason for the recurring discussions about soft-
ware quality throughout the SWEBOK Guide 
—   the   often-unclear   distinction   between   
software  quality  and software  quality  require-
ments  (“the  -ilities”  is  a  common  shorthand  
for  these  terms).  Software  quality  require-
ments (Quality of Service Constraints in the 
Software Requirements KA) are attributes of 
(or  constraints  on)  functional  requirements  
(what the system does). Software requirements 

12-2   SWEBOK
®
 GUIDE V4.0
may  also  specify  resource  use,  a  communi-
cation  protocol,  or  many  other  characteris-
tics (Technology Constraints in the Software 
Requirements   KA).   This   KA   attempts   to   
clarify requirements by using software quality 
in  the  broadest  sense  from  the  definitions  
above  and  by  using  software  quality  require-
ments  as  constraints  on  functional  require-
ments.  Software  product  quality  is  achieved  
by  conforming  to  all  requirements  regard-
less of specified characteristics or grouping or 
naming of requirements.
Software  quality  is  also  discussed  in  many  
other   SWEBOK   Guide   Knowledge   Areas   
because  it  is  a  basic  concept  of  a  software  engi-
neering effort. The primary goal for all engineered 
products  is  to  deliver  maximum  stakeholder  
value while balancing the constraints of develop-
ment, maintenance, and operational cost, some-
times characterized as fitness for use. Stakeholder 
value is expressed in requirements. For software 
products,  stakeholders  could  value  price  (what  
they  pay  for  the  product),  lead  time  (how  fast  
they get the product), and software quality. (See 
the  Software  Requirements  KA  for  a  broader  
discussion of this.)
The    software    process    quality    aspect,    
which is implied by the above, must be made 
explicit. The quality of a software process can 
be  also  observed  in  process  characteristics  
such as efficiency, effectiveness, usability, and 
learnability. Defects in that process will likely 
show  up  as  defects  in  the  resulting  software  
product, as well.
Finally,   the   Agile   and   DevOps   move-
ments  aim  at  improving  the  software  pro-
cess and product quality through compliance 
by  promoting  quick  iteration  feedback  loops  
and  eliminating  organizational  silos  by  col-
locating users and software engineers. Other 
practices like pair programming and the auto-
mation  of  development,  testing,  and  oper-
ations   services   also   bring   value,   improve   
efficiency, and can detect defects early. (Refer 
to the Process KA for Agile life cycles and the 
Software  Operations  KA  for  more  informa-
tion on DevOps processes.)
This KA provides an overview of practices, 
tools, and techniques for understanding soft-
ware  quality  and  planning  and  appraising  
the state of software quality during develop-
ment, maintenance and operation, from both 
a software product perspective and a software 
process  perspective.  Cited  references  provide  
additional details.
BREAKDOWN OF TOPICS FOR 
SOF TWARE QUALITY
The  breakdown  of  topics  for  the  Software  
Quality KA is presented in Figure 12.1.
Software Quality
Software Quality
Fundamentals
Software Quality
Management Process
Software Quality
Assurance Process
Software Quality
Tools
Software 
Engineering Culture 
and Ethics
Value and Cost 
of Quality
Standards, Models 
and Certifications
Software 
Dependability and 
Integrity Levels
Software Quality
Improvement
Plan Quality
Management
Evaluate Quality
Management
Perform corrective 
and Preventive Action
Prepare for Quality
Assurance
Perform Process
Assurance
Perform Product
Assurance
Figure 12.1. Breakdown of Topics for Software Quality

SOFTWARE QUALITY   12-3
1. Software Quality Fundamentals
Agreeing on what constitutes software quality 
for  all  stakeholders  and  communicating  that  
agreement   to   software   engineers   requires   
that  the  many  aspects  of  quality  be  formally  
defined  and  communicated.  The  main  chal-
lenges  the  software  engineer  faces  to  ensure  
quality include the following:
•    Difficulty in clearly defining requirements;
•    Maintaining    effective    communication    
with the client/user;
•    Deviations from specifications;
•    Architecture and design errors;
•    Coding errors;
•    Noncompliance  with  current  processes/
procedures;
•    Inadequate work product reviews and tests;
•    Documentation errors.
Software  quality  is  defined  as  “confor-
mance to established requirements; the capa-
bility  of  a  software  product  to  satisfy  stated  
and implied needs when under specified con-
ditions” [6]. It is further defined “by the degree 
to which a software product meets established 
requirements; however, quality depends upon 
the degree to which those established require-
ments accurately represent stakeholder needs, 
wants,  and  expectations”  [6].  Quality  often  
means the absence of defects. The word defect 
is  overloaded  with  too  many  meanings,  as  
engineers  and  others  use  the  word  to  refer  
to all different types of anomalies. However, 
different  engineering  cultures  and  standards  
often  understand  “defect”  and  other  terms  
as  having  more  specific  meanings.  To  avoid  
confusion, software engineers should use the 
meaning provided by their standards [14]:
• Error: “A human action that produces an 
incorrect result.” Also called human error;
• Defect:  (synonym  of  a  fault)  An  “imper-
fection  or  deficiency  in  a  work  product  
where that work product does not meet its 
requirements  or  specifications  and  needs  
to be either repaired or replaced.” A defect 
is inserted when a person developing the 
software  makes  an  error.  It  hides  in  the  
software until (and if ) it is discovered;
• Failure: The “termination of the ability of 
a  system  to  perform  a  required  function  
or  its  inability  to  perform  within  previ-
ously specified limits; an externally visible 
deviation  from  the  system’s  specification  
event in which a system or system compo-
nent does not perform a required function 
within  specified  limits.”  A  failure  is  pro-
duced when the software executes a defect.
A   software   engineer   should   understand   
software  quality  concepts,  characteristics,  and  
values and their application to the many devel-
opment,  maintenance,  and  operation  activi-
ties. An important concept is that the software 
requirements are expected to define the required 
software  quality  attributes.  Furthermore,  soft-
ware  requirements  influence  the  measurement  
methods  and  acceptance  criteria  for  assessing  
how  the  software  and  related  work  products  
achieve   the   desired   quality   levels.   Another   
important   concept   is   that   software   quality   
should  be  planned  early  and  assessed  at  many  
milestones   during   the   software   life   cycle.   
Finally,  how  to  adapt  software  quality  assur-
ance (SQA) activities to accommodate different 
life cycles, for example Agile software develop-
ment  is  presented  in  detail  in  the  Institute  of  
Electrical  and  Electronics  Engineers  (IEEE)  
Standard 730:2014 [6].
1.1.  Software Engineering Culture and Ethics  
 [1*, c1s1.6; c2s3] [5*]
An  organization’s  culture  affects  how  soft-
ware  engineers  influence  software  quality.  
As Iberle explains [19], software engineering 
practices   vary   depending   on   the   business   
model  (e.g.,  custom,  mass-market,  commer-
cial,  firmware)  and  the  industry  where  the  
software engineers work. Software engineers 
are  expected  to  share  a  commitment  to  soft-
ware  quality  in  the  context  of  their  industry  
and  as  part  of  their  culture.  A  healthy  soft-
ware engineering culture includes many char-
acteristics,  such  as  the  understanding  that  
trade-offs  among  cost,  schedule  and  quality  

12-4   SWEBOK
®
 GUIDE V4.0
are a basic tenet of any product’s engineering. 
A strong software engineering ethic assumes 
that  engineers  accurately  report  information,  
conditions  and  outcomes  related  to  quality.  
Ethics  also  play  a  significant  role  in  soft-
ware  quality  in  the  professional  culture  of  
engineering, and in the attitudes of software 
engineers.  The  IEEE  Computer  Society  and  
the  Association  for  Computing  Machinery  
(ACM)  have  developed  a  code  of  ethics  and  
professional  practice.  (See  Codes  of  Ethics  
and  Professional  Conduct  in  the  Software  
Engineering Professional Practice KA.)
1.2.  Value and Costs of Quality  [1*, c2s2.2]
One  major  factor  driving  resistance  to  imple-
menting   SQA   is   its   perceived   high   cost.   
However, not implementing basic SQA activ-
ities  can  be  costly  as  well.  Software  engineers  
should inform their administration of the risks 
they take when they are not fully committed to 
quality. This can be done by explaining the cost 
of  software  quality  concepts  to  management.  
Cost of software quality (CoSQ ) is defined as 
the sum of the following project costs:
•    Implementation   cost   of   planning   and   
construction   activities   (e.g.,   planning,   
designing, development);
•    Prevention   cost   of   activities   (process   
improvement, tools, training);
•    Appraisal costs activities for defect detec-
tion (e.g., reviews, audits, testing);
•    Nonconformance    and    rework    costs    
(internal    failure    cost    and    external    
failure cost).
The  CoSQ  can  be  broken  down  into  two  
top-level categories: conformance cost and non-
conformance cost. Conformance cost is the total 
of  all  investments  in  error  and  defect  detec-
tion   (appraisal)   and   prevention   activities.   
Appraisal  costs  arise  from  project  activities  
that  are  intended  to  find  errors  and  defects.  
These   include   testing   (as   detailed   in   the   
Software Testing KA) and reviews and audits 
(as detailed later in this KA). Appraisal costs 
extend to subcontracted software suppliers, if 
any.  Prevention  costs  include  investments  in  
software  process  improvement  (SPI)  efforts,  
quality   infrastructure,   quality   tools,   work   
product  templates  and  training.  These  costs  
might not be specific to a project; they often 
span the larger organization. 
Nonconformance  cost  is  the  total  of  all  
spending  dealing  with  errors  and  defects  that  
have   been   detected.   Pre-delivery   costs   are   
those  incurred  to  repair  errors  and  defects  
found  during  appraisal  activities  and  discov-
ered  before  the  software  product  is  delivered  
to  the  customer.  Post-Delivery  costs  include  
those  incurred  responding  to  software  fail-
ures discovered after delivery to the customer. 
External  costs  include  the  rework  needed  to  
repair  and  test  an  updated  release.  External  
costs  include  rework  and  repair  of  the  unin-
tended   and   uncompensated   side   effects   or   
consequences  of  defects.  However,  the  finan-
cial impact on the customer who encounters a 
failure  is  just  as  important.  For  example,  the  
customer’s  lost  productivity,  lost  data,  and  
potential  loss  of  reputation  in  the  market-
place  must  be  acknowledged  and  accounted  
for. Beyond the impact on the customer, low-
quality software can also impact the public and 
the  environment.    Software  engineers  should  
seek  the  optimal  CoSQ  —  the  minimal  total  
cost for a specified quality level. 
1.3.  Standards, Models, and Certifications  
 [1*, c4] [7, c24s24.2]
Sound  use  of  software  engineering  software  
standards  and  software  process  assessment  
and  improvement  improves  software  quality.  
One of the key general software engineering 
standards   is   ISO/IEC/IEEE   12207:2017,   
which  describes  the  software  life  cycle  pro-
cesses.  Foremost,  software  engineers  should  
know   the   key   software   engineering   stan-
dards that apply to their specific industry. As 
Iberle  discussed  [19],  the  practices  software  
engineers  use  vary  greatly  depending  on  the  
industry,  business  model  and  organizational  
culture where they work. For example, IEEE 
1228:1994 Standard for Software Safety Plans 
and IEEE 1633:2016 Recommended Practice 

SOFTWARE QUALITY   12-5
on   Software   Reliability   target   industries   
where safety and reliability are important.
The   Plan-Do-Check-Act   (PDCA)   para-
digms  differ  from  standards  in  that  it  often  
proposes  “best  practices”  for  software  engi-
neers from a specific perspective. (Refer to the 
Software  Engineering  Process  KA  for  more  
information  about  the  PDCA  paradigm  for  
software.) 
Other industry “best practices” models such 
as the Control Objectives for Information and 
Related  Technologies  (COBIT)  for  informa-
tion  technology  governance  [27],  the  Project  
Management Body of Knowledge (PMBOK®) 
for  project  management  [25],  the  Business  
Analysis Body of Knowledge (BABOK®) [28], 
the  Capability  Maturity  Model  Integration  
(CMMI)    [29]    and    The    Open    Group    
Architecture  Framework  (TOGAF)  propose  
software related practices that can improve the 
quality of software processes and products [30]. 
Software  organizations  can  also  consider  the  
possible advantages of obtaining registrations 
or  certifications  (e.g.,  ISO  9001  for  quality  
[10],  ISO  27001  for  security  [31],  (e.g.,  ISO  
9001 for quality [10], ISO 27001 for security 
[31] and ISO 20000 for operations [32]), and 
software engineers can also obtain Scrum and 
Scaled  Agile  Framework®  (SAFe®)  certifica-
tions for Agile processes [22]. The use of these 
models  and  certifications  have  been  shown  
to  augment  stakeholders’  confidence  that  the  
software  engineers’  knowledge  and  skills  are  
up to date and recognized internationally. 
1.4.  Software Dependability and Integrity 
Levels  [1*, c4s4.8, c7s7.3.3] [11]
Software-intensive   and   safety-critical   sys-
tems are those in which a system failure could 
harm human life, other living things, physical 
structures,  or  the  environment.  The  software  
in  these  systems  is  considered  safety-critical  
and  requires  the  use  of  systematic  methods  
and  tools  to  ensure  its  high  level  of  quality.  
A  growing  number  of  industries  are  using  
increasing   numbers   of   safety-critical   soft-
ware, including transportation systems, chem-
ical  and  nuclear  plants,  and  medical  devices.  
Software  failure  in  these  systems  could  have  
catastrophic  effects.  Engineers  use  industry  
standards,  such  as  software  considerations  in  
airborne  systems  and  equipment  certification  
DO-178C  [8]  and  railway  applications  EN  
50128  [18],  and  emerging  processes,  tools,  
and techniques to develop safety-critical soft-
ware  more  safely.  These  standards,  tools  and  
techniques  reduce  the  risk  of  injecting  faults  
into  the  software  and  thus  improve  software  
availability,   reliability,   and   maintainability.   
Software  engineers  and  their  managers  must  
understand the threats and issues and develop 
the  skills  needed  to  anticipate  and  prevent  
accidents before they occur [15].
Safety-critical   software   can   be   catego-
rized  as  direct  or  indirect.  Direct  software  is  
embedded in a safety-critical system, such as 
an aircraft’s flight control computer. Indirect 
software  includes  software  applications  used  
to  develop  safety-critical  software.  Indirect  
software  is  included  in  software  engineering  
environments and software test environments.
Three     complementary     techniques     for     
reducing   failure   risk   are   avoidance,   detec-
tion   and   removal,   and   damage   limitation.   
These  techniques  impact  software  functional  
requirements,  performance  requirements  and  
development processes. Increasing risk implies 
increasing  SQA  and  more  rigorous  review  
techniques such as inspections [16]. Higher risk 
levels might necessitate more thorough inspec-
tions of requirements, design, and code, or the 
use  of  more  formal  verification  and  valida-
tion  techniques.  Another  technique  for  man-
aging and controlling software risk is building 
assurance cases. An assurance case is a reasoned, 
auditable  artifact  created  to  support  the  con-
tention  that  its  claim  or  claims  are  satisfied.  
It  contains  the  following  relationships:  one  or  
more  claims  about  properties,  arguments  that  
logically  link  the  evidence  and  any  assump-
tions to the claims, and a body of evidence and 
assumptions supporting these arguments [9].
1.4.1.   Dependability  [7, c10] 
In cases where system failure may have severe 
consequences,    overall    dependability    (e.g.,    

12-6   SWEBOK
®
 GUIDE V4.0
hardware,   software,   and   human   or   oper-
ational  dependability)  is  the  main  quality  
requirement, aside from basic software func-
tionality,  for  the  following  reasons:  System  
failures affect many people; users often reject 
systems  that  are  unreliable,  unsafe,  or  inse-
cure; system failure costs could be important; 
and undependable systems might cause infor-
mation  loss.  Many  standards  address  dif-
ferent  perspectives  of  dependability,  such  as  
reliability  and  availability. System  and  soft-
ware  dependability  regroups  several  related  
quality characteristics: availability, reliability, 
maintainability and supportability, safety and 
security  [21].  When  developing  dependable  
software, engineers can apply tools and tech-
niques to reduce the risk of injecting faults into 
the intermediate deliverables or the final soft-
ware product. They can use static, dynamic, or 
formal methods for verification and validation 
(V&V), and testing processes, as well as other 
specialized techniques, methods, and tools to 
identify  defects  that  affect  dependability  as  
early as possible in the software life cycle [7*, 
c10.5]. Additionally, they may have to incor-
porate specific mechanisms into the software 
to  guard  against  external  attacks  and  to  tol-
erate faults during its operation.
1.4.2.  Integrity Levels of Software  
 [1*, c4s4.8, c7s7.3.2] [11]
Defining  integrity  levels  is  a  method  of  risk  
management. An integrity level is “a value rep-
resenting  project-unique  characteristics  (e.g.,  
complexity, criticality, risk, safety level, secu-
rity level, desired performance, and reliability) 
that  define  the  importance  of  the  system,  
software,  or  hardware  to  the  user”  [11].  The  
characteristics  used  to  determine  software  
integrity level vary depending on the intended 
application  and  use  of  the  system.  The  soft-
ware is a part of the system, and its integrity 
level is determined as a part of that system.
The   assigned   software   integrity   levels   
might change as the software evolves. Design, 
coding,  procedural  and  technology  features  
implemented  in  the  system  or  software  can  
raise or lower the assigned software integrity 
levels.  The  software  integrity  levels  estab-
lished  for  a  project  result  from  agreements  
among  the  acquirer,  supplier,  developer,  and  
independent assurance authorities. A software 
integrity level scheme is used to determine soft-
ware integrity levels [11].
Software  engineers  should  know  that  in  
certain   safety-critical   industries,   such   as   
avionics,   railways,   nuclear   power,   medical   
devices  and  many  others,  industry-specific  
guidance  can  require  a  certain  level  of  inde-
pendence  for  software  quality  activities  and  
can   assign   minimum   V&V   techniques   to   
be  used  by  integrity  level  (example  of  such  
techniques  are:  usability  analysis,  algorithm  
analysis,  boundary  value  analysis,  data  flow  
analysis, walk-through review [11][26]).
2. Software Quality Management Process
“Software  quality  management”  (SQM)  is  
concerned   with   coordinating   activities   to   
direct and control an organization with regard 
to  software  quality”  [6].
 
The  purpose  of  the  
Quality Management process is to assure that 
products,  services,  and  implementations  of  
the  quality  management  process  meet  orga-
nizational  and  project  quality  objectives  and  
achieve customer satisfaction.  
Software  engineers  can  learn  about  the  
SQM  process  in  the  many  software  engi-
neering  standards,  models,  and  certifications 
available and used widely in the industry. 
An important concept of SQM is the design 
and  upkeeping  of  a  Quality  Management  
System  (QMS).  As  proposed  by  ISO90003  
[26]  which  interprets  ISO9001  concepts  for  
the software industry.
QMS  defines  processes,  process  owners,  
requirements for the processes, measurements 
of the processes and their outputs, and feed-
back channels throughout the whole software 
life cycle. A QMS comprises many key activ-
ities:  SQA,  V&V,  reviews  and  audits,  soft-
ware configuration management (SCM), and 
requires  policies,  procedures,  and  processes  
to ensure that everyone involved understands 
what  is  expected  in  terms  of  software  pro-
cess  and  product  quality.  For  a  QMS  to  be  

SOFTWARE QUALITY   12-7
effective,   management   support   is   impera-
tive.  Management  support  implies  that  proj-
ects are trained to the QMS requirement and 
have enough resources to achieve the quality 
goal defined for it. Management sponsorship 
should  be  solicited  frequently  during  soft-
ware project review to ensure software quality 
activities  are  executed  and  nonconformities  
addressed.
For  a  software  project,  software  quality  
processes  consist  of  tasks  and  techniques  to  
indicate  how  software  plans  (e.g.,  software  
management,  development,  quality  manage-
ment or configuration management plans) are 
implemented  and  how  well  the  intermediate  
and final products meet their specified require-
ments.  Results  from  these  tasks  are  assem-
bled in reports for management. SQM process 
management is tasked with ensuring that the 
report results are accurate and acted upon.
Risk    management    can    also    play    an    
important role in delivering quality software. 
Incorporating  disciplined  risk  analysis  and  
management  techniques  into  the  software  
life cycle processes can help improve product 
quality.    (See    the    Software    Engineering    
Management KA for related material on risk 
management.)
2.1.  Software Quality Improvement  
 [1*, s9.9 and c9] [2] [3]
Software quality improvement (SQI) is done 
using  many  different  approaches  within  the  
software industry, including software process 
improvement  (SPI),  Six  Sigma,  Lean,  and  
Kaizen  just  to  name  a  few.  For  example,  the  
SPI  activities  seek  to  improve  process  effec-
tiveness,  efficiency,  and  other  characteristics  
to  improve  software  quality.  For  example,  
although SPI could be included in any of the 
first   three   categories,   many   organizations   
organize  SPI  into  a  separate  category  that  
might span many projects. 
Software product quality can be improved 
using  Lean  principles  as  well  as  an  iterative  
process   of   continual   improvement,   which   
includes management control, coordination of 
activities, and feedback from many concurrent 
processes:  (1)  the  process  of  improving  the  
software  life  cycle  processes;  (2)  the  pro-
cess  of  fault/defect  categorization,  detection,  
removal,  and  prevention;  and  (3)  a  personal  
improvement process. 
The  theory  and  concepts  behind  quality  
improvement  —  such  as  building  quality  
through the prevention and early detection of 
defects,  continual  improvement,  and  stake-
holder focus  — are also pertinent to software 
engineering. These concepts are based on the 
work  of  experts  in  quality  who  have  stated  
that  a  product’s  quality  is  directly  linked  to  
the  quality  of  the  process  used  to  create  it.  
Improvement  models  such  as  the  Plan-Do-
Check-Act (PDCA) improvement cycle, evo-
lutionary  delivery,  Kaizen,  and  techniques  
like quality function deployment (QFD) offer 
ways  to  specify  quality  objectives  and  deter-
mine whether they are met. 
Finally,  since  software  engineering  is  a  
complex  process,  it  cannot  be  reduced  to  a  
cookbook  of  procedures.  To  complement  the  
process  and  tools  improvement  movement,  
Humphrey  proposed  the  personal  software  
process  (PSP)  for  software  engineers  to  also  
assess  their  skills  and  knowledge  constantly  
and continually improve them as well. 
2.2.  Plan Quality Management [1*, c13]
Software quality planning includes determining 
which  quality  standards  and  models  are  to  be  
used, defining specific quality goals, estimating 
the effort to be used to achieve each goal; and 
deciding at what milestone the software quality 
activity should take place. In some cases, soft-
ware  quality  planning  also  includes  defining  
the software quality processes to be used.
First,   the   software   organization   must   
commit to quality by establishing their quality 
management  system  (QMS)  which  includes  
quality  management  policies,  objectives,  and  
procedures.  This  requires  that  the  respon-
sibility  and  authority  for  implementing  the  
QMS are assigned and that they are indepen-
dent of current project management teams.
An  approved  organizational  policy,  about  
software  quality,  helps  in  guiding  projects  

12-8   SWEBOK
®
 GUIDE V4.0
and  products  development  decisions  as  well  
as behavior of personnel. Software engineers 
should  promote  the  use  of  graphically  repre-
sented  processes  and  procedures  that  imple-
ment the quality policy and explain the roles, 
activities  to  be  executed  and  the  expected  
results  of  key  software  engineering  activi-
ties.  Consequently,  for  a  QMS  to  be  used  
in  improvement  its  processes  should  be  doc-
umented  with  its  user  in  mind  and  iden-
tify where quality controls are to be verified. 
Finally,  procedures  explain  in  detail  what  
steps are taken to execute a specific activity. 
2.3.  Evaluate Quality Management
Once  the  QMS  is  in  place,  the  ISO/IEC  
Technical  Specification  TS  33061:2021  [23]  
Standard defines a process assessment model 
for software life cycle processes using five pro-
cess capabilities levels (from level 0: incomplete 
to  level  5:  optimizing  process).  Additionally,  
software engineers can assess the maturity of 
their QMS activities in their software projects 
using the IEEE 730:2014 Standard guidance 
[6].  Management  sponsorship  supports  pro-
cess  and  product  evaluations.  The  evaluation  
findings  feed  into  an  improvement  program  
for identifying detailed actions and improve-
ment  projects  to  be  addressed  in  a  feasible  
time  frame.  Periodically,  the  software  engi-
neers  will  gather  and  analyze  quality  assur-
ance  evaluation  results.  This  can  be  achieved  
by  looking  at  quality  measures  and  defect  
characterization produced by the projects.
2.3.1.   Software Quality Measurement  
 [1*, c10] [7, c24s24.5]
Software   quality   measurements   are   used   
to    support    decision-making.    With    the    
increasing sophistication of software, quality 
questions  go  beyond  whether  the  software  
works  to  how  well  it  achieves  measurable  
quality  goals.  Quantifying  some  attribute  
of  software  can  help  engineers  evaluate  its  
quality or the quality of its process. (Process 
measurement  is  described  in  detail  in  the  
Process K A.) 
Software  quality  measurement  helps  engi-
neers    make    determinations    about    soft-
ware   quality   (because   models   of   software   
product  quality  include  measures  to  deter-
mine the degree to which the software product 
achieves  quality  goals);  managerial  questions  
about  effort,  cost,  and  schedule;  when  to  stop  
testing and release a product (see Test-Related 
Measures  in  the  Software  Testing  KA);  and  
the efficacy of process improvement efforts.
The CoSQ assurance activities are an issue 
frequently  raised  in  deciding  how  a  project  
or  a  software  development  and  maintenance  
organization  should  be  organized.  Often,  
generic models of cost are used; these models 
are based on when a defect is found and how 
much  effort  it  takes  to  fix  the  defect  rela-
tive  to  finding  the  defect  earlier  in  develop-
ment.  Software  quality  measurement  data  
collected internally may offer a better picture 
of  cost  within  the  project  or  organization.  
Although the software quality measurement 
data may be useful by itself (e.g., the number 
of  defective  requirements  or  the  proportion  
of   defective   requirements),   mathematical   
and  graphical  techniques  can  help  project  
stakeholders   interpret   the   measures.   (See   
the  Engineering  Mathematical  Foundations  
KA.) These techniques include the following:
•    Descriptive statistics-based analysis (e.g., 
Pareto analysis, run charts, scatter plots, 
normal distribution);
•    Statistical  tests  (e.g.,  the  binomial  test,  
chi-squared test);
•    Trend  analysis  (e.g.,  control  charts;  see  
The Quality Toolbox in Further Readings);
•    Prediction (e.g., reliability models).
Descriptive statistics-based techniques and 
tests  often  provide  a  snapshot  of  the  more  
troublesome  areas  of  the  software  product  
under  examination.  The  resulting  charts  and  
graphs are visualization aids decision-makers 
can use to focus resources and conduct process 
improvements where they seem most needed. 
Results from trend analysis may indicate that 
a  schedule  is  slipping  or  that  certain  classes  
of faults may become more likely unless some 

SOFTWARE QUALITY   12-9
corrective action is taken in development. The 
predictive  techniques  help  estimate  testing  
effort and schedule and predict failures. (More 
discussion on measurement in general appears 
in  the  Software  Engineering  Process  and  
Software   Engineering   Management   KAs.   
More  specific  information  on  testing  mea-
surement is presented in the Software Testing 
KA.)   Software   quality   measurement   also   
includes  measuring  defect  occurrences  and  
applying  statistical  methods  to  understand  
what  types  of  defects  occur  most  frequently.  
Three widely used software quality measure-
ments are error density (number of errors per 
unit size of documents/software), defect den-
sity  (number  of  defects  found  divided  by  the  
size  of  the  software),  and  failure  rate  (mean  
time  to  failure).  Reliability  models  are  built  
from  failure  data  collected  during  software  
testing  or  from  software  in  service  and  thus  
can  be  used  to  estimate  the  probability  of  
future  failures  and  assist  in  decisions  about  
when  to  stop  testing.  This  information  can  
be used in SPI to determine methods to pre-
vent,  reduce  or  eliminate  defect  recurrence.  
The  information  also  helps  engineers  under-
stand trends, how well detection and contain-
ment  techniques  are  working,  and  how  well  
the  development  and  maintenance  processes  
are progressing. They can use these measure-
ment  methods  to  develop  defect  profiles  for  
a  specific  application  domain.  Then,  for  the  
next  software  project  within  that  organi-
zation,  the  profiles  can  be  used  to  guide  the  
SQM  processes  —  that  is,  to  focus  effort  
on  where  problems  are  most  likely  to  occur.  
Similarly,  benchmarks,  or  defect  counts  typ-
ical of that domain, may help engineers deter-
mine  when  the  product  is  ready  for  delivery.  
(Discussion about using measurement data to 
improve  development  and  maintenance  pro-
cesses  appears  in  the  Software  Engineering  
Management    and    Software    Engineering    
Process KAs.)
2.4.  Perform Corrective and Preventive Actions 
It  is  important  that  when  quality  manage-
ment objectives are not met, corrective actions 
be  documented  and  submitted  so  that  the  
QMS  be  improved  to  prevent  problem  from  
reoccurring  in  future  software  projects.  This  
requires  that  project  participants  have  a  way  
of   reporting   software   engineering   process   
and  tools  problems  to  an  independent  orga-
nization that will document and monitor the 
progress of the corrective actions and inform 
the relevant stakeholders.  
2.4.1.   Defect Characterization  [1*, c1s 3]
To  help  in  the  elimination  of  the  cause  or  
causes of an existing nonconformity or unde-
sirable  situation  to  prevent  recurrence,  soft-
ware   engineers   can   use   software   quality   
control   (SQC)   techniques   to   find   errors,   
defects,  and  failures  in  their  processes  and  
products.  When  tracking  errors,  defects  and  
failures, the software engineer is interested in 
the number and types of incidents. Numbers 
alone,  without  classification,  might  be  insuf-
ficient  to  help  in  identifying  the  underlying  
causes and thus to prevent them in the future. 
Therefore, software engineers should establish 
a meaningful defect classification taxonomy to 
describe and categorize such anomalies. One 
probable  action  resulting  from  peer  reviews  
and testing findings is to remove these errors 
and defects early from the work product under 
examination. 
Other SQM activities attempt to eliminate 
their causes (e.g., root cause analysis (RCA)). 
RCA  activities  include  analyzing  and  sum-
marizing the findings to find root causes and 
using measurement techniques to improve the 
software  engineering  processes,  techniques  
and   tools.   (Process   improvement   is   pri-
marily discussed in the Software Engineering 
Process KA. RCA is further discussed in the 
Engineering Foundations KA.)
Data  on  errors  and  defects  found  during  
SQA  and  control  techniques  may  be  lost  
unless they are recorded. For some techniques 
(e.g.,  peer  reviews  and  inspections),  software  
engineers are present to record such data and 
to address issues and make decisions. In addi-
tion, when automated tools are used (see Topic 
4,  Software  Quality  Tools),  the  tool  output  

12-10   SWEBOK
®
 GUIDE V4.0
may provide defect trends reports that can be 
provided to the organization’s management. 
3. Software Quality Assurance Process
3.1.  Prepare for Quality Assurance  
 [1*, c1s1.5, c4s4.6]  [6]
Software  quality  assurance  (SQA)  is  defined  as  
“a  set  of  activities  that  define  and  assess  the  
adequacy of software processes to provide evi-
dence that establishes confidence that the soft-
ware processes are appropriate for and produce 
software products of suitable quality for their 
intended  purposes.”  To  correct  a  common  
misunderstanding, SQA is not only testing of 
a software. A key attribute of SQA, in critical 
systems, is the objectivity of the SQA function 
concerning the quality of a software product. 
In this case, the SQA function might also be 
organizationally  independent  of  the  project;  
that  is,  free  from  technical,  managerial,  and  
financial  pressures  [6].  SQA  has  two  aspects:  
product   assurance   and   process   assurance,   
which are introduced in Section 2.3. 
The software quality plan (in some industry 
sectors,  it  is  termed  the  software  quality  
assurance plan (SQAP)) defines the activities 
and tasks used to ensure that software devel-
oped  for  a  specific  product  satisfies  the  proj-
ect’s established requirements and user needs 
within  project  cost  and  schedule  constraints  
and  is  commensurate  with  project  risks.  The  
SQAP  first  ensures  that  quality  targets  are  
clearly defined and understood.
The  SQAP’s  quality  activities  and  tasks  
are specified, along with their costs, resource 
requirements,   objectives,   and   schedule   in   
relation  to  related  objectives,  in  the  software  
engineering  management,  software  develop-
ment  and  software  maintenance  plans.  The  
SQAP identifies documents, standards, prac-
tices,  and  conventions  governing  the  project  
and  how  these  items  are  checked  and  mon-
itored  to  ensure  adequacy  and  compliance.  
The SQAP also identifies measures; statistical 
techniques; procedures for problem reporting 
and corrective action; resources such as tools, 
techniques,  and  methodologies;  security  for  
physical media; training; and SQA reporting 
and  documentation.  Moreover,  the  SQAP  
addresses the SQA activities of any other type 
of activity described in the software plans — 
such  as  procurement  of  supplier  software  for  
the project, commercial off-the-shelf (COTS) 
software  installation  and  service  after  soft-
ware  delivery.  It  can  also  contain  acceptance  
criteria and reporting and management activ-
ities  that  are  critical  to  software  quality.  The  
SQA  plan  should  not  conflict  with  the  soft-
ware  configuration  management  plan  or  any  
other   relevant   project   plannning   artifact.   
More  over  they  should  be  considered  com-
plimentary  activities  (for  process  SQAP  the  
SCM Process Audit and the Testing activities 
for SCM Functional Audit).
Software  quality  encompasses several  per-
spectives:  the  software  process  quality,  the  
software  end-product  quality  and  the  soft-
ware  work  products  (also  called  intermediary 
products) quality. The next sections cover each 
perspective  of  software  quality  knowledge  a  
software engineer must have.
3.2.  Perform Process Assurance  
 [1*, c3s3.2–s3.3, c4s4.6.1.3, c8, c9] [7, c25]
Crosby  [2]  and  Humphrey  [3]  have  demon-
strated   that   software   quality   management   
(SQM)   and   software   engineering   process   
quality have a direct effect on the quality of the 
final  software  product.  (Models  and  criteria  
that  evaluate  and  improve  the  capabilities  of  
software  organizations  are  primarily  project  
organization and management considerations 
and,  as  such,  are  covered  in  the  Software  
Engineering    Management    and    Software    
Engineering   Process   KAs.)   International   
Organization for Standardization (ISO) 9001 
[10] proposes another process quality perspec-
tive,  where  a  management  system  that  over-
sees the processes’ actors, activities, controls, 
input, and outputs ensures the quality of out-
puts (e.g., work products and final product). A 
management system is defined as a “set of inter-
related  or  interacting  elements  of  an  organi-
zation  to  establish  policies  and  objectives,  
and  processes  to  achieve  those  objectives”  

SOFTWARE QUALITY   12-11
[10]. This perspective requires software engi-
neering  organizations  to  take  the  time  to  
describe  their  policies,  processes,  and  proce-
dures with enough detail that software engi-
neer roles and responsibilities are clear during 
life cycle activities (as detailed in the Software 
Engineering Process KA).
SQA activities, listed in the IEEE 730:2014 
Standard [6], describe the many quality assur-
ance activities that should be conducted early 
in  a  software  project’s  life  cycle  to  ensure  
quality.  Software  engineers  should  be  aware  
of  the  need  to  plan  and  execute  SQA  activ-
ities  at  certain  project  milestones  and  keep  
records  of  their  execution.  These  activities  
consist of document and code reviews as well 
as  verification  and  validation  (V&V)  activi-
ties,  including  testing  (as  detailed  in  Section  
3.4 of this KA), which evaluate the output of 
a  process’s  compliance  with  its  requirements  
and specifications.
Finally,    software    configuration    man-
agement  (SCM)  is  an  important  activity  to  
ensure the quality of work products and soft-
ware. Configuration management is defined as 
the “discipline applying technical and admin-
istrative direction and surveillance to:
•    identify  and  document  the  functional  
and  physical  characteristics  of  a  config-
uration item;
•    control changes to those characteristics;
•    record and report change processing and 
implementation status;
•    verify      compliance      with      specified      
requirements.” 
Software  engineers  should  identify  which  
work  products  and  software  artifacts  require  
configuration management. In addition, they 
should  be  familiar  with  source  code  ver-
sioning   processes,   which   involve   keeping   
track of baselined and incremental versions of 
the  software  and  ensuring  that  changes  dif-
ferent  developers  make  do  not  interfere  with  
one  another,  and  they  should  know  how  to  
operate  the  version  control  tool  kit.  (Refer  
to  the  Software  Configuration  Management  
KA for more information about this process.)
3.3.  Perform Product Assurance  
 [1*, s3.2–s3.3] [7, c4, s4.6.1.2] 
First,  the  software  engineer  must  determine  
the real purpose of the software to be designed 
and constructed. Stakeholder requirements are 
paramount here. They include quality require-
ments (called Quality of Service Constraints in 
the  Software  Requirements  KA)  and  func-
tional requirements. Thus, software engineers 
are  responsible  for  eliciting  quality  require-
ments that might not be explicit at the outset 
and  for  understanding  their  importance  and  
the  difficulty  in  defining  them,  measuring  
them,  and  establishing  them  for  final  accep-
tance. Software engineers should understand 
how to define quality requirements as well as 
their quality targets to ensure they can effec-
tively  be  measured  at  the  acceptance  stage  
of  the  project.  During  the  project  planning,  
software  engineers  must  keep  these  quality  
requirements in mind. They must also antici-
pate potential additional development costs if 
attributes such as safety, security and depend-
ability are important.
An  international  standard  on  what  con-
stitutes  a  software  product’s  many  measur-
able  quality  characteristics  was  reached  and  
is described in ISO/IEC 25010:2011 [4]. This 
standard  proposes  several  software  product  
quality  models,  consisting  of  characteristics  
and  sub-characteristics,  for  software  product  
quality  and  software  quality  in  use.  Another  
is   IEEE   982.1:2005   Standard   Dictionary   
of  Measures  to  Produce  Reliable  Software.    
These  software  characteristics  are  commonly  
called product  quality  requirements,  which  are  
nonfunctional   software   requirements   [7*,   
c4,s4.6.1.2]. Software engineers should know 
the many software characteristics that can be 
planned, implemented, and measured during 
software  construction  (e.g.,  functional  suit-
ability,  performance  efficiency,  compatibility,  
usabilit y,  reliabilit y,  securit y,  maintainabilit y,  
and  portability).  Software  engineers  should  
also  know  that  certain  quality  characteris-
tics  have  conflicting  impacts.  For  example,  
trying  to  augment  the  security  characteristic  
by encrypting data might adversely affect the 

12-12   SWEBOK
®
 GUIDE V4.0
performance characteristic. This international 
standard also proposes a general data quality 
model that focuses on data quality as part of 
a  computer  system  and  defines  quality  char-
acteristics  for  target  data  used  by  humans  
and systems.
Another  software  product  quality  perspec-
tive  is  the  quality  of  work  products.  The  term  
work product means any artifact resulting from 
a  process  used  to  create  the  final  software  
product.  Work  products  include  system/sub-
system  specifications,  software  requirements  
specifications  for  a  system’s  software  compo-
nents,   software   design   descriptions,   source   
code,  software  test  documentation  and  test  
reports.  Sound  engineering  practice  requires  
that  intermediate  work  products  relevant  to  
quality be evaluated using work product reviews 
and inspections (discussed later in this chapter) 
throughout the software engineering process.
3.4.   V&V and Testing  [1*, c7] [11]
Verification  ensures  that  the  product  is  built  
correctly in that the output products of a life 
cycle  phase  meet  the  specifications  imposed  
on  them  in  previous  phases.  Verification  is  
defined as “the process of evaluating a system 
or component to determine whether the prod-
ucts of a given development phase satisfy the 
conditions imposed at the start of that phase” 
[11]. Alternatively, validation ensures that the 
right product is built — the product fulfills its 
specific intended purpose. It is defined as “the 
process  of  evaluating  a  system  or  component  
during or at the end of the development pro-
cess to determine whether it satisfies specified 
requirements.”
The  purpose  of  V&V  is  to  help  the  devel-
opment  organization  build  quality  into  the  
software   throughout   the   development   life   
cycle.  V&V  includes  software  testing  tasks.  
Software  testing  is  a  necessary  activity  to  
ensure  product  quality.  However,  in  most  
cases,   software   testing   is   insufficient   to   
establish  confidence  that  the  software  fits  
its  intended  use.  V&V  tasks  listed  in  IEEE  
Standard  1012:2016  [11]  objectively  assess  
products  and  processes  throughout  the  life  
cycle.  This  assessment  demonstrates  whether  
the requirements are correct, complete, accu-
rate,  consistent,  and  testable.  The  verifica-
tion process and the validation process should 
begin  early  in  development  or  maintenance.  
This  prevents  defects  late  in  the  life  cycle,  
which  would  incur  rework  and  significantly  
increase   costs.   Software   engineers   should   
identify the product integrity level and ensure 
the minimum V&V tasks are assigned for key 
product features concerning both the product’s 
immediate predecessor and the planned spec-
ifications. Optional V&V tasks are also listed 
and  can  improve  software  product  quality.  
Keeping  a  record  of  the  traceability  among  
software  work  products  can  help  augment  
the quality of the V&V activities. Traceability 
is  defined  as  the  “ability  to  trace  the  history,  
application or location of an object” [14]. 
Early planning of V&V activities ensures 
that  each  resource,  role,  and  responsibility  
is clearly assigned. The resulting V&V plan 
documents  the  various  resources  and  their  
roles  and  SQA  activities,  as  well  as  the  
techniques  and  tools  to  be  used. Software 
engineers   should   choose   and   apply   the   
proper  V&V  task  depending  on  the  soft-
ware integrity level. (Refer to Section 1.4.2) 
V&V  can  also  be  executed  by  an  indepen-
dent organization for very critical software. 
Independent   verification   and   validation   
(IV&V) are defined as “V&V performed by 
an  organization  that  is  technically,  mana-
gerially, and financially independent of the 
development organization” [11].
Software  V&V  tasks  can  be  sorted  into  
static,    dynamic    and    formal    tasks    [20].    
Dynamic  techniques  involve  executing  the  
software;  static  techniques  involve  analyzing  
documents and source code but not executing 
the  software;  formal  techniques  use  mathe-
matics and formal specification languages.
It should be noted that there are no strong 
boundaries   between   "Static   analysis   tech-
niques",  "Dynamic  analysis  techniques"  and  
"Formal  analysis  techniques".  For  example,  
static  and  dynamic  analysis  techniques  usu-
ally have a strong formal background such as 
data-flow analysis or model checking.

SOFTWARE QUALITY   12-13
3.4.1.   Static Analysis Techniques
Static    analysis    techniques    directly    ana-
lyze  a  work  product’s  content  and  structure  
(including  requirements,  interface  specifica-
tions, designs, and models) without executing 
the software. The only way to detect non-ex-
ecutable code is through static analysis as no 
dynamic test can verify that. Static techniques 
can be executed manually or with the help of a 
tool. Tools and techniques for statically exam-
ining  software  work  can  help  software  engi-
neers in this task. For example, code reading, 
peer review of a work product, and static anal-
ysis of source code control flow are considered 
static techniques because they do not involve 
executing the software code.
We  will  see,  in  section  3.4.5  that  review  
and audit processes are consideredstatic anal-
ysis  activities,  meaning  that  no  software  or  
models  are  executed.  Instead,  they  examine  
software   engineering   artifacts   (also   called   
intermediary  or  work  products)  concerning  
standards  established  by  the  organization  or  
project for those artifacts.
3.4.2.  Dynamic Analysis Techniques
Dynamic   analysis   techniques   involve   exe-
cuting or simulating the software code, looking 
for   errors   and   defects.   Different   dynamic   
techniques  are  performed  throughout  soft-
ware  development,  maintenance,  and  opera-
tion. Generally, these are testing techniques, 
but  simulation,  model  analysis  and  model  
checking   are   considered   dynamic   analysis   
techniques.  (See  the  Software  Engineering  
Models and Methods KA.) “In addition, black 
box  testing  is  considered  a  dynamic  analysis  
technique,  as  the  software  engineer  analyzes  
the  output  received  following  the  entry  of  
inputs.” (See the Software Testing KA.)
3.4.3.  Formal Analysis Techniques
 [7*, c10s10.5]
Formal  analysis  techniques  (also  called  formal 
methods)   are   “mathematical   approaches   to   
software  development  where  you  define  a  
formal  model  of  the  software.  You  may  then  
formally  analyze  this  model  to  search  for  
errors   and   inconsistencies”   [7*,   c10s10.5].   
Sometimes,  the  software  requirements  may  
be  written  using  a  more  formal  specification  
language known as formal methods. They are 
notably  used  to  verify  software  requirements  
and  designs.  They  have  mostly  been  used  to  
verify  crucial  parts  of  critical  systems,  such  
as  specific  security  and  safety  requirements.  
(See  also  Formal  Methods  in  the  Software  
Engineering   Models   and   Methods   KA.)   
Different groups may perform testing during 
software    development,    including    groups    
independent  of  the  development  team.  The  
Software  Testing  KA  is  devoted  entirely  to  
this subject.
3.4.4.  Software Quality Control and Testing  
 [1*, c7s7.10]
Testing  is  considered  an  important  product  
quality   control   activity   part   of   a   soft-
ware  development  project’s  V&V  processes.  
Quality  Control  is  “a  set  of  activities  that  
measure,  evaluate  and  report  on  the  quality  
of  software  project  artifacts  throughout  the  
project life cycle” [25]. Software testing is an 
important  quality  control  activity  to  ensure  
software  quality.  Software  testing  is  one  of  
many  verification  activities  that  confirm  that  
software   development   output   meets   input   
requirements.  IEEE  730:2014  [6]  lists  the  
many testing and retesting activities software 
engineers should plan, execute, and record. It 
also recommends that testing completion cri-
teria  be  set.  Software  engineers  should  plan  
the  testing  activities,  including  levels,  tech-
niques, measures, and tools. Software quality 
engineering team, for critical systems, should 
particularly be involved in qualifying software 
products prior to its delivery (i) either for fur-
ther integration or (ii) for operations in target 
computing  environment;  as  an  independent  
test and evaluation activity, without involving 
development  team  members  in  the  process.  
(Refer to the Testing KA for details about the 
knowledge  software  engineers  should  have  
about software testing.)

12-14   SWEBOK
®
 GUIDE V4.0
3.4.5. Technical Reviews and Audits  
 [1*, c5, c6] [23, s4, s5]
We  have  seen  SQC  techniques  for  assessing  
the  quality  of  the  software  in  section  2.4.1.  
For  the  other  artefacts,  product  quality  con-
trol is assessed using reviews and inspections 
of these work products. These SQC activities 
are  planned  and  executed  during  develop-
ment,  maintenance,  and  operations  activities  
[17].  Peer  reviews  are  defined  as  “the  review  
of  work  products  performed  by  peers  during  
development of the work products to identify 
defects for removal” [14]. For example, during 
software  development,  a  code  review  (often  
done  by  using  a  pull  request  technique/tool)  
occurs when a peer reviews the code, often at 
the software developer’s request, before it can 
be merged into a project. 
Reviews are valuable because they can iden-
tify issues early in development or even before 
a component is designed. Fixing a defect in a 
component that has been coded is much more 
expensive than catching it beforehand. 
Different types of work product reviews (e.g., 
formal, and informal) are distinguished by pur-
pose,  level  of  independence,  tools  and  tech-
niques  used,  roles  involved,  and  by  the  subject  
of the activity. Reviews play important roles in 
software  quality,  in  SCM,  and  in  the  sharing  
of   knowledge   among   colleagues.   However,   
these  different  roles  share  a  single  purpose  —  
to ensure the quality of the delivered products. 
Reviews  should  be  part  of  the  software  engi-
neering  culture  and  should  be  planned,  exe-
cuted, and documented during the software life 
cycle.  In  Agile  life  cycles,  pair  programming  
invites  continuous  reviews.  Different  review  
types  for  work  products  are  described  in  the  
ISO/IEC 20246:2017 Standard [12]: 
•    Ad  hoc  reviews  —  unstructured  reviews  
where each reviewer is expected to find as 
many defects as possible of any type; 
•    Checklist-based    reviews    —    system-
atic  reviews  identifying  issues  based  on  
checklists; 
•    Scenario-based reviews — reviews where 
reviewers  are  provided  with  structured  
guidelines  on  how  to  read  through  the  
work product under review; 
•    Perspective-based   reviews   —   reviews   
where  reviewers  take  on  different  stake-
holder  viewpoints  and  review  the  work  
product   from   that   stakeholder’s   view-
point; and 
•    Role-based  reviews  —  reviews  in  which  
the  reviewer  evaluates  the  work  product  
from  the  perspective  of  various  stake-
holder  roles,  which  might  differ  from  
their daily role. 
Audits  are  more  formal  activities  that  are  
often  mandated  to  be  performed  by  third  
parties  to  ensure  independence.  In  mature  
organizations,  technical  reviews  and  audits  
are  fully  integrated  with  the  overall  project  
plans.  Therefore,  technical  reviews  and  audits  
should  be  planned,  approved,  and  conducted.  
Although  a  project  audit  often  addresses  the  
whole project’s current state, technical reviews 
can  also  be  more  focused  and  address  a  spe-
cific  project  phase  [24].  System  requirements  
reviews  help  ensure  that  the  level  of  under-
standing  of  top-level  system  requirements  is  
adequate to support further requirements anal-
ysis  and  design  activities  and  that  the  system  
can  proceed  into  initial  system  design  with  
acceptable   risk;   System   functional   or   pre-
liminary  design  reviews  help  ensure  that  the  
system under review can proceed into prelimi-
nary or detailed design with acceptable risk and 
that  all  system  requirements  and  functional  
performance  requirements  derived  from  the  
approved  preliminary  system  specification  are  
defined and consistent with the project budget, 
program schedule, risk, and other program and 
system constraints; Preliminary design reviews 
help  ensure  that  the  preliminary  design  for  
the system under review is sufficiently mature 
and ready to proceed into detailed design and 
can meet the stated performance requirements 
within  program  budget,  schedule,  risk  and  
other  program  and  system  constraints;  Test  
readiness  reviews  assess  test  objectives,  test  
methods  and  procedures,  test  scope,  safety,  
readiness  for  the  project  test  and  evaluation,  
and whether test resources have been properly 

SOFTWARE QUALITY   12-15
identified   and   obtained;   Production   readi-
ness  reviews  ascertain  that  the  system  design  
is ready for production and that the project has 
accomplished  adequate  production  planning  
for entering production.
4. Software Quality Tools  
 [1*, c3s3.2.3, c7s7.8.1, c7s7.11]
Software    tools    improve    software    quality.    
Simple  tools  can  be  forms  and  checklists  (e.g.,  
a  requirements  traceability  matrix  or  a  code  
review checklist). But automated tools can also 
be of great help to improve software efficiency 
and  quality.  Examples  of  automated  tools  are  
tools that allow code versioning/branching (e.g., 
Git) and pull requests for code review. DevOps 
tools  in  services/scripts  like  on-demand  envi-
ronments,   continuous   integration/continuous   
delivery (CI/CD), code quality assessment, and 
automated testing are important contributors to 
software quality. (See the Software Operations 
KA discussion about tools.) 
These tools are known as static and dynamic 
analysis tools. Static analysis tools input source 
code,  perform  syntactical  and  semantic  anal-
ysis  without  executing  the  code,  and  present  
results to users. There is a large variety in the 
depth, thoroughness and scope of static anal-
ysis  tools  that  can  be  applied  to  artifacts,  
including  models,  and  source  code.  (See  the  
Software   Construction,   Software   Testing,   
and  Software  Maintenance  KAs  for  descrip-
tions of dynamic analysis tools.) Categories of 
static analysis tools include the following: 
•    Tools  that  facilitate  and  partially  auto-
mate  reviews  and  inspections  of  docu-
ments  and  code.  These  tools  can  route  
work to different participants to partially 
automate and control the review process. 
In  addition,  they  allow  users  to  enter  
defects   found   during   inspections   and   
reviews for later removal; 
•    Tools   that   help   organizations   perform   
software   safety   hazard   analysis.   These   
tools provide, for example, automated sup-
port for failure mode and effects analysis 
(FMEA) and fault tree analysis (FTA); 
•    Tools  that  support  tracking  of  software  
problems.  These  tools  enable  entry  of  
anomalies   discovered   during   software   
testing  and  subsequent  analysis,  disposi-
tion,  and  resolution.  Some  tools  include  
support  for  workflow  and  for  tracking  
problem resolution status; and 
•    Tools  that  analyze  data  captured  from  
software  engineering  environments  and  
software   test   environments   and   pro-
duce  visual  displays  of  quantified  data  
in graphs, charts, and tables. These tools 
sometimes  include  the  functionality  to  
perform  statistical  analysis  on  data  sets  
(to  discern  trends  and  make  forecasts).  
Some of these tools provide defect injec-
tion  and  removal  rates,  defect  densities,  
yields, and distribution of defect injection 
and removal for each life cycle phase.
MATRIX OF TOPICS VS. REFERENCE MATERIAL
Topic
Laporte and April 2018 [1*]Sommerville 2 016 [7 *] IEEE Software Code of Ethics [5*] Wiegers 2013 [13*]
1. Software Quality Fundamentals  
1.1. Software Engineering Culture 
and Ethics
Ch. 1s1.6, Ch. 2s3X 
1.2. Value and Cost of QualityCh. 2s2.2 

12-16   SWEBOK
®
 GUIDE V4.0
1.3. Standards, Models and 
Certifications
Ch. 4Ch. 24s24.2 
1.4. Software Dependability and 
Integrity Levels
Ch. 4s4.8
Ch . 7s7. 2-7. 3
Ch. 10 
2. Software Quality 
Management Process
  
2.1. Software Quality ImprovementCh. 9s9.9  
2.2. Plan Quality Management 
2.3. Evaluate Quality ManagementCh. 10Ch. 24s24.5
2.4. Perform Corrective and 
Preventive Actions
Ch. 1,s3 
3. Software Quality 
Assurance Process
  
3.1. Prepare for Quality AssuranceCh. 1s1.5, Ch. 4s4.6 Ch. 14
3.2. Perform Process AssuranceCh. 3s3.2-s3.3
Ch. 8, Ch. 9, 
Ch. 4s4.6.1.3
Ch. 25 
3.3. Perform Product AssuranceCh. 3s3.2-3.3
Ch. 7, Ch. 5, 
Ch. 4s4.6.1.2
Ch. 4s4.1.2 
3.4. Verification & Validation  
a n d   Te s t s
Ch. 5, Ch. 6, Ch. 7Ch. 10s10.5
4. Software Quality ToolsCh. 3s3.2.3, Ch. 
7s7. 8 .1, C h .  7s7.11  
X
FURTHER READINGS
IEEE 730-2014, “IEEE Standard for Software 
Quality Assurance Processes,” 2014 [6]. 
Requirements  for  initiating,  planning,  con-
trolling, and executing the Software Quality 
Assurance  processes  of  a  software  develop-
ment  or  maintenance  project  are  established  
in this standard. 
IEEE  Std  1012-2016,  “IEEE  Standard  for  
System, Software, and Hardware Verification 
and Validation,” 2016 [11].
Verification    and    validation    (V&V)    pro-
cesses  are  used  to  determine  whether  the  
development   products   of   a   given   activity   
conform  to  that  activity’s  requirements  and  
whether  the  product  satisfies  its  intended  
use  and  user  needs.  V&V  life  cycle  process  
requirements are specified for different integ-
rity levels. 
ISO/IEC  Std  20246-2017,  “Software  and  
Systems    Engineering    —    Work    Product    
Reviews,” 2017 [12]. 
This   international   standard   establishes   a   
generic  framework  for  work  product  reviews  
that  can  be  referenced  and  used  by  all  orga-
nizations involved in the management, devel-
opment,  testing  and  maintenance  of  systems  
and software. 

SOFTWARE QUALITY   12-17
N.   Leveson,   Safeware:   System   Safety   and   
Computers [1 5 ]. 
This  book  describes  the  importance  of  soft-
ware safety practices and how these practices 
can  be  incorporated  into  software  develop-
ment projects.
T. Gilb and D. Graham, Software Inspection [16].  
This  book  introduces  measurement  and  sta-
tistical  sampling  for  reviews  and  defects.  It  
presents   techniques   that   produce   quanti-
fied  results  for  reducing  defects,  improving  
productivity,  tracking  projects  and  creating  
documentation.
K.  E.  Wiegers,  Peer  Reviews  in  Software:  A  
Practical Guide [17 *]. 
This   book   provides   clear,   succinct   expla-
nations   of   different   peer   review   methods   
distinguished by level of formality and effec-
tiveness.  It  provides  pragmatic  guidance  for  
implementing  the  methods  and  for  deter-
mining  which  methods  are  appropriate  for  
given circumstances.
REFERENCES
[1*] C.Y. Laporte and A. April, Software 
Quality Assurance, IEEE Press, 2018.
[2] P.B. Crosby, Quality Is Free, McGraw-
Hill, 1979.
[3] W. Humphrey, Managing the Software 
Process, Addison-Wesley, 1989.
[4] ISO/IEC, “ISO/IEC 25010:2011 
Systems and Software Engineering 
— Systems and Software Quality 
Requirements and Evaluation 
(SQuaRE) — Systems and Software 
Quality Models,” ed., 2011.
[5*] IEEE CS/ACM Joint Task Force on 
Software Engineering Ethics and 
Professional Practices, “Software 
Engineering Code of Ethics and 
Professional Practice https://www 
.computer.org/education/code-of 
-ethics. 
[6]    IEEE, “IEEE 730 Standard for 
Software Quality Assurance 
Processes,” ed., IEEE, 2014.
[7*] I. Sommerville, Software Engineering, 
10th ed., New York: Addison-
Wesley, 2016.
[8] RTCA, “DO-178C, Software 
Considerations in Airborne Systems 
and Equipment Certification,” ed.,  
5 January 2012. Also known as 
ED-12C in EUROCAE.
[9] ISO/IEC, “ISO/IEC 15026-1:2019 
Systems and Software Engineering — 
Systems and Software Assurance — 
Part 1: Concepts and Vocabulary,” ed., 
ISO/IEC, 2019.
[10] “ISO 9001:2015 Quality Management 
Systems — Requirements,” ed., 
ISO, 2015.
[11]  IEEE, “IEEE Std. 1012:2016, 
Standard for System and Software 
Verification and Validation,” 
IEEE, 2016.
[12] ISO/IEC 20246:2017, “Software and 
systems engineering — Work product 
reviews,” ed., 2017.
[13*] K.E.  Wiegers, Software Requirements, 
3rd ed., Redmond, WA: Microsoft 
Press, 2013.
[14]  ISO/IEC/IEEE, “ISO/IEC/IEEE 
24765:2017 Systems and Software 
Engineering — Vocabulary,” 
2nd ed. 2017.
[15] N. Leveson, Safeware: System Safety 

12-18   SWEBOK
®
 GUIDE V4.0
and Computers, Addison-Wesley 
Professional, 1995.
[16] T. Gilb and D. Graham, Software 
Inspection, Addison-Wesley 
Professional, 1993.
[17*] K. Wiegers, Peer Reviews in Software: 
A Practical Guide, Addison-Wesley 
Professional, 2001.
[18] BS EN 50128:2011+A2:2020, 
“Standard for Railway Applications 
– Communications, Signaling and 
Processing Systems – Software for 
Railway Control and Protection 
Systems,” British-Adopted European 
Standard, 10 August 2020.
[19] K. Iberle, They don’t care about quality, 
proceedings of STAR East, Orlando, 
United States, 2013, available at 
https://kiberle.com/publications/. 
[20] D. Wallace, L. M. Ippolito, and 
B.B. Cuthill, Reference Information 
for the Software Verification and 
Validation Process, National Institute 
of Standards and Technology 
(NIST), U.D. Department of 
Commerce, Special Publication 
500-234, 1996.
[21] IEC 60300-1:2014, “Dependability 
Management — Part 1: Guidance for 
Management and Application,” version 
3, 25 September 2014.
[22] D. Leffingwell, Safe 4.5 Reference 
Guide: Scaled Agile Framework For 
Lean Enterprises, 2nd ed., New-York, 
Addison-Wesley, 2018.
[23] ISO/IEC TS 33061:2021, 
“Information technology — Process 
assessment — Process Assessment 
Model for Software Life Cycle 
Processes,” 2021-04.
[24]  IEEE Std 15288.2:2014, “IEEE 
Standard for Technical Reviews and 
Audits on Defense Programs.”
[25] A guide to the Project management 
Body of Knowledge, 7
th
 edition, PMI, 
2021, 368p.
[26]  ISO/IEC/IEEE 90003:2018, 
“Guidelines for the application of 
ISO 9001:2015 to computer soft-
w a re ”, 2 018-11.
[27] COBIT, “Control Objectives for 
Information Technology”, version 
2019, ISACA and the IT Governance 
Institute.
[28] BABOK, “A guide to the Business 
Analysis Body of Knowledge”, version 
3, International Institute of Business 
Analysis, 04-2015.
[29] CMMI, “Capability Maturity Model 
Integration”, version 10, ISACA, 2023.
[30] TOGAF, “Open Group Architecture 
Framework”, version 10, 04-2022.
[31] ISO/IEC 27001:2022, “Information 
security, cybersecurity, and pri-
vacy protection  Information 
security —management systems — 
Requirements”, 10 -2022.

13-1 
CHAPTER 13
Software Security
ACRONYMS
CCCommon Criteria
SDLCSecure Development Life Cycle
INTRODUCTION
Security has become a significant issue in soft-
ware development because of potential misuse 
and  increasing  malicious  activity  targeting  
computer  systems.  In  addition  to  the  usual  
correctness and reliability concerns, software 
developers must pay attention to the security 
of the software they develop. Secure software 
development   builds   security   by   following   
a   set   of   established   and/or   recommended   
rules  and  practices.  Secure  software  mainte-
nance complements secure software develop-
ment  by  ensuring  that  no  security  problems  
are  introduced  during  software  maintenance  
and  that  identified  vulnerabilities,  which  are  
errors that attackers can exploit, can be han-
dled  during  the  software  life  cycle.  Security  
vulnerabilities are not only introduced at the 
development, but also by third party compo-
nents such as libraries, COTS, or OS.
BREAKDOWN OF TOPICS FOR 
SOF TWARE SECURITY
The  breakdown  of  topics  for  the  Software  
Security  knowledge  area  (KA)  is  shown  in  
Figure 13.1.
1. Software Security Fundamentals  [37, 9]
A  generally  accepted  belief  about  software  
security  is  that  it  is  much  better  to  design  
security into software than to patch it in after 
the  software  is  developed.  To  design  secu-
rity  into  software,  one  must  consider  every  
development life cycle stage. Secure software 
development  involves  software  requirements  
security,  software  design  security,  software  
construction  security  and  software  testing  
security. In addition, security must be consid-
ered  during  software  maintenance,  as  secu-
rity faults and loopholes can be and often are 
introduced during maintenance.
1.1.  Software Security  [10*]
Security  is  a  product  quality  characteristic  
representing the degree to which a product or 
system protects information and data so that 
persons or other products or systems have data 
access appropriate to their types and levels of 
authorization   [10].   (For   more   information   
about  product  quality,  refer  to  the  Software  
Qua lit y K A.)
1.2.  Information Security  [11*]
Information    security   preserves   confidenti-
ality,  integrity  and  availability  of  informa-
tion.  Other  properties,  such  as  authenticity,  
accountability, non-repudiation and reliability 
can  also  be  involved  [11].  Confidentiality  is  
the  property  of  ensuring  that  information  is  
not  disclosed  to  unauthorized  individuals,  
entities or processes. Integrity is the property 
of  accuracy  and  completeness.  Availability 
is   the   property   of   being   accessible   and   
usable  on  demand  by  an  authorized  entity.  
Software  engineers  should  define  the  secu-
rity properties of their software and maintain 
them  throughout  the  software  development  
life cycle.

13-2   SWEBOK
®
 GUIDE V4.0
1.3.  Cybersecurity  [12*][38]
Cybersecurity   is   safeguarding   of   people,   
society, organizations and nations from cyber 
risks. Safeguarding means to keep cyber risk 
at a tolerable level.
Generally,  cybersecurity  addresses  secu-
rity   issues   in   cyberspace,   including   the   
following:
•    Social engineering attacks
•    Hacking
•    The   proliferation   of   malicious   soft-
ware (malware)
•    Spyware
•    Other potentially unwanted software [12]
Software  engineers  should  consider  the  
mitigation of such threats as part of software 
development.
2. Security Management and Organization 
 [1*, c7][13]
Security   governance   and   management   are   
most  effective  when  they  are  systematic;  in  
other  words,  when  they  are  woven  into  the  
culture and fabric of organizational behaviors 
and actions. Project managers need to elevate 
software  security  from  a  stand-alone  tech-
nical concern to an enterprise issue [1].
2.1.  Capability Maturity Model  
 [3*, c22][14]
Many  organizations  practice  security  engi-
neering in the development of computer pro-
grams, including operating systems, functions 
that  manage  and  enforce  security,  packaged  
software  products,  middleware,  and  applica-
tions. Therefore, a diverse array of individuals 
must know how to apply appropriate methods 
and  practices,  including  product  developers,  
service  providers,  system  integrators,  system  
administrators  and  even  security  specialists.  
Systems  Security  Engineering  —  Capability  
Maturity  Model  (SSE-CMM),  which  helps  
measure  the  process  capability  of  an  organi-
zation that performs risk assessments [14], can 
be an important tool.
2.2.  Information Security Management System  
 [15*]
International  Organization  of  Standardization/
International   Electrotechnical   Commission   
(ISO/IEC) 27001:2022 specifies the require-
ments  for  establishing,  implementing,  main-
taining    and    continually    improving    an    
information    security    management    system    
(ISMS)   within   the   organizational   context   
[15].  ISMS  is  a  documented  plan  for  man-
aging  the  technology-related  security  of  an  
Software Security
Software Security
Fundamentals
Software Security
Engineering 
and Process
Software 
Engineering for 
Software Systems
Domain Specific
Software Security
Software Security
Information 
Security
Cybersecurity
Security 
Engineering 
and Development
Lifecycle
Common Criteria 
for Information 
Technology 
Security Evaluation
Security
Requirements
Security Design
Security Patterns
Construction 
for Security
Security Testing
Vulnerability
Management
Software Security
Tools
Security 
Vulnerability
Checking Tools
Penetration
Testing Tools
Security for
Container 
and Cloud
Security for
IoT Software
Security for
Machine 
Learning-Based
Application
Security 
Management and 
Organization
Capability 
Maturity Model
Information 
Security
Management 
System
Agile Practice
for Software Security
Figure 13.1. The Breakdown of Topics for the Software Security KA

SOFTWARE SECURITY   13-3
organization. This includes documenting risks 
and taking measures to address them, aiming 
to protect the organization’s data and prevent 
security  breaches  [15].  Organization  should  
use   it   to   continually   conduct   risk   assess-
ments  to  identify  security  risks  and  vulnera-
bilities and implement protective measures by 
deploying an IT team to monitor these risks. 
An ISMS can thus also raise new or changed 
existing  software  security  requirements.  In  
addition,    software  security  requirements  are  
derived from laws, regulations and obligations 
for compliance.
2.3.  Agile Practice for Software Security  
 [4*,c15,c16]
Agile  teams  need  to  understand  and  adopt  
security practices and take more responsibility 
for  their  systems’  security.  Security  profes-
sionals must learn to accept change, work faster 
and more iteratively, and think about security 
risks and how to manage risks in incremental 
terms.  Finally,  and  most  important,  secu-
rity  needs  to  become  an  enabler  instead  of  a  
blocker. The keys to a successful Agile security 
program  are  the  involvement  of  the  security  
team and developers, enablement, automation, 
and agility to keep up with Agile teams [4].
3. Software Security Engineering and 
Processes
3.1.  Security Engineering and Secure 
Development Life Cycle (SDLC)  
 [1*, c1][16*][36]
Software  is  only  as  secure  as  its  development  
process.  Security  must  be  built  into  software  
engineering  to  ensure  software  security.  The  
SDLC  concept  is  one  trend  that  aims  to  do  
this.  SDLC  uses  a  classical  spiral  model  that  
views security holistically from the perspective 
of the software life cycle and ensures that secu-
rity is inherent in software design and develop-
ment, not an afterthought later in production. 
The  SDLC  process  is  claimed  to  reduce  soft-
ware maintenance costs and increase software 
reliability against security-related faults.
Recently, DevSecOps (meaning the integra-
tion  of  development,  security  and  operations)  
has   emerged.   Beyond   SDLC,   DevSecOps   
includes  an  approach  to  culture,  automation  
and platform design to make the software life 
cycle as Agile and responsible as Agile devel-
opment and continuous integration (CI).
3.2.  Common Criteria for Information 
Technology Security Evaluation  
 [3*, c22, c25][34][35]
Security  evaluation  establishes  confidence  in  
the security functionality of IT products and 
the assurance measures applied to them. The 
evaluation results may help consumers deter-
mine  whether  IT  products  meet  their  secu-
rity   needs   or   standards   conformity.   ISO/
IEC  15408:2022,  named  Common  Criteria  
(CC)  for  Information  Technology  Security  
Evaluation, is useful as a guide for developing, 
evaluating and/or procuring IT products with 
security functionality [34].
CC addresses the protection of assets from 
unauthorized disclosure, modification or loss 
of  use.  The  categories  of  protection  relating  
to  these  three  types  of  security  failure  are  
commonly called confidentiality, integrity and 
availability, respectively.
4. Security Engineering for Software 
Systems  [1*,c1,c3][3*,c1,c3]
4.1.  Security Requirements  
 [1*,c3][2*,c2][3*,c20,c30][18]
Security  requirements  engineering  includes  
elicitation, specification, and prioritization.  It 
considers threats, as illustrated by misuse and 
abuse cases, threat actors, security risk assess-
ments,  selection  and  application  of  speci-
fication   methods,   prioritization   methods,   
inspections,  and  revisions.    Selection  of  life-
cycle models may impact the order of activities, 
and software product revision implies a need 
to revisit security requirements.  Traceability 
of   security   requirements   throughout   the   
development  process  is  important,  and  secu-
rity  teams  may  include  specialist  in  security  

13-4   SWEBOK
®
 GUIDE V4.0
requirements.    Numerous  methods  and  tools  
exist   in   support   of   security   requirements   
engineering.
4.2.  Security Design  
 [1*,c4][2*,c5][3*,c20,c31][17,40]
Security   design   concerns   how   to   prevent   
unauthorized  disclosure,  creation,  change,  
deletion  or  denial  of  access  to  informa-
tion  and  other  resources.  It  also  concerns  
how  to  tolerate  security-related  attacks  or  
violations  by  limiting  damage,  continuing  
service,  speeding  repair  and  recovery,  and  
failing and recovering securely. Access con-
trol  is  a  fundamental  concept  of  security.  
Most controls build on cryptographic algo-
rithms and cryptographic material like keys. 
It is important to carefully select these and 
how  crypto  material  is  created,  distributed  
and managed.
Software  design  security  deals  with  the  
design  of  software  modules  that  fit  together  
to  meet  the  security  objectives  specified  in  
the  security  requirements.  To  meet  secu-
rity  requirements,  developers  conduct  threat  
modeling, illustrating how a system is being 
attacked  to  specify  a  security  design  for  the  
mitigation.  This  step  clarifies  the  details  of  
security considerations and develops the spe-
cific  steps  for  implementation.  Factors  con-
sidered  may  include  frameworks  and  access  
modes  that  set  up  the  overall  security  mon-
itoring/enforcement strategies, as well as the 
individual policy enforcement mechanisms.
4.3.  Security Patterns  [1*,c4][19, 20, 21]
A security pattern describes a particular recur-
ring security problem that arises in a specific 
context  and  presents  a  well-proven  generic  
solution [21].
4.4.  Construction for Security  
 [1*,c5][3*,c20,c31][22, 23, 24]
Software  construction  security  concerns  how  
to  write  programming  code  for  specific  sit-
uations   to   address   security   considerations.   
The  term  software  construction  security  can  
mean  different  things  to  different  people.  It  
can mean the way a specific function is coded 
so  that  the  code  itself  is  secure,  or  it  can  
mean  the  coding  of  security  into  software.  
Unfortunately,  most  people  entangle  the  two  
meanings   without   distinction.   One   reason   
for such confusion is that it is unclear how to 
ensure a specific coding is secure. For example, 
in  the  C  programming  language,  the  expres-
sions “i<<1” (shift the binary representation of 
i’s value to the left by one bit) and “2*” (mul-
tiply the value of variable i by constant 2) mean 
the same thing semantically, but do they have 
the same security ramifications?
The answer could be different for different 
combinations of ISAs and compilers. Because 
of  this  lack  of  understanding,  software  con-
struction  security  —  in  its  current  state  —  
mostly refers to the second aspect mentioned 
above:  the  coding  of  security  into  software.  
Coding  of  security  into  the  software  can  be  
achieved by following recommended rules. A 
few such rules follow:
•    Structure  the  process  so  that  all  sec-
tions requiring extra privileges are mod-
ules.  The  modules  should  be  as  small  as  
possible  and  perform  only  the  tasks  that  
require those privileges.
•    Ensure that any assumptions in the pro-
gram are validated. If this is not possible, 
document  them  for  the  installers  and  
maintainers  so  they  know  the  assump-
tions attackers will try to invalidate.
•    Ensure   that   the   program   does   not   
share   objects   in   memory   with   any   
other program.
•    Check  every  function’s  error  status.  Do  
not   recover   unless   neither   the   error’s   
cause   nor   its   effects   affect   any   secu-
rity  considerations.  The  program  should  
restore  the  state  of  the  software  to  the  
state it had before the process began and 
then terminate.
Although there are no bulletproof ways to 
achieve  secure  software  development,  some  
general  guidelines  exist  that  can  be  helpful.  

SOFTWARE SECURITY   13-5
These guidelines span every phase of the soft-
ware  development  life  cycle.  The  Computer  
Emergency  Response  Team  (CERT)  pub-
lishes reputable guidelines, and the following 
are its top 10 software security practices (the 
details can be found in [22]):
1.  Validate input.
2.  Heed compiler warnings.
3.  Architect and design for security policies.
4.  Keep it simple.
5.  Default deny.
6. Adhere to the principle of least privilege.
7.   Sanitize data sent to other software.
8. Practice defense in depth.
9. Use effective quality assurance techniques.
10.  Adopt   a   software   construction   secu-
rity standard.
4.5.  Security Testing  
 [1*,c5][2*,c7][3*,c24,c31][26, 27]
Security testing ensures that the implemented 
software  meets  the  security  requirements.  It  
also verifies that the software implementation 
contains  none  of  the  known  vulnerabilities.  
Whereas  general  software  testing  methods  
can  handle  the  former,  the  latter  requires  
security-specific  testing  methods.  (For  more  
information about testing, please refer to the 
Software Testing KA.) 
There   are   two   general   approaches   to   
security-specific  testing.  The  first  approach  
includes  detecting  vulnerabilities  through  
static  analysis,  which  can  be  conducted  on  
the source code or compiled binaries. A static 
analysis  on  the  source  code  can  be  used  to  
detect programming language or implemen-
tation-specific  vulnerabilities,  while  static  
analysis on compiled binaries can be used to 
detect  vulnerabilities  that  are  not  apparent  
in  the  source  code  due  to  compiler  optimi-
zations  or  hidden  in  the  compiled  third-
party  components.  Static  analysis  can  be  
automated using tools, however while auto-
mation can play a significant role, the exper-
tise of security professionals are required to 
properly operate and configure the tools, and 
verify the results.
The  other  approach  to  detect  vulnera-
bilities  is  through  dynamic  testing,  typi-
cally  using  techniques  such  as  vulnerability  
assessment   or   penetration   testing   (also   
known as the ethical hacking test), to detect 
vulnerabilities  in  software  behavior.  Like  
static analysis, there are tools that can auto-
mate  dynamic  testing,  such  as  web  appli-
cation  scanners  and  fuzzing  tools.  Security  
experts  skilled  in  the  application  domain  
should  be  engaged  to  perform  these  tests,  
and  such  tests  should  always  be  conducted  
within  legal  boundaries  and  with  proper  
authorization.  The  latter  aspects  are  cru-
cial  to  differentiate  such  tests  from  illegal  
hacking activities.
4.6.  Vulnerability Management  
 [1*,c5][3*,c24][28,29, 30]
Using  sound  coding  practices  can  help  sub-
stantially  reduce  software  defects  commonly  
introduced  during  implementation  [1].  Such  
common   security   defects   are   categorized   
and   shared   with   databases:   the   Common   
Vulnerabilities   and   Exposures   (CVE)   [28],   
Common Weakness Enumeration (CWE) [29], 
and  Common  Attack  Pattern  Enumeration  
and  Classification  (CAPEC)  [30];  Common  
Vulnerability   Scoring   System   (CVSS)   [41]   
expresses  characteristics  and  severity  of  soft-
ware vulnerabilities. Programmers can refer to 
these  databases  for  security  implementation,  
and some tools are available to check common 
vulnerabilities  in  codes.  Security  maintenance  
encompasses the task to mitigate effects of vul-
nerabilities  in  a  system  and  third  party  com-
ponents which the system uses. The task often 
comes   with   a   vulnerability   disclosure   pro-
cess  that  allows  to  report  the  identification  of  
vulnerabilities.
5. Software Security Tools
5.1.  Security Vulnerability Checking Tools 
 [1*,c6][25]
Security vulnerability checking tools, such 
as source code analyzers and binary analysis 

13-6   SWEBOK
®
 GUIDE V4.0
tools, can be used to identify potential secu-
rity vulnerabilities and issues. Source code 
analyzers  scrutinize  code  to  detect  secu-
rity vulnerabilities, such as injection f laws, 
buffer  overf lows,  and  insecure  library  use.  
They  are  useful  at  finding  vulnerabilities  
that  can  be  identified  through  code  pat-
terns  and  logical  f laws.  Binary  analysis  
tools, on the other hand, examine compiled 
code,  including  third-party  libraries,  for  
vulnerabilities  that  might  not  be  apparent  
in  the  source  code  or  that  arise  from  the  
compilation process. While these tools sig-
nificantly  aid  in  detecting  vulnerabilities,  
they  cannot  find  all  vulnerabilities.  For  
example,  they  might  not  capture  vulner-
abilities  that  manifest  in  hard-to-produce  
software  states  or  that  crop  up  in  unusual  
circumstances [1].
5.2.  Penetration Testing Tools  [2*,c4]
Penetration testing tools can be used to eval-
uate   a   system’s   security   in   its   operational   
environment.  These  tools  perform  controlled  
attacks  on  the  system  to  uncover  vulnerabili-
ties and security weaknesses, using techniques 
such  as  fuzzing  [2],  where  malformed,  mali-
cious, or random data is submitted to the sys-
tem’s various entry points to detect faults. The 
use of penetration testing tools to expose vul-
nerabilities provide insights into how an actual 
attacker could exploit the system.
6. Domain-Specific Software Security
6.1.  Security for Container and Cloud  [31]
Cloud  infrastructure  and  services  are  often  
inexpensive and easy to provision, which can 
quickly lead to having many assets strewn all 
over the world and forgotten. These forgotten 
assets are like a ticking time bomb, waiting to 
explode into a security incident [31].
One important difference with cloud envi-
ronments is that physical assets and protection 
are  generally  not  a  concern.  Developers  can  
gleefully outsource asset tags, anti-tailgating, 
slab-to-slab barriers, placement of data center 
windows,  cameras,  and  other  physical  secu-
rity and physical asset tracking controls [31].
6.2.  Security for IoT Software  [32,33]
As  part  of  today’s  IoT  (internet  of  things),  
systems    are    interconnected    with    many    
other  devices,  especially  back-end  systems  
suffering  from  all  the  well-known  secu-
rity  flaws  inherent  in  today’s  business  IT.  
Attackers gaining access to business IT plat-
forms,  for  instance,  by  exploiting  browser  
vulnerabilities,  will  likely  also  gain  access  
to  weakly  protected  IoT  industrial  devices.  
This  can  cause  severe  damage,  including  
safety  incidents.  Hence,  the  introduction  
of a massive number of end points from the 
consumer  or  industrial  environment  cre-
ates  fertile  ground  for  the  exploitation  of  
weak  links.  Hardening  these  end  points,  
securing  device-to-device  communications,  
and  ensuring  device  and  information  cred-
ibility  in  what  until  now  have  been  closed,  
homogeneous   systems   present   new   chal-
lenges.  Comprehensive  risk  and  threat  anal-
ysis methods, as well as management tools for 
IoT platforms, are required [33].
6.3.  Security for Machine Learning-Based 
Application  [39,c8]
Although  machine  learning  techniques  are  
widely used in many systems, machine learning 
presents  a  specific  vulnerability.  Attackers  
can change the decisions of machine learning 
models. There are two kinds of attacks: model 
poisoning,  which  attacks  training  data,  and  
evasion,   which   attacks   inputs   to   trained   
models [39].

SOFTWARE SECURITY   13-7
MATRIX OF TOPICS VS. REFERENCE MATERIAL
Topic
 Allen et 
al. 2008 [1*]
McGraw 
2006 [2*] 
Bishop  
2019 [3*]
Bell  
2017 [4*]
1. Software Security Fundamentals   
1.1. Software Security  
1.2. Information Security  
1.3. Cybersecurity Ch. 23 
2. Security Management and 
Organization
Ch. 7  
2.1. Capability Maturity ModelCh. 22
2.2. Information Security 
Management System
2.3. Agile Practice for Software SecurityCh. 15,  
Ch. 16
3. Software Security Engineering 
and Processes
Ch. 9
3.1. Security Engineering and Secure 
Development Life Cycle 
Ch. 1Ch. 4
3.2. Common Criteria for Information 
Technology Security Evaluation
Ch. 22,  
Ch. 25
4. Security Engineering for 
Software Systems
Ch. 1, Ch. 15, 
Ch. 1, Ch. 3
4.1. Security RequirementsCh. 3Ch. 2Ch. 20,  
Ch. 31
Ch. 5,  
Ch. 8
4.2. Security DesignCh. 4Ch. 5Ch. 20,  
Ch. 31
Ch. 8
4.3. Security PatternsCh. 4
4.4. Construction for SecurityCh. 5Ch. 20,  
Ch. 31
    4.5.  Security  TestingCh. 5Ch. 24,  
Ch. 31
Ch. 10,  
Ch. 11
4.6. Vulnerability ManagementCh. 24  Ch.  6
5. Software Security Tools
5.1. Security Vulnerability Checking ToolsCh. 6Ch. 6
5.2. Penetration Testing ToolsCh. 4Ch. 31Ch. 11,  
Ch. 12
6. Domain-Specific 
Software Security
6.1. Security for Container and Cloud
6.2. Security for IoT Software
6.3. Security for Machine Learning-Based 
Application

13-8   SWEBOK
®
 GUIDE V4.0
FURTHER READINGS
J.   Viega,   Building   Secure   Software:   How   
to   Avoid   Security   Problems   the   Right   Way, 
Addison-Wesley, 2011.
This    book    introduces    the    definition    of    
Software Security and the activities to develop 
and maintain secure software. It includes not 
only  the  software  development  process  but  
also the related activities such as auditing and 
the monitoring of service.
L.  Kohnfelder,  Designing  Secure  Software:  A  
Guide for Developers, No Starch Press, 2021.
This  book  describes  security  activities  in  the  
software  design  and  implementation  phases,  
including secure programming and web secu-
rity. It also introduces best practices for secure 
software development.
C.W.     Axelrod,     Engineering     Safe     and     
Secure    Software    Systems,    Artech    House    
Publishers, 2012.
This  book  describes  engineering  activities  to  
make software systems safe and secure from a 
risk management viewpoint. It introduces risk 
assessment and mitigation methods for secu-
rity and safety.
REFERENCES
[1*] J.H. Allen, S.J. Barnum, R.J. Ellison, 
G. McGraw, and N.R. Mead, Software 
Security Engineering: A Guide for 
Project Managers, Addison-Wesley 
Professional, 2008.
[2*] G. McGraw, Software Security: 
Building Security In, Addison-Wesley 
Professional, 2006.
[3*]    M. Bishop, Computer Security, 
2nd Edition, Addison-Wesley 
Professional, 2019.
[4*] L. Bell, M. Brunton-Spall, R. Smith, 
and J. Bird, Agile Application Security, 
O’Reilly, 2017.
[5] T. Hsiang-Chih Hsu, Hands-On 
Security in DevOps: Ensure continuous 
security, deployment, and delivery with 
DevSecOps, Packt Publishing, 2018.
[6] T. Hsiang-Chih Hsu, Practical Security 
Automation and Testing: Tools and 
techniques for automated security scan-
ning and testing in DevSecOps, Packt 
Publishing, 2019.
[7] G. Wilson, DevSecOps: A leader’s guide 
to producing secure software without com-
promising flow, feedback and continuous 
improvement, Rethink Press, 2020.
[8] L. Rice, Container Security: 
Fundamental Technology Concepts That 
Protect Containerized Applications, 
O’Reilly & Associates Inc., 2020.
[9] ISO/IEC/JTC1 SC27 Standards: 
Trustworthiness, Cryptography, Data 
security, Cryptography, Security eval-
uation and testing, Security control, 
Identity management and privacy 
technologies.
[10*] ISO/IEC 25010:2023 Systems and 
software engineering — Systems and 
software Quality Requirements and 
Evaluation (SQuaRE) — Product 
quality model.
[11*] ISO/IEC 27000:2018 Information 
technology — Security techniques — 
Information security management sys-
tems — Overview and vocabulary.
[12*] ISO/IEC 27032:2012 Information 
technology — Security techniques — 
Guidelines for cybersecurity.
[13]   ISO/IEC 19770-1:2017 Information 
technology — IT asset management 

SOFTWARE SECURITY   13-9
— Part 1: IT asset management sys-
tems — Requirements.
[14] ISO/IEC 21827:2008 Information 
technology — Security techniques 
— Systems Security Engineering 
— Capability Maturity Model 
(SSE-CMM).
[15*] ISO/IEC 27001:2022 Information 
Security, Cybersecurity And Privacy 
Protection — Information Security 
Management Systems — Requirements.
[16] M. Howard and S. Lipner, The Security 
Development Lifecycle, Microsoft 
Press, 2006.
[17] F. Swiderski and W. Snyder, Threat 
Modeling: Design for Security, Wiley, 2014.
[18] D. Firesmith, “Security use cases,” 
Journal of Object Technology, Vol. 2, No. 
1, pp. 53-64, 2003.
[19]   E. Fernandez-Buglioni, Security Patterns 
in Practice: Designing Secure Architectures 
Using Software Patterns, Wiley, 2013.
[20] C. Nagappan, R. Lai, and R. Steel, 
Core Security Patterns: Best Practices 
and Strategies for J2EE, Web Services, 
and Identity Management, Prentice 
Hall, 2005.
[21] M. Schumacher, E. Fernandez-
Buglioni, D. Hybertson, F. 
Buschmann, and P. Sommerlad, 
Security Patterns: Integrating Security 
and Systems Engineering, Wiley, 2006.
[22] R.C. Seacord, The CERT C Secure 
Coding Standard, Addison-Wesley 
Professional, 2008.
[23] R.C. Seacord, Secure Coding in C and 
C++, Addison-Wesley Professional, 2013.
[24] D. Long, F. Mohindra, D. Seacord, 
R.C. Sutherland, and D.F. Svoboda, 
The CERT Oracle Secure Coding 
Standard for Java, 2011.
[25] J. Erickson, Hacking: The Art of 
Exploitation, 2nd Edition, No Starch 
Press, 2008.
[26] K. Scarfone, M. Souppaya, A. Cody, 
and A. Orebaugh, Technical Guide 
to Information Security Testing and 
Assessment, NIST SP800-115, 2008.
[27] PCI Security Standards Council, PCI 
DSS: Payment Card Industry Data 
Security Standard, Version 3.2, 2017.
[28] MITRE, “Common Vulnerabilities and 
Exposures (CVE),” https://cve.mitre.org/.
[29] MITRE, “Common Weakness 
Enu merat ion (C W E),” ht t ps: //c we.
mitre.org/.
[30] MITRE, “Common Attack Pattern 
Enumeration and Classification 
(CAPEC),” https://capec.mitre.org/.
[31] C. Dotson, Practical Cloud Security, 
O’Reilly, 2019.
[32] “Internet of Things Security Best 
Practices,” IEEE, 2017, https://
internetinitiative.ieee.org/resources/
reports-presentations-publications.
[33] “IoT 2020: Smart and secure IoT plat-
form,” IEC, 2016, https://www.iec.ch 
/basecamp/iot-2020-smart-and-secure 
-iot-platform.
[34]   ISO/IEC 15408-1:2022 Information 
security, cybersecurity and privacy pro-
tection — Evaluation criteria for IT 
security — Part 1: Introduction and 
general model.
[35]  ISO/IEC 18045:2008 Information 
technology — Security techniques 

13-10   SWEBOK
®
 GUIDE V4.0
— Methodology for IT security 
evaluation.
[36] DoD Enterprise DevSecOps, https://
software.af.mil/dsop/documents/.
[37] C. Easttom, Computer Security 
Fundamentals, 4th Edition, Pearson IT 
Certification, 2019.
[38] Y. Diogenes and E. Ozkaya, 
Cybersecurity — Attack and Defense 
Strategies, Second Edition, Packt 
Publishing, 2019.
[39] C. Chio and D. Freeman, Machine 
Learning and Security: Protecting 
Systems with Data and Algorithms, 
O’Reilly, 2018.
[40] I. Sommerville, Software Engineering, 
10th ed., Addison-Wesley, 2016.
[41] FIRST, CVSS v4.0 Specification 
Doc u ment, ht t ps: //w w w.fi rst.org/c v ss 
/specification-document.

14-1 
CHAPTER 14
Software Engineering 
Professional Practice
ACRONYMS
ACM
Association for Computing 
Machinery
CCPA
The California Consumer 
Privacy Act
EEAEuropean Economic Area
ENAEE
European Network 
for Accreditation of 
Engineering Education
EU
European Union
GDPR
The General Data Protection 
Regulation
IEA
International 
Engineering Alliance
IEC
International Electrotechnical 
Commission
IEEE CSIEEE Computer Society
IFIP
International Federation for 
Information Processing
IPIntellectual Property
ISO
International Organization for 
Standardization
NDANondisclosure Agreement
UI/UXUser Interface/User Experience
WIPO
World Intellectual Property 
Organization
WTOWorld Trade Organization
INTRODUCTION
The    Software    Engineering    Professional    
Practice  knowledge  area  (KA)  is  concerned  
with the knowledge, skills, and attitudes soft-
ware engineers must possess to practice soft-
ware engineering in a professional, responsible 
and ethical manner. Because of the widespread 
applications  of  software  products  in  social  
and  personal  life,  software  product  quality  
can profoundly affect personal well-being and 
societal  harmony.  Software  engineers  must  
handle  unique  engineering  problems  to  pro-
duce software with known characteristics and 
reliability. This requirement calls for software 
engineers who possess the proper knowledge, 
skills, training, and experience in professional 
practice. 
Professional  practice  refers  to  a  way  of  con-
ducting services to achieve certain standards or 
criteria in both the process of performing a ser-
vice and the end product resulting from the ser-
vice.  These  standards  and  criteria  can  include  
both   technical   and   non-technical   aspects.   
The  concept  of  professional  practice  is  espe-
cially applicable to professions with a generally 
accepted body of knowledge; code of ethics and 
professional  conduct  with  penalties  for  viola-
tions; accepted processes for accreditation, cer-
tification,   qualification,   and   licensing;   and   
professional societies to provide and administer 
all these. Admission to these professional soci-
eties is often predicated on a prescribed combi-
nation of education and experience.
A software engineer maintains professional 
practice  by  performing  all  work  following  
generally  accepted  practices,  standards,  and  
guidelines  set  forth  by  the  applicable  pro-
fessional  society,  such  as  the  Association  for  
Computing  Machinery  (ACM),  Institute  for  
Electrical  and  Electronics  Engineers  (IEEE),  
or  International  Federation  for  Information  
Processing  (IFIP),  IEEE  Computer  Society  
(IEEE   CS),   International   Organization   for   
Standardization/International Electrotechnical 
Commission   (ISO/IEC),   and   ISO/IEC/
IEEE  provide  internationally  accepted  soft-
ware   engineering   standards.   All   of   these   

14-2   SWEBOK
®
 GUIDE V4.0
standards  and  guidelines  comprise  the  foun-
dation of the professional practice of software 
engineering. 
BREAKDOWN OF TOPICS FOR 
SOF TWARE ENGINEERING 
PROFESSIONAL PRACTICE
The    Software    Engineering    Professional    
Practice  KA’s  breakdown  of  topics  is  shown  
in Figure 14.1.
The subareas presented in this KA are pro-
fessionalism, group dynamics and psychology, 
and communication skills.
1. Professionalism
A software engineer displays professionalism 
notably  by  adhering  to  a  code  of  ethics  and  
professional  conduct  and  to  standards  and  
practices established by the engineer’s profes-
sional community.
One  or  more  professional  societies  often  
represent a professional community, and this 
is  the  case  for  the  engineering  community.  
Those  societies  publish  codes  of  ethics  and  
professional  conduct  as  well  as  criteria  for  
admittance  to  the  community.  Those  criteria  
form the basis for accreditation and licensing 
activities   and   may   determine   engineering   
competence or negligence.
As software is used more widely and deeply 
in  society,  stakeholders’  requirements  have  
likewise  become  wider  and  deeper.  And  as  
software  has  become  socially  vital,  software  
engineers have worked to base the user inter-
face/user   experience   (UI/UX)   on   socially   
inclusive concepts. 
1.1.  Accreditation, Certification and 
Qualification, and Licensing  
 [1*, cls4-s5, cls10] [2] [4*, c12s10]  
 [6] [7] [8] [9] 
1.1.1. Accreditation 
Accreditation  certifies  an  organization’s  com-
petency,  authority,  or  credibility.  Accredited  
schools  or  programs  have  shown  that  they  
adhere  to  particular  standards  and  maintain  
certain qualities. In many countries, the basic 
means by which engineers acquire knowledge 
is by completing an accredited course of study. 
Often,  the  accreditation  process  is  indepen-
dent  of  the  government  and  is  performed  by  
Software Engineering
Professional Practice
Professionalism
Group Dynamics 
and Psychology
Communication 
Skills
Accreditation Certification and
Qualification, and Licensing
Code of Ethics and Professional 
Conduct
Nature and Role of Professional 
Societies
Nature and Role of Software 
Engineering Standards
Economic Impact of Software
Employment Contracts
Legal Issues
Documentation
Trade-off Analysis
Dynamics of Working in 
Teams/Groups
Individual Cognition
Dealing with Problem Complexity
Interacting with Stakeholders
Dealing with Uncertainty and 
Ambiguity
Dealing with Equity, Diversity
and Inclusivity
Reading, Understanding, 
and Summarizing
Writing
Team and Group
Communication
Presentation Skills
Figure 14.1. Breakdown of Topics for the Software Engineering Professional Practice KA

SOFTWARE ENGINEERING PROFESSIONAL PRACTICE   14-3
private  membership  associations.  There  are  
two major global accreditation organizations. 
One is the International Engineering Alliance 
(IEA),   of   which   the   Washington   Accord   
is  a  constituent.  The  other  is  the  European  
Network  for  Accreditation  of  Engineering  
Education   (ENAEE),   which   administers   
EUR-ACE®, the label awarded to engineering 
degree programs at the bachelor’s and master’s 
levels, listed by the European Commission. 
Although  the  accreditation  process  might  
differ for each country and jurisdiction, the gen-
eral  meaning  is  the  same.  Accreditation  of  an  
institution’s course of study means “the accred-
itation body recognizes an educational institu-
tion  as  maintaining  standards  that  qualify  the  
graduates for admission to higher or more spe-
cialized institutions or professional practice.” 
1.1.2. Certification and Qualification
ISO/IEC   24773-1   Software   and   Systems   
Engineering — Certification of Software and 
Systems  Engineering  Professionals  —  Part  
1:  General  Requirements  define  certification  
and qualification [8] defines certification and 
qualification.   ISO/IEC   24773-4   Software   
and  Systems  Engineering  —  Certification  
of    Software    and    Systems    Engineering    
Professionals — Part 4: Software engineering 
[9]  elaborates  requirements  and  recommen-
dations  for  certification  schemes  based  on  
ISO/IEC  24773-1,  which  are  specific  to  the  
domain of software engineering. Certification 
contains recertification. Qualification is sim-
ilar   to   certification   but   does   not   require   
re-qualification.  Certification  refers  to  the  
confirmation  of  a  person’s  particular  char-
acteristics.  A  common  type  of  certification  
is  professional  certification,  which  certifies  a  
person as being able to complete an activity in 
a certain discipline at a stated level of compe-
tency. Professional certification can verify the 
holder’s ability to meet professional standards 
and to apply professional judgment in solving 
or  addressing  problems.  Professional  certifi-
cation  can  also  verify  prescribed  knowledge,  
mastery of best practices and proven method-
ologies, and professional experience. 
An   engineer   usually   obtains   certifica-
tion  by  passing  an  examination  in  addition  
to  meeting  other  experience-based  criteria.  
Nongovernmental organizations, such as pro-
fessional   societies,   often   administer   these   
examinations. In software engineering, certi-
fication  testifies  to  one’s  capability  as  a  soft-
ware engineer. 
The qualification and certification programs 
are designed to confirm a software engineer’s 
knowledge  of  standard  software  engineering  
practices and to advance the engineer’s career. 
A  lack  of  qualification  or  certification  does  
not  exclude  the  individual  from  working  as  
a  software  engineer.  Qualification  or  certifi-
cation  in  software  engineering  is  voluntary.  
Most  software  engineers  are  not  qualified  or  
certified under any program
1.1.3. Licensing
Licensing authorizes a person to perform cer-
tain   activities   and   take   responsibility   for   
resultant   engineering   products.   The   noun   
license  refers  to  both  that  authorization  and  
the  document  recording  that  authorization.  
Governmental authorities or statutory bodies 
usually issue licenses.
Obtaining  a  license  to  practice  requires  an  
individual  to  meet  a  certain  standard  at  a  cer-
tain ability to practice or operate. Sometimes an 
entry-level requirement sets the minimum skills 
and  capabilities  to  practice,  and  as  the  profes-
sional moves through their career, the required 
skills and capabilities change and evolve.
Engineers are licensed to protect the public 
from  unqualified  individuals.  In  some  coun-
tries,  no  one  can  practice  as  a  professional  
engineer unless licensed; further, no company 
may  offer  “engineering  services”  unless  at  
least one licensed engineer is employed there. 
1.2.  Codes of Ethics and Professional Conduct 
 [1*, cls7-cls9, c10s2, Appendix] [3*, c8]  
 [4*, cls2] [5*, c33][10] [11] [13*] 
Codes  of  ethics  and  professional  conduct  
describe  the  values  and  behavior  that  an  
engineer’s professional practice and decisions 

14-4   SWEBOK
®
 GUIDE V4.0
should embody. The professional community 
establishes a code of ethics and professional 
conduct.  This  code  exists  in  the  context  of  
societal norms and local laws and is adjusted 
to agree with those norms and laws as needed. 
A  code  of  ethics  and  professional  conduct  
can offer guidance in the face of conflicting 
imperatives. More than one such code serves 
the   professional   engineering   community.   
For  example,  in  1999,  IEEE  CS  and  ACM  
launched   a   joint   Software   Engineering   
Ethics   and   Professional   Practices   Task   
Force  to  publish  a  code  of  ethics.  In  2018,  
ACM  published  its  ACM  Code  of  Ethics  
and   Professional   Conduct,   and   in   2020,   
IEEE  published  a  revision  of  its  Code  of  
Ethics  which  was  originally  approved  in  
1912.  Then,  in  2021,  IFIP  published  its  
Code  of  Ethics  and  Professional  Conduct,  
adapted  from  ACM’s  Code  of  Ethics  and  
Professional Conduct. 
Once established, codes of ethics and pro-
fessional  conduct  are  enforced  by  the  profes-
sion,  as  represented  by  professional  societies  
or by a statutory body. Violations may be acts 
of commission, such as concealing inadequate 
work,   disclosing   confidential   information,   
falsifying   information,   or   misrepresenting   
abilities.  They  may  also  occur  through  omis-
sion, including failure to disclose risks or pro-
vide  important  information,  failure  to  give  
proper credit or acknowledge references, and 
failure to represent client interests. Violations 
of  a  code  of  ethics  and  professional  conduct  
may result in penalties and possible expulsion 
from professional status. 
Software  engineers  shall  commit  them-
selves  to  making  the  analysis,  specification,  
design,  development,  testing,  and  mainte-
nance  of  software  a  beneficial  and  respected  
profession.  Following  their  commitment  to  
the  health,  safety,  and  welfare  of  the  public,  
software  engineers  shall  adhere  to  the  ten  
principles according to IEEE Code of Ethics 
adopted  by  the  IEEE  Board  of  Directions,  
June 2020. 
Since  the  code  of  ethics  and  professional  
conduct   may   be   introduced,   modified,   or   
replaced   at   any   time,   individual   software   
engineers are responsible for continuing their 
studies  to  stay  current  in  their  professional  
practice. 
1.3.  Nature and Role of Professional Societies  
 [1*, c2s3] [4*, c1s2] [5*, c35s1]
Professional   societies   comprise   a   mix   of   
practitioners  and  academics.  These  societies  
define,  advance,  and  regulate  their  corre-
sponding  professions.  Professional  societies  
help  establish  professional  standards  as  well  
as  codes  of  ethics  and  professional  conduct.  
They  also  engage  in  related  activities,  which  
include the following:
•    Establishing and promulgating a body of 
generally accepted knowledge
•    Providing  the  basis  for  licensing,  certi-
fying, and accrediting 
•    Dispensing disciplinary actions
•    Advancing the profession through confer-
ences, training, publications, and standards
Participation    in    professional    societies    
assists  individual  engineers  in  maintaining  
and sharpening their professional knowledge 
and  relevancy  and  in  expanding  and  main-
taining their professional network.
1.4.  Nature and Role of Software Engineering 
Standards  
 [1*, c10s2] [2] [4*] [5*, c32s6]
Software    engineering    standards    cover    a    
remarkable  variety  of  topics.  They  provide  
guidelines  for  the  practice  of  software  engi-
neering  and  for  processes  to  be  used  during  
the   development,   maintenance,   and   sup-
port  of  software.  By  establishing  a  common  
body   of   knowledge   and   experience,   soft-
ware  engineering  standards  establish  a  basis  
on  which  further  guidelines  may  be  devel-
oped.  Appendix  B  of  this  Guide  presents  
IEEE,  ISO/IEC,  and  ISO/IEC/IEEE  soft-
ware engineering standards that support this 
Guide’s K As. 
Standards  are  valuable  sources  of  infor-
mation    about    requirements    and    other    

SOFTWARE ENGINEERING PROFESSIONAL PRACTICE   14-5
guidance  that  can  support  software  engi-
neers  in  everyday  activities.  Adherence  to  
standards   promotes   discipline   by   enumer-
ating minimal characteristics of products and 
practices.  That  discipline  helps  mitigate  sub-
conscious assumptions or overconfidence in a 
design.  For  these  reasons,  organizations  per-
forming software engineering activities often 
include  conformance  to  standards  as  part  of  
their organizational policies.
1.5.  Economic Impact of Software  
 [3*, c1s1, c10s8] [4*, c1s1] [13*]
The  software  has  economic  effects  at  the  
individual,  business,  and  societal  levels.  For  
example,  software  “success”  may  be  deter-
mined  by  a  product’s  suitability  for  a  recog-
nized  problem  and  by  its  effectiveness  when  
applied  to  that  problem.  At  the  individual  
level,  an  engineer’s  continuing  employment  
may  depend  on  their  ability  and  willingness  
to interpret and execute tasks in meeting cus-
tomers’ or employers’ needs and expectations. 
The customer’s or the employer’s financial sit-
uation may be positively or negatively affected 
by software purchases.
At  the  business  level,  software  properly  
applied to a problem can eliminate months of 
work and translate to elevated profits or more 
effective   organizations.   Organizations   that   
acquire  or  provide  successful  software  may  
become  a  boon  to  the  society  in  which  they  
operate  by  providing  both  employment  and  
improved  services.  However,  the  software’s  
development or acquisition costs can be con-
siderable, like those of any major acquisition.
At the societal level, direct impacts of soft-
ware  success  or  failure  include  the  avoidance  
or experience of accidents, interruptions, and 
loss  of  service.  Indirect  impacts  include  the  
success  or  failure  of  the  organization  that  
acquired or produced the software, increased 
or  decreased  societal  productivity,  harmo-
nious or disruptive social order, and even the 
saving or loss of property or life. In addition, 
as  digitalization  progresses,  easier  and  faster  
access  to  the  information  needed  may  bring  
higher social value.
1.6.  Employment Contracts  
 [1*, c6, c7] [10] [11] [12]
Software  engineering  services  may  be  pro-
vided  under  a  variety  of  client-engineer  rela-
tionships. For example, the work may be done 
through    a    company-to-customer    supplier    
arrangement,  an  engineer-to-customer  con-
sultancy  arrangement,  a  direct-hire,  or  even  
through volunteering. In these situations, the 
customer and supplier agree that a product or 
service will be provided in return for some con-
sideration. Here, we are most concerned with 
engineer-to-customer arrangements and their 
attendant  agreements  or  contracts,  whether  
they are of the direct-hire or consultant variety, 
and the issues they typically address.
A common concern in software engineering 
contracts is confidentiality. Employers derive 
commercial advantage from intellectual prop-
erty (IP), so they strive to protect that prop-
erty   from   disclosure.   Therefore,   software   
engineers  are  often  required  to  sign  nondis-
closure agreements (NDA) or IP agreements 
as  a  precondition  to  working.  These  agree-
ments   typically   apply   to   information   the   
software  engineer  could  gain  only  through  
association  with  the  customer.  The  terms  of  
these agreements may extend past the associ-
ation’s termination.
Another  concern  is  IP  ownership.  Rights  
to  software  engineering  assets  —  products,  
innovations, inventions, discoveries, and ideas 
— may reside with the employer or customer, 
under explicit contract terms or relevant laws, 
if those assets are obtained during the software 
engineer’s  relationship  with  that  employer  or  
customer.  Contracts  differ  in  the  ownership  
of  assets  created  using  non-employer-owned  
equipment or information.
Finally,  contracts  can  also  specify,  among  
other elements: 
•    The location at which work is performed
•    Standards to which that work will be held
•    The    system    configuration    used    for    
development
•    Limitations  of  the  software  engineer’s  
and employer’s liability

14-6   SWEBOK
®
 GUIDE V4.0
•    A  communication  matrix  and/or  esca-
lation plan
•    Administrative details such as rates, fre-
quency of compensation, working hours, 
and working conditions
1.7.  Legal Issues  [1*, c6, c11] [2]  
 [3*, c5s3–c5s4] [4*, c12s3, c13s2]
Legal   issues   surrounding   software   engi-
neering   professional   practice   include   mat-
ters related to standards, trademarks, patents, 
copyrights,   trade   secrets,   professional   lia-
bility,  legal  requirements,  trade  compliance,  
cybercrime,  and data  privacy.  It  is  there-
fore   beneficial   to   know   these   issues   and   
their  applicability.  In  addition,  legal  issues  
are  jurisdictionally  based,  so  software  engi-
neers  must  consult  attorneys  who  specialize  
in the type and jurisdiction of any identified 
legal issues.
1.7.1. Standards
Adherence  to  standards  provides  a  defense  
from legal action or allegations of malpractice. 
1.7.2. Trademarks
A trademark relates to any word, name, symbol, 
or  device  used  in  business  transactions.  It  is  
used  “to  indicate  the  source  or  origin  of  the  
goods.” Trademark protection protects names, 
logos,  images,  and  packaging.  However,  if  a  
name,   image,   or   other   trademarked   asset   
becomes a generic term, trademark protection 
is nullified.
The       World       Intellectual       Property       
Organization    (WIPO)    is    the    authority    
that  frames  the  rules  and  regulations  on  
trademarks.  WIPO  is  the  United  Nations  
agency  dedicated  to  protecting  the  use  of  
IP as a means of stimulating innovation and 
creativ it y. 
1.7.3. Patents
Patents  protect  an  inventor’s  right  to  manu-
facture and sell an idea. A patent consists of 
exclusive  rights  granted  by  a  sovereign  gov-
ernment  to  an  individual,  group  of  individ-
uals,  or  organization  for  a  limited  period.  
Patents  are  an  old  form  of  idea-ownership  
protection and date to the 15th century.
Application for a patent entail keeping and 
producing  careful  records  of  the  process  that  
led to the invention. In addition, patent attor-
neys  help  write  patent  disclosure  claims  in  a  
manner  most  likely  to  protect  the  software  
engineer’s  rights.  Note  that  if  inventions  are  
made during a software engineering contract, 
ownership may belong to the employer or cus-
tomer or be jointly held rather than belong to 
the software engineer.
Rules  vary  concerning  what  is  and  what  
is  not  patentable.  In  many  countries,  soft-
ware  code  is  not  patentable,  but  software  
algorithms may be. Existing and filed patent 
applications can be found at WIPO. 
1.7.4. Copyrights
Most governments give exclusive rights of an 
original work to its creator, usually for a lim-
ited  time,  enacted  as  copyright.  Copyrights  
protect  the  way  an  idea  is  presented  —  not  
the  idea  itself.  For  example,  they  may  pro-
tect  the  particular  wording  of  an  account  of  
a  historical  event,  whereas  the  event  itself  is  
not  protected.  Copyrights  are  long-term  and  
renewable.  As  a  form  of  IP,  they  date  to  the  
17th cent ur y.
1.7.5. Trade Secrets
In many countries, an intellectual asset such as 
a formula, algorithm, process, design, method, 
pattern, instrument, or compilation of informa-
tion may be considered a trade secret, provided 
the asset is not generally known and may pro-
vide  a  business  with  some  economic  advan-
tage.  The  “trade  secret”  designation  provides  
legal protection if the asset is stolen. This pro-
tection is not subject to a time limit. However, 
if another party derives or discovers the same 
asset  legally,  then  the  asset  is  no  longer  pro-
tected and the other party will also possess all 
rights to use it.

SOFTWARE ENGINEERING PROFESSIONAL PRACTICE   14-7
1.7.6. Professional Liability
It  is  common  for  software  engineers  to  be  
concerned   with   professional   liability   mat-
ters. As engineers provide services to a client 
or  employer,  it  is  crucial  that  they  adhere  to  
standards  and  generally  accepted  practices  
to  protect  themselves  against  allegations  of  
or  proceedings  related  to  malpractice,  negli-
gence, or incompetence.
For   engineers   (including   software   engi-
neers), professional liability is related to product 
liability. Under the laws and rules of their juris-
diction, engineers may be held accountable for 
failing to fully and conscientiously follow rec-
ommended practice; this is known as negligence. 
They  may  also  be  subject  to  laws  governing  
strict liability and implied or express warranty, 
where,  by  selling  the  product,  the  engineer  is  
held  to  warrant  that  the  product  is  both  suit-
able  and  safe  for  use.  In  some  countries  (e.g.,  
in the US), privity (a doctrine under which one 
can sue only the person selling the product) is 
no longer a defense against liability actions.
Legal suits for liability can be brought under 
tort  law  in  the  US,  allowing  anyone  who  is  
harmed to recover their loss even if no guaran-
tees  were  made.  Because  it  is  difficult  to  mea-
sure the suitability or safety of software, failure 
to take due care can be used to prove negligence 
on  the  part  of  software  engineers.  Engineers  
can  defend  themselves  against  such  an  allega-
tion  by  showing  that  they  followed  standards  
and  generally  accepted  practices  in  developing  
the  product  to  be  ready  to  consult  with  attor-
neys regarding the standard of care in any rel-
evant  jurisdiction  to  manage  risks  associated  
with product liability or professional liability.
1.7.7. Legal Requirements
Software engineers must operate within local, 
national  and  international  legal  frameworks.  
Therefore, software engineers must know the 
legal requirements for the following:
•    Registration   and   licensing,   including   
examination,  education,  experience,  and  
training requirements
•    Contractual agreements
•    Noncontractual  legalities,  such  as  those  
governing liability
Basic   information   on   the   international   
legal  framework  can  be  accessed  from  the  
World Trade Organization (WTO). 
1.7.8. Trade Compliance
All  software  professionals  must  be  aware  of  
legal  restrictions  on  the  import,  export,  or  
re-export  of  goods,  services,  and  technology  
in the jurisdictions in which they work. Such 
rules often concern export controls and classi-
fication; transfer of goods; acquisition of nec-
essary  governmental  licenses  for  foreign  use  
of hardware and software; services and tech-
nology  by  sanctioned  nations,  enterprises,  or  
individual  entities;  and  import  restrictions  
and duties. Trade experts should be consulted 
for detailed compliance guidance.
1.7.9. Cybercrime
Cybercrime refers to any crime that involves a 
computer,  computer  software,  computer  net-
works,  or  embedded  software  controlling  a  
system.  The  computer  or  software  may  have  
been  used  in  the  commission  of  a  crime  or  
have  been  the  target  of  the  crime.  This  cat-
egory  of  crime  includes  fraud,  unauthorized  
access,  spam,  obscene  or  offensive  content,  
threats,  harassment,  theft  of  sensitive  per-
sonal  data  or  trade  secrets,  and  use  of  one  
computer  to  damage  or  infiltrate  other  com-
puters and automated system controls.
Computer   and   software   users   commit   
fraud  by  altering  electronic  data  to  facilitate  
illegal activity. Forms of unauthorized access 
include  hacking,  eavesdropping,  and  using  
computer  systems  in  a  way  that  is  concealed  
from their owners. Many countries have laws 
that specifically cover cybercrimes, but many 
do not have effective statutes, making cyber-
crime  difficult  to  prosecute  in  some  cases.  
The  software  engineer  has  a  professional  
obligation  to  consider  the  threat  of  cyber-
crime  and  to  consider  how  the  software  

14-8   SWEBOK
®
 GUIDE V4.0
system’s  security  will  protect  the  software  
and  user  information  from  accidental  or  
malicious access, use, modification, destruc-
tion, or disclosure.
Dark patterns are deceptive UI/UX inter-
actions designed to mislead or trick users into 
making  them  do  something  they  may  not  
want  to  do.  These  patterns  do  not  have  the  
users’  interests  in  mind  and  aim  for  exploit-
ability  rather  than  usability.  Creating  dark  
patterns is not good ethical practice. Software 
engineers   should   be   responsible   for   their   
actions and be transparent with users instead 
of manipulating them.
1.7.10. Data Privacy
Software  engineers  should  know  that  data  
privacy  is  a  key  legal  requirement  in  many  
countries.   The   General   Data   Protection   
Regulation  (GDPR),  adopted  on  14  April    
2016,  and  enforceable  since  25  May  2018,  
regulates  data  protection  and  privacy  in  the 
European  Union  (EU)  and  the  European  
Economic Area (EEA). It also addresses the 
transfer of personal data outside the EU and 
EEA  areas.  The  GDPR’s  primary  aim  is  to  
enhance  individuals’  control  and  rights  over  
their data and to simplify the regulatory envi-
ronment for international business.
The  regulation  became  a  model  for  many  
national   laws   outside   the   EU,   including   
the  UK,  Chile,  Japan,  Brazil,  South  Korea,  
Argentina,    and    Kenya.    The    California    
Consumer   Privacy   Act   (CCPA),   adopted   
on  28  June  2018,  has  many  similarities  with  
the GDPR. 
1.8. Documentation  
 [1*, c10s5.8] [3*, c1s5] [4*] [5*, c32]
Providing   clear,   thorough,   and   accurate   
documentation  is  the  responsibility  of  each  
software engineer. The adequacy of documen-
tation is judged according to different criteria, 
based on stakeholder needs. Good documen-
tation  complies  with  accepted  standards  and  
guidelines.  In  particular,  software  engineers  
should document the following:
•    Relevant facts
•    Significant risks and trade-offs 
•    Warnings  of  undesirable  or  dangerous  
consequences  from  the  use  or  misuse  of  
the software
•    Relevant information pertaining to attri-
bute, license type, and sourcing
Software engineers should avoid:
•    Certifying   or   approving   unacceptable    
products
•    Disclosing confidential information
•    Falsifying facts or data
In  addition,  software  engineers  and  their  
managers  should  provide  the  following  doc-
umentation for other elements of the software 
development organization to use:
•    Software requirements specifications, soft-
ware design documents, details on the soft-
ware engineering tools used, software test 
specifications and results, and details about 
the adopted software engineering methods
•    Problems  encountered  during  the  devel-
opment process
For external stakeholders (customers, users, 
others),  software  documentation  should  pro-
vide the following:
•    Information     needed     to     determine     
whether  the  software  is  likely  to  meet  
customer and user needs
•    Description  of  safe  and  unsafe  use  of  
the software
•    Explanation  of  how  to  protect  sensitive  
information  created  by  or  stored  using  
the software
•    Clear identification of warnings and crit-
ical procedures 
Software use may include installation, oper-
ation,   administration,   and   performance   of   
other functions by various groups of users and 
support personnel. If the customer will acquire 
ownership  of  the  software  source  code  or  the  
right to modify the code, the software engineer 

SOFTWARE ENGINEERING PROFESSIONAL PRACTICE   14-9
should  provide  documentation  of  the  func-
tional  specifications,  the  software  design,  the  
test suite, and the necessary operating environ-
ment  for  the  software.  Documents  should  be  
kept  for  at  least  as  long  as  the  software  prod-
uct’s life cycle or the time required by relevant 
organizational or regulatory requirements.
1.9. Trade-Off Analysis  
 [3*, c1s2, c10] [4*, c7s2, c13s4] [13*, 
                                                    c9s5.10]
A   software   engineer   often   has   to   choose   
between  alternative  problem  solutions.  The  
outcome of these choices is determined by the 
software  engineer’s  professional  evaluation  of  
each  alternative’s  risks,  costs,  and  benefits  in  
cooperation  with  stakeholders.  The  software  
engineer’s evaluation is called trade-off analysis. 
Trade-off analysis notably identifies competing 
and complementary software requirements to 
prioritize  the  final  requirements  defining  the  
software to be constructed. (See Requirements 
Negotiation  in  the  Software  Requirements  
KA  and  Determination  and  Negotiation  of  
Requirements  in  the  Software  Engineering  
Management KA.)
  When  an  ongoing  software  development  
project is late or over budget, a trade-off anal-
ysis  is  often  conducted  to  decide  which  soft-
ware requirements can be relaxed or dropped 
given  the  effects  thereof.  The  first  step  in  a  
trade-off analysis is establishing design goals 
(see  Engineering  Design  in  the  Engineering  
Foundations  KA)  and  setting  the  relative  
importance  of  those  goals.  This  permits  the  
identification of the solution that most nearly 
meets those goals; this means that the way the 
goals are stated is critically important.
Design   goals   may   include   minimizing   
monetary   cost   and   maximizing   reliability,   
performance,   or   other   criteria   on   various   
dimensions. However, it is difficult to formu-
late  a  trade-off  analysis  of  cost  against  risk,  
especially   where   primary   production   and   
secondary  risk-based  costs  must  be  weighed  
against each other. 
A  software  engineer  must  ethically  con-
duct  a  trade-off  analysis  —  notably  by  being  
objective  and  impartial  when  selecting  cri-
teria for comparing alternative problem solu-
tions  and  assigning  weights  or  importance  
to  these  criteria.  In  addition,  any  conflict  of  
interest must be disclosed upfront.
2. Group Dynamics and Psychology
Engineering   work   is   often   conducted   in   
teams.  A  software  engineer  should  interact  
cooperatively  and  constructively  with  others  
to  first  determine  and  then  meet  needs  and  
expectations.  Knowledge  of  group  dynamics  
and  psychology  is  an  asset  when  interacting  
with  customers,  coworkers,  suppliers,  and  
subordinates  to  solve  software  engineering  
problems. 
2.1.  Dynamics of Working in Teams/Groups  
 [3*, c1s6] [14*, c1s3.5, c10]
Software  engineers  must  work  with  others.  
On the one hand, they work internally in engi-
neering teams; on the other hand, they work 
with  customers,  members  of  the  public,  reg-
ulators,  and  other  stakeholders.  Performing  
teams — those who demonstrate a consistent 
quality of work and progress toward goals — 
are cohesive and possess a cooperative, honest 
and   focused   atmosphere.   Individual   and   
team goals are aligned so the members natu-
rally commit to and feel ownership of shared 
outcomes. 
Team  members  facilitate  this  atmosphere  
by  being  intellectually  honest,  using  group  
thinking,  admitting  ignorance,  and  acknowl-
edging   mistakes.   They   share   responsibility,   
rewards,  and  workload  fairly.  They  commu-
nicate  clearly  and  directly  to  one  another  and  
in  documents  and  source  code  so  information  
is  accessible  to  everyone.  Peer  reviews  about  
work  products  are  framed  in  a  constructive  
and nonpersonal way. (See Reviews and Audits 
in  the  Software  Quality  KA.)  This  allows  all  
the members to pursue a continuous improve-
ment  and  growth  cycle  without  personal  risk.  
Members   of   cohesive   teams   demonstrate   
respect for one another and their leader.
  One  point  to  emphasize  is  that  software  

14-10   SWEBOK
®
 GUIDE V4.0
engineers must be able to work in multidisci-
plinary  environments  and  varied  application  
domains.  Because  software  is  everywhere,  
from  phones  to  cars,  it  affects  people’s  lives  
far  beyond  the  more  traditional  concept  of  
software made for information management 
in a business environment. 
2.2.  Individual Cognition 
 [3*, c1s6.5] [5*, c33]
Engineers   want   to   solve   problems.   Every   
engineer  strives  to  solve  problems  effectively  
and  efficiently.  However,  the  limits  and  pro-
cesses  of  individual  cognition  affect  prob-
lem-solving.   Individual   cognition   plays   a   
prominent  role  in  problem-solving  in  soft-
ware  engineering,  in  part  because  of  the  
highly abstract nature of software itself.
An  individual’s  (in  particular,  a  software  
engineer’s)  ability  to  decompose  a  problem  
and creatively develop a solution can be inhib-
ited by the following:
•    The need for more knowledge
•    Subconscious assumptions
•    The volume of data
•    Fear of failure or the consequence of failure 
•    Culture, either of the application domain 
or the organization
•    Lack of ability to express the problem 
•    Perceived working atmosphere
•    The individual’s emotional status
The   effects   of   these   inhibiting   factors   
can  be  reduced  by  cultivating  good  prob-
lem-solving habits that minimize the impact 
of  misleading  assumptions.  The  ability  to  
focus  is  crucial,  as  is  intellectual  humility.  
Both  allow  a  software  engineer  to  suspend  
personal   considerations   and   consult   with   
others  freely,  which  is  especially  important  
when working in teams.
Engineers   use   basic   methods   to   facili-
tate   problem-solving.   (See   Problem-Solving   
Techniques  in  the  Computing  Foundations  
KA.)  Breaking  down  problems  and  solving  
them  one  piece  at  a  time  reduces  cognitive  
overload.  By  taking  advantage  of  professional  
curiosity and pursuing continuous professional 
development, engineers gain skills and knowl-
edge. Reading, networking, and experimenting 
with new tools, techniques and methods are all 
valid means of professional development. 
2.3. Dealing with Problem Complexity  
 [3*, c3s2] [4*, c1s1, c20s1-s5] [5*, c33]
Many, if not most, software engineering prob-
lems are too complex and difficult to address 
as a whole or to be tackled by individual soft-
ware  engineers.  When  such  circumstances  
arise,    engineers    typically    use    teamwork    
and  problem  decomposition.  (See  Problem-
Solving    Techniques    in    the    Computing    
Foundations KA.) 
Teams  work  together  to  deal  with  large,  
complex  problems  by  sharing  burdens  and  
drawing on one another’s knowledge and cre-
ativity.  When  software  engineers  work  in  
teams,  individual  engineers’  different  views  
and  abilities  complement  one  another  and  
help  build  a  solution  otherwise  difficult  to  
come  by.  Some  teamwork  examples  in  soft-
ware  engineering  are  pair  programming  (see  
Agile  Methods  in  the  Software  Engineering  
Models  and  Methods  KA)  and  code  review  
(see  Reviews  and  Audits  in  the  Software  
Quality K A).
2.4.  Interacting with Stakeholders  [4*]
The success of a software engineering endeavor 
depends  on  positive  interactions  with  stake-
holders. Stakeholders should provide support, 
information, and feedback at all stages of the 
software  life  cycle.  For  example,  during  the  
early stages, it is critical to identify all stake-
holders  and  discover  how  the  product  will  
affect  them  to  properly  capture  a  sufficient  
definition of stakeholder requirements.
 In Agile software development, the involve-
ment  of  stakeholders  is  even  more  essential  
than  in  other  types  of  development.  First,  
during  development,  stakeholders  may  pro-
vide  feedback  on  specifications  or  early  ver-
sions  of  the  software,  changes  of  priority,  
and  clarification  of  detailed  or  new  software  

SOFTWARE ENGINEERING PROFESSIONAL PRACTICE   14-11
requirements.  Last,  during  software  mainte-
nance and until the end of product life, stake-
holders  can  provide  feedback  on  evolving  or  
new  requirements  and  problem  reports  so  
the  software  can  be  extended  and  improved.  
Clearly, regular stakeholder involvement will 
lead to a better application. It is vital to main-
tain   open   and   productive   communication   
with  stakeholders  during  the  software  prod-
uct’s life cycle. 
2.5.  Dealing with Uncertainty and Ambiguity  
 [4*, c4s1, c4s4, c11s5, c24s5] [14*, c9s4]
As  with  engineers  in  other  fields,  software  
engineers  must  often  deal  with  and  resolve  
uncertainty  and  ambiguities  while  providing  
services  and  developing  products.  The  soft-
ware  engineer  must  reduce  or  eliminate  any  
lack  of  clarity  that  is  an  obstacle  to  per-
forming work.
Often, uncertainty reflects a lack of knowl-
edge.  If  that  is  the  case,  investigating  the  
issue by reading formal sources such as text-
books and professional journals, interviewing 
stakeholders,  or  consulting  with  teammates  
and peers can likely solve the problem.
When uncertainty or ambiguity cannot be 
overcome easily, software engineers or organi-
zations may regard it as a project risk. When 
this is the case, work estimates or pricing are 
adjusted  to  mitigate  the  anticipated  cost  of  
addressing  it.  (See  Risk  Management  in  the  
Software Engineering Management KA.)
2.6.  Dealing with Equity, Diversity, and 
Inclusivity  [4*] [14*, c10s7]
The equity, diversity, and inclusivity environ-
ment  can  affect  a  group’s  dynamics.  This  is  
especially  true  when  the  group  is  geograph-
ically  separated  or  communication  is  infre-
quent  because  such  separation  elevates  the  
importance   of   each   contact.   Intercultural   
communication  is  even  more  difficult  if  the  
difference  in  time  zones  makes  oral  commu-
nication less frequent. 
Multicultural   environments   are   preva-
lent  in  software  engineering,  perhaps  more  
than  in  other  engineering  fields,  because  of  
the strong trend of international outsourcing 
and  the  easy  shipment  of  software  compo-
nents  instantaneously  around  the  globe.  For  
example, it is common for a software project 
to be divided into pieces across national and 
cultural borders. It is also common for a soft-
ware  project  team  to  consist  of  people  from  
diverse cultural backgrounds. 
For  a  software  project  to  succeed,  team  
members  must  embrace  tolerance  of  dif-
ferent  cultural  and  social  norms,  acknowl-
edging  that  not  all  societies  have  the  same  
social  expectations.  The  support  of  leader-
ship and management can facilitate tolerance 
and  understanding.  More  frequent  commu-
nication,   including   face-to-face   meetings,   
can  help  mitigate  geographical  and  cultural  
divisions,  promote  cohesiveness,  and  raise  
productivity.    Also,    communicating    with    
teammates in their native language could be 
beneficial. 
In   the   software   industry,   gender   bias   
is   still   prevalent.   Implementing   broader   
recruiting  strategies,  specific  and  measur-
able  performance  evaluation  criteria,  and  
transparent  procedures  for  assigning  com-
pensation  can  reduce  gender  inequality  in  
the software industry. These trends can con-
tribute  to  building  a  diverse  environment  
for   all   software   engineers,   regardless   of   
their gender. 
3. Communication Skills 
A software engineer must communicate well, 
both  orally  and  in  reading  and  writing.  To  
meet  software  requirements  and  deadlines,  
engineers  must  establish  clear  communica-
tion  with  customers,  supervisors,  coworkers,  
and  suppliers.  Optimal  problem-solving  is  
made  possible  through  the  ability  to  inves-
tigate,   comprehend   and   summarize   infor-
mation.  Customer  product  acceptance  and  
safe  product  use  depend  on  relevant  training  
and  documentation.  The  software  engineer’s  
career success is affected by consistently pro-
viding oral and written communication effec-
tively and on time. 

14-12   SWEBOK
®
 GUIDE V4.0
3.1.  Reading, Understanding, 
and Summarizing  [4*, c4s5] [5*, c33s3] 
Software  engineers  must  be  able  to  read  and  
understand  technical  material.  Technical  mate-
rial includes reference books, manuals, research 
papers, online sources and program source code.
Reading  is  not  only  a  primary  way  of  
improving  skills  but  also  a  way  of  gathering  
information for completing engineering goals. 
A  software  engineer  sifts  through  accumu-
lated information, focusing on the pieces that 
will  be  most  helpful.  Customers  may  request  
that a software engineer summarize the results 
of such information-gathering for them, sim-
plifying or explaining it so that they can make 
the final choice among competing solutions.
Reading  and  comprehending  source  code  
are also components of information-gathering 
and   problem-solving.   For   example,   when   
engineers modify, extend or rewrite software, 
they  must  understand  both  its  implementa-
tion, directly derived from the presented code, 
and its design, which must often be inferred. 
3.2.  Writing  [3*, c1s5] [4*, c4s2-s3]
Software   engineers   can   produce   written   
products  requested  by  customers  or  required  
by generally accepted practice. These written 
products  may  include  source  code,  software  
project   plans,   software   requirement   docu-
ments,  risk  analyses,  software  design  doc-
uments,  software  test  plans,  user  manuals,  
technical  reports  and  evaluations,  justifica-
tions, diagrams and charts, and so forth. 
Clear, concise writing is important because 
writing is often the primary method of com-
munication  among  relevant  parties.  In  all  
cases,  written  software  engineering  products  
must be accessible, understandable, and rele-
vant to their intended audience.
3.3.  Team and Group Communication  
 [3*, c1s6.8] [4*, c22s3] [5*, c27s1]  
 [14*, c10s4]
Effective  communication  among  team  and  
group members is essential to a collaborative 
software   engineering   effort.   Stakeholders   
must  be  consulted;  decisions  must  be  made,  
and  plans  must  be  generated.  The  greater  
the number of team and group members, the 
greater the need to communicate.
However,  the  number  of  communication  
paths  grows  quadratically  with  the  addition  
of  each  team  member.  Furthermore,  team  
members  are  unlikely  to  communicate  with  
anyone perceived to be removed from them by 
more than two degrees (levels). This problem 
can  be  more  serious  when  software  engi-
neering endeavors or organizations are spread 
across national and continental borders.
   Some   communication   can   be   accom-
plished  in  writing.  Software  documentation  
is  a  common  substitute  for  direct  interaction.  
Email  is  another,  but  although  it  is  useful,  it  
is not always enough. Also, if one receives too 
many messages, it becomes difficult to identify 
the important information. Increasingly, orga-
nizations  are  using  enterprise  collaboration  
tools  to  share  information.  In  addition,  elec-
tronic information stores, accessible to all team 
members   for   organizational   policies,   stan-
dards,  common  engineering  procedures,  and  
project-specific information, can be beneficial. 
Some  software  engineering  teams  focus  
on face-to-face interaction and promote such 
interaction   through   office   space   arrange-
ments. Although private offices improve indi-
vidual productivity, other arrangements, such 
as  co-locating  team  members  in  physical  or  
virtual spaces and providing communal work 
areas, can boost collaborative efforts. 
3.4.  Presentation Skills  
 [3*, c1s5] [4*, c22] [14*, c10s7–c10s8]
Software  engineers  rely  on  their  presenta-
tion  skills  during  software  life  cycle  pro-
cesses.  For  example,  software  engineers  may  
walk   customers   and   teammates   through   
software   requirements   during   the   phase   
and  conduct  formal  requirements  reviews.  
(See  Requirement  Reviews  in  the  Software  
Requirements  KA.)  During  and  after  soft-
ware design, software construction, and soft-
ware  maintenance,  software  engineers  lead  

SOFTWARE ENGINEERING PROFESSIONAL PRACTICE   14-13
reviews,  product  walkthroughs  (see  Review  
and Audits in the Software Quality KA), and 
training.  These  require  the  ability  to  present  
technical  information  to  groups  and  solicit  
ideas or feedback.
 Therefore, the software engineer’s ability 
to convey concepts effectively in a presentation 
influences product acceptance, management, 
and  customer  support.  It  also  influences  the  
ability  of  stakeholders  to  comprehend  and  
assist  in  the  product  effort.  This  knowledge  
needs  to  be  archived  in  slides,  knowledge  
write-ups, technical white papers, and other 
material used for knowledge creation.
MATRIX OF TOPICS VS. REFERENCE MATERIAL
1. ProfessionalismBott et al. 
 
2000 [1*]Voland, 
 
20 03 [3*]Sommerville,
 
2016 [4*]McConnel, 
 
2 0 0 4 [5*]To c k e y,   2 0 0 4 [1 3 *]Fa i rley, 2009 [14*]
1.1. Accreditation,
Certification and 
Qualification, and Licensing
c1s5,
c1s10
c12s10
1.2. Codes of Ethics and 
Professional Conduct
c1s7-s9,  
c10s2, App
c1s2
1.3. Nature and Role of 
Professional Societies
c2s3c1s2c35s1
1.4. Nature and Role of 
Software Engineering 
Standards 
c10s2,*c32s6
1.5. Economic Impact 
of Software
c1s1,
c10s8
c1s1*
1.6. Employment Contractsc6, c7*
1.7. Legal Issuesc6, c11c5s3-
s4,
c12s3,
c13s2
1.8. Documentationc10s5c1s5*c32
1.9. Trade-Off Analysisc1s2,
c10
c7s2 ,
c13s4
c9s 5-10
2. Group Dynamics and 
Psychology
2.1. Dynamics of Working in 
Te a m s / G r o u p s
c1s6c1s3-5,
c10
2.2. Individual Cognitionc1s6c33
2.3. Dealing with Problem 
Complexity
c3s2c1s1,
c20s1-s5
2.4. Interacting with 
Stakeholders
*
2.5. Dealing with 
Uncertainty and Ambiguity
c4s1,c4s4,
c11s5c24s5
c9s4

14-14   SWEBOK
®
 GUIDE V4.0
2.6. Dealing with Equity, 
Diversity, and Inclusivity
*c10s7
3. Communication Skills
3.1. Reading, Understanding, 
and Summarizing
c4s5c33s3
3.2. Writingc1s5c4s2-s3
3.3. Team and Group 
Communication
c1s6c22s3c 27s1c10s4
3.4. Presentation Skillsc1s5c22c10 s7-s8
FURTHER READINGS 
G.M.  Weinberg,  The  Psychology  of  Computer  
Programming [1 5 ]. 
This was the first major book to address pro-
gramming as an individual and team effort; it 
has become a classic in the field.
Kinney and Lange, P.A., Intellectual Property 
Law for Business Lawyers [16]. 
This book covers IP laws in the US. It not only 
talks about what the IP law is; it also explains 
why it looks the way it does.
REFERENCES
[1*]  F. Bott et al., Professional Issues in 
Software Engineering, 3rd ed., Taylor & 
Francis, 2000.
[2]  Appendix B of this Guide.
[3*] G. Voland, Engineering by Design, 2nd 
ed., Prentice-Hall, 2003.
[4*] I. Sommerville, Software Engineering, 
10th ed., Addison-Wesley, 2016.
[5*] S. McConnell, Code Complete, 2nd ed., 
Microsoft Press, 2004.
[6] 25 Years Washington Accord, 
IEC, 2014.
[7] EUR-ACE, 2017.
[8] ISO/IEC 24773-1, Software and 
Systems Engineering – Certification 
of Software and System Engineering 
Professionals — Part 1: General 
Requirements.
[9] ISO/IEC 24773-4 Software and Systems 
Engineering — Certification of Software 
and Systems Engineering Professionals 
— Part 4: Software engineering. 
[10] ACM Code of Ethics and Professional 
Conduct, 2018.
[11] IEEE Code of Ethics, 2020.
[12] IFIP Code of Ethics and Professional 
Conduct, 2021.
[13*] S.  Tockey, Return on Software: 
Maximizing the Return on Your Software 
Investment, Addison-Wesley, 2004.
[14*] R. E. Fairley, Managing and Leading 
Software Projects, Wiley-IEEE 
Computer Society Press, 2009.
[15] G. M. Weinberg, The Psychology 
of Computer Programming: Silver 
Anniversary Edition, Dorset 
House, 1998.
[16] Kinney and Lange, P.A., Intellectual 
Property Law for Business Lawyers, 
Thomson West, 2013.

15-1 
CHAPTER 15
Software Engineering 
Economics
ACRONYMS
IRRInternal Rate of Return
MARRMinimum Acceptable 
Rate of Return
SDLCSoftware Development Life Cycle
SPLCSoftware Product Life Cycle
ROIReturn on Investment
SEISoftware Engineering Institute
TCOTotal Cost of Ownership
INTRODUCTION
Software is ubiquitous and has become essen-
tial for many organizations. It serves organiza-
tions in the following ways:
•    as  a  lever  to  reach  an  organization’s  busi-
ness or strategic goals;
•    as  a  catalyst  of  organizational  know-how  
to improve value.
Both  aspects  lead  directly  to  critical  soft-
ware engineering demands:
•    increased productivity;
•    reduced rework
•    reduced development time
•    shorter maintenance turnaround
•    long-term sustainability;
•    innovation;
•    competitiveness;
•    alignment with organizational goals.
Software engineering economics helps soft-
ware engineers work in ways that satisfy these 
critical demands. The Introduction to SWEBOK 
Guide explains that engineering economics is a 
key element of all recognized engineering dis-
ciplines.  Economics  is  the  science  of  choice,  
not  the  science  of  money.  Engineering  eco-
nomics  is  the  applied  microeconomics  branch  
of  economics.  It  asks  the  fundamental  ques-
tion, “Is it in the best interest of this enterprise 
to invest its limited resources in this technical 
endeavor,  or  would  the  same  investment  pro-
duce a higher return elsewhere?” Paraphrasing 
the definition in [1], engineering is “finding the 
balance  between  what  is  technically  feasible  
and what is economically acceptable.”
Software  engineering  must  be  value-based. 
Neutral  —  or  worse,  negative  —  value  from  
an organization’s investment in software is not 
sustainable.  Software  engineering  economics  
aligns  software  technical  decisions  with  the  
organization’s business goals.
“The  organization”  will  at  least  include  the  
organization  where  the  software  engineer  is  
employed.  However,  when  the  software  engi-
neer  is  involved  in  work  for  any  third  party,  
such  as  through  an  external  digital  transfor-
mation contract or other “works for hire” situ-
ation, the business goals of that third party are 
also relevant.
In  all  types  of  organizations  —  for-profit,  
nonprofit  and  government  —  a  value-based  
approach translates into long-term sustainability. 
In for-profit organizations this means achieving a 
tangible return on the software investment. In 
nonprofit  organizations,  this  means  achieving  
the maximum benefit for the least cost.
Software  technical  decisions,  like  an  orga-
nization’s  decision  to  use  a  preexisting  library  
or to develop its own, may appear easy from a 
purely technical perspective. However, they can 
have  serious  implications  for  the  business  via-
bility of a software project as well as the product 
itself.   Most   software   practitioners   wonder   

15-2   SWEBOK
®
 GUIDE V4.0
whether such concerns apply to them. But eco-
nomic decision-making is fundamental to engi-
neering.  Someone  who  cannot  make  decisions  
from  both  a  technical  and  an  economic  per-
spective cannot be considered a true engineer.
Software  engineering  economics  applies  to  
decisions  across  the  entire  software  product  
life  cycle  (SPLC),  from  the  pre-project  deci-
sion  to  develop  the  software  to  end-of-life  
decisions  for  existing  software.  It  also  applies  
to decisions at all levels of technical detail. For 
example,  all  following  questions  involve  an  
economic perspective:
•    can  a  client  organization  benefit  from  a  
digital transformation?
•    does  a  project  proposal  (a  tender)  align  
with a client’s business goals?
•    should  certain  software  functionality  be  
bought or built?
•    should  certain  requirements  be  included  
in scope or not?
•    what  is  the  most  efficient,  cost-effective  
architecture and design?
•    what is an optimal load-balancing strategy 
for a cloud-based deployment that provides 
adequate  response  time  to  clients  without  
incurring unnecessary operational cost?
•    how much risk-based testing is enough?
•    is it better to refactor, redevelop or just live 
with code that has high technical debt?
•    is   it   better   to   focus   maintenance   on   
adding  new  functionality  or  on  fixing  
known defects?
•    would  the  value  of  early  delivery  of  par-
tial   functionality   gained   by   using   an   
Agile  process  outweigh  the  overhead  of  
rework  and  continuous  testing  inherent  
in iterative approaches?
The   Software   Engineering   Economics   
knowledge area (KA) is directly or indirectly 
related to all other KAs in this Guide.
This  KA  also  takes  the  position  that  the  
more  traditional,  purely  financial  view  of  
engineering economics needs to be broadened 
[2]. Value does not always derive from money 
alone; value can also derive from “unquanti-
fiables”  like  corporate  citizenship,  employee  
well-being,  environmental  friendliness,  cus-
tomer loyalty and so on. Therefore, software 
engineering decisions must also consider rel-
evant unquantifiable criteria.
BREAKDOWN OF TOPICS FOR 
SOF TWARE ENGINEERING 
ECONOMICS
The  breakdown  of  topics  for  the  Software  
Engineering   Economics   KA   is   shown   in   
Figure 15.1. 
Software Engineering
Economics
Proposals
Cash Flow
Time-Value
of Money
Equivalence
Bases for
Comparison
Alternatives
Intangible
Assets
Business
Model
Process
Overview
Understand the
Real Problem
Identify all
Reasonable
Technically-
Feasible
Solutions
Define the
Selection
Criteria
Evaluate each
Alternative
against the
Selection Criteria
Select the Preferred
Alternative
Monitor the Performance 
of the Selected Alternative
Minimum
Acceptable
Rate of Return
Economic Life
Planning
Horizon
Replacement
Decisions
Retirement Decisions
Advanced For-Profit
Decision Considerations
Benefit-Cost
Analysis
Cost-
Effectiveness
Analysis
 
Break-Even
Analysis
Optimization
Analysis
Compensatory
Techniques
Non-
Compensatory
Techniques
Identify
Processes and
Define 
Business Goals
Identify
Intangible Assets
linked with
Business Goals
Identify
Software
Products that
Support
Intangible Assets
Define and
Measure Indicators
Intangible Asset
Characterization
Link Specific Intangible 
Assets with the Business Model
Decision Making
Accounting
Cost and Costin
g
Finance
Controlling
Efficiency and
Effectiveness
Productivity
Product or
Service
Project
Program
Portfolio
Product
Lifecycle
Project
Lifecycle
Price and
Pricing
Prioritization
Software
Engineering
Economics
Fundamentals
e Engineering
Decision-Making
Process
For-Profit
Decision-Making
Nonprofit
Decision-Making
Present Economy
Decision-Making
Multiple-
Attribute
Decision-Making
Identifying and
Characterizing
Intangible Assets
Estimation
Practical
Considerations
Related
Concepts
Expert
Judgment
Analogy
Decomposition
Parametric
Multiple
Estimates
Business Case
Multiple-
Currency
Analysis
Systems
inking
Figure 15.1. Breakdown of Topics for the Software Engineering Economics KA

SOFTWARE ENGINEERING ECONOMICS   15-3
1. Software Engineering Economics 
Fundamentals
1.1. Proposals [3*, c3pp23-24]
Software  engineering  decisions  begin  with  
the concept of a proposal — a single, separate 
course of action to be considered (e.g., carrying 
out a particular software development project 
or not). Another proposal could be to enhance 
an   existing   software   component;   another   
might  be  to  redevelop  that  same  software  
from  scratch.  In  deciding  what  algorithm  to  
use in implementing a certain function, each 
candidate considered is a proposal. Every pro-
posal represents a binary unit of choice — the 
software engineer either carries out that pro-
posal or chooses not to. Software engineering 
economics aims to identify the proposals best 
aligned with the organization’s goals.
1.2. Cash Flow [3*, c3pp24-32]
Engineers  must  evaluate  a  proposal  from  a  
financial  perspective  to  make  a  meaningful  
decision  about  it.  The  concepts  of  cash  flow  
instance  and  cash  flow  stream  describe  the  
financial perspective of proposals.
A cash flow instance is a specific amount of 
money flowing into or out of the organization 
at a specific time as a direct result of carrying 
out a proposal. For example, in a proposal to 
develop  and  launch  product  X,  the  payment  
for  new  computers,  if  needed,  would  be  an  
example  of  an  outgoing  cash  flow  instance.  
Money  would  need  to  be  spent  to  carry  out  
that proposal. The sales income from product 
X  in  the  11th  month  after  market  launch  
would  be  an  example  of  an  incoming  cash  
flow instance. Money would come in because 
of carrying out the proposal. 
A  cash  flow  stream  is  the  set  of  cash  flow  
instances  over  time  caused  by  carrying  out  
that  proposal.  The  cash  flow  stream  is  that  
proposal’s   complete   financial   view.   How   
much money goes out? When does it go out? 
How  much  money  comes  in?  When  does  it  
come in? If the cash flow stream for Proposal 
A is more desirable than the cash flow stream 
for Proposal B, then — all other things being 
equal — the organization is financially better 
off carrying out Proposal A than Proposal B. 
Thus,  the  cash  flow  stream  is  an  important  
element of engineering decision-making.
A cash flow diagram is a picture of a cash flow 
stream.  The  cash  flow  diagram  quickly  sum-
marizes the financial view of a proposal. Figure 
15.2 shows an example cash flow diagram.
The cash flow stream is shown in two dimen-
sions. Time runs from left to right and amounts 
of  money  run  up  and  down.  The  horizontal  
axis  is  divided  into  units  representing  years,  
months, weeks, etc., as appropriate for the pro-
posal. Each net cash flow instance is drawn at a 
left-to-right position relative to its timing. The 
amount  of  the  cash  flow  instance  is  shown  as  
an upward or downward arrow. Upward arrows 
indicate  that  money  is  coming  in  (income),  
whereas downward arrows indicate that money 
is spent (expense). The arrow’s length is usually 
proportional to the net amount.
1.3. Time-Value of Money [3*, c5-6]
One  of  the  most  fundamental  concepts  in  
economics — and therefore, in business deci-
sions  —  is  that  money  has  time-value:  Its  
value  changes  over  time.  A  specific  amount  
of money right now almost always has a value 
0
1
2
34
$2900
5
67
-$10,000
-$850
$8150
$650
$5900
$3650
$1400
Figure 15.2. A Cash Flow Diagram

15-4   SWEBOK
®
 GUIDE V4.0
different from the same amount at some other 
time. This concept has been around since the 
earliest  recorded  human  history  and  is  com-
monly expressed as interest.
1.4. Equivalence [3*, c7]
Due to the time-value of money, two or more 
cash flows are equivalent only when they equal 
the same amount of money at the same time. 
Therefore, comparing cash flows makes sense 
only when they are expressed in the same time 
frame. Then, lack of equivalence between the 
two  cash  flows  can  be  determined  accurately  
and can serve as the basis for choice. The pro-
posal with the highest value in the same time 
frame is the most financially desirable.
1.5. Bases for Comparison [3*, c8]
A basis for comparison is a shared frame of ref-
erence  for  comparing  two  or  more  cash  flow  
streams.  It  uses  equivalence  to  meaningfully  
compare two or more proposals. Several bases 
for comparison exist, including the following:
•    present worth;
•    future worth;
•    annual equivalent;
•    internal rate of return (IRR);
•    discounted payback period.
1.6. Alternatives [3*, c9]
Often,  an  organization  could  carry  out  more  
than  one  proposal  if  it  wanted  to.  But  there  
might  be  important  relationships  between  
proposals that need to be considered. Maybe 
Proposal Y can only be carried out if Proposal 
X  is  also  carried  out.  Or  maybe  Proposal  P  
cannot  be  carried  out  if  Proposal  Q  is  car-
ried out, nor could Q be carried out if P were. 
Decisions are easier when there are mutually 
exclusive  paths  —  A,  or  B,  or  C,  or  another  
project, and no others. This topic explains how 
to turn any set of proposals, with their inter-
relationships,  into  a  set  of  mutually  exclu-
sive alternatives. The cash flow stream for any 
alternative is the sum of the cash flow streams 
for  all  the  proposals  it  contains.  The  choice  
can then be made among these alternatives.
One special case is known as the do-nothing 
alternative.  Sometimes  the  best  course  of  
action is not to carry out any of the proposals 
being  considered.  The  do-nothing  alterna-
tive  represents  that  case.  It  doesn’t  mean  do  
nothing  at  all;  it  means  “do  something  else,  
something  that’s  not  in  this  set  of  choices.”  
The do-nothing alternative should be consid-
ered in most, but not all, situations.
1.7. Intangible Assets
Intangible   assets,   also   known   as   knowl-
edge  assets,  are  any  knowledge  that  lies  in  
the  non-visible  side  of  an  organization  but  
affects  that  organization’s  financial  perfor-
mance. According to International Valuation 
Standards  (IVS)  210  §  20.1,  “an  intangible  
asset  is  a  non-monetary  asset  that  manifests  
itself  by  its  economic  properties.  It  does  not  
have physical substance but grants rights and 
economic benefits to its owner” [4].
This can include, but is not limited to, pol-
icies,   procedures,   tools   and   specifications,   
as  well  as  organizational  culture,  experience  
and know-how.
Knowing the organization’s intangible assets 
helps the software engineer better understand 
how proposals may affect or be affected by orga-
nizational  realities.  Otherwise,  hidden  risks  
and  opportunities  that  could  influence  pro-
posals’ success or failure might not be exposed.
The  skills  needed  to  consider  intangible  
assets are the following:
•    intangible     assets     identification     and     
valuation   [Skills   Framework   for   the   
Information     Age     (SFIA),     category     
Strategy  and  Architecture,  subcategory  
Business strategy and planning];
•    knowledge management [SFIA, category 
Strategy  and  Architecture,  subcategory  
Business strategy and planning].
Identifying    and    characterizing    intan-
gible assets are discussed in more detail later 
in this KA.

SOFTWARE ENGINEERING ECONOMICS   15-5
1.8. Business Model 
Peter Drucker, a founder of modern manage-
ment,  defines  a  good  business  model  as  one  
that answers these questions [5]: 
•    “Who is the customer?”
•    “What does the customer value?”
•    “How do we make money?”
•    “What  is  the  underlying  economic  logic  
that explains how we can deliver value to 
customers at an appropriate cost?”
Understanding  the  organization’s  business  
model — as well as its intangible assets — helps 
the  software  engineer  better  understand  how  
proposals  may  affect  or  be  affected  by  orga-
nizational  realities.  Analyzing  the  business  
model  can  help  the  software  engineer  iden-
tify hidden risks and opportunities that could 
influence a proposal’s success or failure [6].
2.  The Engineering Decision-Making 
Process
2.1. Process Overview [3*, c4pp35-36]
Figure 15.3 provides an overview of the engi-
neering decision-making process.
The process is shown as stepwise and sequen-
tial; however, it can be more fluid in practice. 
Steps  can  be  done  iteratively,  can  overlap  and  
can  even  occur  in  different  sequences.  Just  be  
sure not to skip any step or execute it poorly.
When  the  consequences  of  a  wrong  deci-
sion are significant, such as a go/no-go deci-
sion for a large project, more time, effort and 
care should be spent in this process. All steps 
should be completed thoroughly and carefully. 
ISO 12207 [7] and ISO 15288 [8] recommend 
two  additional  early  activities,  which  can  be  
important in high-consequence decisions:
•    define the decision management strategy 
—   this   strategy   might   specify   roles,   
responsibilities, procedures and tools;
•    identify relevant stakeholders, which might 
include appropriate subject matter experts.
When  the  consequences  of  a  wrong  deci-
sion  are  small,  such  as  the  consequences  of  
selecting a minor algorithm or data structure, 
less time, effort and care can be spent, but the 
same general process is followed. Each step is 
discussed in more detail below.
2.2. Understand the Real Problem 
 [3*, c4pp37-39]
The  best  solution  to  a  problem  can  come  
only from thoroughly understanding the real 
problem  to  be  solved.  This  step’s  key  aspects  
include the use of an interrogative technique 
such  as  the  “5  Whys”  technique  and  a  con-
sideration of the broader context surrounding 
the problem. The Empathize stage in Design 
Thinking  [9]  (to  consider  intangible  assets)  
and   looking   closely   at   the   organization’s   
Identify all reasonable
technically feasible
solutions
Evaluate each
alternative against
the selection criteria
Dene the
selection criteria
Understand the
real problem
Select the
preferred alternative
Monitor the
performance of the
selected alternative
Figure 15.3. The Engineering Decision-Making Process

15-6   SWEBOK
®
 GUIDE V4.0
business  model  are  examples  of  considering  
that broader context.
2.3. Identify All Reasonable Technically Feasible 
Solutions [3*, c4pp40-41]
The  goal  of  engineering  decision-making  is  
to  find  the  best  solution.  However,  the  best  
solution must first be identified as a candidate 
before  it  can  be  selected  as  the  best.  If  the  
best solution is not among the set of solutions 
being  considered,  it  cannot  be  selected.  The  
importance  of  creative  thinking  in  this  step  
cannot  be  overstated  when  the  consequences  
of a wrong decision are high.
For some potential solutions, or candidates, 
prototyping is a useful way to verify technical 
feasibility.  Peer  review  can  also  help  verify  
technical  feasibility  and  possibly  spur  the  
identification of even more candidates.
On   the   one   hand,   adding   candidates   
increases the probability that the best one is in 
the set. On the other hand, each adds cost to 
the  decision-making  process.  Software  engi-
neers must use their best judgment in deciding 
when  they  have  enough  candidates.  These  
candidates  are  the  “proposals”  as  defined  in  
the Fundamentals topic, Section 1.
2.4. Define the Selection Criteria 
 [3*, c4pp39-40, c26pp441-442]
Engineering decisions almost always consider 
the   financial   perspective.   However,   other   
decision  criteria  can  also  be  relevant;  when  
this is the case, the decision is a multiple-at-
tribute decision. For example, an environmen-
tally conscious organization may choose a less 
economical solution if it is more eco-friendly. 
In  many  cases,  the  greater  the  consequences  
of  a  wrong  decision,  the  more  selection  cri-
teria need to be considered.
As much as possible, each criterion should 
be  expressed  objectively.  Ideally,  those  objec-
tive terms will be expressed as a monetary value 
— but not necessarily. What is the “value” of a 
clean river? It might not make sense to value a 
river by multiplying the price per kilogram of 
fish by an estimate of the number of fish in the 
river. Decision criteria that can’t be expressed 
objectively  are  called  “unquantifiables,”  “irre-
ducibles” or “intangibles.”
Defining the decision criteria can be a sub-
jective task. Too many criteria could make the 
analysis unwieldy. On the other hand, too few 
criteria  might  not  differentiate  well  between  
proposals and could thus lead to a suboptimal 
choice.  The  potential  for  a  better  decision  
provided  by  including  more  criteria  must  be  
balanced  against  the  extra  effort  required  to  
analyze the criteria.
To the extent that money is a selection crite-
rion, the context of the decision will constrain 
the decision-maker to a for-profit, nonprofit or 
present economy decision analysis, as explained 
in topics 3, 4 and 5, later in this KA.
2.5. Evaluate Each Alternative Against the 
Selection Criteria [3*, c4pp41-42]
Each  alternative  is  evaluated  against  each  
selection  criterion.  When  a  selection  crite-
rion  involves  money,  each  alternative  must  
be  judged  from  the  same  viewpoint.  Use  the  
same  basis  for  comparison  (present  worth,  
future  worth,  IRR,  etc.,  in  for-profit  deci-
sions; benefit-cost ratio or cost-effectiveness in 
nonprofit  decisions,  etc.),  the  same  planning  
horizon, and consider the same kinds of costs 
and  incomes.  An  example  decision  might  be  
buying and adapting an off-the-shelf software 
product  versus  building  a  custom  application  
from  scratch.  Considering  costs  for  a  longer  
time frame for one proposal than for the other 
will make the one using the shorter time frame 
seem  like  the  better  choice  even  though  it  
might not be better over the same time frame.
2.6. Select the Preferred Alternative 
 [3*, c4p42, c26pp447-458]
If  the  only  selection  criterion  is  money,  the  
alternative  with  the  highest  present  worth,  
future  worth,  etc.,  will  be  chosen.  When  
there  are  multiple  criteria,  a  variety  of  tech-
niques  can  be  used  to  evaluate  the  criteria  
together. Multiple-attribute decision-making 
is detailed later in this KA.

SOFTWARE ENGINEERING ECONOMICS   15-7
Engineering  decisions  are  based  on  esti-
mates  (discussed  later  in  this  KA).  The  accu-
racy of an estimate is limited in theory and in 
practice, and the degree of inaccuracy depends 
on the specifics of the situation [3*, c21pp344-
356]. If the degree of inaccuracy is high enough, 
that  inaccuracy  could  change  the  resulting  
decision.  The  following  techniques  [3*,  c23]  
can help engineers address these situations:
•    consider ranges of estimates;
•    perform a sensitivity analysis;
•    delay final decisions.
In  addition,  two  categories  of  techniques  
address   multiple   potential   outcomes   from   
a decision:
•    decision-making-under-risk    techniques    
[3*, c24] are used when probabilities can 
be  assigned  to  the  different  potential  
outcomes.   Specific   techniques   include   
expected  value  decision-making,  expec-
tation   variance   and   decision-making,   
Monte Carlo analysis, decision trees, and 
the expected value of perfect information;
•    decision-making-under-uncertainty tech-
niques  [3*,  c25]  are  used  when  probabil-
ities  cannot  be  assigned  to  the  different  
potential  outcomes.  Specific  techniques  
include  the  Laplace  Rule,  the  Maximin  
Rule,  the  Maximax  Rule,  the  Hurwicz  
Rule and the Minimax Regret Rule.
High-consequence  decisions  may  benefit  
from  formally  recording  the  selected  alterna-
tive and the justification for why that alterna-
tive was selected.
2.7. Monitor the Performance of the Selected 
Alternative [3*, c4pp42-43]
Because  estimation  is  a  fundamental  element  
of engineering decision-making, the quality of 
the decision depends on the quality of the esti-
mates. Bad estimates can easily lead to bad deci-
sions. The software engineer needs to “close the 
loop”  on  estimates  by  comparing  them  to  the  
actual  outcomes.  Otherwise,  no  one  will  ever  
know if the estimates were good [3*, c21pp356-
358].  This  also  helps  improve  estimation  over  
time.  Understanding  what  drives  differences  
between  estimates  and  actual  outcomes  helps  
engineers refine estimation techniques to pro-
duce more accurate estimates in the future.
3.  For-Profit Decision-Making
For-profit decision techniques apply when the 
organization’s  goal  is  profit  —  which  is  the  
case in most companies.
Figure  15.4  shows  the  process  for  identi-
fying the financially best alternative out of a set 
of  proposals.  Arranging  alternatives  in  order  of  
increasing  initial  investment  and  then  selecting  
strictly  better  candidates  means  that,  all  other  
considerations  being  equal,  the  alternative  with  
the smaller initial investment will be chosen. The 
“Is the next candidate strictly better?” decision is 
made in terms of the appropriate basis for com-
parison: present worth, future worth, IRR, etc.
3.1. Minimum Acceptable Rate of Return 
 [3*, c10pp141-143]
The minimum acceptable rate of return (MARR) 
is  the  lowest  IRR  the  organization  would  
consider  a  good  investment.  Generally,  it  
would  not  be  wise  to  invest  in  an  activity  
with  a  return  of  10%  when  another  activity  
returns 20%. The MARR is a statement that 
the  organization  is  confident  it  can  achieve  
at  least  that  rate  of  return.  The  MARR  rep-
resents  the  organization’s  opportunity  cost  
for  investments.  By  investing  in  some  alter-
native, the organization explicitly decides not 
to invest that same money somewhere else. If 
the  organization  is  already  confident  it  can  
achieve  a  known  rate  of  return,  alternatives  
should be chosen only if their rate of return is 
at least that high. A simple way to account for 
that opportunity cost is to use the MARR as 
the interest rate in the basis for comparison. 
3.2. Economic Life [3*, c11pp160-164]
When  an  organization  invests  in  a  partic-
ular  alternative,  money  is  tied  up  in  that  

15-8   SWEBOK
®
 GUIDE V4.0
alternative — so-called frozen assets. The eco-
nomic impact of frozen assets typically starts 
high  and  decreases  over  time.  On  the  other  
hand,  operating  and  maintenance  costs  tend  
to start low and increase over time. An alter-
native’s  total  cost  is  the  sum  of  those  two  
costs.  At  first,  frozen  asset  costs  dominate;  
later,  operating  and  maintenance  costs  dom-
inate. At some point, the sum of the two costs 
is minimized; this is the economic life or min-
imum cost lifetime.
3.3. Planning Horizon [3*, c11]
To  properly  compare  a  proposal  with  a  four-
year life to a proposal with a six-year life, the 
economic effects of either cutting the six-year 
proposal by two years or investing the profits 
from  the  four-year  proposal  for  another  two  
years  need  to  be  addressed.  The  planning 
horizon, sometimes known as the study period, 
is  the  consistent  time  frame  over  which  all  
proposals in the same decision are considered. 
Aspects  such  as  economic  life  and  the  time  
frame over which reasonable estimates can be 
made  need  to  be  factored  into  establishing  a  
planning horizon. Once the planning horizon 
is established, several techniques are available 
for putting proposals with different life spans 
into that planning horizon.
3.4. Replacement Decisions 
 [3*, c12pp171-178] [8*, c9]
A   replacement   decision   happens   when   an   
organization already has a particular asset and 
is considering replacing it with a different asset 
(e.g., deciding between maintaining and sup-
porting legacy software or redeveloping it from 
the ground up). Replacement decisions use the 
same for-profit decision process, but there are 
two additional important considerations: sunk 
cost and salvage value. Replacement does not 
necessarily  need  to  involve  an  entire  asset.  
To the extent that an asset can be replaced in 
smaller  increments,  the  decision-maker  can  
consider   incremental   replacement   options   
among the various economic alternatives.
Start
Stop
Is the next
candidate strictly
better than the
current best?
Compare the next candidate
to the current best
Are there
more alternatives
to compare?
Arrange the alternatives
in order of increasing
initial investment
Assume the rst alternative
is the current best
Make that next candidate
the new current best
e current best is
the best overall
Yes
Yes
No
No
Figure 15.4. The For-Profit Decision-Making Process

SOFTWARE ENGINEERING ECONOMICS   15-9
3.5. Retirement Decisions 
 [3*, c12pp178-181] [8*, c9]
Retirement decisions are about getting out of 
an  activity  altogether,  such  as  when  a  soft-
ware company considers not selling a software 
product anymore or a hardware manufacturer 
considers  not  building  and  selling  a  partic-
ular computer model any longer. Retirement 
decisions can be preplanned or happen spon-
taneously  (e.g.,  when  performance  targets  
are  not  achieved).  Retirement  decisions  can  
be influenced by lock-in factors such as tech-
nology dependency and high exit costs.
3.6. Advanced For-Profit Decision 
Considerations [3*, c13-17]
The  above  concepts  and  techniques  are  often  
sufficient  to  make  a  good  for-profit  decision.  
However, particularly when the consequences 
of a wrong decision are high, additional con-
siderations  may  need  to  be  factored  into  the  
decision analysis, including the following:
•    inflation or deflation;
•    depreciation;
•    income taxes.
4.  Nonprofit Decision-Making
The for-profit decision techniques don’t apply 
when  the  organization’s  goal  isn’t  profit  —  
which  is  the  case  in  government  and  non-
profit   organizations.   These   organizations   
have  a  different  goal,  so  different  decision  
techniques  are  needed.  The  two  techniques  
are  benefit-cost  analysis  and  cost-effective-
ness analysis (discussed below).
4.1. Benefit-Cost Analysis [3*, c18pp303-311]
Benefit-cost  analysis  is  one  of  the  most  
widely  used  methods  for  evaluating  pro-
posals in nonprofit organizations. A propos-
al’s financial benefits are divided by its costs. 
Any  proposal  with  a  benefit-cost  ratio  of  
less than 1.0 can usually be rejected without 
further analysis because it would cost more 
than   it   would   benefit   the   organization.   
Additional    considerations    are    necessary    
when two or more proposals are considered 
at the same time.
4.2. Cost-Effectiveness Analysis 
 [3*, c18pp311-314]
Cost-effectiveness  analysis  shares  much  of  
the  philosophy  and  methodology  of  bene-
fit-cost  analysis.  There  are  two  versions  of  
cost-effectiveness   analysis.   The   fixed-cost   
version  seeks  to  maximize  benefit  given  a  
fixed  upper  bound  on  cost.  The  fixed-effec-
tiveness version seeks to minimize the cost to 
achieve a fixed goal.
5.  Present Economy Decision-Making
This  subset  of  engineering  decision-making  
is  called  present  economy  because  it  does  not  
involve   the   time-value   of   money   (future   
economy). The two forms of present economy 
decisions are presented below.
5.1. Break-Even Analysis [3*, c19]
Given  functions  describing  the  costs  of  two  
or more proposals, break-even analysis helps 
engineers  choose  between  them  by  identi-
fying  points  where  those  cost  functions  are  
equal.  Below  a  break-even  point,  one  pro-
posal  is  preferred,  and  above  that  point,  the  
other  is  preferred.  For  example,  consider  a  
choice  between  two  cloud  service  providers.  
One  provider  has  a  lower  fixed  cost  per  
month with a higher incremental fee for use, 
whereas the other has a higher fixed monthly 
cost  with  a  lower  incremental  fee  for  use.  
Break-even  analysis  identifies  the  use  level  
where  the  costs  are  the  same.  The  organi-
zation’s  expected  use  level  can  be  compared  
to  the  break-even  point  to  identify  the  low-
er-cost provider.
5.2. Optimization Analysis [3*, c20]
Optimization  analysis  studies  one  or  more  
cost functions over a range of values to find the 

15-10   SWEBOK
®
 GUIDE V4.0
point where overall cost is lowest. Software’s 
classic  space-time  trade-off  is  an  example  of  
optimization;  an  algorithm  that  runs  faster  
often  uses  more  memory.  Optimization  bal-
ances the value of faster run time against the 
cost of the additional memory. 
6.  Multiple-Attribute Decision-Making 
 [3*, c26]
Most topics presented in this KA so far have 
discussed  decisions  based  on  a  single  cri-
terion  —  money.  The  alternative  with  the  
best  present  worth,  the  best  incremental  
IRR, the best incremental benefit-cost ratio, 
etc.,  is  the  one  selected.  Aside  from  tech-
nical  feasibility,  money  is  usually  the  most  
important  decision  criterion,  but  it’s  cer-
tainly not always the only one. Often, other 
criteria,  other  “attributes,”  need  to  be  con-
sidered that can’t be cast in terms of money. 
Multiple-attribute   decision-making   tech-
niques allow nonmonetary criteria to be fac-
tored into the decision.
A  variety  of  techniques  can  be  used  to  
address  multiple  criteria,  including  nonmon-
etary  criteria.  These  techniques  fall  into  two  
categories.
6.1. Compensatory Techniques 
 [3*, c26pp449-458]
Also  called  single-dimensioned  techniques,  the  
techniques in this category collapse all criteria 
into  a  single  figure  of  merit.  This  category  is  
called compensatory  because,  for  any  given  
alternative, a lower score in one criterion can 
be compensated by — traded off against — a 
higher  score  in  other  criteria.  Compensatory  
techniques  include  nondimensional  scaling,  
additive   weighting   and   analytic   hierarchy   
process (AHP).
Gilb’s   Impact   Estimation   [11]   and   the   
Software     Engineering     Institute’s     (SEI)     
Architectural    Tradeoff    Analysis    Method    
(ATAM)  [12]  are  examples  of  compensa-
tory      multiple-attribute      decision-making      
techniques  focused  on  identifying  the  best  
software design.
6.2. Non-Compensatory Techniques 
 [3*, c26pp447-449]
Also  called  fully  dimensioned  techniques,  the  
techniques in this category do not allow trade-
offs   among   the   criteria.   Each   criterion   is   
treated as a separate entity in the selection pro-
cess.  Non-compensatory  techniques  include  
dominance, satisficing and lexicography.
7.  Identifying and Characterizing 
Intangible Assets
The  intangible  side  of  an  organization  is  the  
valuable  knowledge  residing  within  it.  This  
includes   employees’   knowledge   about   pro-
cesses,  structures,  procedures,  etc.  (tacit,  or  
implicit,  knowledge),  as  well  as  institutional  
knowledge recorded in various organizational 
resources  (explicit  knowledge).  These  assets  
are usually hidden, the way most of an iceberg 
is  underwater.  The  intangible  assets  must  be  
explicitly  considered  in  many  decisions,  par-
ticularly  when  the  consequences  of  a  wrong  
decision  are  high  for  the  client,  no  matter  if  
the  client  is  internal  or  external  to  the  orga-
nization  for  which  the  software  project  is  
being done.
If  these  assets  are  not  adequately  consid-
ered,  software  engineers  risk  developing  a  
software  solution  that  does  not  fit  the  client  
organization.   Only   when   the   intangible   
assets  are  explicitly  considered  will  the  risk  
of a poorly fitting software solution be min-
imized.   The   Strategic   Intangible   Process   
Assets   Characterization   (SIPAC)   method   
[13]  has  been  used  to  good  effect  to  accom-
plish  this.  SIPAC  steps  are  outlined  in  the  
following subsections.
7.1. Identify Processes and Define Business Goals
Start   by   understanding   the   organization’s   
business  processes  and  business  goals.  If  the  
organization has well-documented processes, 
these  should  be  used;  otherwise,  a  deliberate  
survey will be necessary.
Business goals can include, but are not lim-
ited to, the following:

SOFTWARE ENGINEERING ECONOMICS   15-11
1. maintaining  growth  and  continuity  of  
the organization;
2. meeting financial objectives;
3. meeting responsibility to employees;
4. meeting responsibility to society;
5. managing market position.
7.2. Identify Intangible Assets Linked with 
Business Goals
The  next  step  is  to  comprehensively  iden-
tify the intangible assets. Common examples 
are  policies,  documented  business  processes,  
checklists,  lessons  learned,  templates,  stan-
dards,  procedures,  plans  and  training  mate-
rials.  Organizations  develop  or  acquire  these  
assets to meet their business goals. The assets 
represent  investments  that  provide  business  
value.  One  effective  approach  to  identifying  
an  organization’s  intangible  assets  is  to  start  
with a taxonomy such as described in the fol-
lowing reference [14]. The goal is to identify as 
many  intangible  assets  as  possible  that  serve  
as  a  lever  to  achieve  the  business  goals  iden-
tified  in  the  previous  step.  In  practice,  this  
can  be  an  iterative  process  where  reviewing  
the  already-identified  assets  reveals  the  exis-
tence of others. A practical way to do it is by 
focusing  iteratively  on  the  11  generic  intan-
gible assets (GIAs) described in [6].
Possible GIAs represent all potential parts 
of any business that can be involved in a dig-
ital transformation. Focusing on one or more 
of them allows the software engineer to better 
understand  and  frame  the  project’s  impact.  
Focusing iteratively on the 11 GIAs, the soft-
ware engineer will select the type of GIA to 
be considered and, with this, elicit the specific 
intangible assets associated with each GIA.
In  addition  to  identifying  specific  intan-
gible assets, a qualitative relative “importance” 
must be added to each one as it is identified. 
The importance is a value between 1 and 5 (1 
for lower importance and 5 for higher impor-
tance), depending on how well the asset sup-
ports  achieving  the  business  objectives.  The  
intangible assets with the highest importance 
are likely the most suitable target for the client 
organization.
7.3. Identify Software Products That Support 
Intangible Assets 
Software products that support specific intan-
gible assets will be part of the digital transfor-
mation proposal to be presented to the client 
to help them decide what digital transforma-
tion to implement.
To  identify  products  related  to  specific  
intangible  assets,  the  software  engineer  can  
choose from the following:
•    discovering  them  all  at  a  single  time  by  
using   the   methodology   of   Osterwalder   
[13],  which  promotes  innovation  by  gen-
erating a value map with the stakeholders’ 
emerging  needs,  mapping  the  products  to  
the specific intangible assets;
•    listing  them  if  they  are  known  and  then  
mapping them to specific intangible assets;
•    iteratively  working  with  the  individual  
intangible  assets  by  (1)  selecting  a  spe-
cific  intangible  asset  and  (2)  identifying  
the products, continuing until all specific 
intangible assets have been analyzed.
A single product can support more than one 
specific intangible asset, and each specific intan-
gible asset can be supported by many products.
7.4. Define and Measure Indicators
This  step  defines  and  measures  the  indica-
tors that will be used to characterize how the 
intangible  assets  (through  the  software  prod-
ucts that support those intangible assets) help 
meet business goals through describing, imple-
menting or improving the identified products. 
Quality  indicators  assess  specific  intangible  
asset  characteristics  or  features.  Impact  indi-
cators assess how much the specific intangible 
assets contribute to processes or business goals.
Indicators  must  be  normalized  and  stan-
dardized to operate correctly. 
7.5. Intangible Asset Characterization
Based on the information gathered, the soft-
ware  engineer  determines  the  value  of  the  

15-12   SWEBOK
®
 GUIDE V4.0
identified specific intangible assets based 
on   their   quality   and   impact.   Specific   
intangible assets may be characterized in 
terms  of  their  impact  on  business  goals  
and their quality as organizational assets. 
There  are  three  important  characteriza-
tion cases:
•    case 1: specific intangible assets with both 
impact and quality indicators (Warning, 
Replaceable, Evolving or Stable);
•    case 2: specific intangible assets with only 
quality indicators (Acceptable Quality or 
Unacceptable Quality);
•    case 3: specific intangible assets with only 
impact indicators (Acceptable Impact or 
Unacceptable Impact).
The three characterization cases are shown 
in  Figure  15.5.  The  quadrants  represent  the  
“states”  constituting  different  levels  of  char-
acterization.  The  lines  separating  the  quad-
rants are thresholds of impact and quality that 
define the point at which the impact or quality 
of a specific intangible asset may be considered 
acceptable or not for each organization. These 
thresholds   are   established   for   every   client   
organization  and  specify  what  level  of  orga-
nizational  performance,  quality,  and  impact  
they   will   demand   from   their   knowledge/
intangible assets. Thresholds are used to deter-
mine  when  quality  and/or  impact  are  accept-
able or unacceptable. Let’s look at an example 
of how to interpret Qval and Ival (both Qval 
and  Ival  will  be  explained  in  the  following  
sections). Assuming, for example, that we are 
analyzing the status of an intangible asset with 
both  quality  and  impact  indicators,  and  that  
Qval  is  below  the  quality  threshold  and  Ival  
is  below  the  impact  threshold.  In  these  cir-
cumstances we would say that the status of the 
intangible asset is “warning” as can be seen in 
Figure 15.5.
The characterization uses information from 
standardized-normalized  indicators  to  assess  
the  identified  intangible  assets.  This  assess-
ment  generates  a  descriptive  value  that  will  
determine  the  asset’s  general  state  of  health  
from a quantitative perspective. 
Quality quantitative assessment
The  quality  valuation  considers  only  the  
indicators of the type quality of an intan-
gible asset and calculates a general valua-
tion of it. To evaluate the subset of quality 
indicators, given a set of q quality indica-
tors  for  an  intangible  asset  n,  the  valua-
tion  of  the  quality  is  given  according  to  
Equation 1.
Q        =
q
i=1
X
n
n
i
q
∑
Val
Equation 1. Quality Assessment for a 
Knowledge Asset
Where 
X
n
i
 is each of the q normalized indica-
tors of quality that the intangible asset n has.
Above, Qval is the average of the normal-
ized values of the quality indicators of a cor-
responding specific intangible asset.
Impact quantitative assessment
An  intangible  asset’s  impact  valuation  is  an  
assessment  that  considers  only  the  normal-
ized indicators that are classified as “impact” 
indicators.  To  evaluate  the  subset  of  impact  
indicators, given a set of p normalized impact 
indicators for an intangible asset n, the valua-
tion is given as stated in Equation 2:
 I
n
Val
=
∑
p
i = 1
Z
n
i
p
Equation 2. Impact Assessment for a Specific 
Intangible Asset
Where 
Z
n
i
 is each of the p normalized indica-
tors of impact that the knowledge asset n has.
Where Ival  is  the  average  of  the  normal-
ized values of the impact indicators of a corre-
sponding knowledge asset.
Linear value calculation
Finally, the linear value of an intangible asset 
characterization  is  given  by  the  impact  and  

SOFTWARE ENGINEERING ECONOMICS   15-13
quality valuations (Qval and Ival), following 
these  rules,  assuming  that  both  quality  and  
impact  are  equally  important,  so  K Aval  (t he  
valuation of the intangible asset) is given by:
If 
 
 
Qval
Ival, then
KAval =
Qval + Ival
If 
 
Qval
 Ival, then
KAval = Qval
2
Ival, then
If 
Qval
KAval = Ival
 
This  linear  value  represents  an  intangible  
asset’s  general  state  based  on  the  state  of  its  
indicators.  It  uses  the  algebraic  mean  of  the  
standardized  and  normalized  indicators  to  
represent  the  assets’  general  state  on  a  scale  
[-1, 1] and based on the corresponding inter-
pretation thresholds. If no threshold is explic-
itly mentioned, the linear value is interpreted 
as  follows,  if  the  value  is  0,  then  the  intan-
gible asset is on the target, if the value is 1, it 
means  that  the  intangible  asset  is  100%  over  
the target and if the value is -1 then the intan-
gible asset is -100% under the target.
7.6. Link Specific Intangible Assets with the 
Business Model
Visualizing    the    client    business    model,    
enriched  with  the  intangible  assets  status  
allocated  into  that  model,  gives  organiza-
tional leadership a clear understanding of the 
important relationships among proposed soft-
ware solutions, intangible assets, the business 
model  and  the  business  goals.  The  software  
engineer  can  clearly  show  which  proposed  
solution generates the most value for the busi-
ness. An example is shown in [6].
7.7. Decision-Making
The next step in the decision-making process 
is to prioritize and choose the software prod-
ucts that interest the client organization most. 
There  is  no  simple  rule;  several  criteria  must  
be considered:
•    the  intangible  asset’s  impact  on  business  
goals (defined in previous steps);
•    the  characterization  reached  (defined  in  
previous steps);
•    the impact of intangibles assets status on 
the competitors of the organization under 
improvement;
•    the intangible asset’s impact on the busi-
ness model;
•    cost to implement the products;
•    time to implement the products;
•    complexity of the products.
All  criteria  must  be  considered  to  decide  
what  software  products  should  be  developed  
for  the  client  organization,  making  this  a  
multiple-attribute decision. (See 6., Multiple-
Attribute Decision-Making.)
Upon   considering   all   relevant   criteria,   
the  organization  can  see  the  risks  of  imple-
menting a software solution to automate pro-
cesses that are either not very valuable or not 
in  good  shape.  Instead,  the  software  engi-
neer can offer, in a transparent way, proposals 
that  better  satisfy  the  organization’s  busi-
ness needs.
This  approach  can  be  useful  whenever  an  
engineering decision needs to be made, but it 
is particularly critical in the pre-project stage 
when  there  is  a  need  to  present  the  client  
organization  with  proposals  that  are  best  for  
business value.
8.  Estimation [3*, c21-26]
An estimate analytically predicts some quan-
tity,  like  a  project’s  size,  cost  or  schedule.  
Many  other  quantities  are  also  estimated  in  
software  engineering,  such  as  the  average  
number  of  active  client  sessions  a  cloud  ser-
vice needs to support, the number of times a 
function  will  be  called  during  execution  of  a  
section  of  code,  or  the  number  of  delivered  
defects in a software product.
Software engineers do not estimate purely 
for  the  sake  of  estimating.  Software  engi-
neers estimate to make decisions when critical 
quantities are unknown. For example, a deci-
sion  to  buy  a  functionality  or  build  it  within  

15-14   SWEBOK
®
 GUIDE V4.0
the organization would certainly be based on 
the cost of building it. But the actual cost of 
building  it  cannot  be  precisely  known  until  
the  organization  does  build  it.  Key  informa-
tion needed to make engineering decisions is 
usually not known when those decisions need 
to  be  made.  Instead,  decisions  are  based  on  
estimates.  Behind  every  estimate  is  one  or  
more decisions.
Given that estimates are predictions, there 
is  a  nonzero  probability  that  the  actual  out-
come  will  differ  from  the  estimate.  All  esti-
mates  are  inherently  uncertain.  Sometimes,  
the  uncertainty  is  large,  and  sometimes  it  is  
small. But it is always there. Fortunately, esti-
mates need not be perfect; they need only to 
be good enough to lead the decision-maker to 
make the right decision.
The Software Engineering Code of Ethics 
and  Professional  Practice  [16]  states,  “3.09.  
Ensure realistic quantitative estimates of cost, 
scheduling,  personnel,  quality  and  outcomes  
on any project on which they work or propose 
to  work  and  provide  an  uncertainty  assess-
ment  of  these  estimates”  (underlining  added  
for emphasis). (See [3*, c21pp358-361].)
Estimation  is  covered  extensively  in  [17],  
[18] and [3*]. Several general techniques exist, 
and each is overviewed here. All specific esti-
mation  techniques  use  one  or  a  combination  
of these general techniques.
8.1. Expert Judgment [3*, c22pp367-369]
In  expert  judgment  estimation,  the  estimate  
is  based  purely  on  the  estimator’s  professional  
opinion.  It  is  the  simplest  technique  and  is  
always  available,  and  it  is  particularly  useful  
when the other techniques aren’t available. The 
downside  is  that  this  technique  produces  the  
least  accurate  estimates.  Multiple  expert  judg-
ment estimates can be fed into group estimation 
processes like Wide Band Delphi and Planning 
Poker to produce more accurate estimates.
Case 2:
Only Quality Indicators
Acceptable
Quality
Unacceptable
Quality
WarningEvolving
Unacceptable
Impact
Acceptable
Impact
Case 3:
Only Impact
Indicators
ReplaceableStable
Quality
reshold
Case 1:
Quality and Impact Indicators
Impact reshold
Figure 15.5. Extended Characterization of Specific Intangible Assets

SOFTWARE ENGINEERING ECONOMICS   15-15
8.2. Analogy [3*, c22pp369-371]
Estimation  by  analogy  assumes  that  if  the  
thing   estimated   is   similar   to   something   
already  known,  then  the  estimate  for  the  
new  thing  can  be  based  on  the  actual  result  
for the similar thing, with allowances for rel-
evant  differences.  The  steps  in  estimation  by  
analogy are as follows:
1. Understand the thing to be estimated.
2. Find  a  suitable  analogy  for  which  actual  
results are known.
3. List differences between the thing being 
estimated and the analogy that could sig-
nificantly affect the outcome.
4. Estimate  the  magnitude  of  each  identi-
fied difference.
5. Build  the  estimate  from  the  analogy’s  
actual   result   and   adjustments   for   the   
identified differences.
Estimation   by   analogy   produces   more   
accurate results than expert judgment, and it 
is still relatively quick and easy. On the other 
hand, an appropriate analogy for which accu-
rate  results  are  known  must  be  available  for  
this approach to work.
8.3. Decomposition [3*, c22pp371-374]
Sometimes  called  bottom-up  estimation,  the  
steps in estimation by decomposition are:
1. Break the thing to be estimated into suc-
cessively smaller pieces until the smallest 
pieces can be reasonably estimated.
2. Estimate those smallest pieces.
3. Add  up  the  estimates  for  the  smallest  
pieces to build the estimate for the whole.
4. If the estimates for the smallest pieces don’t 
include allowances for significant cross-cut-
ting  factors,  then  find  a  way  to  address  
those factors. For example, when estimating 
a software project from its design, the esti-
mates  for  the  design  elements  may  not  
include  allowances  for  requirements  work,  
integration  work,  testing  work  and  user  
documentation work.
Estimation    by    decomposition    assumes    
that  overestimates  of  lowest-level  pieces  will  
cancel  out  corresponding  underestimates  of  
other pieces and lead to a more accurate esti-
mate of the whole. The primary disadvantages 
are the following:
•     it can be a lot more work than any other 
technique;
•      if  the  bottom-level  estimates  are  biased  
either  high  or  low,  the  canceling  effect  
doesn’t happen.
8.4. Parametric [3*, c22pp374-377]
Also  called  estimation  by  statistical  methods, 
parametric  estimation  takes  advantage  of  a  
known,  mathematical  relationship  between  
the  thing  being  estimated  and  one  or  more  
observable  factors  about  that  thing,  like  cal-
culating the cost to build a building as a func-
tion of its floor space. The estimation model is 
an  equation:  First,  count  the  observable  fac-
tors, and then plug them into the equation to 
get the resulting estimate.
Parametric estimates are typically the most 
accurate, the most defendable and the easiest 
to use, provided the equation has been devel-
oped  and  validated.  The  disadvantage  is  that  
developing  and  validating  such  an  equation  
requires  an  adequate  base  of  accurate  histor-
ical  data  along  with  some  nontrivial  mathe-
matics and statistics.
8.5. Multiple Estimates 
 [3*, c22pp377-379]
When  the  consequences  of  a  wrong  decision  
are small, it can be acceptable to base the deci-
sion on a single estimate from a single estimator 
using a single estimation technique. However, 
when the consequences of a wrong decision are 
significant, investing extra effort in developing 
more than one estimate can be worthwhile.
To use this approach, engineers estimate the 
same  thing  using  different  techniques,  pos-
sibly  by  different  estimators.  Then,  they  look  
for  convergence  or  divergence  among  those  
multiple   estimates.   Convergence   suggests   

15-16   SWEBOK
®
 GUIDE V4.0
the  individual  estimates  are  probably  accu-
rate, and any of them could be used to make 
the decision. Divergence suggests that one or 
more important factors might have been over-
looked.  Finding  the  factors  that  caused  the  
divergence  and  reestimating  to  produce  con-
verging results often lead to a better estimate 
and thus a better decision.
9.  Practical Considerations
9.1. Business Case
The  business  case  is  the  consolidated,  doc-
umented    information    summarizing    and    
explaining  a  recommended  business  decision  
from different perspectives (cost, benefit, risk 
and so on) for a decision-maker and other rel-
evant stakeholders. It’s used to assess a prod-
uct’s  potential  value,  which  can  be  used  as  a  
basis for an investment decision.
9.2. Multiple-Currency Analysis 
When   a   decision   analysis   involves   cross-
border finances, currency exchange rate varia-
tions may need to be considered. This is often 
done using historical data.
9.3. Systems Thinking
The  ecosystem  in  which  software  engineers  
develop their professional life is complex. To 
understand the whole picture around a client 
organization  and  form  a  holistic  view  of  the  
scenarios  they  analyze,  software  engineers  
can use systems thinking methodologies. This 
approach helps the software engineer create a 
complete set of possible scenarios in which the 
software to be provided could be useful and, 
with  this  information,  explain  to  the  client  
how the software solution can be a value pro-
vider for the organization. Sources for system 
thinking  methodologies  are  Understanding  
Systems    Systems    Innovation    [19]    and    
Business  Dynamics:  Systems  Thinking  and  
Modeling  for  a  Complex  World  [20].  A  way  
to  connect  systems  thinking  methodologies  
with the development of a business model to 
understand the pillars of the client organiza-
tion can be reached here [21].
10.  Related Concepts 
This  topic  includes  concepts  the  software  
engineer may want to bear in mind.
10.1. Accounting [3*, c15pp234-245]
Accounting is part of finance. It allows people 
whose  money  is  used  to  run  an  organization  
to  know  the  results  of  their  investment:  Did  
they get the profit they were expecting? In for-
profit organizations, this relates to the tangible 
return on investment (ROI), while in nonprofit 
and governmental organizations, as well as for-
profit organizations, it translates into sustain-
ably staying in business. Accounting’s primary 
role  is  to  measure  the  organization’s  actual  
financial  performance  and  to  communicate  
financial  information  about  a  business  entity  
to  stakeholders,  such  as  shareholders,  finan-
cial  auditors  and  investors.  Communication  
generally  takes  the  form  of  financial  state-
ments  showing  the  economic  resources  to  be  
controlled.  The  right  information  —  relevant  
and reliable to the user — must be presented. 
Information  and  its  timing  are  partially  gov-
erned  by  risk  management  and  governance  
policies.  Accounting  systems  are  also  a  rich  
source of historical data for estimating.
Software  engineers  must  be  conscious  of  
the software’s importance as a driver of busi-
ness accounts in the digital era.
10.2. Cost and Costing [3*, c15pp245-259]
A  cost  is  the  money  used  to  produce  some-
thing  and,  hence,  is  no  longer  available  for  
use. In economics, a cost is an alternative that 
is given up as a result of a decision. 
Sunk  cost  refers  to  unrecoverable  expenses  
that have occurred, which can cause emotional 
hurdles  looking  forward.  From  a  traditional  
economics viewpoint, sunk costs should not be 
considered  in  decision-making.  Opportunity  
cost is the cost of an alternative that must be 
forgone to pursue another alternative.

SOFTWARE ENGINEERING ECONOMICS   15-17
Costing  is  part  of  finance  and  product  
management. It is the process of determining 
the  cost  based  on  expenses  (e.g.,  production,  
software  engineering,  distribution,  rework)  
and  on  the  target  cost  to  be  competitive  and  
successful in a market. The target cost can be 
below  the  actual  estimated  cost.  The  plan-
ning and controlling of these costs (called cost 
management) is important and should always 
be included in costing. 
An  important  concept  in  costing  is  the  
total  cost  of  ownership  (TCO).  This  holds  
true especially for software because there are 
many  not-so-obvious  costs  related  to  SPLC  
activities  after  initial  product  development.  
TCO for a software product is defined as the 
total  cost  for  acquiring  that  product,  acti-
vating it and keeping it running. These costs 
can  be  grouped  as  direct  and  indirect  costs.  
TCO is an accounting method that is crucial 
in making sound economic decisions. 
10.3. Finance
Finance is the branch of economics concerned 
with   allocating,   managing,   acquiring   and   
investing resources. Finance is an element of 
every  organization,  including  software  engi-
neering organizations.
The field of finance deals with the concepts 
of  time,  money,  and  risk,  and  how  they  are  
interrelated.  It  also  deals  with  how  money  is  
spent and budgeted. Corporate finance is con-
cerned  with  funding  an  organization’s  activ-
ities.  Generally,  this  involves  balancing  risk  
and  profitability  while  attempting  to  maxi-
mize  an  organization’s  wealth  and  the  value  
of its stock. This applies primarily to for-profit 
organizations but also to nonprofit organiza-
tions. The latter needs finances to ensure sus-
tainability, if not to make a tangible profit. To 
do this, an organization must:
•    identify  organizational  goals,  time  hori-
zons, risk factors, tax considerations and 
financial constraints;
•    identify  and  implement  the  appropriate  
business  strategy,  such  as  which  port-
folio  and  investment  decisions  to  take,  
how  to  manage  cash  flow  and  where  to  
get the funding;
•    measure  financial  performance,  such  as  
cash  flow  and  ROI,  and  take  corrective  
actions  in  case  of  deviation  from  objec-
tives and strategy.
Provided   that   many   organizations   use   
software  development  or  acquisition  to  stay  
competitive,  the  software  engineer  must  be  
conscious  of  the  importance  of  software  to  
business finances.
10.4. Controlling
Controlling  is  the  element  of  finance  and  
accounting   that   involves   measuring   and   
correcting  performance.  It  ensures  that  an  
organization’s objectives and plans are accom-
plished.   Controlling   cost   is   a   specialized   
branch of controlling used to detect variances 
of actual costs from planned costs.
In  software  engineering,  this  concept  is  
referred  to  as  processes  and  products  con-
trol  and  evolution.  While  the  organization  
is  seen  as  an  entity  with  its  own  goals,  and  
control  of  the  organizational  goals  is  seen  as  
separate,  software  engineers  must  consider  
control  of  the  organization  part  of  their  job  
by ensuring alignment of their software with 
business goals.
10.5. Efficiency and Effectiveness 
 [10*, c22pp422-23]
Economic efficiency of a process, activity or task 
is the ratio of resources consumed to resources 
expected  to  be  consumed.  Efficiency  means  
“doing  things  right.”  An  efficient  behavior,  
like an effective behavior, delivers results and 
minimizes  effort.  Factors  affecting  efficiency  
in software engineering include product com-
plexity,  quality  requirements,  time  pressure,  
process  capability,  team  distribution,  inter-
ruptions,  feature  churn,  tools  and  program-
ming language. 
Effectiveness  is  about  having  impact.  It  is  
the  relationship  between  achieved  objectives  
and  defined  objectives.  Effectiveness  means  

15-18   SWEBOK
®
 GUIDE V4.0
“doing  the  right  things.”  Effectiveness  looks  
only at whether defined objectives are reached 
— not at how they are reached.
10.6. Productivity [10*, c23pp689]
Productivity  is  the  ratio  of  output  to  input  
from  an  economic  perspective.  Output  is  the  
value  delivered.  Input  covers  all  resources  
(e.g.,  effort)  spent  to  generate  the  output.  
Productivity  combines  efficiency  and  effec-
tiveness  from  a  value-oriented  perspective.  
Maximizing productivity is about generating 
the  highest  value  with  the  lowest  resource  
consumption.
The  Guide  to  the  Project  Management  
Body  of  Knowledge  [23]  defines  rework  as  
“action taken to bring a defective or noncon-
forming   component   into   compliance   with   
requirements  or  specifications.”  It  is  worth  
noting  that  most  software  organizations  are  
unaware that the single largest resource con-
sumer  is,  in  fact,  rework.    In  many  software  
projects  the  cost  of  rework  is  higher  than  
the  cost  of  all  other  project  activities  com-
bined.  The  most  effective  way  to  increase  
productivity  can  be  to  simply  reduce  rework.  
Reducing  software  project  rework  involves  
proactive  quality  improvement  actions  (see  
Chapter 12, Software Quality KA) that either 
a) identify defects earlier so those defects can 
be  fixed at lower resource cost, b) reduce the 
degree  of  defect  cost  growth  (e.g.,  intention-
ally  simpler  code  is  easier  to  modify  than  
complex code so actively managing and con-
trolling  code  complexity  reduces  the  cost  of  
defect  repair),  and  c)  prevent  defects  in  the  
first  place  by,  for  example,  using  appropriate  
templates  and  checklists  in  development  and  
maintenance.
10.7. Product or Service
A product  is  a  tangible  economic  good  (or  
output)  created  in  a  process  that  transforms  
product  factors  (or  inputs)  into  an  output.  
A service  is  an  intangible  resource,  like  con-
sulting.  When  sold,  a  product  or  service  is  a  
deliverable  that  creates  both  a  value  and  an  
experience  for  its  consumers.  A  product  or  
service can be a combination of systems, solu-
tions  and  materials  delivered  internally  (e.g.,  
an in-house IT solution) or externally (e.g., a 
software application), either as is or as a com-
ponent  for  another  product  (e.g.,  embedded  
software). 
10.8. Project [22*, c2s2.4]
A project is “a temporary endeavor undertaken 
to create a unique product, service, or result” 
[24].    In    software    engineering,    different    
project  types  are  distinguished  (e.g.,  product  
development,  outsourced  services,  software  
maintenance,  service  creation,  and  so  on).  
During its life cycle, a software product may 
require  many  projects.  For  example,  during  
the product conception phase, a project might 
be conducted to determine customer need and 
market   requirements;   during   maintenance,   
a  project  might  be  conducted  to  produce  the  
next version of a product.
10.9. Program
A program is “a group of related projects, sub-
programs,  and  program  activities  managed  
in  a  coordinated  way  to  obtain  benefits  not  
available  from  managing  them  individually”  
[24]. Programs are often used to identify and 
manage  different  deliveries  to  a  single  cus-
tomer  or  market  over  a  time  horizon  of  sev-
eral years. 
10.10. Portfolio
Portfolios are “projects, programs, sub-portfo-
lios,  and  operations  managed  as  a  group  to  
achieve  strategic  objectives”  [24].  Portfolios  
are  used  to  group  and  then  manage  simul-
taneously  all  assets  within  a  business  line  
or  organization.  Having  an  entire  portfolio  
to  consider  helps  ensure  that  the  broader  
impacts  of  decisions  are  considered,  such  as  
the decision to allocate resources to a specific 
project, which means that the same resources 
will not be available for the other projects in 
the portfolio.

SOFTWARE ENGINEERING ECONOMICS   15-19
10.11. Product Life Cycle
An  SPLC  includes  all  activities  needed  to  
define, build, operate, maintain and retire a 
software product or service and its variants. 
The  SPLC  activities  of  “operate,”  “main-
tain”  and  “retire”  occur  in  a  much  longer  
time  frame  than  initial  software  develop-
ment  (the  software  development  life  cycle  
(SDLC)). (See Software Life Cycle Models 
in  the  Software  Engineering  Process  KA.)  
Also,   the   operate-maintain-retire   activi-
ties of an SPLC consume more total effort 
and other resources than the SDLC activi-
ties. (See Majority of Maintenance Costs in 
the Software Maintenance KA.) The value 
contributed by a software product or associ-
ated services can be objectively determined 
during  the  “operate  and  maintain”  time  
frame.   Software   engineering   economics   
should  be  concerned  with  all  SPLC  activ-
ities,  including  activities  that  take  place  
after the initial product release.
10.12. Project Life Cycle
Project life cycle activities typically involve 
five  process  groups:  Initiating,  Planning,  
Executing,   Monitoring   and   controlling,   
and   Closing   [23].   (See   the   Software   
Engineering Management KA.) The activ-
ities  within  a  software  project  life  cycle  
are  often  interleaved,  overlapped  and  iter-
ated  in  various  ways  [20*,  c2]  [25].  (See  
the  Software  Engineering  Process  KA.)  
For  instance,  Agile  product  development  
within  an  SPLC  involves  multiple  itera-
tions  that  produce  increments  of  deliver-
able  software.  An  SPLC  should  include  
risk    management    and    synchronization    
with different suppliers (if any) while pro-
viding auditable decision-making informa-
tion  (e.g.,  to  comply  with  product  liability  
needs or governance regulations). The soft-
ware  project  life  cycle  and  the  SPLC  are  
interrelated;  an  SPLC  may  include  sev-
eral SDLCs.
10.13. Price and Pricing [10*, c23s23.1]
A price is what is paid in exchange for a good or 
service. Price is a fundamental aspect of finan-
cial modeling and is one of the four Ps of the 
marketing mix. The other three Ps are product, 
promotion  and  place.  Price  is  the  only  reve-
nue-generating element among the four Ps; the 
rest are costs.
Pricing  is  an  element  of  finance  and  mar-
keting.  It  determines  what  a  company  will  
receive  in  exchange  for  its  products.  Pricing  
factors  include  manufacturing  cost,  market  
placement, competition, market condition and 
product quality. Pricing applies prices to prod-
ucts and services based on factors such as fixed 
amount,  quantity  break,  promotion  or  sales  
campaign,  specific  vendor  quote,  shipment  or  
invoice  date,  combination  of  multiple  orders,  
service  offerings,  and  many  others.  The  con-
sumer’s  needs  can  be  converted  into  demand  
only  if  the  consumer  has  the  willingness  and  
capacity  to  buy  the  product.  Thus,  pricing  is  
crucial  in  marketing.  Pricing  is  initially  done  
during the project initiation phase and is a part 
of the “go” decision-making process.
10.14. Prioritization
Prioritization   involves   ranking   alternatives   
based  on  common  criteria  to  deliver  the  best  
value.  For  example,  in  software  engineering  
projects,  software  requirements  are  often  pri-
oritized to deliver the most value to the client 
within  the  constraints  of  schedule,  budget,  
resources, and technology, or to allow the team 
to  build  the  product  in  increments,  where  the  
first  increments  provide  the  highest  value  to  
the customer. (See Requirements Prioritization 
in   the   Software   Requirements   KA   and   
Software  Life  Cycle  Models  in  the  Software  
Engineering  Process  KA.)  Prioritizing  alter-
natives  is  at  least  implicit  in  the  discussion  
in  2.6.,  Select  the  Preferred  Alternative,  but  
is  explicit  when  a  compensatory  technique  is  
used,  as  described  in  7.6.,  Multiple-Attribute  
Decision-Making.

15-20   SWEBOK
®
 GUIDE V4.0
MATRIX OF TOPICS VS. REFERENCE MATERIAL 
To c k e y   2 0 0 5 
[3*]
Sommerville  
2 016 [10 *]
Fa irley 2 0 0 9 
 [22*]
1. Software Engineering Economics 
Fundamentals
1.1. Proposalsc3pp23-24
1.2. Cash Flowc3pp24-32
1.3. Time-Value of Moneyc5-6
1.4. Equivalencec7
1.5. Bases for Comparisonc8
1.6. Alternativesc9
1.7. Intangible Assets
1.8. Business Model
2. The Engineering Decision-
Making Process
2.1. Process Overviewc4pp35-36
2.2. Understand the Real Problemc4pp37-39
2.3. Identify All Reasonable Technically  
Feasible Solutions
c4pp40-41
2.4. Define the Selection Criteria
c4pp39-40, 
c26pp441-442
2.5. Evaluate Each Alternative Against the 
Selection Criteria
c4pp41-42
2.6. Select the Preferred Alternative
c4p42, 
c 26pp 4 47-458
2.7. Monitor the Performance of the Selected  
Alternative
c4pp42-43
3. For-Profit Decision-Making
3.1. Minimum Acceptable Rate of Return c10pp141-143
3.2. Economic Lifec11pp160-164
3.3. Planning Horizonc11
3.4. Replacement Decisionsc12pp171-178 c9
3.5. Retirement Decisionsc12pp178-181 c9
3.6. Advanced For-Profit Decision Considerationsc13-17
4. Nonprofit Decision-Making
4.1. Benefit-Cost Analysisc18pp303-311
4.2. Cost-Effectiveness Analysisc18pp311-314
5. Present Economy Decision-Making

SOFTWARE ENGINEERING ECONOMICS   15-21
5.1. Break-Even Analysisc19
5.2. Optimization Analysisc20
6. Multiple-Attribute Decision-Making
6.1. Compensatory Techniquesc26pp449-458
6.2. Non-Compensatory Techniquesc26pp447-449
7. Identifying and Characterizing 
Intangible Assets
7.1. Identify Processes and Define Business Goals
7.2. Identify Intangible Assets Linked with 
Business Goals
7.3. Identify Software Products That Support 
Intangible Assets
7.4. Define and Measure Indicators
7.5. Intangible Asset Characterization
7.6. Link Specific Intangible Assets with the 
Business Model
7.7. Decision-Making
8. Estimation
8.1. Expert Judgmentc22pp367-369
8.2. Analogyc22pp369-371
8.3. Decompositionc22pp371-374
8.4. Parametricc22pp374-377
8.5. Multiple Estimatesc22pp377-379
9. Practical Considerations
9.1. Business Case
9.2. Multiple-Currency Analysis
9.3. Systems Thinking
10. Related Concepts
10.1. Accountingc15pp234-245
10.2. Cost and Costingc15pp245-259
10.3. Finance
10.4. Controlling
10.5. Efficiency and Effectivenessc22pp422-23
10.6. Productivityc23pp689
10.7. Product or Service
10.8. Projectc2s2.4

15-22   SWEBOK
®
 GUIDE V4.0
10.9. Program
10.10. Portfolio
10.11. Product Life Cycle
10.12. Project Life Cycle
10.13. Price and Pricingc23s23.1
10.14. Prioritization
FURTHER READINGS
Project  Management  Institute,  A  Guide  to  
the   Project   Management   Body   of   Knowledge   
(PMBOK® Guide) [24].
The PMBOK® Guide provides guidelines for 
managing  individual  projects  and  defines  
project   management-related   concepts.   It   
also  describes  the  project  management  life  
cycle  and  its  related  processes,  as  well  as  
the  project  life  cycle.  It  is  a  globally  rec-
ognized  guide  for  the  project  management  
profession.
Project   Management   Institute   and   IEEE   
Computer   Society,   Software   Extension   to   
the  Guide  to  the  Project  Management  Body  of  
Knowledge (SWX) [25].
SWX  provides  adaptations  and  extensions  to  
the  generic  practices  of  project  management  
documented in the PMBOK® Guide for man-
aging  software  projects.  The  primary  con-
tribution  of  this  extension  to  the  PMBOK® 
Guide  is  its  description  of  processes  that  are  
applicable  to  managing  adaptive  life  cycle  
software projects.
B.W.       Boehm,       Software       Engineering       
Economics [26]. 
This book is classic reading on software engi-
neering  economics.  It  provides  an  overview  
of business thinking in software engineering. 
Although the examples and figures are dated, 
it is still worth reading.
C.     Ebert     and     R.     Dumke,     Software 
Measurement [27]. 
This  book  provides  an  overview  of  quantita-
tive methods in software engineering, starting 
with   measurement   theory   and   proceeding   
to   performance   management   and   business   
decision-making.
D.J.   Reifer,   Making   the   Software   Business   
Case: Improvement by the Numbers [28]. 
This book is classic reading on making a busi-
ness case in software and IT industries. Many 
useful  examples  illustrate  how  the  business  
case is formulated and quantified. 
REFERENCES
[1] E. DeGarmo et al., Engineering 
Economy, 9th ed., Englewood Cliffs, 
NJ: Prentice Hall, 1993.
[2]   P. Rodriguez, C. Urquhart, and E. 
Mendes. “A Theory of Value for Value-
based Feature Selection in Software 
Engineering,” IEEE Transactions on 
Software Engineering, 1, 2020.
[3*] S. Tockey, Return on Software: 
Maximizing the Return on Your Software 
Investment, Boston, MA: Addison-
Wesley, 2005.
[4] International Valuation Standards (IVS), 

SOFTWARE ENGINEERING ECONOMICS   15-23
2019, Norwich: Page Bros, ISBN: 
978-0-9931513-3-3-0.
[5] K. Voigt, O. Buliga, and K. Michl, 
Business Model Pioneers: How 
Innovators Successfully Implement 
New Business Models, 2017.
[6] M.-I. Sanchez-Segura, G.-L. Dugarte-
Peña, A. Amescua-Seco, and F. 
Medina-Domínguez, “Exploring  
How The Intangible Side of an 
Organization Impacts its Business  
Model,” Kybernetes, Vol. 50 No. 10,  
pp. 2790-2822. 2021. https://doi.org 
/10.1108/K-05-2020-0302.
[7] ISO/IEC/IEEE International 
Standard – Systems And Software 
Engineering – Software Life Cycle 
Processes – Part 2: Relation and 
Mapping Between ISO/IEC/IEEE 
12207:2017 and ISO/IEC 12207:2008. 
IEEE, 2020, pp. 1-278, doi: 10.1109/
IEEESTD.2020.9238529.
[8*] ISO/IEC/IEEE 15288 First edi-
tion 2015-05-15: ISO/IEC/IEEE 
International Standard – Systems and 
Software Engineering – System Life 
Cycle Processes, IEEE.
[9] T. Brown and B. Katz, Change by 
Design: How Design Thinking Transforms 
Organizations and Inspires Innovation, 
Revised and updated ed., New York, 
NY: Harper Collins, 2019.
[10*] I.  Sommerville, Software Engineering, 
10th ed., New York: Addison-
Wesley, 2016.
[11] T. Gilb, Competitive Engineering: A 
Handbook for Systems Engineering, 
Requirements Engineering, and 
Software Engineering Using Planguage, 
Oxford, UK: Elsevier Butterworth-
Heinemann, 2005.
[12] R. Kazman, M. Klein, and P. 
Clements, “ATAMSM: Method for 
Architecture Evaluation,” CMU/SEI-
2000-TR-004, Software Engineering 
Institute, August 2000.
[13] M.I. Sanchez-Segura, A. Ruiz-
Robles, F. Medina-Domínguez, 
and G.L. Dugarte-Peña. “Strategic 
Characterization of Process Assets 
Based on Asset Quality and Business 
Impact,” Industrial Management and Data 
Systems, 117(8), 1720-1734. https://doi.
org/10.1108/IMDS-10-2016-0422, 2017.
[14] M.I. Sanchez-Segura, A. Ruiz Robles, 
F. Medina-Domínguez. “Uncovering 
Hidden Process Assets: A Case Study.” 
Information Systems Frontiers, ht t ps: //
www.springerprofessional.de/en 
/uncovering-hidden-process-assets-a 
-case-study/11724394, 2016.
[15] A. Osterwalder, Y. Pigneur, G. 
Bernarda, A. Smith, and T. Papadakos, 
Value Proposition Design, Wiley, 2015.
[16] D. Gotterbarn, K. Miller, and S. 
Rogerson, “Software Engineering  
Code of Ethics,” Commun. 
ACM 40, 11, 110-118, doi: 
10.1145/265684.265699, 1997.
[17] S. McConnell, Software Estimation 
Demystifying the Black Art, 1st ed., 
Microsoft Press, 2009.
[18]  R.D. Stutzke, Estimating Software-
Intensive Systems Projects, Products, and 
Processes, 1st ed., Addison-Wesley, 2005.
[19] M. Ben-Eli, Understanding Systems. 
Systems Innovation, http://bit.ly/2X-
Nlh3D, 2019.
[20] J. Sterman, Business Dynamics: Systems 
Thinking and Modeling for a Complex 
World, McGraw-Hill, 2000.

15-24   SWEBOK
®
 GUIDE V4.0
[21] S. Pereira, G. Medina, et al., “System 
Thinking and Business Model Canvas 
for Collaborative Business Models 
Design,” IFIP Advances in Information 
and Communication Technology,   Vol .  
488, pp. 461-468, 2016.
[22*] R.E. Fairley, Managing and Leading 
Software Projects, Wiley-IEEE 
Computer Society Press, 2009.
[23] Project Management Institute, A 
Guide to the Project Management Body 
of Knowledge (PMBOK® Guide), 7th 
ed., Newton Square, PA: Project 
Management Institute, 2021.
[24] Project Management Institute, Inc., 
PMI Lexicon of Project Management 
Te r m, 2012.
[25] Project Management Institute and 
IEEE Computer Society, Software 
Extension to the PMBOK® Guide Fifth 
Edition, ed: Project Management 
Institute, 2013.
[26] B.W. Boehm, Software Engineering 
Economics, Prentice-Hall, 1981.
[27] C. Ebert and R. Dumke, Software 
Measurement, Springer, 2007.
[28] D.J. Reifer, Making the Software Business 
Case: Improvement by the Numbers, 
Addison-Wesley, 2002.

16-1 
CHAPTER 16
Computing Foundations
ACRONYMS
ADTAbstract Data Type
AIArtificial Intelligence
ANSI
American National Standards 
Institute 
AV L   Tr e eAdelson-Velskii and Landis Tree
BCNFBoyce-Codd Normal Form 
BSTBinary Search Tree
CASE
Common Application 
Service Element 
CDRAMCache DRAM
CERT
Computer Engineering 
Response Team
CISC
Complex Instruction 
Set Computer
CRUDCreate, Read, Update, Delete
CUDA
Compute Unified Device 
Architecture
DAGDirected Acyclic Graph
DALDatabase Access Language
DASDirect Access Storage
DBCSDouble Byte Character Set
DCLData Control Language
DDLData Definition Language
DDR 
SDRAM
Double Data Rate SDRAM
DKNFDomain/Key Normal Form 
DMADirect Memory Access
DMLData Manipulation Language
EDWEnterprise Data Warehouse
FCFSFirst Come, First Served 
FIFOFirst In, First Out
FPUFloating Point Unit
HCIHuman-Computer Interface
HMPP
Hybrid Multicore Parallel 
Programming
HTTPHyper Text Transfer Protocol
IPCInter-Process Communication
ISAInstruction Set Architecture
MIMD
Multiple Instruction, Multiple 
Data Stream 
MISD
Multiple Instruction, Single 
Data Stream 
MISRA
Motor Industry Software 
Reliability Association
MLMachine Learning
NASNetwork Access Storage
OSIOpen Systems Interconnection
PDUProtocol Data Unit
RDBMSRelational DBMS
RDMRuntime Database Manager
RDRAMRambus DRAM
RISC
Reduced Instruction 
Set Computer
RTOSReal Time Operating System
SANStorage Area Network
SASE
Specific Application 
Service Element 
SDRAMSynchronous DRAM
SEISoftware Engineering Institute
SIMD
Single Instruction, Multiple 
Data Stream 
SISD
Single Instruction, Single 
Data Stream 
SQLStructured Query Language
SRTFShortest Remaining Time First

16-2   SWEBOK
®
 GUIDE V4.0
INTRODUCTION
Software engineers must understand and inter-
nalize  the  differences  between  their  role  and  
that of a computer programmer. A typical pro-
grammer converts a given algorithm into a set 
of  computer  instructions,  compiles  the  code,  
creates  links  with  relevant  libraries,  binds,  
loads  the  program  into  the  desired  system,  
executes the program, and generates output.
On  the  other  hand,  a  software  engineer  
studies the requirements, architects and designs 
major  system  blocks,  and  identifies  optimal  
algorithms, communication mechanisms, per-
formance  criteria,  test  and  acceptance  plans,  
maintenance methodologies, engineering pro-
cesses and methods appropriate to the applica-
tions and so on.
The    key    purpose    of    the    Software 
Engineering  Body  of  Knowledge  (SWEBOK)  
Guide  is  to  identify  the  areas  of  knowledge  
that  professional  software  engineers  must  
know, according to practicing subject matter 
experts worldwide.
Software  engineers  are  expected  to  have  
deep  and  broad  knowledge  of  various  con-
cepts of computer science and be able to apply 
them. These concepts form the foundations of 
computing.
BREAKDOWN OF TOPICS FOR 
COMPUTING FOUNDATIONS
The  breakdown  of  topics  for  the  Computing  
Foundations  knowledge  area  (KA)  is  shown  
in Figure 16.1.
1. Basic Concepts of a System or Solution 
 [6*, C10]
The problem to be solved has to be analyzed in 
greater detail for functional requirements, user 
interactions, performance requirements, device 
interfaces,   security,   vulnerability,   durability   
and  upgradability.  A  system  is  an  integrated  
set  of  subsystems,  modules  and  components  
that perform specific functions independently. 
Delineating the problem and solution is critical.
An engineered system ensures the subsys-
tems are designed to be:
•    Modular:  Each  subsystem  (module)  is  
uniform (similar size).
•    Cohesive:  Each  subsystem  performs  one  
specific  task.  Ideally,  systems  should  be  
highly cohesive.
•    Coupled: Each subsystem functions inde-
pendently,  as  much  as  possible.  Ideally,  
systems should be loosely coupled.
Computing 
Foundations
Basic Concepts
of a System 
or Solution
Computer 
Architecture
Types of 
Computer 
Architecture
Microarchitecture 
or Computer 
Organization
Memory
Unit
Input/Output
Devices 
Control Unit
Types of 
Data Structures
Operations on 
Data Structures
Algorithms 
and Attributes 
of Algorithms
Algorithm 
Complexity
Measurement 
of Complexity
Designing 
Algorithms
Sorting 
Techniques
Searching 
Techniques
Hashing
Programming 
Language Types
Programming 
Syntax, Semantics, 
Type Systems
Subprograms 
and Coroutines
Object-Oriented 
Programming
Distributed 
Programming and 
Parallel Programming
Debugging
Standards and 
Guidelines
Processor 
Management
Memory 
Management
Device 
Management
Information 
Management
Network 
Management
Schema
Data Models 
and Storage 
Models
Database 
Management 
Systems
Relational 
Database 
Management 
Systems and 
Normalization
Structured 
Query 
Language
Data Mining 
and Data 
Warehousing
Database Backup 
and Recovery
Types of 
Computer 
Networks
Layered 
Architectures 
of Networks
Open Systems 
Interconnection 
Model
Encapsulation and 
Decapsulation
Application Layer 
Protocols
Design Techniques for 
Reliable and Ecient 
Networks
Internet Protocol 
Suite
Wireless and Mobile 
Networks
Security and 
Vulnerabilities
Computer 
Architecture and 
Organization
Data Structures 
and Algorithms
Programming 
Fundamentals 
and Languages
Operating 
Systems
Database
Management
Computer 
Networks and 
Communications
Human Factors:
User and 
Developer
User Human 
Factors
Developer Human 
Factors
Artificial 
Intelligence and 
Machine Learning
Reasoning
Learning
Models
Perception and 
Problem-Solving
Natural Language 
Processing
Figure 16.1. Breakdown of Topics for the Computing Foundations KA

COMPUTING FOUNDATIONS   16-3
The  subsystems  may  further  be  broken  
down into modules and sub-modules that also 
exhibit these characteristics.
The system may include both software and 
hardware   subsystems.   The   hardware   must   
be  designed  to  support  the  software  subsys-
tems  and  satisfy  all  user  requirements,  espe-
cially user interfaces (input/output (I/O)) and 
performance. 
This   section   focuses   on   designing   and   
building engineered software subsystems. 
The  applications  may  require  systems  that  
are  manual  or  fully  or  semiautomated;  real-
time,  online  or  offline;  distributed  or  single- 
location, and so on. 
The  software  subsystems’  architects  have  
to   consider   appropriate   technology,   tools,   
data structure, operating system, database (if 
required),  user  interfaces,  programming  lan-
guages,  and  algorithms  for  computing  solu-
tions optimally among others.
Software requirements, architecture, design, 
construction,  testing,  methods  and  models,  
quality assurance, and security are discussed in 
detail in other chapters as independent KAs.
The  Computing  Foundations  KA  focuses  
on  explaining  the  key  computer  science  con-
cepts a software engineer has to know well to 
architect, design, construct, deploy and main-
tain useful, high-quality software subsystems.
2. Computer Architecture and 
Organization [6*, C6]
Computer  architecture  refers  to  the  com-
ponents  of  a  computer  system  designed  for  
specific   purposes.   Computer   organization   
explains how the units within the system con-
nect and interact to achieve those purposes. 
System  architects  must  analyze  the  appli-
cation  for  which  the  computer  system  is  to  
be  designed  or  developed;  identify  the  crit-
ical    components,    including    I/O    devices    
required  (along  with  throughput),  types  and  
quantum  of  memory,  processing  power,  and  
coprocessors  required;  and  choose  or  design  
appropriate  computer  architecture  and  orga-
nization. Contingencies should be built in for 
the resources required.
This  content  area  discusses  various  com-
puter architectures and organizations a system 
or software architect needs to know.
2.1.  Computer Architecture [8*, C1.1]
Architecture   describes   what   the   computer   
or  system  does,  and  its  components,  such  as  
memory,  data  storage  devices,  graphics,  and  
the computers or processor’s computing power. 
A computing system typically has memory, I/O 
devices and a central processing unit (CPU). 
These  components  are  connected  through  
physical signal lines called a bus. Typically, three 
types of buses are used for specific purposes:
•    Address bus, which addresses or accesses 
a specific memory location or I/O device.
•    Data   bus,   which   stores   (writes)   or   
retrieves  (reads)  data  to  and  from  the  
memory location.
•    Control bus, which provides control sig-
nals  from  the  CPU  to  I/O  devices  (read  
or  write,  enable  or  disable,  interrupt,  
status, reset, etc.).
Software  engineers  are  expected  to  know  
the  details  of  the  functioning  and  timing  
of  different  types  of  buses  —  first-gener-
ation,    second-generation    and    third-gen-
eration  buses;  internal  and  external  buses;  
serial and parallel buses; simplex, full-duplex 
and   half-duplex   buses;   Mil-Std-1553Bbus,   
Wishbone buses, etc.
2.2.  Types of Computer Architectures 
 [8*, C4.14, C5]
2.2.1.   Von Neumann Architecture [8*, C1.9]
John   von   Neumann   designed   a   computer   
system  architecture  with  five  essential  com-
ponents as shown in Figure 16.2:
•    Arithmetic  logic  unit  (ALU)  that  per-
forms arithmetic and logic computation.
•    Memory where the program and data are 
loaded  and  executed  (program  and  data  
reside in the same memory space).

16-4   SWEBOK
®
 GUIDE V4.0
•    Input   devices   (e.g.,   keyboard,   mouse,   
serial port, hard disk) that allow the user 
to provide inputs and control commands.
•    Output  devices  (e.g.,  monitor,  printer)  
that  transmit  or  communicate  the  com-
puted results.
•    The control unit synchronizes all devices, 
memory and ALU.
2.2.2.    Harvard Architecture [20*]
The   Harvard   architecture   provides   separate   
memory  blocks  for  code  (program  or  instruc-
tions) and data. As the code and data memory 
blocks  are  different,  the  contents  of  address  
0000  in  the  code  block  and  the  contents  of  
address 0000 in the data block are different. The 
CPU reads instructions from the code addresses 
and reads data from the data addresses. 
The  system  design  and  implementation  in  
the  original  Harvard  architecture  were  rela-
tively complex. The modified Harvard architec-
ture provides one memory block but partitions 
it  into  code  and  data  sections.  Data  memory  
sections   are   read/write   capable,   and   code   
memory  sections  are  read-only  (thus  protects  
code  from  getting  corrupted  at  runtime).  I/O  
operations can be performed simultaneously. 
2.2.3.    Instruction Set Architecture [8*, C4.8.3]
An  instruction  set  architecture  (ISA)  is  an  
abstract  model  of  how  a  CPU  executes  the  
instruction  sets  defined  for  the  system.  An  
ISA defines registers (address, data, flags), data 
types,  instructions  specific  to  the  computer  
or  system,  memory  (internal  and  external)  
addressing schemes, and I/O handling models. 
A reduced instruction set computer (RISC) 
architecture  and  a  complex  instruction  set  
computer  (CISC)  architecture  are  the  two  
primary types of ISAs. 
In  RISC,  the  instructions  perform  single  
tasks  such  as  reading  from  memory  or  I/O,  
performing  arithmetic  or  logical  computa-
tion,  and  storing  data  into  memory  or  I/O.  
The  computer  system  is  simple  but  requires  
more instructions to execute a task. It requires 
fewer clock cycles per instruction, and instruc-
tion sizes tend to be fixed. As the instruction 
set is small (fewer instructions), it is easier to 
build a compiler, and the program can be rel-
atively large. RISC architectures are typically 
designed for general-purpose processors. 
The  instructions  are  relatively  more  pow-
erful in CISC and can perform multiple tasks 
such  as  reading  data  from  memory  +  per-
forming  arithmetic  operation  +  storing  the  
result in memory. Here, fewer instructions are 
required  to  perform  a  task,  but  the  instruc-
tions  take  more  clock  cycles  to  complete.  
Instruction  sizes  vary  widely  depending  on  
operations  with  registers,  memory  and  I/O.  
Programs are relatively small. CISCs are typ-
ically  designed  for  specific  purposes  such  as  
digital signal processing (DSP) and graphics.
Memory
Input Devices
ALU
Output Devices
Control Unit
Figure 16.2. Computer Architecture

COMPUTING FOUNDATIONS   16-5
2.2.4.    Flynn’s Architecture or Taxonomy 
 [8*, C9.3]
The computing architectures described above 
consider a single computer at a time. Michael 
J. Flynn proposed concurrent computer archi-
tectures,  where  multiple  instruction  streams  
and  multiple  data  streams  are  used  in  the  
system. Software engineers need to know the 
different  types  of  Flynn’s  architecture,  with  
examples, including the following:
•    Single   instruction,   single   data   stream   
(SISD) architecture.
•    Single  instruction,  multiple  data  stream  
(SIMD) architecture.
•    Multiple  instruction,  single  data  stream  
(MISD) architecture.
•    Multiple    instruction,    multiple    data    
stream (MIMD) architecture.
Variants of these architectures include array 
processing,   parallel   processing,   and   asso-
ciate  processing;  processing  single  program  
multiple  data  streams,  and  multiple  program  
multiple data streams. Software engineers are 
expected to know the differences among these 
architectures, along with case studies, so that 
they can choose the right architecture to solve 
the problem at hand.
2.2.5.    System Architecture [6*, C6]
System   architecture   is   the   overall   system   
design,     considering     hardware     architec-
ture,  software  architecture,  modules,  inter-
faces, data management, and communication 
among  modules.  Distributed  computing  has  
become  affordable  with  the  development  of  
efficient, high-end, high-performance servers, 
storage, network devices, software, and tools. 
Several reference designs or architectures are 
available for any given application.
Typical  system  architectures  include  the  
following:
•    Integrated         system         architecture:         
Computing,  I/O,  data  and  networking  
are   tightly   coupled   and   available   in   
one  box.  This  architecture  is  typically  
used  in  solutions  designed  for  specific  
applications.
•    Distributed        system        architecture:        
Computing  and  storage  are  located  in  
separate but networked boxes. This archi-
tecture  supports  scaling,  provides  cen-
tralized   or   isolated   data   storage,   and   
shares computation load.
•    Pooled system architecture: Several com-
puting, storage and network resources are 
available in pools and provided depending 
on  demand.  This  architecture  provides  
for efficient use of shared resources. 
•    Converged  system  architecture:  As  the  
name  implies,  this  is  the  convergence  
of  distributed  and  pooled  architectures.  
This   architecture   supports   agility   and   
sca labilit y.
Software  engineers  are  also  expected  to  
know and  be  able  to  apply  various  other  
architectures,   including   .NET   Framework   
architecture,  Unix  architecture,  and  virtual  
machine architecture.
2.3.  Microarchitecture or Computer 
Organization [8*, C4]
Microarchitecture  or  computer  organization  
explains how the ISA of a computer is imple-
mented and how different components in the 
system function and interact with one another 
to produce the desired outcome.
System architects and engineers must know 
the  various  components  used  in  the  system  
along with how they function. Some of these 
components are discussed below.
2.3.1.    Arithmetic Logic Unit [8*, C1.2]
The  ALU  performs  all  arithmetic  computa-
tions  and  logical  operations.  The  CPU  typ-
ically  has  an  ALU,  processor,  memory,  and  
control  unit.  High-end  CPUs  may  also  have  
other  functionality-specific  processing  units,  
such  as  a  floating-point  unit  (FPU),  to  per-
form computations involving floating point or 
real numbers (fractions). ALUs have registers 

16-6   SWEBOK
®
 GUIDE V4.0
that  are  high-speed  memory  and  internal  to  
the  ALU.  The  ALU  executes  the  processor  
instruction  sets.  All  operations  are  typically  
carried out on the registers.
Various   schemes   may   be   implemented   
to   improve   the   performance   of   the   ALU,   
including   pipeline   processing   and   parallel   
processing.  The  latest  CPUs  provide  multiple  
cores  and  multiple  threads  that  help  achieve  
maximum   throughput.   Software   engineers   
are expected to know the differences between 
multiple cores and multiple threads, along with 
specific cases illustrating the best use of these. 
Specific-purpose   coprocessors   and   asso-
ciate processors are used with main processors 
to support faster processing.
2.3.2.    Memory Unit [8*, C6]
Memory units are used to store data or infor-
mation,  which  is  accessed  by  the  CPU.  The  
total amount of memory a computer can have 
is  derived  from  the  maximum  number  of  
address lines supported by the CPU. Different 
types  of  memory  used  in  the  system  include  
read-only  memory  (ROM),  and  read-write  
memory or random access memory (RAM).
Software   engineers   working   on   perfor-
mance-critical  applications  are  expected  to  
know  the  differences  among  various  types  
of  memory,  including  static  RAM  (SRAM),  
dynamic    RAM    (DRAM),    asynchronous    
DRAM  (ADRAM),  synchronous  DRAM  
(SDRAM), double-data-rate SDRAM (DDR 
SDRAM), rambus DRAM (RDRAM), and 
cache  DRAM  (CDRAM),  along  with  pros,  
cons and use cases of each.
2.3.3.    Input/Output Devices [8*, C7]
As  the  names  imply,  input  devices  are  those  
that  provide  inputs  to  the  computer  system,  
and output devices are those that deliver com-
puter systems’ output to the user. While some 
devices   are   input   only   (keyboard,   mouse,   
microphone,  etc.)  or  output  only  (printer,  
monitor,  speakers,  etc.),  a  few  devices  serve  
as  both  input  and  output  devices  (e.g.,  touch  
screens, hard disks, USB drives).
Software  engineers  are  expected  to  under-
stand the interface of the I/O devices with the 
system, whether they are memory-mapped I/O 
or I/O-mapped I/O devices, and device drivers 
required for the users or applications to interact 
with the devices through the operating system.
2.3.4.    Control Unit [8*, C4.2]
The  control  unit  synchronizes  multiple  com-
ponents  in  the  computer  system.  Typically,  
control units are part of the CPU. They inter-
pret  instructions  and  coordinate  data  move-
ment  among  different  components  (memory,  
I/O  devices  and  ALU).  Control  units  are  
also used to enable or disable components or 
devices and reset devices.
Software   engineers   are   expected   to   be   
aware of  the  different  types  of  control  units,  
including  hardware  control  units  and  micro  
programmable  control  units  (single-level  and  
two-level control stores), along with the bene-
fits and challenges of each.
3. Data Structures and Algorithms 
 [8*, C2]   [18*, C10 Part V ]
Data  structures  are  fundamental  to  computer  
science  and  software  engineering.  Every  pro-
gram  uses  data  —  receives  input  (data),  per-
forms   specific   functions   on   the   data   and   
produces output. Data structures is about rep-
resenting  different  types  of  data  effectively,  
performing various operations on the data pro-
ficiently,  and  storing  and  retrieving  data  effi-
ciently.  Software  engineers  must  internalize  
data structures, the selection of data structures, 
and operations on them specific to applications. 
In  this  chapter,  different  types  of  data  
structures and various operations on them are 
discussed. 
3.1.  Types of Data Structures [18*, C10], 
 [5*, C2.1 - 2.6]
Data type is an attribute of data. Various data 
types are identified and defined based on dif-
ferent  characteristics  of  data,  the  need  for  
grouping  data  items  and  various  operations  

COMPUTING FOUNDATIONS   16-7
performed   on   data.   Data   structures   are   
grouped  primarily  based  on  the  physical  and  
logical ordering of data items. 
Primarily, data is grouped into three types: 
basic, composite or compound, and abstract. 
Basic or primitive data types include char-
acter,  integer,  float  or  real,  Boolean,  and  
pointer data. 
Compound data types are made of multiple 
basic or primitive, or even multiple compound 
data types. Some of the compound data types 
include sets, graphs, records and partitions.
An abstract data type (ADT) is defined by 
its  behavior  (semantics)  from  the  user’s  per-
spective,  specifically  from  the  point  of  pos-
sible values and operations.
Composite  or  compound  data  types  are  
further grouped under linear, and hierarchical 
or nonlinear data types.
Linear data types include one-dimensional 
and  multidimensional  arrays,  strings,  linked  
lists  (singly  linked  lists,  doubly  linked  lists,  
circular lists), stacks, queues, and hash tables.
Hierarchical    or    nonlinear    data    types    
include  trees,  binary  trees,  n-array  trees,  B  
trees, B+ trees, weighted balanced trees, red-
black trees, heaps, binary heaps and graphs.
In  the  current  era  of  free  text  queries  or  
natural  language  processing,  software  engi-
neers may need to understand strings and var-
ious  operations  on  strings,  and  to  be  able  to  
analyze skip lists.
Software  engineers  must  understand  the  
nuances  of  various  types  of  data  and  their  
sizes   in   memory   (short   integer,   integer,   
long  integer,  long  long  integer,  signed  and  
unsigned  integer,  float,  double,  long  double,  
double  byte  character  set  (DBCS),  Boolean,  
etc.),  along  with  how  various  data  types  are  
represented  and  stored  in  memory  and  how  
various  operations  are  performed  on  them.  
Sets, graphs, and trees are discussed in more 
detail in the Mathematical Foundations KA.
3.2.  Operations on Data Structures 
 [5*, C2.1 - 2.6]
Basic  operations  performed  on  data  structures  
include create, read, update and delete (CRUD). 
Compound data types also require various ways 
of  traversing  data  sets  to  identify  specific  data  
items before performing the operation.
It is important to ensure that any insertion 
or  deletion  of  items  in  a  data  set  or  database  
does not alter the data set or database in a way 
that violates any policy under which the data-
base was designed and built.
Additional  operations  performed  on  data  
structures include sorting the data items in a 
specific  order,  searching  and  locating  a  data  
item,  and  merging  two  or  more  data  sets  
into  one  set  without  disturbing  the  policy  
on  which  the  data  set  is  built.  Searching  
and  sorting  algorithms  are  discussed  in  the  
next section.
Different  data  structures  are  created  to  suit  
specific  applications,  such  as  stacks,  queues,  
trees,   and   graphs.   Software   engineers   are   
encouraged to learn the traversals through non-
linear  data  structures,  which  include  different  
tree parsers (pre-order, in-order, and post-order 
tree traversals), CRUD operations on trees, tree 
balancing,  binary  search  trees  (BSTs),  AVL  
trees,  and  red-black  trees,  and  to  learn  tree  
search  algorithms  (depth  first,  breadth  first,  
shortest  paths,  etc.).  Some  of  these  are  dis-
cussed in the Mathematical Foundations KA.
3.3.  Algorithms and Attributes of Algorithms 
 [18*, C26, C27]
All software implements logic to perform the 
required function. That logic or algorithm to 
perform a specific task has to be designed or 
chosen  with  consideration  for  system  per-
formance,   security,   portability,   maintain-
ability,   scalability   and   simplicity,   among   
other concerns.
The  complexity  of  an  algorithm  is  deter-
mined    by    measuring    the    computational    
resources  (computing  power  and  space)  con-
sumed by that algorithm for a given set of data. 
A  thorough  understanding  of  data  struc-
tures is vital for analyzing and designing good 
algorithms. Refer to the “Data Structures and 
Organization” content area for more details.
The attributes of algorithms are many and 
include functionality, correctness, robustness, 

16-8   SWEBOK
®
 GUIDE V4.0
modularity,    maintainability,    programmer- 
friendliness (ease of integration into the project 
and  ease  of  use),  user-friendliness  (i.e.,  how  
easily it is understood by people), need for pro-
grammer time, simplicity, and extensibility. 
A commonly emphasized attribute of algo-
rithms is “performance” or “efficiency.” 
The  parameters  that  matter  for  an  algo-
rithm’s resource consumption include, but are 
not limited to:
1. Hardware. 
2. Software. 
3. Algorithm selection and design for a spe-
cific problem. 
4. Effective implementation.
3.4.  Algorithm Complexity [5*, S1, S3, S4,  
 S5, S6, S7, S11, S12]
The  complexity  of  an  algorithm  is  a  mea-
sure of the resources it consumes (computing 
power or memory) for a specific problem and 
given data set. 
Choosing  the  right  data  structures  and  
operations  on  data  structures  and  ensuring  
optimal implementation of the algorithm also 
effect the algorithm’s complexity.
3.5.  Measurement of Complexity [5*, S1.1,  
 S3, S4, S5, S6, S11.1, S12.1]
Often,  the  complexity  of  an  algorithm  is  
denoted  by  the  resources  consumed  in  the  
worst-case  scenario.  The  complexity  of  algo-
rithms  is  typically  measured  by  asymptotic  
notations  for  best-case,  worst-case  and  aver-
age-case  scenarios  in  terms  of  resource  con-
sumption for a given data set. 
Popular   asymptotic   notations   for   algo-
rithms are listed in Table 16.1. 
Learning  the  computation  of  the  listed  
notations for different sets of input data (e.g., 
sorted, unsorted, and sorted in reverse order) 
is important.
The complexity of an algorithm can be con-
stant, linear, quadratic, cubic, exponential or 
logarithmic. These complexities are described 
in  Table  16.2.  Typically,  constants  are  not  
considered  when  computing  the  efficiency  of  
an algorithm.
3.6.  Designing Algorithms [18*, Part IV,  
 Part VI]
The   software   engineer   must   consider   the   
specific  application’s  purpose  and  the  per-
formance  requirements  in  order  to  select  an  
appropriate  algorithm.  In  addition,  the  soft-
ware   engineer   must   consider   linear   pro-
gramming  versus  parallel  programming  and  
single- versus multi-threading.
The efficiency of an algorithm is measured 
by the resources it consumes, primarily com-
puting time and memory. 
A  software  engineer  has  to  know  a  few  
standard  algorithms  and  relevant  concepts,  
including the following: 
Asymptotic NotationsDescription
Big OBig O notation provides the upper bound of operations (worst-case 
scenario) for a function f(n).
little-oLittle o notations are used to depict scenarios where the upper bound 
is not tight.
Big Omega (Ω)Big Ω notations are used to depict lower bounds (best-case scenarios) 
for a function f(n). 
little-omega (ω)Little omega (ω) notations are used to depict loosely bound best-case 
scenarios of an algorithm.
Theta (Θ)
Theta notation bounds the function from above and below (provides 
average-case complexity of an algorithm).
Ta b l e   16 .1 . Asymptotic Notations of Algorithms

COMPUTING FOUNDATIONS   16-9
•    Common   types   of   algorithms:   Brute   
force   algorithm,   Recursive   algorithm,   
Divide  &  Conquer  algorithm,  Dynamic  
programming       algorithms,       Greedy       
algorithm,     Backtracking     algorithms,     
Randomized algorithms.
•    Randomized  approximation  algorithms,  
randomized    rounding,    approximation    
algorithms,  P  and  NP  complexity  class  
algorithms,  Cook’s  theorem,  reductions  
and completeness algorithms.
•    Multiple   comparison   operations   per-
formed   simultaneously   in   a   network   
model  of  computation.  Popular  sorting  
network  algorithms  include  comparison  
networks,   zero-one   principle,   merging   
network and bitonic sorter.
•    Optimized   algorithms   for   performing   
several  operations  on  a  matrix,  such  as  
matrix     multiplication,     transposition,     
matrix  inversion,  median,  and  finding  
determinants.
•    Cryptographic    complexity    and    algo-
rithms:  secret  key  (symmetric)  encryp-
tion algorithms, public key (asymmetric) 
encryption      algorithms      and      hash      
functions.
•    One-way functions, class UP, space com-
plexity, deterministic and nondeterministic 
space  complexity  classes,  the  reachability  
method, and Savitch’s theorem.
•    Graph representations, graph algorithms, 
breadth-first    and    depth-first    search,    
topological   sort,   minimum   spanning   
tree,  Kruskal  and  Prim  algorithms,  and  
single-source  shortest  paths  (Bellman-
Ford and Dijkstra algorithms).
•    Complexity   of   randomized   computa-
tion,  interactive  proofs,  complexity  of  
counting, Boolean circuit complexity.
Of  particular  importance  in  many  soft-
ware  systems  are  algorithms  for  sorting  and  
searching, these are discussed in more detail.
3.7.  Sorting Techniques [18*, C6-C9]
Sorting is the process of arranging data items 
in a specific order. 
Popular sorting algorithms include Linear 
sort,  Bubble  sort,  Quick  sort,  Merge  sort,  
Radix sort, Heap sort, Bucket sort, Pigeonhole 
sort,  Bitonic  sort,  Tree  sort,  Cartesian  Tree  
sort,  3-Way  Quick  sort,3-Way  Merge  sort,  
and Sorting Singly / Doubly linked lists.
Each sorting algorithm has its benefits and 
shortfalls.  Selection  of  an  appropriate  algo-
rithm  depends  on  the  size  of  input  data,  the  
type of data (linear or nonlinear), and the type 
of  data  set  (completely  unsorted,  partially  
sorted, etc.). The algorithms are implemented 
in   both   iterative   and   recursive   methods.   
ComplexityNotationDescription
ConstantO(1)Regardless of the data size, the algorithm takes a constant 
number of steps to perform the operation.
LinearO(n)The number of operations is linearly proportional (steps are a 
constant multiple of the data set size n).
QuadraticO(n
2
)The algorithm takes the order of n
2 
steps for performing the 
operation on the data set of size n.
CubicO(n
3
)The algorithm takes the order of n
3
 steps for performing the 
operation on a data set size of n.
ExponentialO(n
k
)
O(2
n
)
O(n!)
The algorithm has an order of exponential dependability for 
performing the operation on a data set of size n.
Logarithmic
O(log (n))
O(N*log (n))
The algorithm takes the order of log (n) steps (base of log is 
typically 2).
Ta b l e   16 . 2 . List of Algorithmic Complexities

16-10   SWEBOK
®
 GUIDE V4.0
Typically,  iterative  methods  are  better  than  
recursive methods for CPU performance and 
memory.  However,  recursion  provides  easy  
methods for solving specific problems, such as 
tree operations. If adequate computing power 
and   memory   are   available,   the   difference   
between  recursive  and  iterative  implementa-
tion methods is negligible. 
In  the case  of  applications  where  certain  
sorting  algorithms  work  best,  software  engi-
neers  should  learn  and  accommodate  any  
preconditions  and  complexities  (demand  on  
memory  and  computing  power)  involved  in  
using them.
3.8.  Searching Techniques [5*, C6]
Searching is a process of finding specific data 
items  or  records  in  a  set  of  data  items  or  a  
database. 
Search  algorithms  are  primarily  catego-
rized  into  sequential  search  (data  set  is  tra-
versed  sequentially  until  the  end  of  the  data  
set) and interval search (the search moves effi-
ciently  through  a  sorted  list,  balanced  tree,  
etc.), based on how data sets are organized.
Depending  on  the  type  of  the  data  item  
and  the  size  of  the  data  set,  various  search  
techniques  are  used  to  find  the  desired  data  
item.   Popular   search   algorithms   include   
linear,  binary,  jump,  interpolation,  exponen-
tial, Fibonacci, sub-list (search a linked list in 
another list), logarithmic, tree and hashing.
3.9.  Hashing [18*, C11.2]
Hashing  is  one  of  the  very  important  and  
popular  technique  in  which  data  of  arbitrary  
size  (key  values)  are  converted  into  values  
of  fixed  size  called  hash  values,  which  index  
into  a  hash  table  so  the  data  records  can  be  
located easily. The function used for that pur-
pose is called a hash function, and the values 
returned  are  called  hash  values,  hash  codes,  
digests, or hash keys.
Different properties of hash functions, such 
as uniformity, efficiency, universality, applica-
bility, deterministic, defined or variable range, 
data normalization, testing, and measurement, 
must   be   understood   and   considered   when   
designing or choosing a hash function.
Va r ious types of hash functions are designed 
for  different  types  of  key  values,  applica-
tions,   and   database   sizes.   Hash   function   
types  include  trivial  hash  function,  division  
method,  mid-square  method,  digit  folding  
method,    multiplicative    hashing,    double    
hashing, open and closed hashing, rehashing, 
extendible  hashing,  and  cryptographic  and  
noncryptographic hash functions.
Software engineers  are  expected  to  learn,  
implement  and  be  able  to  compare  different  
types of hashing algorithms, various collision 
resolution  techniques,  linear  probing,  qua-
dratic  probing,  separate  chaining,  and  open  
addressing.
4. Programming Fundamentals and 
Languages [4*, C6]
Computer  programs  are  sequential  steps  or  
instructions that work on provided inputs and 
generate desired or specific outputs. 
Software engineers must carefully consider 
various  aspects  before  selecting  a  program-
ming language to solve a specific problem.
4.1.  Programming Language Types [8*, C8.4.4]
Depending    on    the    hardware,    operating    
system,   and   application   various   types   of   
programming  languages  are  developed  and  
used. Basic types of programming languages 
include   microprogramming,   machine   lan-
guages,  assembly  programming  and  high-
level programming. 
Microprogramming is executed within the 
microcontroller  or  microprocessor  chips  to  
execute the assembly language instructions. 
Assembly language programs use the mne-
monic  specified  by  the  microcontroller  or  
microprocessor.    Typically,    the    microcon-
trollers  or  microprocessors  are  designed  to  
address specific applications (DSP processors, 
graphics chips, I/O controllers, mathematical 
coprocessors, generic processors, etc.). 
High-level  languages  enable  programs  to  
be written in instructions similar to English, 

COMPUTING FOUNDATIONS   16-11
which  makes  it  easy  for  the  developer  and  
maintainer  to  write  and  maintain  the  pro-
grams.  Various  types  of  high-level  program-
ming languages include the following: 
•    Functional programming languages.
•    Procedural programming languages. 
•    Object-oriented programming languages
•    Scripting languages.
•    Logic programming languages.
A programming language can support more 
than  one  programming  paradigms  Software  
engineers  need  to  study  multiple  program-
ming languages to choose the right one for a 
specific application.
Many programming languages, such as C, 
C++ and Java, use compilers to build execut-
ables, whereas other programming languages, 
such  as  JavaScript,  Ruby  and  Python,  use  
interpreters. 
4.2.  Programming Syntax, Semantics, Type 
Systems [8*, C8.4.4]
The  syntax  of  a  programming  language  is  its  
grammar  —  the  various  constructs  the  pro-
gramming language uses. A compiler or inter-
preter  checks  the  syntax  of  all  declarations,  
statements   (algorithmic   statements,   condi-
tional or logical statements, control statements, 
loops,   special   language-specific   statements,   
micros, etc.), and functions or procedures, and 
creates notifications of any errors.
Semantics  refers  to  the  meaning  or  inter-
pretation of the statement. The meaning could 
vary at runtime, depending on runtime values.
A type system assigns a type to a data item 
or to constructs of a program, such as variables, 
expressions  and  functions.  In  static  typing,  
the type is fixed; it is defined during program 
creation  and  checked  at  compilation  time.  
Languages  such  as  C,  C++  and  Java  support  
static typing. In dynamic typing, the type of a 
variable can change at runtime depending on 
the context and hence is checked at runtime. 
Dynamic  typing  languages  include  Python,  
Perl, PHP and Ruby. Dynamic typing is also 
called polymorphic typing.
Software  engineers  are  expected  to  know  
how  high-level  programming  languages  are  
translated   into   machine   languages,   to   be   
familiar  with  the  various  types  of  compilers,  
and to know the differences among compilers, 
interpreters,  cross-compilers,  assemblers  and  
cross-assemblers.    Software    engineers    are    
encouraged  to  learn  about  compiler  phases,  
including    preprocessing,    lexical    analysis,    
syntax analysis, intermediate code generation, 
optimization,  code  generator,  linkers,  loaders  
and debuggers. 
Tokens,   grammars,   syntax   trees,   parse   
trees and weights to various operators (prece-
dence) in arithmetic and logical equations are 
important to analyze and understand. 
4.3.  Subprograms and Coroutines [4*, C6.3]
Subprograms  or  functions  are  programs  or  
building  blocks  that  perform  specific  (part)  
functions  in  the  scope  of  a  complete  project.  
Subprograms  provide  for  breaking  the  larger  
program  into  smaller  modules.  The  modules  
are  typically  sections  of  code  that  are  used  
multiple times in multiple places. The subpro-
grams  reduce  memory  space,  improve  read-
ability  and  maintainability  of  the  program,  
and  execute  parts  of  the  program  with  dif-
ferent values at different places and times.
The  subprograms  have  an  entry  point  and  
typically  have  multiple  input  parameters  on  
which   the   subprogram   acts   and   produces   
output. The scope of input parameters is local 
to  the  subprogram.  Subprograms  that  return  
value  by  their  name  (which  can  be  used  as  a  
variable  in  a  statement)  are  called  functions, 
and  subprograms  designed  not  to  return  any  
value are called procedures.
By   default,   the   scope   of   subprogram   
parameters  is  dynamic  and  local  to  the  sub-
program.  However,  if  the  subprograms  have  
to remember their history or previous values, 
they have to be declared static or as specified 
in the chosen programming language.
Different   programming   languages   sup-
port   one   or   more   types   of   parameters’   
passing, including pass-by-value, pass-by-ref-
erence,   pass-by-name,   pass-by-result   and   

16-12   SWEBOK
®
 GUIDE V4.0
pass-by-result-value.     Software     engineers     
should  know  the  differences  among  these  
types and use them appropriately.
Many   high-end   languages   support   the   
nesting  of  subroutines  and  recursions,  where  a  
subroutine calls itself. Different types of recur-
sions include cyclic or direct recursion (subrou-
tine calls itself ) and acyclic or indirect recursion 
(subroutine A calls subroutine B, which in turn 
calls subroutine A). It is important to establish 
the exit criteria in recursive subprograms.
Software   engineers   are   encouraged   to   
understand, using case studies, how the sub-
program  return  address  and  parameters  are  
stored  in  memory  (runtime  stack),  how  they  
are used in the subprogram and for returning 
to  the  called  subprogram,  and  the  scope  of  
variables (global and local).
A  subprogram  with  multiple  entry  points,  
where  the  previous  exit  point  is  remembered  
for  resumption  at  a  later  point,  is  called  a  
Coroutine.   A   Coroutine   call   is   typically   
called a resume call. The first resume call enters 
the subroutine from the beginning, and sub-
sequent  resume  calls  enter  the  subroutine  at  
the point where it was exited last. 
High-end      languages      that      support      
Coroutines     include     C++20,     C#,     Java,     
JavaScript,  Kotlin,  Perl,  .NET  Framework,  
Python, Ruby and many assembly languages.
Software   engineers   are   encouraged   to   
understand specific applications where corou-
tines  are  useful  and  to  use  the  coroutines.  It  
is an interesting exercise to implement corou-
tines  in  C,  as  C  does  not  support  corou-
tines natively.
Figure 16.3 depicts the functioning or con-
trol flow of coroutines.
4.4.  Object-Oriented Programming [4*, C6.5] 
As  the  name  suggests,  object-oriented  pro-
gramming  languages  are  based  on  objects.  
The  objects  typically  have  both  data  and  
functions that operate on that data. The data 
of  an  object  is  typically  called  the  object’s  
attributes or properties, and the code or func-
tions  that  work  on  the  attributes  are  called  
operations  externally  (by  the  client  or  user)  
and  called  methods  internally  (referring  to  
how  the  operation  is  implemented  by  the  
developer). 
A  Class  is  a  programmer-defined  proto-
type that defines the attributes and methods. 
Objects   are   actual   instances   of   a   Class.   
There  could  be  multiple  Objects  of  a  Class  
with  varied  characteristics.  For  example,  a  
Class  can  be  defined  by  the  characteristics  
and  operations  of  a  vehicle,  whereas  objects  
are  instances  of  the  class  vehicle  such  as  car,  
bus or truck.
The objects interact with one another using 
the methods or operations. 
Important   characteristics   of   object-ori-
ented  programming  (OOP)  are  Abstraction,  
Encapsulation, Inheritance and Polymorphism. 
Abstraction is a property that exposes only 
required  or  relevant  information  and  func-
tionality  to  the  user,  hiding  the  details  and  
nonessentials.  Thus,  the  implementation  is  
hidden from the user of the superclass.
One of the key benefits of encapsulation is 
the ability to hide or protect data from unau-
thorized  users.  The  software  engineer  can  
give different levels of protection to data and 
methods  by  declaring  them  private  (local  to  
class)  or  public  (available  to  other  classes).  
This also protects data from corruption, either 
intentional or accidental.
Subroutine S1Subroutine S2Subroutine S3
Resume S1
Resume S3
Resume S3
Resume S2Resume S2
Resume S1
Figure 16.3. Example of Coroutine

COMPUTING FOUNDATIONS   16-13
Inheritance   is   an   important   feature   of   
OOP,   where   a   subclass   or   derived   class   
inherits the properties of a superclass or base 
class.   Primary   inheritance   modes   include   
public, protected and private modes.
Polymorphism  is  another  key  feature  of  
OOP.  Polymorphism  is  a  provision  of  pro-
viding  a  single  interface  to  entities  of  dif-
ferent  types.  For  example,  shape  could  be  
a  base  class  with  draw  as  a  method,  and  
objects  could  be  a  circle,  triangle  or  rect-
angle. The implementation of method draw, 
though  the  name  is  the  same,  differs  for  a  
circle, triangle and rectangle. Polymorphism 
has two types:
• Static  or  compile-time  polymorphism:  The 
methods   (functions)   or   operators   are   
overloaded  and  resolved  during  compile  
time.   Example:   The   methods,   though   
they  have  the  same  name,  will  have  dif-
ferent types or numbers of parameters.
• Dynamic  or  runtime  polymorphism:  The 
overloaded   method   to   be   executed   is   
resolved   at   runtime.   Example:   When   
both base class and derived class have the 
same  method,  the  base  class  method  is  
said to be overridden.
Popular OOP languages include C++, C#, 
Cobol 2002, Java, Python, Lisp, Perl, Object 
Pascal, Ruby and Smalltalk.
It’s   important   to   recognize   that   using   
OOP requires a different mindset than using 
traditional,   procedural,   or   structured   pro-
gramming does.
4.5.  Distributed Programming and Parallel 
Programming [4*, C6.6]
In  a  distributed  computer  system,  multiple  
parts of the software are run on multiple com-
puters, connected through computer networks, 
to achieve a common goal. Writing such pro-
grams is called distributed programming.
Parallel  programming  is  a  type  of  com-
puting in which different parts of the program 
are run in parallel to achieve the same objec-
tive or goal. Table 16.3 compares distributed 
and parallel programming. High Performance 
Computing (HPC) aims to speed-up the exe-
cution of software, both distributed program-
ming  and  parallel  programming  are  ways  to  
do  this  and  is  increasingly  used  together  in  
hybrid software.
4.6.  Debugging [6*, C2.2.2]
Programs,   when   written,   are   expected   to   
function  properly  and  generate  the  expected  
output.   However,   programmers   often   face   
three types of errors — syntax errors, runtime 
errors, and logical errors — at different stages 
of software development. 
Syntax errors are deviations from the stan-
dard  format  specified  by  programming  lan-
guages.   These   are   explicitly   identified   by   
compilers and are easy to fix. 
Runtime  errors  surface  when  a  program  
runs into an unexpected condition or situation 
such as dividing by zero, memory overflow, or 
addressing a wrong or unauthorized memory 
location or device, or when a program tries to 
perform an illegitimate or unauthorized oper-
ation or tries to access a library, for example. 
The  programs  must  be  thoroughly  tested  for  
various types of inputs (valid data sets, invalid 
data  sets  and  boundary  value  data  sets)  and  
conditions to identify these errors. Once iden-
tified, runtime errors are easy to fix. 
Logical  errors  are  slipups  in  implementing  
the logic to achieve the desired output. These 
errors must be traced and resolved with various 
data  for  each  functionality.  Several  sophisti-
cated high-end debuggers help trace each vari-
able  or  data  item  and  support  setting  various  
types of break points.
4.7.  Standards and Guidelines [3*, C28.5, 
                                                      C31.5]
As   the   computing   system   or   application   
becomes bigger and complex, more program-
mers are involved. Their individual program-
ming  styles  affect  the  project  schedules  and  
make system integration difficult, so systems 
become  defect-prone,  and  maintenance  and  
enhancement become challenging. 

16-14   SWEBOK
®
 GUIDE V4.0
An    estimated    82%    of    vulnerabilities    
are   caused   by   clashes   between   program-
ming styles.
§
 
Hence,  quality-conscious  companies  often  
have defined tools, standards and guidelines, 
which  set  rules  and  recommendations  for  
their programmers and testers to follow. 
When    software    teams    follow    appro-
priate  coding  standards,  they  create  read-
able,   cleaner,   portable,   reusable,   modular,   
§ https://www.ptsecurity.com/ww-en/analytics/web-vulnerabilities-2020/
easily  maintainable,  less  defect-prone  soft-
ware   code,   and   project   schedules   become   
more predictable. The following practices can 
help organizations implement such standards 
successfully:
•    Carefully  choose  the  coding  standards  
and guidelines that suit the application or 
system being developed.
•    Consider    open    standards    created    by    
ParametersDistributed ProgrammingParallel Programming
FunctionalityA task is shared and executed by mul-
tiple computers that are networked.
Two or more processors on a computer 
share and execute the task in parallel.
ComputersMultiple computers in different loca-
tions but networked.
Two computer with one or more 
processors or cores.
MemoryEach computer has its own memory.Computers can have shared or 
distributed memory.
CommunicationComputers communicate 
through networks.
Processes communicate through a 
bus or inter-process communication 
(IPC) methods.
BenefitsFailure of one computer does not 
affect the functioning of the task, as 
it is transferred to another computer.
Provides scalability and reliability for 
end users.
As multiple processes run in parallel, 
generally the performance increases. 
Failure of one processor does not 
affect the performance of other 
processors or cores
DisadvantagesHaving multiple systems could 
become expensive; the cost must be 
weighed against customers’ need for 
application uptime.
Network delays could affect the 
overall functioning of the task.
Designing an efficient distributed 
computing system is relatively difficult.
Using multiple processors or cores 
could be expensive.
Dependency of one process 
on another process could 
introduce latency.
Example  
Applications
Telephone and cellular networks, 
internet, World Wide Web networks, 
distributed database management 
systems, network file systems, grid 
computing, cloud computing.
2D and 3D simulations and rendering 
in computer graphics, scientific 
computing.
Example  
Programming  
Languages, 
libraries 
engines, 
framaworks 
Golang, Elixir, Scala, Fortran,  
C and C++.
Apache Hadoop, Apache Spark, 
Apache Flink, Apache Beam, CUDA, 
OpenCL, OpenHMPP, MPP, 
OpenMP for C, C++ and Fortran.
Ta b l e   16 . 3 . Comparison of Distributed and Parallel Programming

COMPUTING FOUNDATIONS   16-15
community participation, such as Software 
Engineering   Institute   (SEI)   Computer   
Emergency  Response  Team  (CERT),  as  
well as closed standards created by working 
groups such as the Motor Industry Software 
Reliability Association (MISRA).
•    Educate  programmers  to  follow  adopted  
standards and guidelines. 
•    Use tools and periodic reviews to ensure 
adopted     standards     and     guidelines     
are followed.
•    Review  and  revise  standards  and  guide-
lines  from  time  to  time,  learning  from  
project execution.
SC  22  is  a  subcommittee  of  the  Joint  
Technical  Committee  ISO/IEC  JTC  1  of  the  
International Organization for Standardization 
(ISO)  and  the  International  Electrotechnical  
Commission  (IEC)  for  defining  standards  for  
programming  languages,  their  environments  
and   system   software   interfaces   (ISO/IEC 
JTC 1/SC 22).  Software engineers are recom-
mended to refer these standards as well.
5. Operating Systems [19*]
An  operating  system  (OS)  is  software  that  
manages  the  computer’s  hardware  and  pro-
vides  a  platform  for  software  applications.  
Software   engineers   need   a   good   general   
understanding of OSs and OS objectives, ser-
vices, and functions.
Different types of OSs have been designed 
over time to support various types of systems 
or  applications,  including  batch  processing,  
multiprogramming,       time-sharing,       and       
dual-mode  operation  —  for  protecting  I/O,  
memory, CPU, kernels and micro-kernels.
To  choose  an  appropriate  OS,  software  
engineers  have  to  analyze  different  types  of  
operating  systems,  such  as  single-user,  sin-
gle-tasking,    multiuser,    multitasking    and    
multi-threading OSs; real-time OS (RTOS); 
network  OS;  and  distributed  OS.  For  small  
systems,  an  operating  system  may  not  be  
required.  It  is  important  to  study  examples  
of  each  type  and  compare  their  benefits  and  
limitations. 
Software   engineers   need   to   understand   
operating   systems’   basic   structure,   system   
architecture  types,  design  approaches,  the  
architecture  of  distributed  OS  and  issues  in  
distributed OS.
An  operating  system  typically  has  four  
major  components:  processor  management,  
memory  management,  device  management  
and information management. 
5.1.  Processor Management [19*, C2, C8]
Software   engineers   must   understand   the   
concepts  of  processor,  process  and  address  
space.  They  must  understand  booting,  pro-
cesses, cores, threads, user and kernel threads, 
fork and exec, synchronization, and hardware 
support for locking. They should compare and 
contrast  various  CPU  scheduling  concepts,  
scheduling   algorithms,   algorithm   evalua-
tions, multiple processor scheduling and real-
time  scheduling,  concurrent  programming,  
deadlocks,  critical  regions,  conditional  crit-
ical regions, and monitors.
Communication    among    different    pro-
cesses   is   important   in   multitasking,   mul-
tiuser OSs. A software engineer must have a 
deep understanding of inter-process commu-
nication (IPC), and types of IPCs, including 
messages, pipes, shared memory, semaphores, 
modularization and process synchronization. 
Various  types  of  locks  are  used  to  ensure  
proper  synchronization  of  data  among  pro-
cesses,  including  semaphores,  binary  sema-
phores, counting semaphores and mutex locks. 
Deep  understanding  of  common  challenges  
of  IPCs,  deadlocks,  deadlock  scenarios,  and  
deadlock characterization; prevention, avoid-
ance,  detection  and  recovery  of  deadlocks;  
and  precedence  graphs  is  critical  and  to  be  
internalized with the help of case studies.
Software  engineers  are  required  to  study,  
with  examples,  concurrent  languages,  pro-
cesses  and  scheduling,  job  and  process  con-
cepts,   and   various   types   of   scheduling:   
CPU-I/O interleaving, non-preemption, con-
text  switching,  and  scheduling  algorithms  
(first   come,   first   served   (FCFS),   shortest   
job  first  (SJF),  shortest  remaining  time  first  

16-16   SWEBOK
®
 GUIDE V4.0
(SRTF), priority scheduling, round robin and 
combined schemes).
5.2.  Memory Management [19*, C3]
A software engineer needs a very good under-
standing  of  how  memory  is  managed  in  the  
system  and  of  the  different  types  of  memory  
and  relevant  concepts  —  physical  memory,  
virtual memory, secondary memory, memory 
hierarchy, linking and memory allocation.
Engineers  must  understand  memory  frag-
mentation    (both    external    fragmentation,    
internal fragmentation), and various memory 
management    concepts,    including    units,    
paging,   page   tables,   segmentation,   paged   
segmentation,  virtual  memory  management,  
demand paging, page replacement, thrashing 
and swapping.
Memory  is  allocated  to  processes  in  dif-
ferent  ways  —  for  example,  through  contig-
uous   allocation,   noncontiguous   allocation,   
dynamic partitioned memory allocation, stat-
ic-swapping and overlays.
An   understanding   of   logical   addresses,   
partitions,   static   versus   dynamic   memory   
allocation,    free    space    management,    and    
defragmentation  of  memory  blocks  is  also  
important. 
As the physical memory available is always 
limited,  various  memory  page  replacement  
strategies are designed and implemented. These 
strategies   include   first-in-first-out   (FIFO),   
not-recently-used  (NRU),  least  recently  used  
(LRU), most recently used (MRU), least fre-
quently  used  (LFU),  most  frequently  used  
(MFU),  longest  distance  first  (LDF),  second  
chance, and aging among others.
5.3.  Device Management [19*, C5]
A  software  engineer  must  have  good  knowl-
edge of different types of I/O devices — mem-
ory-mapped  and  I/O-mapped  devices,  block  
and  character  devices,  and  buffering  devices.  
Engineers   should   compare   and   contrast   
polled,  interrupt-driven  and  direct  memory  
access  (DMA)  I/O  devices,  and  blocking  
versus non-blocking I/O devices. 
Device   drivers   are   software   programs   
that  provide  an  interface  between  hardware  
and  applications.  Software  engineers  should  
understand  device  drivers,  the  various  types  
of  device  drivers,  device  driver  tables,  device  
driver  functions,  and  interfaces  for  various  
types  of  hardware  devices,  as  well  as  hard-
ware  and  software  interrupts  and  interfaces  
by interrupts and polling. 
Software engineers should also understand 
that issues with caching, scheduling, spooling 
and performance can arise for shared devices 
in  multiuser,  multitasking  OSs  and  device  a  
mechanism for resolving them.
5.4.  Information Management [19*, C4]
Software  engineers  need  to  understand  the  
following: 
•    The  concept  of  a  process,  a  system  pro-
grammer’s view of processes, an operating 
system’s view of processes, and operating 
system services for process management
•    File system management, storage manage-
ment,  file  attributes,  directory  structure,  
file  system  structure,  mass  storage  struc-
ture, I/O systems, protection and security 
•    User and operating system views of the file 
system and various types of file systems — 
simple  file  system,  symbolic  file  system,  
logical file system and physical file system
Engineers  should  be  familiar  with  various  
operations including access control lists (ACLs), 
access matrix, access control, access control ver-
ification,  capabilities  allocation  strategy,  I/O  
initiators, device strategy, device handlers, disk 
scheduling,  disk  space  management,  existence  
and  concurrency  control,  schemes  and  com-
bined  schemes,  authentication  schemes,  direc-
tory  namespace,  hierarchies,  directed  acyclic  
graph (DAGs), hard and soft links.
5.5.  Network Management [4*, C4.1]
Network   management   is   the   process   of   
administering and managing various types of 
networks. This content area includes network 

COMPUTING FOUNDATIONS   16-17
management   concepts,   distributed   objects,   
distributed  file  systems,  and  network  archi-
tecture, design, issues and resolutions.
A  network  manager  will  need  detailed  
knowledge  of  physical  and  logical  time,  as  
well  as  internal  and  external  synchroniza-
tion  protocols  in  network  management  such  
as Cristian’s algorithm, Berkeley’s algorithm, 
the  Network  Time  Protocol,  Lamport’s  log-
ical  clock,  Vector  clocks,  Casual  ordering  of  
messages, and global state.
Other  important  topics  include  distrib-
uted   computation,   termination   detection,   
distributed  mutual  exclusion  and  election,  
simple  and  multicast-based  mutual  exclusion  
algorithms;  Centralized,  Ring  based,  Ricart  
Agrawala’s  algorithm,  Maekawa’s  algorithm,  
Election  algorithms,  Bully’s  algorithm  and  
multicast communication.
In   addition,   software   engineers   should   
understand important principles include hard-
ware  security,  external  security,  operational  
security,  password  protection,  access  control,  
security kernels, and the layered approach.
6. Database Management
A database is a collection of related data ele-
ments, collected specifically for use by one or 
more applications and stored in an organized 
format for easy and quick access, using one or 
more  key  values.  The  data  items  or  elements  
are  stored  in  one  or  more  databases  or  files,  
and  the  relationship  among  them  is  estab-
lished using a database schema.
Basic operations performed on the database 
include creating the database and its elements 
(table,  index,  views,  functions,  procedures,  
etc.),  deleting  or  dropping  items  from  the  
database,  modifying  contents  and  structure  
of the database, and data retrieval, comment, 
and rename actions.
Different  types  of  databases  include  rela-
tional  databases,  not  only  structured  query  
language (NoSQL) databases, columnar data-
bases,   object-oriented   databases,   key-value   
databases,  document  databases,  hierarchical  
databases,  graph  databases,  time  series  data-
bases, and network databases. Understanding 
what type of database works best for specific 
applications   and   analyzing   the   definition,   
structure, specific pros and cons of each type 
of  database;  what  along  with  examples  helps  
software  engineers  choose  the  right  type  of  
database for a given application. 
When selecting a database, software engi-
neer  should  evaluate  data  models,  storage  
models, types of databases, key values, graphs, 
column family, volume of data, consistent data 
access time, and the number of users or appli-
cations accessing the database (traffic), etc.
The learners and users of the database system 
need  to  create  two  roles  (database  user  and  
database  architect),  review  several  case  studies  
of  increasing  complexity,  create  multiple  data-
bases, and analyze the information. This process 
significantly helps one to understand and inter-
nalize the database design and management.
6.1.  Schema [22*, C2.1.4]
A database schema is a structure or record of 
data  items,  defined  in  one  or  more  database  
tables,  and  the  relationships  between  them.  
The  schema  may  also  contain  formulae  to  
check the integrity of data items, relationships, 
indexes, functions or procedures and views. 
While a physical schema explains how the 
database  is  designed  at  physical  level  (files),  
the  logical  schema  describes  how  different  
data  items  are  defined  in  one  or  more  tables  
and interconnected.
Different  types  of  schemata  used  in  the  
industry include star, snowflake and fact con-
stellation schemata. Different types of keys used 
in schemata include Primary Key, Secondary / 
Alternate  Key,  Foreign  Key,  Composite  Key,  
Surrogate Key and Candidate Key. 
Parameters  that  influence  the  definition  
and use of schemata include overlap preserva-
tion,  extended  overlap  preservation,  normal-
ization and minimality.
6.2.  Data Models and Storage Models 
 [22*, C2.3]
A  data  model  specifies  the  logical  aspects  of  
data  structure  in  a  data  store,  and  a  storage  

16-18   SWEBOK
®
 GUIDE V4.0
model  specifies  the  physical  aspects  of  data  
structure  in  a  data  store.  It  is  difficult  to  
achieve both data consistency and high avail-
ability in a database.
The two primary data models used to dis-
tinguish databases are the following:
•    The ACID (atomicity, consistency, isola-
tion, durability) model provides for high 
data consistency. ACID-compliant data-
bases  are  ideal  for  a  finance-intensive  
application.
•    The BASE (basically available, soft state, 
eventual   consistency)   model   provides   
flexible  methods  to  process  data,  which  
suits NoSQL database types.
Types   of   storage   models   include   the   
following:
i. DAS   (direct   access   storage):   Storage   
devices  are  physically  or  directly  con-
nected    to    the    computer    that    pro-
cesses the data.
ii. NAS  (network  access  storage):  Data  is  
stored in a network and accessed by mul-
tiple computers or applications.
iii.   SAN (storage area network): Data is stored 
in multiple servers and efficiently provided 
to users through a computer network. 
6.3.  Database Management Systems  [22*, C1.3]
Database  management  systems  (DBMSs)  are  
software  systems  that  provide  the  necessary  
tools for maintaining data optimally, retrieving 
stored  information  effectively,  protecting  and  
securing stored data, and managing access for 
users of different levels of authority.
Typical DBMSs include:
• A  database  engine:  This  is  the  core  of  a  
DBMS.  The  database  engine  manages  
efficient  storing  and  retrieving  of  data.  
Users with privileges can access the data-
base engine.
• A  database  manager:  This  program  or  set  
of  programs  performs  all  DBMS  func-
tionality in a database (creating, purging, 
backing    up,    retrieving,    maintaining,    
cloning  and  deleting  data).  It  is  also  
responsible  for  maintaining  the  DBMS  
with patches and updates.
• A   runtime   database   manager   (RDM):   
The  RDM  checks  for  user  authentica-
tion  and  privileges  before  any  operation  
is  performed,  provides  access  to  a  con-
text-based  database,  provides  concurrent  
access  to  the  database  by  multiple  users,  
and ensures data integrity.
• Database languages: These help in storing, 
retrieving, modifying and retrieving data, 
controlling user access (privileges), speci-
fying schemata and views, and performing 
various operations. Popular database lan-
guages  include  data  definition  language  
(DDL), database access language (DAL), 
data   manipulation   language   (DML),   
Transaction  Control  Language  (TCL),    
and data control languages (DCL), 
• A query processor: This basic and key com-
ponent  of  DBMS  provides  an  effective,  
rich  and  English-like  interface  for  users  
to  access  the  database  and  perform  var-
ious functions or operations.
• Reporting: Reporting applies specified fil-
ters,  extracts  requested  data  and  records  
from  one  or  more  database  tables,  and  
presents information as specified.
Several   free   and   open-source   database   
management systems are available. 
6.4.  Relational Database Management Systems 
and Normalization [22*, C4]
Conventional   file   system-based   databases   
suffered  from  data  redundancy,  data  incon-
sistency,   data   access   challenges,   unautho-
rized access, lack of concurrent access, among 
other issues. 
A  relational  database  management  system  
(RDBMS) stores data in tables and, unlike in 
a DBMS, its data tables relate to one another, 
multiple  data  items  can  be  accessed  simulta-
neously,  a  large  amount  of  data  is  handled,  
multiple  users  can  access  data  concurrently,  
data  redundancy  is  significantly  reduced,  and  

COMPUTING FOUNDATIONS   16-19
multiple levels of data security are supported.
Computer  science  engineers  must  under-
stand the difference between the various types 
of RDBMS, such as Objective RDBMS, Object 
Oriented RDBMS, be familiar with examples, 
and know the applications they suit best.
Database  normalization  is  the  process  of  
organizing  data  in  a  database  and  removing  
data redundancy and data inconsistency from 
the   tables.   Normalization   might   increase   
the  number  of  tables  and  increase  the  query  
time. If this occurs, then — depending on the 
application  and  the  requirement  —  de-nor-
malization is applied, where data redundancy 
is added for quicker data access. 
Different types of database normalizations 
are the following:
i. First normal form (1 NF): Removes dupli-
cation   or   redundancy.   Each   table   cell   
has  a  single  value  (creates  more  entries  
and  tables).  Each  row  has  unique  values.  
Related data is identified with a unique key.
ii. Second  normal  form  (2  NF):  The  table  
should be in 1 NF; no partial dependency 
(creates separate tables with records refer-
enced by multiple records or tables).
iii.   Third  normal  form  (3  NF):  The  table  
should be in 2 NF. Transitive dependen-
cies are removed.
iv.    Boyce-Codd   normal   form   (BCNF/3.5   
NF): The table should be in 3 NF, and X 
should be the super-key for any (X->Y).
v. Fourth  normal  form  (4  NF):  The  table  
should be in 3.5 NF and should not have 
a multivalued dependency.
vi. Fifth  normal  form  (5  NF):  The  table  
should  be  in  4  NF  and  cannot  be  split  
into any more tables without losing data.
vii. Sixth  normal  form  or  domain/key  normal  
form (6 NF/DKNF): The table should be in 
5 NF, and every join dependency is trivial.
Most  databases  are  typically  normalized  
until 3 NF or BCNF. An alternative normal 
form, DKNF, is defined where insertion and 
deletion of anomalies is avoided (see [13]). 
Database     engineers     are     encouraged     
to   understand   normalization   forms   with   
examples and case studies and to understand 
the challenges one would face if the database 
were  not  normalized.  Although  normaliza-
tion is essential and provides various benefits, 
it also increases the number of tables and pro-
cessing time. 
6.5.  Structured Query Language  
 [22*, C6, C7, C8]
Structured  query  language  (SQL)  is  a  stan-
dard  and  popular  database  language  for  cre-
ating,  updating,  and  deleting  databases  and  
for  retrieving  information  from  databases.  
SQL  is  an  inevitable  part  of  most  database  
management systems. 
Typical  SQL  syntax  has  several  language  
constructs   or   elements,   including   clauses,   
expressions, predicates, queries and statements. 
All operations on a database, including cre-
ating,  updating,  deleting  and  viewing  tables;  
performing different normalizations; purging 
data;  and  searching  through  the  database  
based on various combinations of parameters 
or filters, can be performed using SQL.
Most   databases   support   SQL   (except   
NoSQL databases), and the SQL syntax and 
library  of  functions  supported  vary  across  
database  providers  (much  like  programming  
languages — though different languages sup-
port similar features, the syntaxes vary). 
Database  engineers  also  have  to  decide  
whether    to    use    static/embedded    SQL,    
dynamic  SQL  or  a  combination  of  the  two,  
after weighing the pros and cons of each option 
for  the  particular  application.  They  should  
also know the differences between simple and 
complex views and use them appropriately.
SQL  is  standardized  and  adopted  by  the  
American  National  Standards  Institute  (ANSI)  
and ISO. The standards are revised from time to 
time; the first SQL standard was SQL-86, issued 
in 1986, and the most recent is SQL:2019. 
6.6.  Data Mining and Data Warehousing 
 [22*, C34]
Databases  are  designed  to  store  transactions  
and retrieve them efficiently. 

16-20   SWEBOK
®
 GUIDE V4.0
Data warehousing extracts data from mul-
tiple  databases  efficiently  and  stores  it  in  a  
common database so data mining can be per-
formed effectively on the compiled data. Data 
warehouses  are  typically  huge,  as  they  store  
historical data records.
Data  mining  extracts  requested  informa-
tion  from  the  data  warehouse,  applying  var-
ious   filters   and   conditions.   Data   mining   
applies   pattern   recognition   algorithms   to   
huge data sets to generate required reports. 
The  different  types  of  warehouses  include  
enterprise data warehouse (EDW), operational 
data store (ODS), and data mart (DM).
Many efficient tools are available to create 
data warehouses and mine data from them.
Database  engineers  must  know  different 
data  mining  techniques,  including  associa-
tion, clustering, classification, sequential pat-
terns and prediction, and know how to apply 
them for various uses and industries, such as 
health  care,  fraud  detection,  customer  rela-
tionship  management,  finance  and  banking,  
anomaly  detection,  prediction,  neural  net-
works, statistics, and data visualization.
6.7.  Database Backup and Recovery [22*, C22]
Database  systems  are  prone  to  failures,  and  
data can be corrupted. It is crucial to prevent 
data corruption and — if it does occur — to 
recognize it immediately and recover the data.
Updating   the   database   for   transactions   
must  be  carried  out  carefully  (with  commits  
at specific checkpoints), and must incorporate 
techniques such as undoing, deferred updates, 
immediate updates, caching or buffering, and 
shadow paging. 
Databases   must   be   backed   up   periodi-
cally to ensure data safety. Backup techniques 
include  Full  database  backup,  Differential  
backup and Transaction log backup. 
7. Computer Networks and 
Communications [4*, C4.1], [24*, C1]
A computer network is a group of devices that 
are  connected  for  sharing  information.  The  
connected  devices  (nodes  on  the  network)  
can be located near one another, on the same 
premises,  or  somewhere  else.  Networking  is  
required  for  certain  benefits,  including  cer-
tain   modes   of   communication   and   infor-
mation  sharing;  the  ability  to  share  devices  
such  as  printers,  routers  and  video  cameras;  
global information and data storing; security 
and  policy  enforcement;  remote  monitoring;  
shared business models; and web browsing. 
As  we  are  in  the  internet  era,  computer  net-
working is a critical element in computing, and 
the practitioners of computer science engineering 
have  to  study  computer  networks  and  commu-
nication  concepts,  including  examples  and  case  
studies.  Many  computing  paradigms  (distrib-
uted  computing,  grid  computing,  cloud  com-
puting, etc.) are based on networking principles. 
It  is  important  for  software  engineers  to  
understand the following: 
•    Different types of computer networks.
•    Layered architectures of networks.
•    Open systems interconnect (OSI) layers 
•    Encapsulation and decapsulation.
•    Application layer protocols.
•    Design  techniques  for  reliable  and  effi-
cient networking.
•    Internet and packet delivery.
•    Wireless and mobile networks.
•    Security and vulnerabilities.
7.1.  Types of Computer Networks 
 [4*, C4.1], [24*, C1.2.1]
Different  types  of  computer  networks  are  
designed and used based on the need, such as 
the following:
1. Personal     area     network     (PAN)     /     
home network.
2. Local area network (LAN).
3. Wireless local area network (WLAN).
4. Wide area network (WAN).
5. Campus area network (CAN).
6. Metropolitan area network (MAN).
7.   Storage area network (SAN).
8. System-area network (SAN).
9. Enterprise private network (EPN).
10.  Virtual private network (VPN).

COMPUTING FOUNDATIONS   16-21
It  is  important  to  understand  each  of  the  
above network type as well as examples, ben-
efits, limitations and available solutions to cir-
cumvent challenges.
7.2.  Layered Architectures of Networks 
 [24*, C1.5]
A  communication  system  includes  hardware  
and  software,  and  these  components  have  
become  complex  to  meet  complicated  use  
scenarios  and  user  demands.  To  support  the  
implementation and maintenance of such sys-
tems, ISO has developed a layered approach, 
where every layer has specific functionality for 
processing  data  and  transferring  it  from  one  
node to another.
Each layer is independent in its function-
ality  and  provides  services  from  the  lower  
layer  to  the  upper  layer  without  providing  
details of how each layer’s service is imple-
mented. Each layer (“n”) on a machine com-
municates with the same layer (“n”) on the 
peer machine. Rules used in a conversation 
are called layer-n protocol (see Figure 16.4).
The basic elements of the layered approach 
are service, protocol and interface. 
• Service: The set of actions a layer provides 
to the adjacent higher layer is the service.
• Protocol:  The  set  of  rules  a  layer  uses  
to  exchange  information  with  the  peer  
entity is called the protocol. The rules are 
primarily for managing both the contents 
and order of the messages used.
• Interface:    The    interface    provides    a    
medium   for   transferring   the   message   
from one layer to another layer.
Software  engineers  are  expected  to  under-
stand  the  essential  functionalities  required,  
various modes in which the data or information 
is  communicated  from  one  layer  to  the  other,  
and  data  packet  formation  and  interpretation  
at peer levels. A useful exercise is to take exam-
ples of different protocols and analyze them.
7.3.  Open Systems Interconnection Model 
 [24*, C1.5]
The Open   Systems   Interconnection   (OSI)   
Model  was  defined  by  the  ISO.  It  serves  as  
a  reference  model  for  information  exchange  
between applications on two systems or com-
puters through a physical medium. 
  
 
Layer 5 (Application Layer)
Layer 5 (Application Layer) 
Layer 4
Layer 4
Layer 3
Layer 3
Layer 2
Layer 2
Layer 1 (Physical Layer)
Layer 1 (Physical Layer)
Layer 5 Protocol
Layer 4 Protocol
Layer 3 Protocol
Layer 2 Protocol
Layer 1 Protocol
Figure 16.4. Pictorial Representation of Layered Networking

16-22   SWEBOK
®
 GUIDE V4.0
OSI  proposes  seven  (7)  layers,  and  each 
layer  is  assigned  a  specific  task.  Each  layer  
independently  processes  the  data  it  receives  
from the upper or lower layer and passes it to 
the lower or upper layer, as appropriate.
Engineers   must   understand   each   OSI   
layer,  its  functionality  protocol,  the  input  
and  output  of  each  layer  in  each  direction  
(from  lower  layer  to  upper  layer  and  vice  
versa).  Engineers  should  analyze  whether  
all  seven  layers  are  required  for  all  proto-
cols  and  what  is  necessary  to  optimize  for  
performance.
1. Physical Layer (Layer 1).
2. Data Link Layer (Layer 2).
3. Network Layer (Layer 3).
4. Transport Layer (Layer 4).
5. Session Layer (Layer 5).
6. Presentation Layer (Layer 6).
7.   Application Layer (Layer 7).
Engineers must understand the nuances of 
each layer, with examples. 
7.4.  Encapsulation and Decapsulation 
 [24*, C1.5.2]
Each  layer,  while  sending  data  from  the  
upper   layer   to   the   lower   layer,   inserts   
additional  information  at  the  beginning  
(header)  and  optionally  at  the  end  of  the  
data  packet  received  from  the  upper  layer,  
treating the packet received from the upper 
layer  as  data.  This  is  encapsulation.  The  
protocol  data  unit  (PDU),  which  is  the  
data packet containing additional informa-
tion from all layers, is sent to the receiving 
system.  At  the  receiving  end,  each  layer  
extracts its header from the PDU, deciphers 
the information to treat the data appropri-
ately, and sends the remaining PDU to the 
upper layer. 
Learning  about  cross-layer  optimization,  
the principles to which it must adhere, and its 
applications  is  important.  Engineers  should  
analyze  the  PDU  structures  of  each  layer  of  
OSI, the Internet protocol suite and the asyn-
chronous transfer mode (ATM).
7.5.  Application Layer Protocols [24*, C2]
The application layer, being the top most layer, 
provides services and interfaces to interact with 
users’ application. There are two types of appli-
cation layers in the OSI model: common appli-
cation  service  element  (CASE)  and  specific  
application  service  element  (SASE).  Example  
applications include file transfer (FTP, TFTP, 
NFS),   remote   login   (Telnet,   Zoho   Assist,   
Anydesk,  TeamViewer,  etc),  e-mail  (SMTP)  
networking support (DNS), network manage-
ment (SNMP, DHCP), devices (LPD), etc. 
Software  engineers  practicing  in  a  net-
working  domain  need  to  understand  CASE  
and   SASE   application   services,   including   
example applications in each category.
7.6.  Design Techniques for Reliable and Efficient 
Network [24*, C1.5]
To day ’s  information  technology-based  busi-
nesses  need  around-the-clock,  reliable,  effi-
cient  and  scalable  networks  and  high-speed  
internet  availability.  Catering  to  varied  busi-
ness  needs,  the  networks  and  their  manage-
ment has become complex as well. 
It  is  critical  to  identify  network  require-
ments (both business goals and technical solu-
tions) along with a road map (scalability). The 
fundamental  design  goals  should  include  reli-
ability, security, availability and manageability. 
Engineers should expect threats and intrusions 
at  multiple  levels  and  design  security  at  mul-
tiple levels. Systems must be set up to monitor 
the networks for both proper functioning and 
malfunctioning; identify faults, vulnerabilities 
and hacks quickly; and fix them. 
Engineers  must understand  and  learn  the  
nuances  of  designing  a  network  while  using  
appropriate firewalls, LAN/VLANs, subnets, 
quality  of  service  (QoS),  Demilitarized  Zone  
(DMZ),  Spanning  Tree  (especially  for  hier-
archical  network),  port  or  network  interface  
controller  (NIC)  channel,  security  (both  poll  
security and physical security), wireless access 
points, and wireless access controllers.
Even  when  the  design  and  implementation  
are  well  planned  and  executed,  one  has  to  be  

COMPUTING FOUNDATIONS   16-23
constantly vigilant for attacks and continuously 
upgrade to better systems, devices and tools.
7.7.  Internet Protocol Suite [24*, C3]
Data is transmitted in packets from one com-
puter to another, either in the same network 
or  in  a  different  one.  The  Internet  Protocol  
suite,  or  TCP/IP,  defines  data  communi-
cation   between   two   computers   connected   
via  the  internet.  The  top  three  layers  of  the  
OSI  model  (Application,  Presentation  and  
Session  layers)  are  merged  into  the  applica-
tion  layer,  and  the  network  layer  is  revised  
specifically for internet functioning. Internet 
Protocol is the fulcrum of today’s internet or 
network layer. 
Multiple  variations  of  Internet  Protocols  
are designed and used for different purposes. 
The protocols include TCP/IP (Transmission 
Control Protocol/Internet Protocol), UDP/IP 
(User Datagram protocol / Internet Protocol), 
SMTP (Simple Mail Transfer Protocol), PPP 
(Point to Point Protocol), FTP File Transfer 
Protocol,    SFTP    (Secure    FTP),    HTTP    
(Hyper   Text   Transfer   Protocol),   HTTPS   
(HTTP Secure), Telnet (Terminal Network), 
PoP3  (Post  office  Protocol  3),  VOIP  (Voice  
over  Internet  Protocol),  SLIP  (Serial  Line  
Internet  Protocol).  It  is  important  to  know  
the differences between these along with use 
cases (applications where each type is used or 
where it works best). 
Mobile  Internet  Protocol  is  a  communi-
cations  protocol  that  conforms  to  an  IETF  
(Internet  Engineering  Task  Force)  standard  
and allows users to move their mobile devices 
(laptops, mobile phones, etc.) seamlessly from 
one  network  to  the  other  without  changing  
the IP address.
Internet  Protocol  Version  4  (IPV4)  uses  a  
32-bit IP address, whereas IPV6 uses 128-bit 
IP addresses. 
Private  IP  addresses  are  translated  into  
public  IP  addresses  using  either  NAT  (net-
work   address   translation)   or   PAT   (port   
address translation). Both use IPV4, but PAT 
uses  port  numbers.  Different  technologies  
used to communicate between IPV4 and IPV6 
devices  include  dual-stack  routers,  tunneling  
and NAT protocol translators.
Professional  computer  network  architects  
and  programmers  need  to  understand  IPV6  
addressing, routing, transitioning to IPV6 from 
IPV4, dual-dress stacks, tunneling and NAT64. 
7.8.  Wireless and Mobile Networks [c24*, C7]
Wireless   networks   provide   the   ability   for   
devices to connect and communicate without 
the hassle of wires and cables. They also pro-
vide flexibility and ease of using the devices. 
Different  wireless  technologies  are  used  for  
different applications: 
•    Wireless personal area networks (WPAN). 
•    Wireless local area networks (WLAN) .
•    Wireless wide area networks (WWAN). 
A  mobile  or  cellular  network  is  a  radio  
network  spread  over  a  specific  area  of  land  
(called a cell). The cells are served by base sta-
tions,  which  are  fixed-location  transceivers.  
To  avoid  interference  and  ensure  guaran-
teed  bandwidth,  the  adjacent  cells  use  a  dif-
ferent  set  of  frequencies.  These  cells,  when  
connected, provide wide area radio coverage. 
The  cell  patterns  take  different  shapes,  but  
squares, circles and hexagons are typical. 
Different  methods  of  data  transmission  
are used between channels, such as frequency 
division multiple access (FDMA), time divi-
sion  multiple  access  (TDMA),  code  division  
multiple access (CDMA), space division mul-
tiple access (SDMA), etc. 
Wireless  technology  has  evolved  over  sev-
eral   generations.   Software   Engineers   are   
encouraged to learn the differences among 1G, 
2G, 3G, 4G and 5G technologies, along with 
the  core  network,  access  system,  frequency,  
bandwidth and technologies used in each.
7.9.  Security and Vulnerabilities [24*, C9]
Although   wireless   technology   provides   the   
ease  of  connecting  seamlessly  to  the  network,  
it is also prone to attacks unless the network is 
secured. Risks to unsecured wireless networks 

16-24   SWEBOK
®
 GUIDE V4.0
include Piggybacking, Wardriving, Evil Twins 
attacks, Wireless sniffing, Unauthorized com-
puter  access,  Shoulder  sniffing  and  Theft  of  
mobile devices.
Communication   over   the   internet   via   
mobile  device  is  highly  vulnerable  to  cyber-
attacks. In addition to wardriving, mentioned 
above,  typical  wireless  and  mobile  device  
attacks include SMiShing, War driving, WEP 
attacks,  WPA  attacks,  Bluejacking,  Reply  
attacks, Blue snarfing, RF Jamming, etc.
Many   precautionary   measures   must   be   
implemented  and  strictly  followed  to  reduce  
such  risks.  These  measures  include  changing  
default  passwords,  changing  passwords  fre-
quently,   restricting   access   to   authorized   
users,  encrypting  data  in  the  system  and  on  
the  network,  and  installing  multiple  levels  
of  firewalls.  In  addition,  users  must  protect  
and  hide  (not  publicize)  service  set  identifier  
(SSID),  use  effective  antivirus  software,  and  
update and upgrade it regularly; use a virtual 
private  networks  (VPN),  use  file-sharing  or  
system-sharing  access  with  care,  and  disable  
access  after  use;  and  update  or  upgrade  the  
access point or access controller, gateway and 
other devices with security patches when they 
become available. 
8. User and Developer Human Factors
The  thought  processes  and  behaviors  of  soft-
ware  developers  typically  differ  from  that  of  
software  users.  This  content  area  identifies  
salient  parameters  that  matter  for  end  users  
as  well  as  the  perspective  of  the  developers.  
Human-computer   interface   (HCI)   focuses   
on    designing    and    developing    computer    
technology  for  users  to  interact  with  com-
puting systems.
User  satisfaction  is  measured  in  terms  of  
user   experience   (UX).   An   ideal   interface   
would  facilitate  interaction  that  is  as  natural  
as the interaction between two human beings.
8.1.  User Human Factors [3*, C8]
Users expect software to be robust; to have an 
intuitive  graphical  user  interface  (GUI)  that  
guides the user through minimal, intelligent, 
easy-to-follow steps to achieve the end result; 
to  be  secure;  and  to  provide  fast,  consistent  
responses.
The  interface  should  help  users  use  the  
system easily. The interface should be self-ex-
planatory  and  enable  self-learning.  The  mes-
sages,   whether   communicating   results   or   
errors,  should  be  clear  and  complete.  The  
system  should  be  able  to  regain  its  original  
state if there are errors. 
The system should allow users to interrupt 
during the processing and undo the operation, 
wherever possible. 
The  software  engineer  needs  to  identify  
the profile of users the system; system’s func-
tionality,  input  and  output  interfaces  users  
use  (keyboard,  touch  pad,  audio,  video,  etc.)  
to interact with the system, the system’s fault 
tolerance,  the  system’s  performance  parame-
ters. among others.
Ty pically,  user  interface  development  goes  
through several iterations, starting with a proto-
type. The user interface devices must be robust.
8.2.  Developer Human Factors [3*, C31 - C32]
The software lives much longer than the time 
taken  to  develop.    Invariably,  the  software  
engineers who maintain the code are different 
from those who develop.  Hence, the code has 
to  be  written  with  more  care  and  for  use  by  
other programmer / software engineer.
Meaningful    and    comprehensive    docu-
mentation  is  crucial  at  all  stages  of  software  
lifecycle.  
Defining  and  adopting  apt  coding  stan-
dard for the project, and ensuring every team 
member implements the same in spirit is key 
for  developing  clean  code  that  lives  longer  
with minimal maintenance.
Programming  style  is  another  key  ingre-
dient of a good code.  Code has to be legible, 
should be like reading a good poem and easily 
comprehendible.    Using  meaningful,  consis-
tent  and  detailed  comments  is  essential  to  
ensure code readability. 
Other traits   of   a   good   software   pro-
grammer  include  being  a  team  player,  enjoy  

COMPUTING FOUNDATIONS   16-25
solving  puzzles  creatively,  be  agile,  be  struc-
tured / modular among others.
Good   coding   standards   include   defining 
naming  conventions  for  various  types  of  vari-
ables,  functions/procedures,  comment  struc-
ture/styles,  indentation  styles,  structuring  the  
code into paragraphs (of related functions), etc.
“Code  is  read  many  more  times  than  it  is  
written. Consider whether write-time conve-
nience is a false economy” — Steve McConnell
“Clean  code  always  looks  like  it  was  written  
by   someone   who   cares”   —   Robert   (Uncle   
Bob) Martin
9. Artificial Intelligence and Machine 
Learning                                                         [17*]
Intelligence  is  the  ability  to  acquire  and  cor-
relate  information  and  knowledge  to  make  a  
correct  decision  for  a  specific  task.  Artificial 
intelligence   (AI)   enables   computer   systems   
to  become  intelligent,  like  human  beings.  
Machine learning (ML) enables computer sys-
tems to learn from experiences and to use the 
knowledge  gained  to  make  smart  decisions  
—  to  become  artificially  intelligent.  Deep  
learning uses artificial neural network models 
for learning and making predictions.
Everyone  expects  all  systems  they  use  to  
be   smart,   reliable,   consistent,   secure   and   
fault-tolerant  —  and  to  get  better  every  day.  
AI and ML work toward enabling systems to 
accomplish all this.
An  ideal  AI  system  would  be  one  that  a  
human  could  not  identify  it  as  a  computer;  
humans would not be able to distinguish the 
computer from a human being.
Several  tools  have  been  developed  and  are  
available  for  creating  AI  systems.  Using  proven  
tools helps engineers build a stable system faster.
9.1.  Reasoning
Reasoning  means  analyzing  sets  of  informa-
tion available for a given situation and deter-
mining  the  cause  of  the  situation.  Reaching  
this conclusion is an important ability of AI, 
as the conclusion informs AI’s decision about 
what to do next. 
Different  types  of  reasoning  used  in  AI  
include the following:
Deductive Reasoning
 is a standard and stra-
tegic  approach  to  mapping  available  facts,  
information and knowledge to arrive at a con-
clusion.  In  this  approach,  available  facts  and  
information  are  considered  to  be  authentic.  
For example, if the premises are “All girls are 
beautiful” and “Michu is a girl,” then the con-
clusion is “Michu is beautiful.”
Inductive Reasoning is  about  introducing  a  
hypothesis and creating generalizations from 
the available facts and premises. Unlike deduc-
tive reasoning, in inductive reasoning, even if 
the premises are certain, the conclusion would 
be probable, depending on whether the induc-
tive argument is strong or weak. For example, 
check  the  location  of  all  engineers  working  
on  a  project  and  if  they  are  from  Bengaluru,  
India  state  “All  employees  working  on  the  
gaming project are from Bengaluru.”
Abductive Reasoning starts with an incom-
plete set of data or information and proceeds 
to derive the most likely conclusion from the 
latest data. For example, a doctor analyzes the 
latest  lab  reports  of  a  patient  to  predict  the  
course of the disease. 
Common Sense Reasoning makes inferences 
about  situations  based  on  similar  past  expe-
riences.  For  example,  if  a  motorcycle  skids  
while  driving  on  a  wet  road,  that  informa-
tion  is  remembered  and  considered  during  
future rides.
Monotonic Reasoning occurs when the con-
clusion remains permanent or constant after it 
is reached. For example, “The Himalayas are 
one of the tallest mountain ranges.”
Non-Monotonic  Reasoning  (NMR)  occurs 
when  the  inference  changes  values  or  direc-
tion based on new knowledge or information. 
NMR is based on assumptions and deals with 

16-26   SWEBOK
®
 GUIDE V4.0
incomplete or not-known facts. For example, 
the rule is “Birds fly”. But a few birds do not 
fly including penguins.  
Software engineers are encouraged to learn 
other  reasoning  methods,  such  as  metalevel  
reasoning, procedural numeric reasoning, and 
formal reasoning, as well.
9.2.  Learning
We learn from our observations, experiments 
and   experiences.   Enabling   computers   to   
learn  and  to  remember  what  they’ve  learned  
for  future  use  is  critical  for  building  AI  sys-
tems. An AI system learns when observations 
and  outcomes  of  experiments  (signals)  are  
fed  back  into  the  system.  Different  types  of  
learning include the following:
Supervised  Learning,  the  computer  system  
trains by receiving labeled (i.e., training) data. 
Subsequently,  when  any  input  is  provided,  
the  system  compares  it  with  the  data  it  was  
trained  on  and  generates  output.  Naturally,  
the  more  training  data,  the  better  the  out-
come.   Supervised   learning   uses   multiple   
learning  techniques,  including  the  classifica-
tion  technique  and  the  regression  technique.  
Supervised learning may not be able to handle 
complex tasks.
Unsupervised  Learning,  labeled  or  training  
data is not provided to the system. The system 
has  to  figure  out  common  patterns  from  the  
input given and make inferences. The data is 
analyzed in real time. 
Semi-supervised  Learning, the  system  is  
trained  with  partly  labeled  and  partly  unla-
beled  data.  This  type  of  learning  has  been  
shown to be effective.
Reinforcement  Learning  is  based  on  inter-
actions  with  the  environment.  In  this  type  
of   learning,   the   system   receives   feedback   
(an  error  message  or  a  reward)  and  learns  
from  that  feedback.  No  data  is  provided  to  
the  system  (neither  labeled  nor  unlabeled).  
Various algorithms are produced in reinforced 
learning.  This  is  a  trial-and-error  method  
for learning.
Software  engineers  working  on  AI  are  
expected   to   know   various   other   learning   
techniques   as   well,   including   dimension-
ality reduction learning, self-learning, feature 
learning,  sparse  learning,  anomaly  detection  
and robot learning, along with the key differ-
ences  between  the  methods  and  the  applica-
tions where each method works well.
9.3.  Models
AI  models  are  inference  engines  or  tools  
(algorithms)  that  can  arrive  at  the  best  deci-
sions based on relevant data.
Different models are created to enable effi-
cient  ML,  with  or  without  training  data.  
Models used in ML include the following:
Linear Regression model is based on super-
vised learning, where the relationship between 
input and output variables is determined and 
used. This model is commonly used in health 
care and banking applications.
Logistic  Regression model  is  a  statistical  
model primarily used for classifying dependent 
variables from given independent variables. 
Artificial  Neural  Networks  are  inspired  by  
biological neural networks in a brain. The sys-
tems are designed to learn naturally from the 
inputs without specific rules. 
Decision Tree model is used where past deci-
sions are used to arrive at a decision. The name 
“tree” is used because the data is stored in the 
form of a tree. 
Naïve Bayes model works on the assumption 
that the presence of a feature does not depend 
on  the  presence  of  any  other  feature.  Spam  
filtering  is  one  of  the  applications  that  suits  
this model.
Support Vector Machine (SV M), is a super-
vised ML algorithm used to analyze a limited 
quantum of data. SVM is typically faster than 

COMPUTING FOUNDATIONS   16-27
artificial  neural  networks  because  it  works  
with limited data.
Random Forest
 model uses multiple decision 
trees for making a final decision. The random 
forest model is useful for solving both regres-
sion and classification problems.
AI  models  are  key  to  making  the  most  
appropriate   decisions.   As   different   models   
suit specific applications or domains, software 
engineers are encouraged to learn many other 
AI models as well, such as Linear Discriminant 
Analysis,    Learning    Vector    Quantization,    
K-nearest Neighbors (KNN), etc.
9.4.  Perception and Problem-Solving
Solving  a  problem  efficiently  and  quickly  is  
the  goal  of  AI.  Problem-solving  predomi-
nantly  comprises  understanding  user  com-
mands  and  executing  them,  as  humans  do.  
Depending on the application and problem to 
be solved, AI systems use the relevant knowl-
edge  base  and  predicate  logic  to  identify  the  
most appropriate solution. 
AI systems dealing with the external world, 
obtain  environmental  data  through  sensors  
(cameras;   microphones;   temperature,   pres-
sure and light sensors, etc.), analyzes the data 
using its knowledge base or inference engine, 
and acts upon it.
Based on capabilities and functionality, AI 
systems are categorized into multiple types. 
Type  I  AI  systems  are  designed  to  do  
specific  tasks  with  intelligence.    Examples  
include  Chess  games,  speech  and  image  rec-
ognition, among others.
Ty p e   II AI systems analyze the current sit-
uation  or  environment  and  do  not  normally  
refer  to  previous  decisions  made  in  a  similar  
situation  to  arrive  at  an  appropriate  action.    
Reactive systems or reactive machines typically 
make decisions and execute commands at that 
instance,  referring  to  the  existing  knowledge  
base. A good example is a self-driving cars.
Ty p e  III,  or  self-aware,  AI  systems  have  
consciousness and are mindful. These systems 
adopt  the  mind  theory  and  predict  the  mood  
of  the  other  person  or  entity  based  on  the  
person’s action or type of action. For example, 
if the driver in the vehicle behind the system 
honks,  then  the  AI  system  might  conclude  
that the driver is angry or unhappy. Social and 
ethical behavior is part of conscious systems.
9.5.  Natural Language Processing
Natural language processing (NLP) is a crucial 
part  of  AI  systems,  enabling  users  to  interact  
with the AI systems in a way that is similar to 
how they interact with other humans. AI sys-
tems  understand  human  languages  and  exe-
cute  commands  delivered  in  those  languages.  
AI systems that work on voice commands need 
to  understand  not  only  the  human  language,  
but also the slang or pronunciation of the user. 
9.6.  AI and Software Engineering
Software  engineering  and  AI  are  mutually  
related to each other in basically two ways: AI 
applications in software engineering (i.e., AI 
for SE) and software engineering for AI sys-
tems (i.e., SE for AI). 
AI  for  SE  aims  to  establish  efficient  ways  
of building high-quality software systems by 
replicating  human  developers’  behavior.  It  
ranges  over  almost  all  development  stages,  
from  resolving  ambiguous  requirements  to  
predicting  maintainability,  particularly  well  
applied  in  software  quality  assurance  and  
analytics,  such  as  defect  prediction, test case 
generation,  vulnerability  analysis,  and  pro-
cess  assessment  [15].  Although  human-cen-
tric  software  engineering  activities  benefit,  
engineers should be aware of limitations and 
challenges  inherent  to  the  nature  of  AI  and  
ML,  especially  the  uncertain  and  stochastic  
behavior   and   the   necessity   of   sufficiently   
labeled and structured datasets [15].
The development of AI systems is different 
from  traditional  software  systems  since  the  
rules  and  system  behavior  of  AI  systems  are  
inferred from training data rather than written 
down  as  program  code  [16].  Thus,  there  is  a  
need for particular support of SE for AI, such 
as interdisciplinary collaborative teams of data 
scientists  and  software  engineers,  software  

16-28   SWEBOK
®
 GUIDE V4.0
evolution  focusing  on  large  and  changing  
datasets,  and  ethics  and  equity  requirements  
engineering   [16].   Recommended   software   
engineering practices for AI are often formal-
ized as patterns, such as ML software design 
patterns [17].
MATRIX OF TOPICS VS. REFERENCE MATERIAL
TopicsTanenbaum, Bos [19*]CLR S [18 *]H.Washizaki [17*]Horowitz et al. 2007 [5*]S McConnell [3*]Sommerville 2011 [6*]L. Null and J. Lobur [8*]Articles and JournalsJ.G. Brookshear [4*
]
Thomas Connolly, 
 
Carolyn Begg [22
]
Kurose & Ross [24]
1. Basic 
Concept of 
a System 
or Solution
C10
2. Computer 
Architecture 
and 
Organization
2.1 Computer 
Architecture
C1.1
2.2 Types of 
Computer 
Architecture
C4.14, 
C5
2.2.1 Von 
Neumann 
Architecture
C1.9
2.2.2 Harward 
Architecture
[20]
2.2.3 Instruction 
Set Architecture
C4.8.3
2.2.4 Flynn’s 
Architecture 
or Taxonomy
C9.3
2.2.5 System 
Architecture
C6C6
2.3 Micro 
Architecture 
or Computer 
Organization
C4
2.3.1 Arithmetic 
Logic Unit
C1.2
2.3.2 
Memory Unit
C6
2.3.3 Input / 
Output Unit
C7

COMPUTING FOUNDATIONS   16-29
2.3.4 
Control Unit
C4.2
3. Data 
Structures and 
Algorithms
c10,  
Part 
V
C2
3.1 Types of Data 
Structures
c10S2.1-2.6
3.2 Operations on 
Data Structures
S2.1-2.6
3.3 Algorithms 
and Attributes of 
Algorithms
c26, 
c27
3.4 Algorithm 
Complexity
s1.1–1.3, 
s3.3–3.6, 
s4.1–4.8, 
s5.1–5.7, 
s6.1–6.3, 
7. 6 , s11.1, 
s12.1
3.5 Measurement 
of Complexity
s1.1–s3.3– 
3.6, 
s4.1–4.8, 
s5.1–5.7, 
s6.1–6.3, 
s7.1–7. 6 , 
s11.1,  
s12.1
3.6 Designing 
Algorithms
Part 
I V,    
Part 
VII
3.7 Sorting 
Te c h n i q u e s
c6, 
c7,  
c8,  
c9
3.8 Searching 
Te c h n i q u e s
C6
3.9 Hashing
c11.2
4. 
Programming 
Fundamentals 
and Languages
C6
4.1 Programming 
Language Types
C8.4.4
4.2 Programming 
Syntax, Semantics, 
Type Systems
C8.4.4
4.3 Subprograms 
and Coroutines
C6.3

16-30   SWEBOK
®
 GUIDE V4.0
4.4 Object-
Oriented 
Programming
C6.5
4.5 Distributed 
Programming 
and Parallel 
Programming
C6.6
4.6 Debugging
C2.2.2
4.7 Standards 
and Guidelines
C28.5,  
C31.5
5. Operating  
Systems
5.1 Processor 
Management
c2, 
c8
5.2 Memory 
Management
c3
5.3 Device 
Management
c5
5.4 Information 
Management
c4
5.5 Network 
Management
C4.1
6. Database 
Management
6.1 Schema
C2.1.4
6.2 Data 
Models and 
Storage Models
C2.3
6.3 Database 
Management  
Systems
C1.3
6.4 Relational 
Database 
Management 
Systems and 
Normalization
C4
6.5 Structured 
Query Language
C6,  
C7,    
C8
6.6 Data Mining 
and Data 
Warehousing
C34
6.7 Database 
Backup 
and Recovery
C22
7. C ompute r 
Networks and  
Communications
C4.1
C1
7. 1   Ty p e s   
of Computer  
Networks
C4.1C1.2.1

COMPUTING FOUNDATIONS   16-31
7.2 Layered 
Architecture 
of Networks
C1.5
7.3 Open Systems 
Interconnection  
Model
C1.5
7.4 Encapsulation 
and 
Decapsulation
C1.5.2
7.5 Application 
Layer Protocols
C2
7.6 Desig n 
Techniques for 
Reliable and 
Efficient Network
C1.5
7.7 Inte r net 
Protocol Suite
C3
7.8 Wireless and 
Mobile Networks
C7
7.9 Security and 
Vulnerabilities
C8
8. User and 
Developer 
Human Factors
8.1 User 
Human Factors
c8
8.2. Developer 
Human Factors
c 31-
c32
9. A r tificia l 
Intelligence 
and Machine
Learning
C1
9.1 Reasoning
9.2 Learning
9.3 Models
9.4 Perception 
and 
Problem-Solving
9.5 Natural 
Language 
Processing
9.6 AI and 
Software 
Engineering

16-32   SWEBOK
®
 GUIDE V4.0
REFERENCES
[1] Joint Task Force on Computing 
Curricula, IEEE Computer Society and 
Association for Computing Machinery, 
Software Engineering 2014: Curriculum 
Guidelines for Undergraduate Degree 
Programs in Software Engineering, 
2014; http://sites.computer.org/ccse/
SE2004Volume.pdf.
[2*] G. Voland, Engineering by Design, 2nd 
ed., Prentice Hall, 2003.
[3*] S. McConnell, Code Complete, 2nd ed., 
Microsoft Press, 2004.
[4*] J.G. Brookshear, Computer Science: 
An Overview, 12th ed., Addison-
Wesley, 2017.
[5*] E. Horowitz et al., Computer 
Algorithms, 2nd ed., Silicon Press, 2007.
[6*] I. Sommerville, Software Engineering, 
9th ed., Addison-Wesley, 2011.
[7]   ISO/IEC/IEEE, “ISO/IEC/IEEE 
24765:2017 Systems and Software 
Engineering — Vocabulary,” 2nd ed. 2017.
[8*]  L. Null and J. Lobur, The Essentials 
of Computer Organization and 
Architecture, 5th ed., Jones and Bartlett 
Publishers, 2018.
[9 *] J. Nielsen, Usability Engineering, 
Morgan Kaufmann, 1994.
[10] ISO 9241-420:2011 Ergonomics of 
Human-System Interaction, ISO, 2011.
[11*] M. Bishop, Computer Security: Art and 
Science, 2
nd
 ed, Addison-Wesley, 2018.
[12] R.C. Seacord, The CERT C Secure 
Coding  Standard, Addison-Wesley 
Professional, 2016.
[13] R. Fagin, “A Normal Form for Relational 
Databases that is based on Domains 
and Keys,” ACM Transactions on 
Database Systems, Vol. 6, No. 3, ACM, 
September 1981
[14] I. Goodfellow, Y. Bengio, A. 
Courville, Deep Learning (Adaptive 
Computation and Machine Learning 
series) Illustrated Edition, 2018.
[1 5 ] S. Shafiq, A. Mashkoor, C. Mayr-
Dorn, A. Egyed, “A Literature 
Review of Using Machine Learning 
in Software Development Life Cycle 
Stages,” IEEE Access, Volume 9, IEEE, 
October 2021.
[16] S. Martínez-Fernández, J. Bogner, 
X. Franch, M. Oriol, J. Siebert, A. 
Trendowicz, A. M. Vollmer, “Software 
Engineering for AI-Based Systems: A 
Survey,” ACM Transactions on Software 
Engineering and Methodology, Vol. 31, 
No. 2, ACM, April 2022.
[17] H. Washizaki, F. Khomh, Y. G. 
Gueheneuc, H. Takeuchi, N. 
Natori, T. Doi, S. Okuda, “Software 
Engineering Design Patterns for 
Machine Learning Applications,” 
Computer, Vol. 55, No. 3, IEEE 
Computer Society, March 2022.
[18] Thomas H Cormen, Charles E 
Leiserson, Ronald L Rivest, Clifford 
Stein, “Introduction to Algorithms,” 
Fourth Edition, 2022.
[19] Andrew W Tanenbaum, Herbert Bos, 
“Modern Operating Systems,” 4e, 2016.
[20] https://ieeexplore.ieee.org/document 
/9779481 
[21] Neal Ford, Mark Richards, Pramod 
Sadalage and Zhamak Dehgh, Software 
Architecture: The Hard Parts, O Reilly, 
First Edition – 2021

COMPUTING FOUNDATIONS   16-33
[22] Thomas Connolly, Carolyn Begg, 
Database Systems - A Practical Approach to 
Design, Implementation and Management, 
6th Edition – Pearson
[23] Michael J. Hernandez, Database 
Design For Mere Mortals, 4th Edition, 
Add ison-Wesley
[24] James F Kurose, Keith W Ross, 
Computer Networking - A Top-Down 
Approach, 7th Edition, Pearson

17-1 
CHAPTER 17
Mathematical Foundations
ACRONYMS
BSTBinary Search Tree
CFGContext-Free Grammar
CSGContext-Sensitive Grammar
FSMFinite-State Machine
GCDGreatest Common Divisor
IHInduction Hypothesis
LHSLeft-Hand Side
PSGPhrase Structure Grammar
RHSRight-Hand Side
INTRODUCTION
Software  engineers  can  write  code  only  for  
something    that    follows    well-understood,    
unambiguous     logic.     The     Mathematical     
Foundations   Knowledge   Area   (KA)   helps   
software  engineers  comprehend  this  logic,  
which  they  translate  into  source  code.  The  
mathematics  in  this  KA  differs  greatly  from  
typical  arithmetic,  which  deals  with  num-
bers. This KA focuses on logic and reasoning, 
which  are  the  essence  of  the  mathematics  a  
software engineer must address.
Mathematics,  in  a  sense,  is  the  study  of  
formal systems. The word formal is associated 
with  preciseness,  so  there  can  be  no  ambig-
uous  or  erroneous  interpretation  of  the  facts.  
Mathematics is therefore the study of all cer-
tain truths about any concept. This concept can 
be about numbers, symbols, images, sounds or 
video — almost anything. In short, numbers 
and numeric equations aren’t the only subjects 
of  preciseness.  On  the  contrary,  a  software  
engineer  must  have  a  precise  abstraction  on  
complex, diverse application domains.
The Mathematical Foundations KA covers 
basic  techniques  to  identify  a  set  of  rules  for  
reasoning in the context of the system under 
study.  Anything  you  can  deduce  following  
these  rules  is  an  absolute  certainty  within  
the  context  of  that  system.  This  KA  defines  
and  discusses  techniques  that  can  represent  
and  take  forward  a  software  engineer’s  rea-
soning and judgment in a precise (and there-
fore mathematical) manner. The language and 
methods  of  logic  discussed  allow  software  
engineers to describe mathematical proofs to 
infer  conclusively  the  absolute  truth  of  cer-
tain concepts beyond just numbers. This KA’s 
objective is to help software engineers develop 
the  skill  to  identify  and  describe  such  logic  
and  verify  that  the  logic  in  the  code  is  con-
sistent  with  abstractions.  The  emphasis  is  on  
helping  software  engineers  understand  the  
basic concepts rather than on developing their 
arithmetic abilities.
BREAKDOWN OF TOPICS FOR 
MATHEMATICAL FOUNDATIONS
The breakdown of topics for the Mathematical 
Foundations KA is shown in Figure 17.1.
1. Basic Logic [1*, c1]
1.1.  Propositional Logic
A  proposition  is  a  statement  that  is  either  
true  or  false,  but  not  both.  Consider  declar-
ative  sentences  for  which  it  is  meaningful  to  
assign  either  of  the  two  status  values:  true  

17-2   SWEBOK
®
 GUIDE V4.0
or  false.  The  following  are  some  examples  of  
propositions:
•    The sun is a star.
•    Elephants are mammals.
•    2 + 3 = 5.
However, a + 3 = b is not a proposition, as 
it is neither true nor false. Whether it is true 
depends on the values of the variables a and b. 
The  Law  of  Excluded  Middle:  For  every  
proposition p, either p is true, or p is false.
The Law of Contradiction: For every propo-
sition  p,  it  is  not  the  case  that  p  is  both  true  
and false.
Propositional  logic  is  the  area  of  logic  that  
deals with propositions. A truth table displays 
the relationships between the truth values of 
propositions.
A Boolean variable is a variable whose value 
is either true or false. Computer bit operations 
correspond  to  logical  operations  of  Boolean  
variables.
The basic logical operators include negation 
(not,  ¬  p),  conjunction  (and,  p  ∧  q),  disjunc-
tion (or, p ∨ q), exclusion (p ⊕ q), and impli-
cation (p → q). Compound propositions may 
be formed using various logical operators.
A  compound  proposition  that  is  always 
true  is  a  tautology.  A  compound  proposition  
that is always false is a contradiction. A com-
pound proposition that is neither a tautology 
nor a contradiction is a contingency.
Compound  propositions  that  always  have  
the same truth value are called logically equiv-
alent  (denoted  by  ≡).  Some  common  logical  
equivalences are the following:
•    Identity laws: 
p ∧ T ≡ p p ∨ F ≡ p
•    Domination laws: 
p ∨ T ≡ T p ∧ F ≡ F
•    Idempotent laws: 
p ∨ p ≡ p p ∧ p ≡ p
•    Double negation law: 
¬ (¬ p) ≡ p 
•    Commutative laws: 
p ∨ q ≡ q ∨ p p ∧ q ≡ q ∧ p
•    Associative laws: 
(p ∨ q) ∨ r ≡ p ∨ (q ∨ r) (p ∧ q) ∧ r 
≡ p ∧ (q ∧ r)
•    Distributive laws: 
p ∨ (q ∧ r) ≡ (p ∨ q) ∧ (p ∨ r) 
p ∧ (q ∨ r) ≡ (p ∧ q) ∨ (p ∧ r)
Mathematical 
Foundations
Basic Logic
Set, Relation, 
Function
Finite-State 
Machine
Number eory  
Propositional
Logic
Predicate
Logic
Set Operations
Properties at Set
Relations and
Funtions
Types of Numbers
Divisibility
Prime Number
Greatest
Common Divisor
Discrete 
Probability
Algebraic
Structures
Group
Ring
Proof 
Techniques
Direct Proof
Proof by
Contradiction
Proof by
Induction
Proof by Example
Graph and Tree
Graph
Tree
Grammar
Language
Recognition
Basics of 
Counting
Numerical
Precision, Accuracy 
and Error
Calculus
Figure 17.1. Breakdown of Topics for the Mathematical Foundations KA

MATHEMATICAL FOUNDATIONS   17-3
•    De Morgan’s laws: 
¬ (p ∧ q) ≡ ¬ p ∨ ¬ q 
¬ (p ∨ q) ≡ ¬ p ∧ ¬ q
1.2.  Predicate Logic 
A predicate  is  a  verb  phrase  template  that  
describes  a  property  of  objects  or  a  relation-
ship  among  objects  represented  by  the  vari-
ables. For example, in the sentence The flower 
is  Red,  the  template  is  Red  is  a  predicate.  It  
describes  a  property  of  the  flower.  The  same  
predicate may be used in other sentences. 
Predicates are often given a name (e.g., Red 
or simply R) that can represent the predicate (in 
this case, Red or R can represent the predicate is 
red). Assuming R is the name for the predicate 
is red, sentences that assert an object is the color 
red  can  be  represented  as  R(x),  where  x  rep-
resents an arbitrary object. R(x) reads as x is red.
Quantifiers  allow  statements  about  entire  
collections  of  objects  so  that  enumerating 
each object by name is not necessary.
•    The universal quantifier ∀x  asserts  that  a  
sentence  is  true  for  all  values  of  variable  
x (e.g., ∀x Tiger(x) → Mammal(x) means 
all tigers are mammals).
•    The  existential  quantifier ∃x  asserts  that  
a  sentence  is  true  for  at  least  one  value  
of  variable  x  (e.g.,  ∃x  Tiger(x) →  Man-
eater(x)  means  there  exists  at  least  one  
tiger that is a man-eater).
Thus,  while  universal  quantification uses 
implication,  existential  quantification natu-
rally uses conjunction.
A   variable   x   introduced   into   a   logical   
expression  by  a  quantifier  is  bound  to  the  
closest  enclosing  quantifier.  Similarly,  in  a  
block-structured    programming    language,    
a  variable  in  a  logical  expression  refers  to  
the  closest  quantifier  within  whose  scope  
it  appears.  For  example,  in  ∃x  (Cat(x) ∧ ∀x 
(Black(x))), x in Black(x) is universally quan-
tified.  Therefore,  the  expression  implies  that  
cats exist and everything is black. 
A variable is a free variable if it is not bound 
to a quantifier.
Propositional  logic  falls  short  in  repre-
senting many assertions used in mathematics, 
computer   science   and,   therefore, software 
engineering.  It  also  fails  to  compare  equiva-
lence  and  other  relationships  between  prop-
ositions.   For   example,   the   assertion   “a   is   
greater  than  1”  is  not  a  proposition  because  
one  cannot  infer  whether  it  is  true  or  false  
without knowing the value of a. Thus, propo-
sitional logic cannot deal with such sentences. 
However,  such  assertions  appear  quite  often 
in  mathematics,  and  we  want  to  infer  infor-
mation  from  those  assertions.  Also,  prop-
ositional  logic  cannot  capture  the  pattern  
involved in the following two logical equiva-
lences: “Not all men are smokers” and “Some men 
don’t smoke.” Each of these two propositions is 
treated  independently  in  propositional  logic.  
There is no mechanism in propositional logic 
to determine whether the two are equivalent. 
Hence, propositional logic treats each equiva-
lent proposition individually rather than apply 
a general formula that covers all equivalences 
collectively. 
Predicate  logic  addresses  these  issues.  In 
a  sense,  predicate  logic  (also  known  as  first-
order   logic   or   predicate   calculus)   extends   
propositional   logic   to   formulas   involving   
terms and predicates.
2. Proof Techniques   [1*, c1]
A proof is an argument that rigorously estab-
lishes  the  truth  of  a  statement.  Proofs  can  
themselves be represented formally as discrete 
structures.
Statements used in a proof include axioms 
and postulates that are essentially the under-
lying assumptions about mathematical struc-
tures,  the  hypotheses  of  the  theorem  to  be  
proved and previously proved theorems.
•    A theorem  is  a  statement  that  can  be  
shown to be true.
•    A lemma  is  a  simple  theorem  used  in  
proving other theorems.
•    A corollary  is  a  proposition  that  can  be  
established  directly  from  a  theorem  that  
has been proved.

17-4   SWEBOK
®
 GUIDE V4.0
•    A conjecture  is  a  statement  whose  truth  
value is unknown.
When  a  conjecture’s  proof  is  found,  that  
conjecture  becomes  a  theorem.  Many  times,  
conjectures are shown to be false and, hence, 
are not theorems.
2.1.  Direct Proof
Direct  proof  is  a  technique  to  establish  that  
the implication p → q is true by showing that 
q  must  be  true  when  p  is  true.  For  example,  
to  show  that  if  n  is  odd,  then  n
2
  −  1  is  even,  
suppose n is odd for some integer k — i.e., n 
= 2k + 1: 
∴ n
2
 = (2k + 1)
2
 = 4k
2
 + 4k + 1
As  the  first  two  terms  of  the  Right-Hand  
Side  (RHS)  are  even  numbers  irrespective 
of the value of k, the Left-Hand Side (LHS) 
(n
2
)  is  an  odd  number.  Therefore, n
2
  −  1  is  
even. Direct proof can also be called Proof by 
Deduction.
2.2.  Proof by Contradiction
A  proposition  p  is  true  by  contradiction  if  
proved  based  on  the  truth  of  the  implica-
tion ¬ p → q, where q is a contradiction. For 
example, to show that the sum of 2x + 1 and 
2y  −  1  is  even,  assume  that  the  sum  of  2x  +  
1 and 2y − 1 is odd. In other words, 2(x + y), 
which is a multiple of 2, is odd. This is a con-
tradiction. Hence, the sum of 2x + 1 and 2y 
− 1 is even. 
An inference rule is a pattern establishing 
that  if  a  set  of  premises  are  all  true,  then  it  
can  be  deduced  that  a  certain  conclusion  
statement is true. The reference rules of addi-
tion,  simplification  and  conjunction  need  to  
be studied.
A    closely    related    approach,    Proof    by    
Contrapositive, takes the opposite approach by 
assuming the conclusion is false and proving 
that  the  hypothesis  is  also  false.  If  it  can  be  
shown  that    ¬  q  →  ¬  p  is  true,  then  p  → q 
must also be true.
2.3.  Proof by Induction
Proof  by  induction  is  done  in  two  parts.  
First,  the  proposition  is  established  to  be  
true for a base case — typically for the posi-
tive integer 1. Then, in the second part, it is 
established  that  if  the  proposition  holds  for  
an  arbitrary  positive  integer  k,  then  it  must  
also hold for the next greater integer, k +  1.  
In  other  words,  proof  by  induction  is  based  
on the rule of inference that tells us that the 
truth of an infinite sequence of propositions 
P(n), ∀n ∈  [1,  ...,  ∞]  is  established  if  first  
P(1)  is  true,  and,  second  ∀k ∈  [2,  ...,  n]  if  
P(k) → P(k + 1). 
For a proof by induction, it is not assumed 
that  P(k)  is  true  for  all  positive  integers  
k.  Proving  a  theorem  or  proposition  only  
requires  us  to  establish  that  if  it  is  assumed  
P(k) is true for any arbitrary positive integer 
k, then P(k + 1) is also true. An in-depth dis-
cussion  of  the  correctness  of  induction  as  a  
valid proof technique is beyond the scope of 
this KA. The following proposition is proved 
using induction:
Proposition: The sum of the first n positive 
odd integers P(n) is n
2
.
Basis  Step:  The  proposition  is  true  for  n  =  
1 as P(1) = 1
2
 = 1. The basis step is complete.
Inductive  Step:  The  induction  hypothesis  
(IH) is that the proposition is true for n = k, k 
being an arbitrary positive integer k. 
∴ 1 + 3 + 5 + ... + (2k − 1) = k
2
Now, it’s to be shown that P(k) → P(k + 1).
P(k + 1) = 1 + 3 + 5 + ... + (2k − 1) + (2k + 1)
 = P(k) + (2k + 1)
          =          k
2
 + (2k + 1) [using IH]
          =          k
2
 + 2k + 1
 = (k + 1)
2
 
Thus, it is shown that if the proposition is 
true for n = k, then it is also true for n = k + 1.
The  basis  step  together with  the  inductive  
step of the proof show that P(1) is true and the 
conditional statement P(k) → P(k + 1) is true 
for all positive integers k. Hence, the proposi-
tion is proved.

MATHEMATICAL FOUNDATIONS   17-5
2.4.  Proof by Example
Proof by example is only valid when the core 
of  the  proof  is  “there  exists”  and  one  needs  
only  to  show  that  at  least  one  valid  instance  
does exist. More generally, however, proof by 
example  has  often  been  called  Inappropriate  
Generalization  where  validity  is  assumed  to  
be illustrated through one or a few examples 
rather than a full proof. Showing only one or a 
few specific examples where p → q is not suf-
ficient to prove that for all cases p → q.
3. Set, Relation, Function  [1*, c2]
Set. A set is a collection of objects called ele-
ments. A set can be represented by listing its 
elements between braces (e.g., S = {1, 2, 3}).
The symbol ∈ is used to express that an ele-
ment belongs to a set or is a member of the set. 
Its  negation  is  represented  by  ∉  (e.g.,  1  ∈ S, 
but 4 ∉ S).
In  a  more  compact  representation  of  a  set  
using set builder notation, {x | P(x)} is the set 
of all x such that P(x) for any proposition P(x) 
over  any  universe  of  discourse.  Examples  of  
important sets include the following:
•    Ν = {0, 1, 2, 3, ...} = the set of nonnega-
tive integers.
•    Ζ = {..., -3, -2, -1, 0, 1, 2, 3, ...} = the set 
of integers.
Finite  and  Infinite  Set.  A  set  with  a  finite  
number  of  elements  is  called  a  finite  set.  
Conversely, any set that does not have a finite 
number of elements in it is an infinite set. For 
example, the set of all natural numbers is an 
infinite set. 
Cardinality. The cardinality of a finite set S 
is the number of elements in S. This is repre-
sented as |S| (e.g., if S = {1, 2, 3}, then |S| = 3).
Universal  Set.  In  general,  S  =  {x ∈  U  |  
p(x)}, where U is the universe of discourse in 
which the predicate P(x) must be interpreted. 
The universe  of  discourse  for  a  given pred-
icate  is  often  referred  to  as  the universal  set. 
Alternatively,  one  may  define  a  universal  set  
as the set of all elements.
Set Equality. Two sets are equal if and only 
if they have the same elements —
 i.e., X = Y ≡ ∀p (p ∈ X ↔ p ∈ Y).
Subset.  X  is  a  subset  of  set  Y,  or  X  is  con-
tained in Y, if all elements of X are included 
in Y. This is denoted by X ⊆ Y. In other words, 
X ⊆ Y if and only if ∀p(p ∈ X → p ∈ Y) If X 
= {1, 2, 3} and Y = {1, 2, 3, 4, 5}, then X ⊆ Y.
If X is not a subset of Y, it is denoted as X 
 Y.
Proper  Subset.  X  is  a  proper  subset  of  Y 
(denoted  by  X ⊂ Y)  if  X  is  a  subset  of  Y  but  
not equal to Y — i.e., there is some element in 
Y that is not in X.
In other words, X ⊂ Y if (X ⊆ Y) ∧ (X ≠ Y). 
If X = {1, 2, 3}, Y = {1, 2, 3, 4}, and Z = {1, 2, 
3}, then X ⊂ Y, but X is not a proper subset of 
Z. Sets X and Z are equal sets.
If X  is  not  a  proper  subset  of  Y,  it  is  
denoted as X ⊄ Y.
Superset. If X  is  a  subset  of  Y,  then  Y  is  
called a superset of X. This is denoted by Y ⊇ 
X — i.e., Y ⊇ X if and only if X ⊆ Y. If X = {1, 
2, 3} and Y = {1, 2, 3, 4, 5}, then Y ⊇ X.
Empty Set. A set with no elements is called 
an empty set. An empty set, denoted by φ, is 
also referred to as a null or void set.
Power Set. The set of all subsets of a set X 
U
X
Figure 17.2. Venn Diagram for Set X
U
X ∩ Y
XY
Figure 17.3. Intersection of Sets X and Y

17-6   SWEBOK
®
 GUIDE V4.0
is called the power set of X. It is represented 
as ℘(X). If X = {a, b, c}, then ℘(X) = {φ,  {a},  
{b}, {c}, {a, b}, {a, c}, {b, c}, {a, b, c}}. If |X| = n, 
then |℘ (X)| = 2n.
Venn Diagrams. Venn diagrams are graphic 
representations of sets as enclosed areas in the 
plane.  For  example,  in  Figure  17.2,  the  rect-
angle  represents  the  universal  set,  and  the  
shaded region represents a set X.
3.1.  Set Operations
Intersection.  The  intersection  of  two  sets,  X 
and Y, denoted by X ∩ Y, is the set of common 
elements in both X and Y. In other words, X 
∩ Y = {p | (p ∈ X) ∧ (p ∈ Y)}. For example, {1, 
2, 3} ∩ {3, 4, 6} = {3}.
If X ∩ Y = φ, then the two sets X and Y are 
said to be disjoint.
A  Venn  diagram  for  set  intersection  is  
shown  in  Figure  17.3.  The  common  portion  
of the two sets represents the set intersection.
Union. The  union  of  two  sets,  X  and  Y, 
denoted by X ∪ Y, is the set of all elements in 
X, in Y or in both. In other words, X ∪ Y = {p 
| (p ∈ X) ∨ (p ∈ Y)}. For example, {1, 2, 3} ∪ 
{3, 4, 6} = {1, 2, 3, 4, 6}.
It  may  be  noted  that  |X ∪ Y|  =  |X|  +  |Y| 
− |X ∩ Y|.
A  Venn  diagram  illustrating  the  union  of  
two  sets  is  represented  by  the  shaded  region  
in Figure 17.4.
Complement Set. The set of elements in the 
universal set that do not belong to a given set 
X  is  called  its  complement  set  X’.  In  other  
words, X’ ={p | (p ∈ U) ∧ (p ∉ X)}.
The  shaded  portion  of  the  Venn  diagram  in  
Figure 17.5 represents the complement set of X.
Set  Difference  or  Relative  Complement.  The  
set  of  elements  that  belong  to  set  X  but  not  
to set Y builds the set difference of Y from X. 
This is represented by X − Y. In other words, 
X − Y = {p | (p ∈ X) ∧ (p ∉ Y)}. For example, 
{1, 2, 3} − {3, 4, 6} = {1, 2}.
It may be proved that X − Y = X ∩ Y’.
Set   difference   X   –   Y   is   illustrated   by   
the  shaded  region  in  Figure  17.6  using  a  
Ve n n   d i a g r a m .
Cartesian  Product.  An  ordinary  pair  {p, q} 
is a set with two elements. In a set, the order 
of the elements is irrelevant, so {p, q} = {q, p}. 
In an ordered pair (p, q), the order of occur-
rences of the elements is relevant. Thus, (p, q) 
≠ (q, p) unless p = q. In general, (p, q) = (s, t) if 
and only if p = s and q = t.
Given  two  sets,  X  and  Y,  their  Cartesian  
product X × Y is the set of all ordered pairs (p, 
q) such that p ∈ X and q ∈ Y. In other words, X 
× Y = {(p, q) | (p ∈ X) ∧ (q ∈ Y)}. For example, 
{a, b} × {1, 2} = {(a, 1), (a, 2), (b, 1), (b, 2)}.
3.2.  Properties of Sets
Some of the important properties and laws of 
sets are mentioned below:
U
X ∪ Y
XY
Figure 17.4. Union of Sets X and Y
U
X – Y
XY
Figure 17.6. Venn Diagram for X − Y
U
X
Figure 17.5. Venn Diagram for 
Complement Set of X

MATHEMATICAL FOUNDATIONS   17-7
•    Associative Laws:
• X ∪ (Y ∪ Z) = (X ∪ Y) ∪ Z
• X ∩ (Y ∩ Z) = (X ∩ Y) ∩ Z
•    Commutative Laws:
• X ∪ Y = Y ∪ X X ∩ Y = Y ∩ X
•    Distributive Laws:
• X ∪ (Y ∩ Z) = (X ∪ Y) ∩ (X ∪ Z)
• X ∩ (Y ∪ Z) = (X ∩ Y) ∪ (X ∩ Z)
•    Identity Laws:
• X ∪ φ = X X ∩ U = X
•    Complement Laws:
• X ∪ X’ = U X ∩ X’ = φ
•    Idempotent Laws:
• X ∪ X = X X ∩ X = X
•    Bound Laws:
• X ∪ U = U X ∩ φ = φ
•    Absorption Laws:
• X ∪ (X ∩ Y) = X X ∩ (X ∪ Y) = X
•    De Morgan’s Laws:
•    (X ∪ Y)’ = X’ ∩ Y’     (X ∩ Y)’ = X’ ∪ Y’
3.3.  Relation and Function
A relation is an association between two sets of 
information. Consider a set of residents of a city 
and their phone numbers. The pairing of names 
with  corresponding  phone  numbers  is  a  rela-
tion. This pairing is ordered for the entire rela-
tion. For each pair, either the name comes first, 
followed by the phone number, or the reverse. 
The set from which the first element is drawn 
is  called  the  domain  set,  and  the  other  set  is  
called  the  range  set.  The  domain  is  what  you  
start with, and the range is what you end with.
A  function  is  a  well-behaved  relation.  A  
relation R(X, Y) is well-behaved if every ele-
ment  of  the  domain  set  X  corresponds  to  a  
single  element  of  the  range  set  Y.  Consider  
domain set X as a set of people and range set 
Y  as  their  phone  numbers.  If  a  person  may  
have more than one phone number, then this 
relation  is  not  a  function.  However,  if  we  
draw  a  relation  between  the  names  of  resi-
dents and their dates of birth with the name 
set  as  domain,  then  this  becomes  a  well-be-
haved  relation  and  hence  a  function.  This  
means  that  while  all  functions  are  relations,  
not  all  relations  are  functions.  In  the  case  of  
a function given an x, there is one and exactly 
one y for each ordered pair (x, y).
For  example,  consider  the  following  two  
relations:
A: {(3, –9), (5, 8), (7, –6), (3, 9), (6, 3)}
B: {(5, 8), (7, 8), (3, 8), (6, 8)}
Are these functions as well?
In relation A, the domain is all x-values — 
i.e., {3, 5, 6, 7} — and the range is all y-values 
— i.e., {–9, –6, 3, 8, 9}.
Relation A  is  not  a  function,  as  there  are  
two  different  range  values,  –9  and  9,  for  the  
same x-value, 3.
In  relation  B,  the  domain  is  the  same  as  
for A — i.e., {3, 5, 6, 7}. However, the range 
is  a  single  element  —  {8}.  This  qualifies  as  a  
function even if all x-values are mapped to the 
same  y-value.  Here,  each  x-value  is  distinct,  
so the relation is well-behaved and is therefore 
a function. Therefore, Relation B may be rep-
resented by the equation y = 8.
Whether a relation may be characterized as 
a  function  can  be  verified  using  the  vertical  
line test presented below:
Given  the  graph  of  a  relation,  if  one  can  
draw a vertical line that crosses the graph in 
more than one place, then that relation is not 
a function.
Y
L1L2
X
F i g u re 17.7. Vertical Line Test for Function

17-8   SWEBOK
®
 GUIDE V4.0
In Figure 17.7, both lines L1 and L2 cut the 
graph for the relation three times. This signi-
fies  that  for  each  of  these  x-values  (with  L1  
representing one x-value and L2 representing 
another),  there  are  three  different  y-values.  
Thus, the relation is not a function. Of course, 
either  L1  or  L2  alone  would  be  enough  to  
prove that the relation is not a function.
4. Graph and Tree  [1*, c10, c11]
4.1.  Graph
In a graph G = (V, E), V is the set of vertices 
(nodes)  and  E  is  the  set  of  edges.  Edges  are  
also called arcs or links.
F is a function that maps the set of edges E 
to a set of ordered or unordered pairs of ele-
ments V.  In  Figure  17.8,  G  =  (V, E)  where  V 
= {A, B, C}, E = {e1, e2, e3}, and F  =  {(e1, (A, 
C)), (e2, (C, B)), (e3, (B, A))}.
The  simple  graph  in  Figure  17.8  consists  
of a set of vertices or nodes and a set of edges 
connecting  unordered  pairs.  The  edges  in  
simple  graphs  are  undirected.  Such  graphs  
are  also  called  undirected  graphs.  In  Figure  
17. 8 ,  (e1, (A, C)) may be replaced by (e1,  (C,  
A)),  as  the  pair  between  vertices  A  and  C  
is  unordered.  This  is  true  for  the  other  two  
edges as well.
In  a  multigraph,  more  than  one  edge  may  
connect  the  same  two  vertices.  Two  or  more  
connecting  edges  between  the  same  pair  of  
vertices   may   reflect   multiple   associations   
between  the  same  two  vertices.  Such  edges  
are called parallel  or  multiple edges. In Figure 
17.9, the edges e3 and e4 both connect A and 
B. Figure 17.9 is a multigraph where edges e3 
and e4 are multiple edges.
In a pseudograph, edges connecting a node to 
itself are allowed. Such edges are called loops.
In Figure 17.10, the edge e4 both starts and 
ends  at  B.  Figure  17.10  is  a  pseudograph  in  
which e4 is a loop.
A directed  graph G  =  (V, E)  consists  of  a  
set of vertices V and a set of edges E that are 
ordered  pairs  of  elements  of  V.  A  directed  
graph may contain loops. In Figure 17.11, G = 
(V, E) is a directed graph where V = {A, B, C}, 
A
BCe2
e1e3
Figure 17.8. Example of a Graph
A
BCe2
e4
e1e3
Fig ure 17.9. Example of a Multigraph
A
BCe2
e4
e1e3
Figure 17.10. Example of a Pseudograph
A
BCe2
e1e3
Figure 17.11. Example of a Directed Graph
A
BC
e293
e1
7615
e3
Figure 17.12. Example of a Weighted Graph

MATHEMATICAL FOUNDATIONS   17-9
E = {e1, e2, e3}, and F  =  {(e1, (A, C)), (e2, (B, 
C)), (e3, (B, A))}.
In weighted graph G = (V, E), each edge has 
a weight associated with it. The weight of an 
edge  typically  represents  the  numeric  value  
associated  with  the  relationship  between  the  
corresponding  two  vertices.  In  Figure  17.12,  
the  weights  for  the  edges  e1, e2  and  e3  are  
taken to be 76, 93 and 15, respectively. If the 
vertices A, B and C represent three cities in a 
state,  the  weights  could  be,  for  example,  the  
distances in kilometers between these cities.
Let G = (V, E) be an undirected graph with 
edge set E. Then, for an edge e ∈ E where e = 
{u, v}, the following expressions are often used:
• u, v  are  said  to  be  adjacent, neighbors, or 
connected.
•    Edge e is incident with vertices u and v.
•    Edge e connects u and v.
•    Ve r t ic e s  u and v are endpoints for edge e.
If  vertex  v ∈  V,  the  set  of  vertices  in  the  
undirected graph G = (V, E), then:
•    The degree  of  v,  deg(v),  is  its  number  of  
incident edges, except that any self-loops 
are counted twice.
•    A  vertex  with  degree  0  is  called  an  iso-
lated vertex.
•    A  vertex  of  degree  1  is  called  a  pen-
dant vertex.
Let G = (V, E) be a directed graph. If e(u, 
v) is an edge of G, then the following expres-
sions can be used to describe the graph:
• u is adjacent to v, and v is adjacent from u.
• e comes from u and goes to v.
• e connects u to v, or e goes from u to v.
•    The initial vertex of e is u.
•    The terminal vertex of e is v.
If  vertex  v  is  in  the  set  of  vertices  for  the  
directed graph G = (V, E), then:
• In-degree  of  v,  deg
−
(v),  is  the  number  of  
edges  going  to  v,  i.e.,  for  which  v  is  the  
terminal vertex.
• Out-degree of v, deg
+
(v), is the number of 
edges coming from v, i.e., for which v is 
the initial vertex.
• Degree of v, deg(v) = deg
−
(v) + deg
+
(v), is 
the sum of v’s in-degree and out-degree. 
•    A  loop  at  a  vertex  contributes  1  to  both  
the   in-degree   and   the   out-degree   of   
this vertex.
According  to  the  definitions  above,  the  
degree  of  a  node  is  unchanged  whether  we  
consider its edges to be directed or undirected.
In an undirected graph, a path of length n 
from u to v is a sequence of n adjacent edges 
from vertex u to vertex v.
•    A path is a circuit if u = v.
•    A path traverses the vertices along it. 
•    A  path  is  simple  if  it  contains  no  edge  
more than once.
A  cycle  on  n  vertices  C
n 
for  any  n  ≥  3  is  a  
simple graph where V = {v
1
, v
2
, ..., v
n
} and E = 
{{v
1
, v
2
}, {v
2
, v
3
}, ..., {v
n−1
, v
n
}, {v
n
, v
1
}}.
For  example, Figure  17.13  illustrates  two  
cycles of lengths 3 and 4.
An adjacency  list  is  a  table  with  one  row  
per  vertex,  listing  its  adjacent  vertices.  The  
Figure 17.13. Example of Cycles C
3
 and C
4
A
BCe2
e1e3
AB
DC
e1
e3
e4
e2
Figure 17.14. Adjacency List for the Graph in 
F i g u re 17.10
Vertex Adjacent Nodes
AB, C
BA, B, C
CA, B

17-10   SWEBOK
®
 GUIDE V4.0
adjacency  list  for  a  directed  graph  maintains  
a listing of the terminal nodes for each vertex. 
Figure  17.14  illustrates  the  adjacency  lists  
for  the  pseudograph  in  Figure  17.10  and  the  
directed graph in Figure 17.11. As the out-de-
gree of vertex C in Figure 17.11 is 0, there is 
no entry against C in the adjacency list.
Different  representations  for  a  graph  —  
e.g.,  adjacency  matrix,  incidence  matrix  and  
adjacency lists — need to be studied.
4.2.  Tree
A  tree  T(N, E)  is  a  hierarchical  data  struc-
ture of n = |N| nodes with a specially desig-
nated root node R while the remaining n − 1 
nodes  form  subtrees  under  the  root  node  R. 
The number of edges |E| in a tree are always 
equal to |N| − 1.
The  subtree  at  node  X  is  the  subgraph  of  
the tree consisting of node X, its descendants 
and  all  edges  incident  to  those  descendants.  
As an alternative to this recursive definition, a 
tree may be defined as a connected undirected 
graph with no simple circuits.
However,  a  tree  is  strictly  hierarchical,  
whereas  a  graph  is  flat.  In  a  tree,  an  ordered  
pair is built between two nodes as parent and 
child.  Each  child  node  in  a  tree  is  associ-
ated with only one parent node, whereas this 
restriction  is  meaningless  for  a  graph,  where  
no parent-child association exists. 
An undirected graph is a tree if and only if 
there is a unique simple path between any two 
of its vertices.
Figure 17.15 presents a tree T(N, E) with a 
set of nodes N = {A, B, C, D, E, F, G, H, I, J, 
K}. The edge set E is {(A, B), (A, C), (A, D), (B, 
E), (B, F), (B, G), (C, H), (C, I), (D, J), (D, K)}.
The  parent  of  a  non-root  node  v is  the  
unique node u with a directed edge from u to 
v.  Each  node  in  the  tree  has  a  unique  parent  
node except for the tree’s root node. While root 
nodes can serve as parent nodes, they have no 
parent nodes themselves. In Figure 17.15, root 
node A is the parent node for nodes B, C and 
D. Similarly, B is the parent of E, F and G, and 
so on. The root node A has no parent.
A node that has children is called an internal 
node.  For  example,  in  Figure  17.15,  node  A 
and node B are examples of internal nodes. 
The degree of a node in a tree is the same as 
its number of children. For example, in Figure 
17.15, root node A and its child B are both of 
degree 3. Nodes C and D have degree 2.
A  node’s  distance  from  the  root  node  in  
number  of  hops  is  called  its  level.  Nodes  in  
a tree are at different levels. The root node is 
at level 0. Alternately, a node X’s level is the 
unique  path’s  length  from  the  tree’s  root  to  
node X.  Root  node  A  is  at  level  0  in  Figure  
17.15.  Nodes  B, C  and  D  are  at  level  1.  The  
remaining nodes in Figure 17.15 are at level 2.
A tree’s height is the maximum of the levels 
of  tree  nodes.  For  example,  in  Figure  17.15,  
the tree’s height is 2.
A  node  is  called  a  leaf  if  it  has  no  chil-
dren,  and  the  degree  of  a  leaf  node  is  0.  For  
example, in Figure 17.15, nodes E through K 
are leaf nodes with degree 0. 
The ancestors or predecessors of a non-root 
node X are all the nodes in the path from the 
root to node X. For example, in Figure 17.15, 
nodes A and D form the set of ancestors for J. 
A  node  X’s  successors  or  descendants are 
all the nodes that have X as their ancestor. For 
a tree with n nodes, all remaining n − 1 nodes 
are  successors  of  the  root  node.  In  Figure  
17.15, node B has successors in E, F, and G.
If node X is an ancestor of node Y, then node Y 
is a successor of X.
Two or more nodes sharing the same parent 
node  are  called  sibling  nodes.  For  example,  
in  Figure  17.15,  nodes  E  and  G  are  siblings.  
However, nodes E and J, though at the same 
level, are not sibling nodes. 
A
BCD
EFGIHJ
K
Figure 17.15. Example of a Tree

MATHEMATICAL FOUNDATIONS   17-11
Two sibling nodes are at the same level, but two 
nodes at the same level are not necessarily siblings.
A  tree  is  called  an  ordered  tree  if  the  rela-
tive position of occurrences of children nodes 
is significant. For example, a family tree is an 
ordered tree if, as a rule, the name of an elder 
sibling  always  appears  before  (on  the  left  of )  
the younger sibling.
In  an  unordered  tree,  the  relative  position  
of  occurrences  between  the  siblings  has no 
significance and may be altered arbitrarily.
A  binary  tree  is  formed  with  0  or  more  
nodes where there is a root node R and all the 
remaining nodes form a pair of ordered sub-
trees  under  the  root  node.  In  a  binary  tree,  
no  internal  node  can  have  more  than  two  
children.  In  addition  to  this  criterion  for  
the  degree  of  internal  nodes,  a  binary  tree  
is  always  ordered.  If  the  positions  of  the  left  
and right subtrees for any node in the tree are 
swapped, then a new tree is created.
In  Figure  17.16,  the  two  binary  trees  are  
different, as the positions of occurrences of A’s 
children differ in the two trees.
According to [1*], a binary tree is called 
a full binary tree if every internal node has 
exactly two children. For example, the binary 
tree in Figure 17.17 is a full binary tree, as 
both internal nodes A and B are of degree 2. 
A full binary tree that meets the definition 
above is also called a strictly binary tree.
Both binary trees in Figure 17.18 are com-
plete binary trees. The tree in Figure 17.18(a) 
is a complete and full binary tree. A complete 
binary tree has all its levels filled, except pos-
sibly  the  last  one.  If  a  complete  binary  tree’s  
last level is not full, nodes occur from the left-
most positions available.
Interestingly,    following    the    definitions    
above, the tree in Figure 17.18(b) is a complete 
but not full binary tree, as node B has only one 
child in D. On the contrary, the tree in Figure 
17.17  is  a  full  but  not  complete  binary  tree,  
as B’s children occur in the tree, whereas the 
children of C do not appear in the last level.
A binary tree of height H is balanced if all 
leaf nodes occur at levels H or H − 1. All three 
binary  trees  in  Figures  17.17  and  17.18  are  
balanced binary trees.
There are at most 2
H
 leaves in a binary tree 
of  height  H.  In  other  words,  if  a  binary  tree  
with L  leaves  is  full  and  balanced,  then  its  
height is H  =|log
2
L|. This is true for the two 
trees  in  Figures  17.17  and  17.18(a),  as  both  
trees are full and balanced. However, the tree 
in Figure 17.18(b) is not a full binary tree. 
A binary search tree (BST) is a special kind 
of binary tree in which each node contains a 
distinct  key  value,  and  the  key  value  of  each  
node  in  the  tree  is  less  than  every  key  value  
in its right subtree and greater than every key 
value in its left subtree.
A traversal algorithm is a procedure for sys-
tematically visiting every node of a binary tree. 
Tree traversals may be defined recursively.
A
BC
A
CB
Figure 17.16. Examples of Binary Trees
A
CB
DE
F i g u re 17.17. Example of a Full Binary Tree
AA
(a)(b)
C
BCB
DEDGF
Figure 17.18. Example of Complete Binary Trees

17-12   SWEBOK
®
 GUIDE V4.0
If T  is  a  binary  tree  with  root  R  and  the  
remaining nodes form an ordered pair of non-
null left subtree T
L
 and nonnull right subtree 
T
R
 below R, then the preorder traversal func-
tion PreOrder(T) is defined as:
PreOrder(T) = R, PreOrder(T
L
), 
PreOrder(T
R
) ... eqn. 1
The  recursive  process  of  finding  the  pre-
order traversal of the subtrees continues until 
the  subtrees  are  found  to  be  Null.  Here,  
commas  have  been  used  as  delimiters  for  
improved readability.
The postorder and in-order may be similarly 
defined using eqn. 2 and eqn. 3, respectively.
PostOrder(T) = PostOrder(T
L
), 
PostOrder(T
R
), R ... eqn. 2
InOrder(T) = InOrder(T
L
), R, 
InOrder(T
R
) ... eqn. 3
The tree in Figure 17.19 is a binary search 
tree  (BST).  The  pre-order,  post-order  and  
in-order  traversal  outputs  for  this  BST  are  
given below in their respective orders:
Preorder  output:  9,  5,  2,  1,  4,  7,  6,  8,  13,  
11, 10, 15
Postorder  output:  1,  4,  2,  6,  8,  7,  5,  10,  
11, 15, 13, 9
In-order  output:  1,  2,  4,  5,  6,  7,  8,  9,  10,  
11, 13, 15
5. Finite-State Machine   [1*, c13]
A  computer  system  may  be  abstracted  as  a  
mapping from state to state, driven by inputs. 
In other words, a system may be considered a 
transition function T: S × I → S × O, where S 
is  the  set  of  states  and  I  and  O  are  the  input  
and output functions.
If  the  state  set  S  is  finite,  the  system  is  
called a finite-state machine (FSM).
Alternatively,    a    finite    state    machine    
(FSM)  is  a  mathematical  abstraction  com-
posed of a finite number of states and transi-
tions between those states. For example, if the 
domain S × I is reasonably small, then one can 
specify T  explicitly,  using  diagrams  similar 
to a  flow  graph  to  illustrate  how  logic  flows  
for different inputs. However, this is practical 
only for machines with a very small informa-
tion capacit y.
An  FSM  has  a  finite  internal  memory,  an  
input feature that reads symbols one at a time 
in a sequence, and an output feature. 
The  operation  of  an  FSM  begins  from  a  
start state, goes through transitions depending 
on  the  input  to  different  states,  and  can  end  
in any valid state. However, only a few of the 
states  mark  a  successful  flow  of  operation.  
These are called accept states.
The  information  capacity  of  an  FSM  is  
C  =  log  |S|.  Thus,  if  we  represent  a  machine  
having an information capacity of C bits as an 
FSM, then its state transition graph will have 
|S| = 2
C
 nodes.
An  FSM  is  formally  defined  as  M =  (S, I, 
O, f, g, s
0
).
9
146810
513
151172
Fig ure 17.19. A Binary Search Tree
1, 2
1, 2
0, 2
0, 3
0, 3
1, 3
S₀
S₁
S₂
Figure 17.20. Example of an FSM

MATHEMATICAL FOUNDATIONS   17-13
S is the state set.
I is the set of input symbols.
O is the set of output symbols.
f is the state transition function.
g is the output function.
s
0
 is the initial state.
Given an input x ∈ I on state S
k
, the FSM 
transitions to  state  S
h
,  following  state  transi-
tion function f, and produces an output y ∈ O, 
using the output function g.
Fig ure 17.20 illustrates an FSM with S
0
 as 
the start state and S
1
 as the final state. Here, S 
= {S
0
, S
1
, S
2
}; I = {0, 1}; O = {2, 3}; f(S
0
, 0) = S
2
; 
f(S
0
, 1) = S
1
; f(S
1
, 0) = S
2
; f(S
1
, 1) = S
2
; f(S
2
, 0) = 
S
2
; f(S
2
, 1) = S
0
; g(S
0
, 0) = 3; g(S
0
, 1) = 2; g(S
1
, 
0) = 3; g(S
1
, 1) = 2; g(S
2
, 0) = 2; g(S
2
, 1) = 3.
The state transition and output values for dif-
ferent inputs on different states may instead be 
represented using a state table. The state table 
for the FSM in Figure 17.20 is shown in Figure 
17.21. Each pair against an input symbol rep-
resents  the  new  state  and  the  output  symbol.  
Figures  17.21(a)  and  17.21(b)  are  alternative  
representations of the FSM in Figure 17.20.
6. Grammar   [1*, c13]
The  grammar  of  a  natural  language  defines  
whether  a  combination  of  words  makes  a  
valid  sentence.  Unlike  natural  languages,  a  
formal language is specified by a well-defined 
set  of  rules  for  syntaxes.  The  valid  sentences  
of  a  formal  language  can  be  described  by  a  
grammar  with  the  help  of  these  rules,  called  
production rules.
A formal language is a set of finite-length 
words  or  strings  over  some  finite  alphabet,  
and a grammar specifies the rules for forming 
those words or strings. The entire set of words 
that  are  valid  for  a  grammar  constitutes the 
language for the grammar. Thus, the grammar 
G is any compact, precise mathematical defi-
nition  of  a  language  L  as  opposed  to  a  raw  
listing  of  all  legal  sentences  or  examples  of  
those sentences in that language.
A grammar implies an algorithm that can 
generate  all  legal  sentences  of  the  language.  
There are different types of grammars.
A    phrase    structure    grammar    (PSG)    
or  Type-0  grammar  G  =  (V, T, S, P)  is  a  
4-tuple in which:
• V is the vocabulary — i.e., the set of words.
• T ⊆ V is a set of words called terminals. 
• S ∈ N   is   a   special   word   called   the   
start symbol.
• P is the set of production rules for substi-
tuting one sentence fragment for another.
There exists another set, N = V − T, of words 
called nonterminals.  The  nonterminals  repre-
sent concepts such as noun. Production rules are 
applied on strings containing nonterminals until 
no  more  nonterminal  symbols  are  present  in  
the string. The start symbol S is a nonterminal.
The   language   generated   by   a   formal   
grammar G, denoted by L(G), is the set of all 
strings over the set of alphabets V that can be 
generated,  starting  with  the  start  symbol,  by  
applying production rules until all the nonter-
minal symbols are replaced in the string.
For example, let G  =  ({S, A, a, b}, {a, b}, S, 
{S → aA, S → b, A → aa}).  Here,  the  set  of  
terminals  is  N  =  {S, A},  where  S  is  the  start  
symbol.  The  three  production  rules  for  the  
grammar  are  given  as  P1: S → aA; P2: S → 
b; P3: A → aa. 
Applying  the  production  rules  in  all  pos-
sible ways, the following words may be gener-
ated from the start symbol:
Current 
State
Input
InputInput
Current 
State
(a)(b)
Output
 f
State 
Tr ans g
01
32
32
0101
S₂,S₁,
32
S₂,S₂,
23
S₂,S₀,
S₂
S₁
S₀
S₂
S₂
S₁
S₁
32
S₂S₂
23
S₂S₀
S₀
F i g u re 17. 21. Tabular Representation of an FSM

17-14   SWEBOK
®
 GUIDE V4.0
S  → aA     (using     P1 on start symbol)
          → aaa    (using    P3)
S  → b  (using P2 on start symbol)
Nothing else can be derived from G. Thus, 
the  language  of  the  grammar  G  consists  of  
only two words: L(G) = {aaa, b}.
6.1.  Language Recognition 
Formal grammars can be classified according 
to  the  types  of  productions  they  allow.  The  
Chomsky   hierarchy   (introduced   by   Noam   
Chomsky  in  1956)  describes  such  a  classifi-
cation scheme. 
From  Figure  17.22,  we  can  infer  the  fol-
lowing about different grammars:
1. Every  regular  grammar  is  a  context-free  
grammar (CFG).
2. Every    CFG    is    a    context-sensitive    
grammar (CSG).
3. Every    CSG    is    a    phrase    structure    
grammar (PSG).
Context-Sensitive    Grammar    (CSG):    All    
fragments in the RHS are either longer than 
the  corresponding  fragments  in  the  LHS  or  
empty; in other words, if b → a, then |b| < |a| 
or a = φ. A formal language is context-sensi-
tive if a CSG generates it.
Context-Free  Grammar  (CFG):  All  frag-
ments  in  the  LHS  are  of  length  1;  in  other  
words, if A → a, then |A| = 1 for all A ∈ N. 
The  term  context-free  derives  from  the  fact  
that A can always be replaced by a, regardless 
of the  context  in  which  it  occurs.  A  formal  
language  is  context-free  if  a  CFG  generates  
it.  Context-free  languages  are  the  theoret-
ical basis for the syntax of most programming 
languages.
Regular  Grammar:  All  fragments  in  the  
RHS  are  either single  terminals  or  a  pair  
built by a terminal and a nonterminal; if A → 
a,  then  either  a ∈ T, a  =  cD,  or  a  =  Dc  for  c 
∈ T, D ∈ N.
If a  =  cD,  the  grammar  is  called  a  right 
linear grammar. On the other hand, if a = Dc, 
the  grammar  is  called  a  left  linear  grammar. 
Both the right linear and left linear grammars 
are regular or Type-3 grammars. 
The  language  L(G)  generated  by  a  regular  
grammar G is called a regular language.
A  regular  expression  A  is  a  string  (or  pat-
tern)  formed  from  the  following  pieces  of 
information: a ∈ Σ, the set of alphabets, ε, 0, 
and  the  operations  OR  (+),  PRODUCT  (•),  
and CONCATENATION (*). The language 
of G, L(G)  is  equal  to  all  those  strings  that  
match G, L(G) = {x ∈ Σ*|x matches G}.
For any a ∈ Σ, L(a) = a; L(ε) = {ε}; L(0) = 0.
+    functions   as   an   or,   L(A   +   B)   =   
L(A) ∪ L(B).
•    creates  a  product  structure,  L(AB)  =  
L(A) • L(B).
*   denotes  concatenation,  L(A*)  =  {x
1
x
2
 
... x
n
 | x
i
 ∈ L(A) and n ≥ 0}.
For  example,  the  regular  expression  (ab)* 
matches the set of strings: {ε, ab, abab, ababab, 
abababab,  ...}.  The  regular  expression  (aa)* 
matches the set of strings on one letter ‘a’ with 
even  length.  The  regular  expression  (aaa)*  +  
(aaaaa)*  matches  the  set  of  strings  of  length  
equal to a multiple of 3 or 5.
7. Number Theory   [1*, c4]
Number  theory  is  one  of  the  oldest  branches  
of  pure  mathematics  and  one  of  the  largest.  
It  concerns  questions  about  numbers,  usu-
ally  meaning  whole  numbers,  and  fractional  
Type 0: PSG
Type 1: CSG
Type 2: CFG
Type 3:
Regular Grammar
Figure 17.22. Chomsky Hierarchy of Grammars

MATHEMATICAL FOUNDATIONS   17-15
or  rational  numbers.  The  different  types  of  
numbers include integer, real number, natural 
number, complex number and rational number.
7.1.  Types of Numbers
Natural   Numbers:   This   group   of   numbers   
starts  at  1  and  continues  with  2,  3,  4,  5  and  
so on. Zero is not in this group. There are no 
negative or fractional numbers in the group of 
natural numbers. The common mathematical 
symbol for the set of all natural numbers is N.
Whole  Numbers:  This  group  has  all  natural  
numbers plus the number 0.
Unfortunately,  not  everyone  accepts  the  
above  definitions  of  natural  and  whole  num-
bers. There seems to be no general agreement 
about whether to include 0 in the set of nat-
ural numbers. Many mathematicians consider 
that, in Europe, the sequence of natural num-
bers  traditionally  started  with  1  (0  was  not  
even considered a number by the Greeks). In 
the  19th  century,  set  theoreticians  and  other  
mathematicians   started   the   convention   of   
including 0 in the set of natural numbers.
Integers:  This  group  includes  all  the  whole  
numbers  and  their  negatives.  The  common  
mathematical symbol for the set of all integers 
is Z — i.e., Z = {..., −3, −2, −1, 0, 1, 2, 3, ...}.
Rational   Numbers:   These   numbers   can   
be  expressed  as  a  ratio  of  two  integers.  The  
common  symbol  for  the  set  of  all  rational  
numbers is Q.
Rational  numbers  may  be  classified  into  
three types based on how the decimals act: (1) 
decimals  do  not  exist  (e.g.,  15);  or  (2)  deci-
mals do exist, and they terminate (e.g., 15.6); 
(3)  decimals  do  exist,  and  they  repeat  with  a  
pattern, as in 1.666... (which is 5/3). 
Irrational  Numbers:  These  numbers  cannot  
be  expressed  as  an  integer  divided  by  an  
integer.  These  numbers  have  decimals  that  
never terminate and never repeat with a pat-
tern (e.g., PI or √2).
Real  Numbers:  This  group  comprises  all  
rational and irrational numbers. The numbers 
algebra  uses  are  real  numbers.  The  common  
mathematical  symbol  for  the  set  of  all  real  
numbers is R.
Imaginary  Numbers:  These  are  all  based  
on  the  imaginary  number  i.  This  imaginary  
number is equal to the square root of −1. Any 
real  number  multiple  of  i  is  an  imaginary  
number (e.g., i, 5i, 3.2i, −2.6i).
Complex   Numbers:   A   complex   number 
is  a  combination  of  a  real  number  and  an  
imaginary  number  in  the  form  a  +  bi.  The  
real part is a, and b is called the imaginary 
part.  The  common  mathematical  symbol  
for the set of all complex numbers is C. For 
example, 2 + 3i, 3 − 5i, 7.3 + 0i, and 0 + 5i 
are complex numbers, but the latter two are 
equivalent  to  real  numbers.  7.3  +  0i  is  the  
same as the real number 7.3. Similarly, 0 + 
5i is same as the imaginary number 5i.  All  
real  numbers  are  complex  numbers  with  0  
for  the  imaginary  part,  and  all  imaginary  
numbers  are  complex  numbers  with  0  for  
the real part.
7.2.  Divisibility
Elementary  number  theory  involves  divisi-
bility  among  integers.  Let  a, b ∈  Z  with  a 
≠ 0. The expression a|b says that a divides b 
if ∃c ∈ Z, and the expression b = ac  means  
that  there  is  an  integer  c  such  that  c  times  
a  equals  b.  For  example,  3|−12  is  true,  but  
3|7 is false.
If a divides b, then we say that a is a factor of 
b or a is a divisor of b, and b is a multiple of a.
b is even if and only if 2|b. 
Let a,  d  ∈  Z  with  d  >  1.  Then  a  mod  d 
denotes  the  remainder  r  from  the  division  
algorithm with dividend a and divisor d, i.e., 
the remainder when a is divided by d. We can 
compute (a mod d) by a − d* ⎣a /d⎦, where ⎣a /d⎦ 
represents the floor of the real number.
Let Z
+
 = {n ∈ Z | n > 0} and a, b ∈ Z, m ∈ 
Z
+
. Then a is congruent to b modulo m, written 
as a ≡ b (mod m), if and only if m | a − b.
Alternately, a is congruent to b modulo m if 
and only if (a − b) mod m = 0.
7.3.  Prime Number
An integer p > 1 is prime if and only if it is not 
the  product  of  any  two  integers  greater  than  

17-16   SWEBOK
®
 GUIDE V4.0
1; i.e., p is prime if p > 1 ∧ ∃ ¬ a, b ∈ N: a > 1, 
b > 1, a * b = p.
The  only  positive  factors  of  a  prime  p  are  
1  and  p  itself.  The  numbers  2,  13,  29,  61,  
etc.,  are  prime  numbers.  Nonprime  integers  
greater than 1 are called composite numbers. A 
composite number may be composed by mul-
tiplying two integers greater than 1.
There  are  many  interesting  applications 
of  prime  numbers;  among  them  is  the  pub-
lic-key  cryptography scheme,  which  involves  
the  exchange  of  public  keys  containing  the  
product p*q of two random large primes p and 
q (a private key) that must be kept secret by a 
given pa r t y.
7.4.  Greatest Common Divisor
The greatest common divisor gcd(a, b) of inte-
gers a, b  is  the  greatest  integer  d  that  is  a  
divisor both of a and of b — i.e., 
d = gcd (a, b) for max (d: d|a ∧ d|b).
For example, gcd(24, 36) = 12.
Integers a  and  b  are  called  relatively  prime 
or coprime  if  and  only  if  their  GCD  is  1.  
For  example,  neither  35  nor  6  is  prime,  but  
they   are   coprime,   as   these   two   numbers   
have  no  common  factors  greater  than  1,  so  
their GCD is 1.
A set of integers X = {i
1
, i
2
, ...} is relatively 
prime  if  all  possible  pairs  i
h
, i
k
, h  ≠  k  drawn  
from the set X are relatively prime.
8. Basics of Counting  [1*, c6]
The sum rule states that if a task t
1 
can be done 
in n
1
 ways and a second task t
2 
can be done in 
n
2
 ways, and if these tasks cannot be done at 
the same time, then there are n
1 
+ n
2
 ways to 
do either task.
•    If A  and  B  are  disjoint  sets,  then  |A ∪ 
B|=|A| + |B|.
•    In  general  if  A1, A2,  ...,  An  are  disjoint  
sets, then |A1 ∪ A2 ∪ ... ∪ An| = |A1| + 
|A2| + ... + |An|.
If 200 athletes do sprint events and 30 ath-
letes participate in the long jump event, then 
how many ways are there to pick one athlete 
who is either a sprinter or a long jumper?
Using  the  sum  rule,  the  answer  would  be  
200 + 30 = 230.
The product  rule  states  that    if  a  task  t
1 
can 
be done in n
1
 ways and a second task t
2 
can be 
done  in  n
2
  ways  after  the  first  task  has  been  
done,  then  there  are  n
1
  *  n
2
  ways  to  perform  
the procedure.
•    If A and B are disjoint sets, then |A × B| 
= |A| * |B|.
•    In general, if A1, A2, ..., An  are  disjoint  
sets,  then  |A1  ×  A2  ×  ...  ×  An|  =  |A1|  *  
|A2| * .... * |An|.
If 200 athletes do sprint events and 30 ath-
letes participate in the long jump event, then 
how  many  ways  are  there  to  pick  two  ath-
letes so that one is a sprinter and the other is 
a long jumper?
Using the  product  rule,  the  answer  would  
be 200 * 30 = 6,000.
The principle of inclusion-exclusion states that 
if a task t
1 
can be done in n
1
 ways and a second 
task t
2 
can be done in n
2
 ways at the same time 
with t
1
,  then  to  find  the  total  number of  ways  
the two tasks can be done, one must subtract the 
number of ways to do both tasks from n
1
 + n
2
.
•    If A and B are not disjoint, |A ∪ B| = |A| 
+ |B| − |A ∩ B|.
In  other  words,  the  principle  of  inclu-
sion-exclusion aims to ensure that the objects 
in the intersection of two sets are not counted 
more than once.
Recursion  is  the  general  term  for  defining  
an  object  in  terms  of  itself.  There  are  recur-
sive algorithms, recursively defined functions, 
relations, sets, etc.
A recursive function is a function that calls 
itself. For example, we can define f (n) = 3 * f(n 
− 1) for all n ∈ N and n ≠ 0 and f(0) = 5.
An  algorithm  is  recursive  if  it  solves  a  
problem  by  reducing  it  to  an  instance  of  the  
same problem with a smaller input.

MATHEMATICAL FOUNDATIONS   17-17
A phenomenon is said to be random if indi-
vidual  outcomes  are  uncertain  but  the  long-
term  pattern  of  many  individual  outcomes  is  
predictable.
The   probability   of   any   outcome   for   a   
random  phenomenon  is  the  proportion  of  
times the outcome would occur in a very long 
series of repetitions.
The  probability  P(A)  of  any  event  A  satis-
fies 0 ≤ P(A) ≤ 1. Any probability is a number 
between  0  and  1.  If  S  is  the  sample  space  in  
a  probability  model,  then  P(S)  =  1.  All  pos-
sible  outcomes  together  must  have  a  proba-
bility of 1.
Tw o   events are disjoint if they have no out-
comes  in  common  and  so  can  never  occur  
together.  If  A  and  B  are  two  disjoint  events,  
P(A or B) = P(A) + P(B). This is known as the 
addition rule for disjoint events.
If two events have no outcomes in common, 
the probability that one or the other occurs is 
the sum of their individual probabilities.
Permutation  is  an  arrangement  of  objects  
in  which  the  order  matters  without  repeti-
tion. For example, one can choose r objects in 
a particular order from a total of n objects by 
using 
n
P
r
 ways, where 
n
p
r
 = n! / (n − r)!. Various 
notations, such as 
n
P
r
 and P(n, r), are used to 
represent the number of permutations of a set 
of n objects taken r at a time.
Combination  is  a  selection  of  objects  in  
which the order does not matter without rep-
etition.  This  is  different  from  a  permutation  
because the order does not matter. If only the 
order  is  changed  (and  not  the  members),  no  
new  combination  is  formed.  One  can  choose  
r objects in any order from a total of n objects 
using 
n
C
r
 ways, where 
n
C
r
 = n! / [r! * (n − r)!].
9. Discrete Probability  [1*, c7]
Probability is the mathematical description of 
randomness.  Basic  definitions  of  probability  
and randomness are provided in the previous 
section.  Here,  we  start  with  the  concepts  
behind  probability  distribution  and  discrete  
probabilit y.
A probability    model    is    a    mathemat-
ical  description  of  a  random  phenomenon  
consisting of two parts: a sample space S and 
a way of assigning probabilities to events. The 
sample  space  defines  the  set  of  all  possible  
outcomes,  whereas  an  event  is  a  subset  of  a  
sample space representing a possible outcome 
or a set of outcomes.
A random variable is a function or rule that 
assigns a number to each outcome. Basically, 
it  is  a  symbol  that  represents  the  outcome  of  
an  experiment.  For  example,  X  could  be  the  
number of heads when the experiment is flip-
ping  a  coin  n  times.  Similarly,  S  could  be  
the  speed  of  a  passing  car  as  measured  on  a  
radar detector.
The  values  for  a  random  variable  could  
be discrete or continuous, depending on the 
experiment. A discrete random variable can 
hold  all  possible  values  (i.e.,  can  represent  
all possible outcomes) without missing any, 
although  it  might  take  an  infinite  amount  
of  time.  A  continuous  random  variable  is  
used  to  measure  an  uncountable  number  
of  values  even  when  an  infinite  amount  of  
time is given.
For  example,  if  random  variable  X  rep-
resents  an  outcome  that  is  a  real  number  
between  1  and  100,  then  X  may  have  an  
infinite number of values. Therefore, one can 
never list all possible outcomes for X, even if 
an  infinite  amount  of  time  is  allowed.  Here,  
X  is  a  continuous  random  variable.  On  the  
other hand, for the same interval of 1 to 100, 
another random variable Y can be used to list 
all integer values in the range. Here, Y is a dis-
crete random variable.
An  uppercase  letter,  say  X,  will  represent  
the name of the random variable. Its lowercase 
counterpart, x, will represent the value of the 
random variable.
The probability that the random variable X 
will equal x is: 
P(X = x) or, more simply, P(x).
A    Probability    Distribution    (Density)    
Function  (PDF)  is  a  table,  formula  or  graph  
that  describes  the  values  of  a  random  vari-
able  and  the  probabilities  associated  with  
these   values.   Probabilities   associated   with   

17-18   SWEBOK
®
 GUIDE V4.0
discrete  random  variables  have  the  following  
properties:
•    0 ≤ P(x) ≤ 1 for all x
•     ΣP(x) = 1
A discrete probability distribution can be rep-
resented as a discrete random variable.
The mean μ of a probability distribution model 
is the sum of the product terms for individual 
events and their outcome probability. In other 
words,  for  the  possible  outcomes  x
1
, x
2
,  ...,  
x
n
  in  a  sample  space  S  if  p
k
  is  the  probability  
of  outcome  x
k
,  the  mean  of  this  probability  
would be μ = x
1
p
1
 + x
2
p
2
 + ... + x
n
p
n
. The mean 
of the probability density for the distribution 
in Figure 17.23 would be the following:
   1 * (1/6) + 2 * (1/6) + 3 * (1/6) + 4 * (1/6) + 5 *  
    (1/6) + 6 * (1/6) 
   = 21 * (1/6) = 3.5
Here, the sample space refers to the set of 
all possible outcomes.
The variance σ
2
 of a discrete probability model 
is σ
2
 = (x
1
 – μ)
2
p
1
 + (x
2
 – μ)
2
p
2
 + ... + (x
k
 – μ)
2
p
k
. 
The standard deviation, σ, is the square root of 
the variance. For the probability distribution 
in Figure 17.23, the variation σ
2
 would be the 
following:
   σ
2
  =  [(1  –  3.5)
2
  *  (1/6)  +  (2  –  3.5)
2
  *  (1/6)   
    + (3 – 3.5)
2
 * (1/6) + (4 - 3.5)
2
 * (1/6) + (5  
    – 3.5)
2
 * (1/6) + (6 – 3.5)
2
 * (1 /6)]
   =   (6.25   +   2.25   +   0.25   +   0.5   +   2.25    
    + 6.25) * (1/6) 
   = 17.5 * (1/6) 
   = 2.90
∴ standard deviation s = 1.70
These  numbers  aim  to  derive  the  average  
value from repeated experiments. This is based 
on the most important principle in probability 
— i.e., the average value from repeated exper-
iments  is  likely  to  be  close  to  the  expected  
value   of   one   experiment.   Moreover,   the   
average value is more likely to be closer to the 
expected  value  of  any  one  experiment  as  the  
number of experiments increases.
10. Numerical Precision, Accuracy, and Error 
 [2*, c1]
The  main  goal  of  numerical  analysis  is  to  
develop  efficient  algorithms  for  computing  
precise numerical values of functions, as well 
as finding solutions to algebraic and differen-
tial equations, optimization problems, etc.
Digital  computers  can  store  finite  num-
bers  only.  A  digital  computer  cannot  repre-
sent  any  infinitely  large  number  —  be  it  an  
integer, rational number, or any real or com-
plex number [see section 7, Number Theory]. 
The  mathematics  of  approximation  is  critical  
for working with numbers in the finite range 
a computer can handle.
Each  number  in  a  computer  is  assigned  a  
location (e.g., an address or register) and con-
sists of a quantity of binary digits, or bits. A 
k-bit location can store any of N = 2
k
 different 
numbers.  A  32-bit  location  can  store  any  of  
N  =  2
32
  ≈  4.3  ×  10
9
 different numbers,  while  
a  64-bit  location  can  store  any  of  N  =  2
64
  ≈  
1.84  ×  10
19
 different numbers.  The  question  
is  how  to  distribute  those  numbers  for  max-
imum  efficiency  and  accuracy  in  practical  
computations.
One  choice  is  to  distribute  the  numbers  
evenly,  leading  to  fixed-point  arithmetic.  In  
this  system,  the  first  bit  represents  the  sign,  
and  the  remaining  bits  represent  magnitude.  
The decimal point — more appropriately, the 
binary  point  (the  transition  between  whole  
and  fractional  values)  —  can  be  anywhere.  
Integer  numbers  are  represented  by  placing  
the  binary  point  immediately  to  the  right  of  
the  least  significant  bit,  and  integer  num-
bers  between  −2
k−1
−1  and  2
k−1
  can  be  stored.  
Placing the binary point to the left of the least 
X
123456
P(x)
1/61/61/61/61/61/6
Figure 17.23. A Discrete Probability Function for a 
Rolling Die

MATHEMATICAL FOUNDATIONS   17-19
significant bit allows non-integer values to be 
represented.
Another  choice  is  to  space  the  numbers  
closely  together,  say  with  a  uniform  gap  of  
2
−n
,  and  thereby  distribute  the  total  N  num-
bers uniformly over the interval −2
−n−1
N < x ≤ 
2
−n−1
N.  Real  numbers  lying  between  the  gaps  
are  represented  by  either  rounding  (meaning  
the  closest  exact  representative)  or  chopping 
(meaning the exact representative immediately 
below — or above, if negative — the number). 
Numbers  outside  the  range  must  be  rep-
resented  by  the  largest  (or  largest  negative)  
number that can be represented. This becomes a 
symbol for overflow, which occurs when a com-
putation produces a value outside the range.
When processing speed is a significant bot-
tleneck, fixed-point representations can be an 
attractive  and  faster  alternative  to  the  more  
cumbersome  floating-point  arithmetic  most  
commonly used in practice.
Accuracy   and   precision   are   important   
terms in numerical analysis. 
Accuracy is the closeness with which a mea-
sured  or  computed  value  agrees  with  the  
true value.
Precision,  on  the  other  hand,  is  the  close-
ness  with  which  two  or  more  measured  or  
computed values for the same thing agree. In 
other  words,  precision  is  the  closeness  with  
which a number represents an exact value.
Let x  be  a  real  number,  and  let  x*  be  an  
approximation. The absolute error in the approx-
imation x* ≈ x is defined as | x* − x |. The relative 
error is defined as the ratio of the absolute error 
to the size of x — i.e., |x* − x| / | x | — which 
assumes x  ≠  0;  otherwise,  relative  error  is  not  
defined. For example, 1,000,000 is an approx-
imation of 1,000,001 with an absolute error of 
1 and a relative error of 10
−6
, whereas 10 is an 
approximation  of  11  with  an  absolute  error  of  
1 and a relative error of 0.1. Typically, relative 
error is more intuitive and the preferred deter-
miner of the size of the error. The present con-
vention is that errors are always ≥ 0 and are = 0 
if and only if the approximation is exact.
An approximation x* has k significant dec-
imal  digits  if  its  relative  error  is  <  5  ×  10
−
k−1
.  This  means  that  the  first  k  digits  of  x* 
following its first nonzero digit are the same 
as those of x.
Significant digits are the digits of a number 
that  are  known  to  be  correct.  In  a  measure-
ment,  one  uncertain  digit  is  included.  For  
example, measurement of length with a ruler 
of 15.5 mm with ±0.5 mm maximum allow-
able error has two significant digits, whereas a 
measurement of the same length using a cal-
iper  and  recorded  as  15.47  mm  with  ±0.01  
mm maximum allowable error has three sig-
nificant digits.
11. Algebraic Structures
This   section   introduces   a   few   representa-
tions  used  in  higher  algebra.  An  algebraic  
structure  consists  of  one  or  two  sets  closed  
under  some  operations  and  satisfying  several  
axioms, including none. For example, group, 
monoid, ring and lattice are examples of alge-
braic structures. Group, monoid and ring are 
defined in this section. 
11.1. Group
A  set  S  closed  under  a  binary  operation  •  
forms a group if the binary operation satisfies 
the following four criteria:
•    Associative: ∀a, b, c ∈ S, the equation (a • 
b) • c = a • (b • c) holds.
•    Identity: There exists an identity element 
I ∈ S such that for all a ∈ S, I • a = a • I = a.
•    Inverse:  Every  element  a ∈  S  has  an  
inverse a′ ∈ S with respect to the binary 
operation,  i.e.,  a  •  a′ = I;  for  example,  
the  set  of  integers  Z  with  respect  to  the  
addition  operation  is  a  group.  The  iden-
tity  element  of  the  set  is  0  for  the  addi-
tion operation. In ∀x ∈ Z, the inverse of x 
would be –x, which is also included in Z.
•    Closure property: ∀a, b ∈ S, the result of 
the operation a • b ∈ S.
A group that is commutative i.e., a • b = b • 
a is known as a commutative or Abelian group. 
The  set  of  natural  numbers  N  (with  the  
operation of addition) is not a group because 

17-20   SWEBOK
®
 GUIDE V4.0
there is no inverse for any x > 0 in the set of 
natural  numbers.  (The  third  criterion,  the  
inverse criterion, is violated.) However, the set 
of natural numbers has some structure.
Sets with an associative operation (the first 
criterion) are called semigroups; if they also have 
an identity element (the second criterion), they 
are called monoids. The set of natural numbers 
under  addition  is  an  example  of  a  monoid,  a  
structure that  is  not  quite  a  group  because  it  
is missing the requirement that every element 
have an inverse under the operation.
A  monoid  is  a  set  S that  is  closed  under  a  
single  associative  binary  operation  •  and  has  
an identity element I ∈ S such that for all a ∈ 
S, I • a = a • I = a. A monoid must contain at 
least one element. The set of natural numbers 
N  forms  a  commutative  monoid  under  addi-
tion with identity element 0. The same set of 
natural numbers N also forms a monoid under 
multiplication  with  identity  element  1.  The  
set  of  positive  integers  P  forms  a  commuta-
tive  monoid  under  multiplication  with  iden-
tity element 1.
It  may  be  noted  that,  unlike  those  in  a  
group,  elements  of  a  monoid  need  not  have  
inverses.  A  monoid  can  also  be  considered  a  
semigroup with an identity element. 
A subgroup  is  a  group  H contained within 
a bigger group, G, such that the identity ele-
ment  of  G  is  contained in H,  and  whenever  
h
1
  and  h
2
  are  contained  in  H,  so  are  h
1
  •  h
2
 
and h
1
−1
.
 
Thus,  the  elements  of  H,  equipped  
with  the  group  operation  on  G  restricted  to  
H, form a group.
Given any subset S of a group G, the sub-
group  generated  by  S  consists  of  products  
of  elements  of  S  and  their  inverses.  It  is  the  
smallest  subgroup  of  G  containing  S.  For  
example,  let  G  be  the  Abelian  group  whose  
elements  are  G =  {0,  2,  4,  6,  1,  3,  5,  7}  and  
whose group operation is addition modulo 8. 
This group has a pair of nontrivial subgroups: 
J = {0, 4} and H = {0, 2, 4, 6}, where J is also a 
subgroup of H. 
In  group  theory,  a  cyclic  group is  a  group  
that  can  be  generated  by  a  single  element,  
in the sense that the group has an element a 
(called  the  generator  of  the  group)  such  that,  
when this element is written multiplicatively, 
every element of the group is a power of a.
A  group  G  is  cyclic  if  G  =  {a
n
  for  any  
integer n}. 
Since any group generated by an element in 
a group is a subgroup of that group, showing 
that the only subgroup of a group G that con-
tains a  is  G  itself  suffices  to  show  that G  is  
cyclic. For example, the group G = {0, 2, 4, 6, 
1, 3, 5, 7}, with respect to addition modulo 8 
operation,  is  cyclic.  The  subgroups  J =  {0,  4}  
and H = {0, 2, 4, 6} are also cyclic.
11.2. Ring
If  we  take  an  Abelian  group  and  define  a  
second  operation  on  it,  a  new  structure  is  
found  that  is  different  from  just  a  group.  If  
this second operation is associative and is dis-
tributive over the first, then we have a ring. 
A ring is a triple of the form (S, +, •), where 
(S, +) is an Abelian group, (S, •) is a semigroup 
and • is distributive over +; i.e., ∀ a, b, c ∈ S, 
the equation a • (b + c) = (a • b) + (a • c) holds. 
Further, if • is commutative, then the ring is 
said to be commutative. If there is an identity 
element  for  the  •  operation,  then  the  ring  is  
said to have an identity.
As  an  example,  (Z,  +,  *),  i.e.,  the  set  of  
integers  Z  with  the  usual  addition  and  mul-
tiplication  operations,  is  a  ring.  As  (Z,  *)  is  
commutative,   this   ring   is   a   commutative   
or  Abelian  ring.  The  ring  has  1  as  its  iden-
tity element.
Note  that  the  second  operation  may  not  
have an identity element, nor do we need to 
find an inverse for every element with respect 
to this second operation. As for what distrib-
utive  means,  intuitively,  it  is  what  we  do  in  
elementary  mathematics  when  we  perform  
the  following  operation:  a  *  (b  +  c)  =  (a  *  b) 
+ (a * c).
A field  is  a  ring  for  which  the  elements  of  
the  set,  excluding  0,  form  an  Abelian  group  
with the second operation. A simple example 
of  a  field  is  the  field  of  rational  numbers  (R,  
+,  *)  with  the  usual  addition  and  multiplica-
tion operations. The numbers are of the form 
a/b ∈ R, where a, b are integers and b ≠ 0. The 

MATHEMATICAL FOUNDATIONS   17-21
additive  inverse  of  such  a  fraction  is  simply  
−a/b, and the multiplicative inverse is b/a, pro-
vided that a ≠ 0.
12. Engineering Calculus
Calculus is a branch of mathematics that deals 
with  study  of  continuous  transition,  deriva-
tives and integrals of functions using methods 
originally  based  on  the  summation  of  infin-
itesimal  differences.  Engineering  Calculus  
focuses  on  learning  analytical  geometry  and  
vectors for engineering applications.  
Engineering     Calculus     includes     the     
learning of the following:
•    Limits
•    Continuity
•    Differentiation
•    Integration
•    Transcendental functions
•    Vector calculus
Limits are the building blocks of Calculus.  
For  a  function  f(x),  the  limit  of  the  function  
at a point ‘a’ is the value the function achieves 
at a point ‘a’.
L = lim 
x->a
 f(x) 
A function is said to be Continuous on the 
interval [a, b] if it is continuous at each point 
in the interval.
Lim  f(x) = f (a)
x->a 
The two major elements of calculus are differ-
ential calculus and integral calculus.
• Differential   calculus   analyzes   the   rate   
of   change   of   one   quantity   in   rela-
tion  to  the  rate  of  change  of  another.  
Geometrically, it is the slope of the line 
tangent to the graph of the function. The 
rate  of  change  of  x  with  respect  to  y  is  
expressed as dx /dy.
• Integral calculus analyzes such concepts as 
the area or volume enclosed by a function.
A  transcendental  function,  in  contrast  to  
an algebraic function, is an analytic function 
that does not satisfy a polynomial equation.
Vector  calculus  deals  with  the  differentia-
tion  and  integration  of  vector  fields  in  the  
three-dimensional Euclidean space.
Software   engineers   are   encouraged   to   
learn Engineering Calculus with case studies.  
These concepts are required for analysing and 
extrapolating data. 
13. New Advancements
13.1. Computational Neurosciences
Computational  Neurosciences  is  a  branch  of  
Neurosciences that uses mathematical models, 
computer simulations and brain abstraction to 
understand  and  analyze  cognitive  abilities  of  
the nervous systems. This enables the learning 
of  control  theory,  cybernetics,  quantitative  
psychology, machine learning, artificial intel-
ligence,  creative  /  imagination  and  connec-
tionism among others.
The  central  assumption  of  computational  
neuroscience is that the brain computes. What 
does  that  mean?  Generally  speaking,  a  com-
puter  is  a  dynamic  system  whose  state  vari-
ables  encode  information  about  the  external  
world. In short, computation equals coding plus 
dynamics.  Some  neuroscientists  study  the  way  
that  information  is  encoded  in  neural  activity  
and   other   dynamic   variables   of   the   brain.   
Others  try  to  characterize  how  these  dynamic  
variables evolve over time. The study of neural 
dynamics  can  be  further  subdivided  into  two  
separate strands. One tradition, exemplified by 
the work of Hodgkin and Huxley, focuses on the 
biophysics of single neurons. The other focuses 
on the dynamics of networks, concerning itself 
with  phenomena  that  emerge  from  the  inter-
actions  between  neurons.  Therefore  computa-
tional  neuroscience  can  be  divided  into  three  
sub-specialties:  neural  coding,  biophysics  of  
neurons, and neural networks.
13.2. Genomics
The in-silico analysis of nucleotide sequences 

17-22   SWEBOK
®
 GUIDE V4.0
of  chromosome(s)  from  a  given  organism  is  
called  “genome”.  The  genome  is  the  genetic  
material   of   living   organisms,   containing   
hereditary characteristics. It is constituted by 
DNA.  Genomic  studies  aim  to  understand  
how genes and genetic information are orga-
nized within the genome and how this orga-
nization determines their function.
Genomics   deals   with   structure,   func-
tion,  mapping,  evolution  and  editing  of  
genomes,  including  sequencing  and  anal-
ysis of genomes.
Significant research works are being under-
taken  in  the  areas  of  preventive  and  thera-
peutic  healthcare,  especially  in  the  area  of  
detection,  analysis  and  repair  of  genetic  dis-
orders.    These  include  genome  data  security,  
genome  data  sharing,  efficiency  in  genome  
data analysis among others.
Genomics  encompasses  a  variety  of  tech-
niques   and   approaches,   including   DNA   
sequencing,  bioinformatic  analysis,  study  of  
genetic  variation,  computational  modeling,  
and much more. 
The   advancement   of   DNA   sequencing   
technologies  and  bioinformatic  analysis  has  
significantly  propelled  progress  in  genomics,  
enabling  detailed  study  of  genomes  across  
various organisms.
Due  to  the  large  amount  of  data  repre-
sented by nucleotide sequences obtained from 
genome sequencing, informatics is required to 
handle  these  data.  And  the  development  of  
specific software for the field relies heavily on 
Software Engineering.
MATRIX OF TOPICS VS.  
REFERENCE MATERIAL
Rosen 2018 [1*]Cheney and Kincaid 2020 [2*]
1. Basic Logicc1
2. Proof Techniquesc1
3. Set, Relation, Functionc2
4. Graph and Treec10, c11
5.    Finite State Machinec13
6. Grammarc13
7.    Number Theoryc4
8. Basics of Countingc6
9. Discrete Probabilityc7
10.  Numerical Precision, 
Accuracy and Error
c2
11.  Algebraic Structures
12. Calculus
REFERENCES
[1*] K. Rosen, Discrete Mathematics and Its 
Applications, 8th ed., McGraw-Hill, 2018.
[2*] E.W. Cheney and D.R. Kincaid, 
Numerical Mathematics and Computing, 
7th ed., Addison Wesley, 2020.

18-1 
CHAPTER 18
Engineering Foundations
ACRONYMS
CADComputer-Aided Design
CMMICapability Maturity Model Integration
PDFProbability Density Function
PMFProbability Mass Function
RCARoot Cause Analysis
SDLCSoftware Development Life Cycle
INTRODUCTION
The  Institute  of  Electrical  and  Electronics  
Engineers  (IEEE)  defines  engineering  as  “the  
application of a systematic, disciplined, quanti-
fiable  approach  to  structures,  machines,  prod-
ucts, systems or processes” [1]. As the theory and 
the practice of software engineering mature, it is 
increasingly apparent that software engineering 
as a discipline is based on skills and knowledge 
that are common to all engineering disciplines. 
This knowledge area (KA) explores engineering 
foundations pertinent to other engineering dis-
ciplines that also apply to software engineering. 
The  focus  is  on  covering  topics  that  support  
other  KAs  while  minimizing  duplication  of  
content covered elsewhere in this Guide. 
BREAKDOWN OF TOPICS FOR 
ENGINEERING FOUNDATIONS
The breakdown of topics for the Engineering 
Foundations KA is shown in Figure 18.1.
1. The Engineering Process [2*, c4]
The engineering process, which is common to 
all engineering disciplines, is discussed more 
fully in the Software Engineering Economics 
KA. (Refer to that chapter for more informa-
tion.) A brief, high-level summary is included 
here. Figure 18.2 shows the process flow.
The engineering process is necessarily iter-
ative; knowledge gained at any point may be 
relevant  to  earlier  steps,  triggering  iteration.  
These steps are briefly defined below:
•    Understand     the     real     problem     —     
Engineering begins when a need is recog-
nized and no existing solution meets that 
need.  However,  the  problem  that  needs  
to  be  solved  is  not  always  the  problem  
engineers  are  asked  to  solve.  Use  root  
cause analysis techniques (discussed later 
in  this  KA)  to  discover  the  underlying  
problem needing a solution.
•    Define     the     selection     criteria     —     
Engineering   decisions   must   consider   
various  factors;  for  example,  they  must  
consider  financial  criteria,  as  discussed  
in  the  Software  Engineering  Economics  
KA. Be sure to identify all relevant selec-
tion criteria.
•    Identify  all  reasonable,  technically  fea-
sible  solutions  —  The  best  solution  is  
rarely  the  first  solution  that  comes  to  
mind. Therefore, consider multiple tech-
nically  feasible  solutions  to  ensure  that  
the  optimal  solution  is  among  the  set  
considered.
•    Evaluate each solution against the selec-
tion criteria — Determine how well each 
technically  feasible  solution  satisfies  the  
need  while  meeting  the  various  criteria  
(for example, financial criteria).
•    Select  the  preferred  option  —  Identify  
which  technically  feasible  solution  best  
satisfies the selection criteria.

18-2   SWEBOK
®
 GUIDE V4.0
•    Monitor the performance of the selected 
solution — The engineering process nec-
essarily  depends  on  estimates,  and  those  
estimates  can  be  wrong.  Therefore,  it  is  
essential to evaluate the selected alterna-
tive’s real-world performance and, if nec-
essary (and possible), decide whether one 
of the other alternatives might be better.
Much   of   the   rest   of   this   KA   elabo-
rates  on  details  of  this  higher-level  engi-
neering process.
2. Engineering Design [3*, c1s2-s4]
A  product’s  design  will  affect  or  even  deter-
mine its life cycle costs. This is true for man-
ufactured  products  as  well  as  for  software.  
Software  design  is  guided  by  the  features  to  
be implemented and the quality attributes to 
be achieved. In the software engineering con-
text, “design” has a particular meaning; while 
there are commonalities between engineering 
design  as  discussed  in  this  section  and  soft-
ware  engineering  design  as  discussed  in  the  
Software Architecture KA and the Software 
Design  KA,  there  are  also  many  differences.  
For example, the scope of engineering design 
is generally viewed as much broader than that 
of software design.
Many disciplines involve solving problems 
for  which  there  is  a  single  correct  solution.  
In  engineering,  most  problems  have  many  
solutions,  and  the  focus  is  on  finding  a  fea-
sible solution (among many alternatives) that 
best  meets  the  needs  presented,  economi-
cally. In business, where the goal may be to 
foster innovation in the marketplace, product 
definitions may derive from a business case. 
Whichever  is  the  origin,  possible  solutions  
are  often  constrained  by  explicitly  imposed  
limitations such as cost, available resources, 
and the state of discipline or domain knowl-
edge. In engineering problems, implicit con-
straints  (such  as  the  physical  properties  of  
materials  or  the  laws  of  physics)  sometimes  
restrict  the  set  of  feasible  solutions  for  a  
given problem.
2.1.  Engineering Design in Engineering 
Education
Various  engineering  education  accreditation  
bodies,  including  the  Canadian  Engineering  
Accreditation  Board  and  the  Accreditation  
Board   for   Engineering   and   Technology   
(ABET),  place  great  value  on  engineering  
design,  as  evidenced  by  their  high  expecta-
tions in this area. 
The  Canadian  Engineering  Accreditation  
Board requires specified levels of engineering 
design  experience  and  coursework  for  engi-
neering students and certain qualifications for 
the  faculty  members  who  teach  such  course-
work or supervise design projects. The organi-
zation’s accreditation criteria state: 
Engineering
Foundations
e
Engineering
Process
Engineering
Design
Abstraction 
and
Encapsulation
Empirical
Methods and
Experimental
Techniques
Statistical
Analysis
Modeling,
Simulation,
and 
Prototyping
Engineering
Design in
Engineering
Education
Design as a
Problem-
Solving
Activity
Designed
Experiment
Observational
Study
Retrospective
Study
Levels of
Abstraction
Encapsulation
Hierarchy
Alternate
Abstractions
Unit of 
Analysis
(Sampling 
Units),
Population, 
and Sample
Correlation and
Regression
Measurement
Levels (Scales) of
Measurement
Implications of
Measurement
eory on
Programming
Languages
Direct and
Derived Measures
Reliability and 
Validity
Assessing
Reliability
Goal-Question-
Metric Paradigm:
Why Measure?
Root Cause
Analysis
Root Cause
Analysis Techniques
Root Cause-
Based
Improvement
Industry 4.0 
and Software
Engineering
Standards
Modeling
Simulation
Prototyping
Figure 18.1. Breakdown of Topics for the Engineering Foundations KA

ENGINEERING FOUNDATIONS   18-3
Design: An ability to design solutions for com-
plex, open-ended engineering problems and to 
design  systems,  components  or  processes  that  
meet  specified  needs  with  appropriate  atten-
tion to health and safety risks, applicable stan-
dards, and economic, environmental, cultural, 
and societal considerations [4, p7].
Similarly,    ABET    defines    engineering    
design as follows:
...  a  process  of  devising  a  system,  component,  
or  process  to  meet  desired  needs  and  specifica-
tions within constraints. It is an iterative, cre-
ative,  decision-making  process  in  which  the  
basic  sciences,  mathematics,  and  engineering  
sciences  are  applied  to  convert  resources  into  
solutions [5, p7].
Thus,  engineering  design  is  vital  to  the  
training  and  education  of  all  engineers.  The  
rest of this section focuses on various aspects 
of engineering design.
2.2.  Design as a Problem-Solving Activity  
 [3*, c1s4, c2s1, c3s3] [6*, c5s1]
Engineering   design   is   primarily   a   prob-
lem-solving  activity.  Finding  a  solution  is  
particularly challenging because design prob-
lems  tend  to  be  open-ended  and  vaguely  
defined, and there are usually several ways to 
solve  the  same  problem.  Design  is  generally  
considered a wicked problem — a term coined 
by  Horst  Rittel  in  the  1960s  when  design  
methods  were  a  subject  of  intense  interest.  
Rittel sought an alternative to the linear, step-
by-step  process  many  designers  and  design  
theorists were exploring and argued that most 
problems  addressed  by  designers  are  wicked  
problems.  As  explained  by  McConnell,  a  
wicked problem presents a paradox: One can 
define it only by solving it, or by solving part 
of  it.  However,  that  solution  is  not  the  final  
solution;  a  wicked  problem  must  be  solved  
once  to  define  it  clearly  and  solved  again  to  
create a solution that works. This has been an 
important  insight  for  software  designers  for  
decades [6*, c5s1].
3. Abstraction and Encapsulation 
 [6*, c5s2-4]
Abstraction   is   an   indispensable   technique   
associated  with  problem-solving.  It  refers  to  
both the process and the result of generaliza-
tion, where one reduces the information about 
a concept, problem or observable phenomenon 
in order to focus on the “big picture.” One of 
the most important skills in any engineering 
undertaking is the ability to frame the levels 
of abstraction appropriately.
According  to  Voland,  “Through  abstrac-
tion,  we  view  the  problem  and  its  possible  
solution  paths  from  a  higher  level  of  con-
ceptual  understanding.  As  a  result,  we  may  
become better prepared to recognize possible 
relationships between different aspects of the 
Define the
selection criteria
Identify all 
reasonable technically 
feasible solutions
Select the
preferred alternative
Monitor the
performance of the
selected alternative
Evaluate each
alternative against
the selection criteria
Understand the
real problem
Figure 18.2. The Engineering Process

18-4   SWEBOK
®
 GUIDE V4.0
problem  and  thereby  generate  more  creative  
design solutions” [2*]. This is true in computer 
science in general (such as hardware vs. soft-
ware)  and  in  software  engineering  in  partic-
ular (e.g., data structure vs. data flow).
Dijkstra states, “The purpose of abstracting 
is  not  to  be  vague,  but  to  create  a  new  
semantic level in which one can be absolutely 
precise” [7].
3.1.  Levels of Abstraction 
When   abstracting,   we   concentrate   on   one   
“level”  of  the  big  picture  at  a  time,  confident  
that we can connect effectively with levels above 
and  below.  Although  we  focus  on  one  level,  
abstraction  does  not  mean  knowing  nothing  
about the neighboring levels. Abstraction levels 
do not necessarily correspond to discrete com-
ponents  in  reality  or  in  the  problem  domain,  
but  to  well-defined  standard  interfaces  such  
as application programming interfaces (APIs). 
Standard  interfaces  offer  advantages  such  as  
portability,  easier  software/hardware  integra-
tion and wider usage.
3.2.  Encapsulation
Encapsulation  is  a  mechanism  used  to  imple-
ment abstraction. When we are working with 
one level of abstraction, the information con-
cerning the levels below and above that level 
is encapsulated. This can be information about 
the concept, problem, or observable phenom-
enon  or  the  permissible  operations  on  these  
entities.  Encapsulation  usually  means  hiding  
underlying  details  about  the  level  above  the  
interface  provided  by  the  abstraction.  For  
example,  hiding  information  about  an  object  
is  useful  because  we  don’t  need  to  know  the  
details of how the object is represented or how 
the operations on the object are implemented.
3.3.  Hierarchy
When  we  use  abstraction  in  our  problem  
formulation  and  solution,  we  might  use  dif-
ferent  abstractions  at  different  times  —  in  
other  words,  we  work  on  different  levels  of  
abstraction as the situation requires. Usually, 
these  different  levels  of  abstraction  are  orga-
nized in a hierarchy. There are many ways to 
structure  a  particular  hierarchy,  and  the  cri-
teria used in determining the specific content 
of  each  layer  vary  depending  on  the  individ-
uals performing the work.
Sometimes,  a  hierarchy  of  abstraction  is  
sequential,  meaning  that  each  layer  has  one  
and  only  one  predecessor  (lower)  layer  and  
one  and  only  one  successor  (upper)  layer  —  
except  the  upmost  layer  (which  has  no  suc-
cessor) and the bottommost layer (which has 
no   predecessor).   Sometimes,   however,   the   
hierarchy  is  organized  in  a  tree  structure,  
which  means  each  layer  can  have  more  than  
one  predecessor  layer  but  only  one  successor  
layer.  Occasionally,  a  hierarchy  can  have  a  
many-to-many structure, in which each layer 
has  multiple  predecessors  and  successors.  A  
hierarchy never contains a loop.
A  hierarchy  often  forms  naturally  in  task  
decomposition.  Often,  task  analysis  can  be  
decomposed    hierarchically,    starting    with    
the  organization’s  larger  tasks  and  goals  and  
breaking  each  into  smaller  subtasks  that  can  
again be subdivided. This continuous division 
of  tasks  into  smaller  ones  produces  a  hierar-
chical structure of tasks and subtasks.
3.4.  Alternate Abstractions
Sometimes,   multiple   alternate   abstractions   
for  the  same  problem  are  useful  to  keep  dif-
ferent perspectives in mind. For example, we 
can  have  a  class  diagram,  a  state  chart  and  
a  sequence  diagram  for  the  same  software  
at  the  same  level  of  abstraction.  These  alter-
nate abstractions do not form a hierarchy but 
complement each other, helping to illuminate 
the problem and its solution. Though benefi-
cial,  keeping  alternate  abstractions  in  sync  is  
sometimes difficult.
4. Empirical Methods and Experimental 
Techniques  [8*, c1]
The    engineering    process    involves    pro-
posing  solutions  or  models  of  solutions  and  

ENGINEERING FOUNDATIONS   18-5
conducting experiments or tests to study those 
proposed solutions or models. Thus, engineers 
must understand how to create an experiment 
and  analyze  the  results  to  evaluate  proposed  
solutions.   Empirical   methods   and   experi-
mental techniques help the engineer describe 
and  understand  variability  in  their  observa-
tions,  identify  the  sources  of  that  variability,  
and make decisions.
Three types of empirical studies commonly 
used   in   engineering   efforts   are   designed   
experiments,  observational  studies  and  ret-
rospective  studies.  Brief  descriptions  of  the  
commonly used methods are given below.
4.1.  Designed Experiment
A designed or  controlled  experiment  tests  a  
hypothesis by manipulating one or more inde-
pendent  variables  to  measure  their  effect  on  
one  or  more  dependent  variables.  A  precon-
dition  for  conducting  this  experiment  is  the  
existence  of  a  clear  hypothesis.  Therefore,  
engineers need to understand how to formu-
late clear hypotheses.
Designed   experiments   allow   engineers   
to  determine  precisely  how  the  variables  are  
related  and,  specifically,  whether  a  cause-ef-
fect  relationship  exists  between  them.  Each  
combination of values of the independent vari-
ables is a treatment. The simplest experiments 
have  just  two  treatments,  representing  two  
levels  of  a  single  independent  variable  (e.g.,  
using a tool vs. not using a tool). More com-
plex  experimental  designs  arise  when  more  
than  two  levels,  more  than  one  independent  
variable, or any dependent variables are used.
4.2.  Observational Study
An observational or  case  study  is  an  empirical  
inquiry  that  makes  observations  of  processes  
or  phenomena  within  a  real-world  context.  
While an experiment deliberately ignores con-
text,  an  observational  or  case  study  includes  
context.  A  case  study  is  most  useful  when  it  
focuses on how and why questions, on when the 
behavior of those involved cannot be manipu-
lated,  and  on  when  contextual  conditions  are  
relevant and the boundaries between the phe-
nomena and context are unclear.
4.3.  Retrospective Study
Retrospective  studies  involve  the  analysis  of  
historical  data,  and  thus  are  also  known  as  
historical studies. This type of study uses data 
(regarding  some  phenomenon)  archived  over  
time.  This  archived  data  is  then  analyzed  to  
find  relationships  between  variables,  to  pre-
dict  future  events  or  to  identify  trends.  One  
limitation  is  that  the  quality  of  the  analysis  
depends  on  the  quality  of  the  archived  data,  
and historical data may be incomplete, incon-
sistently measured or incorrect.
5. Statistical Analysis  
 [8*, c9s1, c2s1] [9*, c11s3] 
Engineers must understand how product and 
process  characteristics  vary.  Engineers  often  
encounter  situations  where  the  relationship  
between  different  variables  must  be  studied.  
Most studies use samples, but the results need 
to be understood with respect to the full pop-
ulation. Therefore, engineers must understand 
statistical techniques for collecting and inter-
preting  reliable  data  (sampling  and  analysis)  
to  arrive  at  results  that  can  be  generalized.  
These techniques are discussed below.
5.1.  Unit of Analysis (Sampling Units), 
Population, and Sample
Unit  of  analysis.  In  any  empirical  study,  the  
researchers  must  make  observations  based  
on  chosen  units  called  the  units  of  anal-
ysis  or  sampling  units.  These  units  must  be  
clearly  identified  and  be  appropriate  for  the  
analysis.  For  example,  in  a  study  of  the  per-
ceived usability of a software product, the user 
or  the  software  function  might  be  the  unit  
of analysis.
Population.  The  set  of  all  respondents  or  
items  (possible  sampling  units)  forms  the  
population.  For  example,  for  a  study  of  the  
perceived usability of a software product, the 
set of all possible users forms the population.

18-6   SWEBOK
®
 GUIDE V4.0
In  defining  the  population,  care  must  be  
taken  to  differentiate  the  study  and  target  
populations.  The  population  being  studied  
and  the  population  for  which  the  results  are  
generalized will differ if the study involves a 
sample.  For  example,  when  the  study  popu-
lation  consists  only  of  past  observations  but  
generalizations  are  required  for  the  future,  
the  study  population  and  the  target  popula-
tion are not the same.
Sample.  A  sample  is  a  subset  of  the  pop-
ulation.  The  most  crucial  issue  in  selecting  
a  sample  is  its  representativeness,  including  
size. The samples must be drawn in a way that 
ensures draws are independent, and the rules 
of drawing samples must be predefined so the 
probability of selecting a particular sampling 
unit  is  known  beforehand.  This  method  of  
selecting samples is called probability sampling. 
Random   variable.   In   statistical   termi-
nology,  the  process  of  making  observations  
or  measurements  on  the  sampling  units  is  
referred to as conducting the experiment. For 
example, if the experiment is to toss a coin 10 
times and count the number of times the coin 
lands  on  heads,  every  10  tosses  of  the  coin  
is  a  sampling  unit  and  the  number  of  heads  
for  a  given  sample  is  the  observation  or  out-
come for the experiment. The outcome of an 
experiment is obtained in terms of real num-
bers  and  defines  the  random  variable  being  
studied. The attribute of the items being mea-
sured  at  the  outcome  of  the  experiment  rep-
resents the random variable being studied; the 
observation  obtained  from  a  particular  sam-
pling  unit  is  a  particular  realization  of  the  
random  variable.  In  the  example  of  the  coin  
toss,  the  random  variable  is  the  number  of  
heads observed for each experiment. 
The set of possible values of a random vari-
able  may  be  finite  or  infinite  but  countable  
(e.g., the set of all integers or the set of all odd 
numbers). In such a case, the random variable 
is  called  a  discrete  random  variable.  In  other  
cases,  the  random  variable  under  consider-
ation  may  take  values  on  a  continuous  scale  
and is called a continuous random variable.
Event.  A  subset  of  possible  values  of  a  
random  variable  is  called  an  event.  Suppose  
X  denotes  some  random  variable;  then,  for  
example, we may define different events such 
as X ≥ x or X < x and so on.
Distribution of a random variable. A random 
variable’s  range  and  pattern  of  variation  are  
given by its distribution. When the distribu-
tion of a random variable is known, it is pos-
sible to compute the probability of any event. 
Some  distributions  occur  commonly  and  are  
used to model many random variables occur-
ring in practice in the context of engineering. 
A  few  of  the  more  commonly  occurring  dis-
tributions are described below:
• Binomial  distribution  is  used  to  model  
random  variables  that  count  the  number  
of  successes  in  n  trials  carried  out  inde-
pendently of each other, where each trial 
results  in  success  or  failure.  We  assume  
that   the   chance   of   a   successful   trial   
remains constant [8*, c3s5].
• Poisson  distribution  is  used  to  model  the  
count  of  occurrences  of  some  event  over  
time or space [8*, c3s8].
• Normal distribution is used to model con-
tinuous   or   discrete   random   variables   
by  taking  a  very  large  number  of  values  
[8*, c4s5].
Concept  of  parameters.  Parameters  charac-
terize  a  statistical  distribution.  For  example,  
the proportion of successes in any given trial is 
the only parameter characterizing a binomial 
distribution.  Similarly,  the  Poisson  distribu-
tion  is  characterized  by  a  rate  of  occurrence.  
A normal distribution is characterized by two 
parameters: its mean and standard deviation.
Once  the  values  of  the  parameters  are  
known,  the  distribution  of  the  random  vari-
able  is  revealed  and  the  chance  (probability)  
of  any  event  can  be  computed.  The  proba-
bilities  for  a  discrete  random  variable  can  be  
computed through the probability mass func-
tion  (PMF).  The  PMF  is  defined  at  discrete  
points  and  gives  the  point  mass  —  i.e.,  the  
probability  that  the  random  variable  takes  
that  particular  value.  Likewise,  for  a  contin-
uous random variable, we have the probability 
density function (PDF). The PDF needs to be 

ENGINEERING FOUNDATIONS   18-7
integrated  over  a  range  to  obtain  the  proba-
bility that the continuous random variable lies 
between  certain  values.  Thus,  if  the  PMF  or  
PDF  is  known,  the  chances  of  the  random  
variable taking a certain set of values may be 
computed theoretically.
Concept  of  estimation  [8*,  c7s1,  c7s3].  The  
true values of the parameters of a distribution 
are usually unknown and need to be estimated 
from  the  sample  observations.  The  estimates  
are  functions  of  the  sample  values  and  are  
called statistics. For example, the sample mean 
is  a  statistic  and  may  be  used  to  estimate  the  
population mean. Similarly, the rate of occur-
rence  of  defects  estimated  from  the  sample  
(rate of defects per line of code) is a statistic and 
serves  as  the  estimate  of  the  population  rate  
of  defects  per  line  of  code.  The  statistic  used  
to  estimate  a  population  parameter  is  often  
referred to as the estimator of the parameter.
The  results  of  the  estimators  themselves  
are random. If we take a different sample, we 
will  likely  get  a  different  population  param-
eter  estimate.  In  the  theory  of  estimation,  
we  need  to  understand  different  properties  
of  estimators  —  particularly,  how  much  the  
estimates can vary across samples and how to 
choose  between  different  ways  to  obtain  the  
estimates. For example, if we wish to estimate 
the mean of a population, we might use as our 
estimator a sample mean, a sample median, a 
sample mode or the midrange of the sample. 
Each  of  these  estimators  has  different  statis-
tical  properties  that  might  impact  the  stan-
dard error of the estimate.
Types of estimates [8*, c7s3, c8s1]. There are 
two  types  of  estimates:  point  estimates  and  
interval  estimates.  When  we  use  the  value  of  
a statistic to estimate a population parameter, 
we  get  a  point  estimate.  As  the  name  indi-
cates,  a  point  estimate  gives  a  point  value  of  
the parameter estimated.
Although  point  estimates  are  often  used,  
they   leave   room   for   many   questions.   For   
instance, they do not tell us anything about the 
possible  error  size  or  the  estimate’s  statistical  
properties.  Thus,  we  might  need  to  supple-
ment a point estimate with information about 
the  sample  size  and  the  estimate’s  variance.  
Alternatively,  we  might  use  an  interval  esti-
mate. An interval estimate is a random interval 
whose lower and upper limits are functions of 
the  sample  observations  and  the  sample  size.  
The limits are computed based on assumptions 
regarding  the  sampling  distribution  of  the  
point estimate on which the limits are based. 
Properties  of  estimators.  Various  statistical  
properties  of  estimators  are  used  to  deter-
mine the appropriateness of an estimator in a 
given  situation.  The  most  important  proper-
ties are efficiency, consistency with respect to 
the population, and lack of bias.
Tests  of  hypotheses  [8*,  c9s1].  A  hypothesis 
is  a  statement  about  the  possible  values  of  a  
parameter.  For  example,  suppose  someone  
claims that a new method of software devel-
opment reduces the occurrence of defects. The 
hypothesis  is  that  the  rate  of  occurrence  of  
defects  has  been  reduced.  When  we  test  the  
hypothesis,  we  decide  —  based  on  sample  
observations — whether it should be accepted 
or rejected.
To  test  hypotheses,  the  null  and  alterna-
tive  hypotheses  are  formed.  The  null  hypoth-
esis is the hypothesis of no change, denoted as 
H
0
. The alternative hypothesis is written as H
1
. 
The  alternative  hypothesis  may  be  one-sided  
or two-sided. For example, if we have the null 
hypothesis that the population mean is not less 
than some given value, the alternative hypoth-
esis would be that it is less than that value, and 
we  would  have  a  one-sided  test.  However,  if  
we  have  the  null  hypothesis  that  the  popula-
tion  mean  is  equal  to  some  given  value,  the  
alternative  hypothesis  would  be  that  it  is  not  
equal,  and  we  would  have  a  two-sided  test  
(because  the  true  value  could  be  either  less  
than or greater than the given value).
The  first  step  in  testing  a  hypothesis  is  to  
compute  a  statistic.  In  addition,  a  region  is  
defined  such  that  if  the  computed  value  of  
the statistic falls within that region, the null 
hypothesis  is  rejected.  This  region  is  called  
the critical region (also known as the confidence 
interval).  In  tests  of  hypotheses,  we  need  to  
accept  or  reject  the  null  hypothesis  based  on  
the  evidence  obtained.  In  general,  the  alter-
native hypothesis is the hypothesis of interest. 

18-8   SWEBOK
®
 GUIDE V4.0
If the computed value of the statistic does not 
fall inside the critical region, then we cannot 
reject the null hypothesis. This indicates that 
there  is  insufficient  evidence  to  believe  that  
the alternative hypothesis is true.
As  the  decision  is  based  on  sample  obser-
vations, errors are possible; the types of such 
errors are summarized in the following table.
NatureStatistical decision
Accept H
0
Reject H
0
H
0
 is  
true
OKType I error 
(probability = α)
H
0
 is  
false
Type II error 
(probability = β)
OK
In testing hypotheses, we aim to maximize 
the power of the test (the value of 1 − β) while 
ensuring that the probability of a type I error 
(the value of α) is maintained within a partic-
ular value — typically 5%. 
Also  note  that  construction  of  a  test  of  a  
hypothesis  includes  identifying  statistic(s)  to  
estimate the parameter(s) and defining a crit-
ical region such that if the computed value of 
the statistic falls within the critical region, the 
null hypothesis is rejected.
5.2.  Correlation and Regression 
 [8*, c11s2, c11s8]
A  major  objective  of  many  statistical  investi-
gations is to establish relationships that make 
it possible to predict one or more variables in 
terms  of  others.  Although  it  is  desirable  to  
predict a quantity exactly in terms of another 
quantity, that is seldom possible, and, in many 
cases,  we  must  be  satisfied  with  estimating  
the average or expected values. 
The  relationship  between  two  variables  is  
studied using correlation and regression. Both 
these concepts are explained briefly below.
Correlation.  The  degree  of  the  linear  rela-
tionship  between  two  variables  is  measured  
using the correlation coefficient. Computing the 
correlation  coefficient  is  appropriate  for  two  
variables that measure two different attributes 
of the same entity. The correlation coefficient 
takes  a  value  between  −1  and  +1.  The  values  
−1 and +1 indicate a situation where the asso-
ciation  between  the  variables  is  perfect  (i.e.,  
given the value of one variable, the other can 
be  estimated  with  no  error).  A  positive  cor-
relation  coefficient  indicates  a  positive  rela-
tionship (i.e., if one variable increases, so does 
the other). On the other hand, when the vari-
ables are negatively correlated, an increase of 
one leads to a decrease in the other.
Always  remember  that  correlation  does  
not  imply  causation.  Thus,  if  two  variables  
are  correlated,  we  cannot  conclude  that  one  
causes the other.
Regression.   The   correlation   analysis   only   
measures  the  degree  of  relationship  between  
two variables. The analysis to find the strength 
of  the  relationship  between  two  variables  is  
called regression analysis. This analysis uses the 
coefficient of determination — a value between 
0  and  1.  The  closer  the  coefficient  is  to  1,  the  
stronger the relationship between the variables. 
A value of 1 indicates a perfect relationship.
6. Modeling, Simulation, and Prototyping 
 [3*, c6] [10*, c13s3] [11*, c5]
Modeling is part of the abstraction process used 
to  represent  aspects  of  a  system.  Simulation 
uses a model of the system to conduct designed 
experiments  to  better  understand  the  system,  
its  behavior  and  relationships  among  subsys-
tems, as well as to analyze aspects of the design. 
Modeling  and  simulation  can  be  used  to  con-
struct theories or hypotheses about the system’s 
behavior. Engineers then use those theories to 
make predictions about the system. Prototyping 
is  another  abstraction  process  where  a  partial  
representation (that captures aspects of interest) 
of  the  product  or  system  is  built.  A  prototype  
may  be  an  initial  version  of  the  system  that  
lacks the full functionality of the final version. 
6.1.  Modeling
A model is always an abstraction of some real 
or imagined artifact. Engineers use models in 
many  ways  as  part  of  their  problem-solving  
activities.  Some  models  are  physical,  such  as  

ENGINEERING FOUNDATIONS   18-9
a  made-to-scale  miniature  construction  of  a  
bridge  or  building.  Other  models  are  non-
physical  representations,  such  as  a  comput-
er-aided  design  (CAD)  drawing  of  a  cog  or  
a  mathematical  model  for  a  process.  Models  
help   engineers   understand   aspects   of   a   
problem. They can also help engineers deter-
mine  what  they  know  and  what  they  don’t  
know about the problem.
There are three types of models: iconic, ana-
logic and symbolic. An iconic model is a visually 
equivalent but incomplete two-dimensional or 
three-dimensional  representation  (e.g.,  maps,  
globes  or  built-to-scale  models  of  structures  
such as bridges or highways). An iconic model 
resembles the artifact modeled. 
In contrast, an analogic model is a function-
ally equivalent but incomplete representation. 
The  model  behaves  like  the  physical  artifact  
even though it may not physically resemble it. 
Examples of analogic models include a minia-
ture airplane for wind tunnel testing or a com-
puter simulation of a manufacturing process.
Finally, a symbolic model uses a higher level 
of abstraction, modeling the process or system 
with symbols such as equations. The engineers 
can use the symbols to understand, describe, 
and  predict  the  properties  or  behavior  of  the  
final  system  or  product.  An  example  is  the  
equation F = ma. 
6.2.  Simulation 
All   simulation   models   are   depictions   of   
reality. A central issue in simulation is how to 
abstract data and create an appropriate simpli-
fication of reality. Developing this abstraction 
is vital, as misspecification of the abstraction 
would invalidate the results of the simulation 
exercise. Simulation can be used for a variety 
of testing purposes.
Simulation is classified based on the type of 
system under study; simulation can be either 
continuous or discrete. In software engineering, 
the emphasis is primarily on discrete simula-
tion.  Discrete  simulations  may  model  event  
scheduling  or  process  interaction.  The  main  
components in such a model include entities, 
activities  and  events,  resources,  the  state  of  
the system, a simulation clock, and a random 
number  generator.  The  simulation  generates  
output that must be analyzed.
An important problem in the development 
of  a  discrete  simulation  is  that  of  initializa-
tion.  Before  a  simulation  can  be  run,  the  ini-
tial  values  of  all  the  state  variables  must  be  
provided. As the simulation designer may not 
know what initial values are appropriate for the 
state  variables,  these  values  might  be  chosen  
somewhat arbitrarily. For instance, it might be 
decided  that  a  queue  should  be  initialized  as  
empty and idle. This choice for an initial con-
dition can have a significant but unrecognized 
impact on the simulation outcome.
6.3.  Prototyping
Constructing   a   prototype   of   a   system   is   
another  abstraction  process.  In  this  case,  an  
initial  version  of  the  system  is  constructed,  
often  while  the  system  is  designed,  which  
helps  the  designers  determine  the  feasibility  
of their design.
A prototype has many uses, including elic-
iting  requirements,  designing  and  refining  
a  user  interface,  and  validating  functional  
requirements.  The  objectives  and  purposes  
for building the prototype will guide its con-
struction  and  determine  the  level  of  abstrac-
tion used. 
The  role  of  prototyping  is  somewhat  dif-
ferent for physical systems and software. With 
physical systems, the prototype might be the 
first  fully  functional  version  of  a  system,  or  
it  might  be  a  model  of  the  system.  In  soft-
ware engineering, prototypes are also abstract 
models of part of the software. However, they 
are usually not constructed with all the archi-
tectural, performance and other quality char-
acteristics  expected  in  the  finished  product.  
In  either  case,  prototype  construction  must  
have  a  clear  purpose  and  be  planned,  mon-
itored  and  controlled  —  it  is  a  technique  to  
study a specific problem within a limited con-
text [12*, c2s8]. 
In  conclusion,  modeling,  simulation  and  
prototyping   are   powerful   techniques   for   
studying  the  behavior  of  a  system  from  a  

18-10   SWEBOK
®
 GUIDE V4.0
given perspective. All can be used to perform 
designed experiments to study various aspects 
of  the  system.  However,  these  are  abstrac-
tions  and,  as  such,  may  not  model  all  attri-
butes of interest.
7. Measurement 
 [2*, pp442-447] [3*, c4s4]  
 [12*, c7s5] [13*, c3s1-2]
Knowing  what  to  measure,  how  to  measure  
it, what can be done with measurements and 
even why to measure is critical in engineering 
endeavors.  Everyone  involved  in  an  engi-
neering project must understand the measure-
ment  methods,  the  measurement  results  and  
how those results can and should be used.
Measurements  can  be  physical,  environ-
mental,   economic,   operational   or   another   
sort  of  measurement  that  is  meaningful  to  
the  project.  This  section  explores  the  theory  
of  measurement  and  how  it  is  fundamental  
to  engineering.  Measurement  starts  as  an  
abstract  concept  and  progresses  to  a  defini-
tion  of  the  measurement  method  and  then  
to  the  actual  application  of  that  method  to  
obtain a measurement result. Each step must 
be  understood,  communicated  and  properly  
performed to yield usable data. In traditional 
engineering,  direct  measures  are  often  used.  
In  software  engineering,  a  combination  of  
both direct and derived measures (defined in 
7.3 below) is necessary [13*, p273].
The   theory   of   measurement   states   that   
measurement  is  an  attempt  to  describe  an  
underlying  empirical  system.  Measurement  
methods specify activities that assign a value 
or symbol to an attribute of an entity.
Attributes  must  then  be  defined  in  terms  
of  the  operations  used  to  identify  and  mea-
sure them (the measurement methods). In this 
approach,  a  measurement  method  is  defined  
as  a  precisely  specified  operation  that  yields  
a  symbol  (called  the  measurement  result)  as  
part  of  the  measurement  of  an  attribute.  To  
be  useful,  the  measurement  method  must  be  
well  defined.  Arbitrariness  or  vagueness  in  
the  method  leads  to  ambiguity  in  the  mea-
surement results.
In some cases — particularly in the physical 
world — the attributes we wish to measure are 
easy  to  grasp;  however,  in  an  artificial  world  
like software engineering, defining attributes 
might  not  be  that  simple.  For  example,  the  
attributes of height, weight, distance, etc., are 
easily and uniformly understood (though they 
may  not  be  very  easy  to  measure  in  all  circum-
stances). In contrast, attributes such as software 
size and complexity require clear definitions.
Operational  definitions.  The  definition  of  
attributes, to start with, is often rather abstract. 
Such  definitions  do  not  facilitate  measure-
ments.  For  example,  we  might  define  a  circle  
as  a  line  forming  a  closed  loop  such  that  the  
distance  between  any  point  on  this  line  and  
a fixed interior point called the center is con-
stant.  We  might  further  say  that  the  fixed  
distance  from  the  center  to  any  point  on  the  
closed  loop  is  the  circle’s  radius.  Though  the  
concept  has  been  defined,  no  means  of  mea-
suring the radius has been proposed. The oper-
ational  definition  specifies  the  exact  steps  or  
method  used  to  carry  out  a  specific  measure-
ment. This can also be called the measurement 
method; sometimes, a measurement procedure 
might be required to be even more precise.
The  importance  of  operational  definitions  
can  hardly  be  overstated.  Take  the  case  of  
the  apparently  simple  measurement  of  a  per-
son’s height. Unless we specify various factors 
—for  example,  the  time  the  height  is  mea-
sured (because the height of individuals varies 
throughout the day), how the variability cre-
ated by hair is handled, whether the measure-
ment is taken when the person is wearing shoes 
or  not,  the  accuracy  expected  (to  the  nearest  
inch, 1/2 inch, centimeter, etc.) — then even 
this  simple  measurement  will  produce  sub-
stantial  variation.  Therefore,  engineers  must  
appreciate  the  need  to  define  measurements  
from an operational perspective.
7.1.  Levels (Scales) of Measurement 
 [2*, pp442-447] [12*, c7s5] [13*, c3s2]
Once  the  operational  definitions  have  been  
determined,    actual    measurements    can    be    
taken.  Measurement  may  be  carried  out  in  

ENGINEERING FOUNDATIONS   18-11
four  different  scale  types:  nominal,  ordinal,  
interval, and ratio. Brief descriptions of each 
are given below:
Nominal  scale:  This  is  the  lowest  level  of  
measurement  and  represents  the  most  unre-
stricted  assignment  of  symbols,  which  are  
only  labels.  Nominal  scales  involve  classifi-
cation  where  measured  entities  are  put  into  
one of the mutually exclusive and collectively 
exhaustive  categories  (classes).  Examples  of  
nominal scales are the following:
•    Job titles in an organization
•    Automobile  styles  (sedan,  coupe,  hatch-
back, minivan, etc.)
•    Software development life cycle (SDLC) 
models (waterfall, iterative, Agile, etc.)
In  nominal  scales,  no  relationship  among  
symbols may be inferred. The only valid types 
of  manipulation  of  measures  in  a  nominal  
scale are the following:
•    Determining  whether  two  entities  have  
the  same  or  different  symbol  (e.g.,  “Is  
your  job  title  the  same  as  or  different  
from my job title?”)
•    Counting  the  number  of  entities  having  
the   same   symbol   (e.g.,   “How   many   
employees  have  the  job  title  Software  
Engineer Level 2 in this organization?”)
Statistical  analyses  may  be  carried  out  to  
understand   how   entities   belonging   to   dif-
ferent  classes  perform  with  respect  to  some  
other variable.
Ordinal scale: Ordinal scales extend nominal 
scales by requiring a strict ordering relationship 
among  the  symbols.  Ordinal  scales  are  neces-
sarily transitive (if A > B and B > C, then A > 
C). The following are examples of ordinal scales:
•    Finish order in a race (1st, 2nd, 3rd)
•    Probabilities    expressed    using    terms    
(remote,     unlikely,     even,     probable,     
almost certain)
•    Severities   expressed   using   terms   (neg-
ligible,      marginal,      serious,      critical,      
catastrophic)
•    Level of agreement expressed using terms 
(strongly agree, somewhat agree, neutral, 
somewhat disagree, strongly disagree)
•    Capability  Maturity  Model  Integration  
(CMMI) staged maturity levels
All   manipulations   of   values   on   nom-
inal  scales  are  valid  on  ordinal  scales,  while  
ordinal  scales  also  support  more-than  and  
less-than comparisons. For example:
•    Did you finish that race before, tied with 
or after me?
•    Is  Event  X  the  same,  more  or  less  prob-
able than Event Y?
•    Is Event X the same, more or less severe 
than Event Y?
•    Is  the  CMMI  staged  maturity  level  of  
Organization A the same, higher or lower 
than that of Organization B?
When  an  ordinal  scale  uses  numbers  as  
symbols  —  like  the  CMMI  staged  maturity  
levels 1, 2, 3, 4 and 5 — those numbers cannot 
be manipulated arithmetically. We cannot say 
that  the  difference  between  CMMI  staged  
maturity level 5 and level 4 (5 − 4) compares in 
any meaningful way to the difference between 
level 3 and level 2 (3 − 2). Neither can we say 
that CMMI staged maturity level 4 is twice as 
good as level 2. Ordinal scales that use numbers 
as  symbols  are  commonly  misused  in  exactly  
this way — for example, to present mean and 
standard deviation (e.g., “The average software 
organization  worldwide  has  a  CMMI  staged  
maturity  level  of  1.763.”).  Such  misuse  can  
easily lead to erroneous conclusions [13*, p274]. 
(We  can  compute  the  median  on  an  ordinal  
scale,  as  this  only  involves  counting.)  Using  
nonnumerical symbols, such as initial, repeat-
able,  defined,  managed,  and  optimizing  (for  
CMMI  staged  maturity  levels),  is  preferred  
because  it  helps  prevent  such  mistreatment.  
Properly  chosen  labels  also  better  communi-
cate the meaning of each label.
Interval scale: Interval scales extend ordinal 
scales by requiring that the difference between 
any  pair  of  adjacent  values  is  constant.  The  
following are examples of interval scales:

18-12   SWEBOK
®
 GUIDE V4.0
•    Temperatures    expressed    in    degrees    
Celsius  and  Fahrenheit:  The  difference  
between  −9°C  and  −8°C  is  the  same  as  
that between 26°C and 27°C. The differ-
ence between −9°F and −8°F is the same 
as the difference between 26°F and 27°F.
•    Calendar  dates:  The  difference  between  
any  two  consecutive  dates  is  always  one  
day: 24 hours.
•    Shoe sizes in North America: The differ-
ence between size 3 and size 4 is the same 
as the difference between a size 10 and size 
11 — one-third of an inch, or 8.467 mm.
All  manipulations  of  values  on  ordinal  
scales   are   valid   on   interval   scales,   while   
interval scales also support addition and sub-
traction. For example:
•    The  difference  between  −9°C  and  0°C  is  
the  same  as  that  between  0°C  and  9°C.  
The difference between −50°F and 0°F is 
the same as that between 25°F and 75°F.
•    The   length   of   time   between   May   6   
and  May  9  is  the  same  as  that  between  
November 8 and November 11.
Interval   scales   support   most   statistical   
analyses,  like  mean,  standard  deviation,  cor-
relation   and   regression.   Any   manipulation   
involving  multiplication  or  division  of  values,  
on the other hand, is meaningless because 0 on 
an interval scale, if it even exists, does not rep-
resent  the  absence  of  the  measured  quantity.  
A 0 point on an interval scale is arbitrary with 
respect  to  the  attribute  measured.  Consider  
that  0°  (both  C  and  F)  do  not  represent  the  
absence  of  heat  (absolute  zero),  and  a  North  
American  size  0  shoe  has  non-zero  length.  
Therefore, 30°C cannot be interpreted as twice 
as hot as 15°C, nor is a North American size 
9 shoe three times longer than a size 3 shoe.
Ratio  scale:   Ratio   scales   extend   ordinal   
scales  by  requiring  the  0  point  to  represent  
the  absence  of  the  measured  attribute.  The  
following are examples of ratio scales:
•    Temperature in degrees Kelvin (K)
•    Shoe  sizes  in  the  Mondopoint  system  
(commonly  used  for  athletic  shoes,  ski  
boots,  skates  and  ballet  shoes);  a  size  
270/105 shoe fits a foot 270 mm long and 
105 mm wide
•    Count  of  decision  constructs  (e.g.,  if(),  
for(), while(), in a given source code file)
•    Money
Ratio scales support all arithmetic and sta-
tistical  manipulations.  Values  in  one  ratio  
scale  can  often  be  trivially  transformed  into  
corresponding  values  in  another  ratio  scale  
that  measures  the  same  attribute  by  using  a  
multiplication factor. Distances in inches can 
be   trivially   transformed   into   centimeters,   
weights  in  kilograms  can  be  trivially  trans-
formed  into  pounds,  speed  in  knots  can  be  
trivially transformed into kilometers per hour, 
and so on.
An additional measurement scale, the abso-
lute  scale,  is  a  ratio  scale  with  uniqueness  of  
measure  (no  transformation  is  possible).  The  
number  of  software  engineers  working  on  a  
project  is  an  absolute  scale  because  there  are  
no  other  meaningful  measures  for  numbers  
of people.
7.2.  Implications of Measurement Theory for 
Programming Languages
Common  programming  languages  support  a  
set of built-in data types, often including the 
following:
•    Whole number types over varying ranges: 
int, integer, byte, short, long, etc.
•    Floating-point   numbers   over   varying   
ranges with varying precision: real, float, 
double, etc.
•    Single characters: char
•    Ordered sequences of characters: string
Many     languages,     although     not     all,     
also   support   type-safe   enumeration   (e.g.,   
Java’s “enum”).
Unfortunately,  these  languages  offer  no  
support for measurement theory. They do not 
prevent,  nor  even  warn  programmers  about,  
inappropriate  manipulations.  The  whole  and  

ENGINEERING FOUNDATIONS   18-13
floating-point  number  data  types  in  pro-
gramming  languages  operate  as  ratio  scales  
and support the full range of manipulations: 
comparison,   addition,   subtraction,   multi-
plication,  division  and  so  on.  But  consider  
CMMI  staged  maturity  level  expressed  as  
a  number.  In  measurement  theory  terms,  as  
shown  above,  it  is  an  ordinal  scale,  so  addi-
tion, subtraction, multiplication and division 
are  inappropriate.  If  any  programmer  rep-
resents a CMMI staged maturity level using 
a  whole  number  data  type,  nothing  pre-
vents  the  programmer  from  inappropriately  
adding,  subtracting,  multiplying  or  dividing  
that number.
The same can be said for characters, strings 
and  enumerations.  Programming  languages  
implement   them   as   ordinal   scales;   how-
ever,  they  might  only  be  intended  for  repre-
senting nominal-scale values. More-than and 
less-than comparisons are allowed even when 
inappropriate.  The  string  “minivan”  appears  
alphabetically  before  the  string  “sedan,”  but  
drawing  any  conclusion  other  than  the  mere  
alphabetical  ordering  of  arbitrary  text  strings  
as a result of that fact is inappropriate.
Common  programming  languages  allow  
programmers to easily write code that is inap-
propriate  according  to  measurement  theory.  
As  long  as  programming  languages  allow  
it,  programmers  can  and  will  —  intention-
ally  or  unintentionally  —  misuse  measure-
ment  scale  types.  A  more  sensible  solution  
would  be  data-type  semantics  that  explicitly  
enforce  measurement  theory.  For  example,  
a   language   could   explicitly   support   nom-
inal  scales,  as  shown  in  Figure  18.3  Sample  
A.  That  language  could  then  prevent,  or  at  
least  warn  programmers  against,  more-than  
or less-than comparisons as shown in Figure 
18.3 Sample B.
If  more-than  or  less-than  comparisons  are  
needed,   the   language   supports   declaration   
of  an  ordinal  type  as  shown  in  Figure  18.3  
Sample  C.  Figure  18.3  Sample  D  would  not  
trigger  any  error  or  warning.  Similarly,  an  
interval scale could be supported, as shown in 
Figure  18.3  Sample  E.  A  ratio  scale  could  be  
supported, as shown in Figure 18.3 Sample F.
Common programming languages have no 
problem with the code shown in Figure 18.3 
Sample G. On the other hand, a measurement 
theory–aware  programming  language  would  
be   expected   to   generate   a   compiler   error   
or  warning  with  the  code  shown  in  Figure  
18.3 Sample H.
Future   programming   languages   should   
enforce  measurement  theory  and  not  allow  
developers to manipulate measurements inap-
propriately. But until languages support mea-
surement  theory,  software  engineers  need  to  
at least understand it and be on the lookout for 
inappropriate  manipulations  in,  for  example,  
code reviews.
7.3.  Direct and Derived Measures 
 [13*, c7s5]
Measures  may  be  either  direct  or  derived  
(sometimes   called   indirect    measures).    An    
example of a direct  measure is a count of how 
many  times  an  event  occurred,  such  as  the  
number of defects found in a software product. 
A derived measure combines direct measures 
in a way that is consistent with the measure-
ment  methods  used  for  those  measures.  For  
example,  calculating  the  average  hours  spent  
to  repair  per  defect  is  a  derived  measure.  In  
both  cases,  the  measurement  method  deter-
mines how to perform the measurement. The 
scale  types  of  those  measures  constrain  how  
they  can  be  manipulated.  When  different  
scale types are involved:
•    The scale type of the result of the manip-
ulation  can  be  no  higher  than  the  scale  
type   of   the   most   primitive   measure-
ment  scale  involved  (e.g.,  a  manipula-
tion  involving  an  interval  scale  and  a  
ratio  scale  can  only  be  done  as  if  both  
are interval scales and can yield no better 
than an interval scale result).
•    Investment   is   required   to   make   the   
more   primitive   scale   type   compatible   
with  any  higher  scale  type  (e.g.,  effort  
is required to bring the interval scale up 
to  a  ratio  scale  so  the  result  can  also  be  
ratio-scaled).

18-14   SWEBOK
®
 GUIDE V4.0
7.4.  Reliability and Validity [13*, c3s4-5]
A basic question to ask when considering any 
measurement method is whether the proposed 
measurement  method  is  truly  measuring  the  
concept  with  good  quality.  Reliability  and  
validity  are  the  two  most  useful  criteria  for  
addressing this question.
The reliability of a measurement method is the 
extent to which the application of the method 
yields  consistent  results.  Reliability  refers  to  
the consistency of the values obtained when the 
same item is measured several times. When the 
results agree with each other, the measurement 
method is said to be reliable. Reliability usually 
depends on the operational definition. It can be 
quantified by using the variation index, which 
is computed as the ratio between the standard 
deviation and the mean. The smaller the index, 
the more reliable the measurement results.
Vali dit y  refers  to  whether  the  measurement  
method measures what we intend to measure. The 
validity of a measurement method may be consid-
ered  from  three  different  perspectives:  construct  
validity, criteria validity and content validity.
7.5.  Assessing Reliability [13*, c3s5]
Methods   for   assessing   reliability   include   
the  test-retest  method,  the  alternative  form  
Nominal enum automobile_style = sedan, coupe, hatchback, 
 minivan, suv, sports_car;
Sample A
if( thisCarStyle >= sedan ) then ... // this is not allowed
Sample B
ordinal enum CMMI_staged_level = initial, repeatable, defined, 
 managed, optimizing;
Sample C
if( anOrgsCMMILevel > repeatable ) then ...
Sample D
interval AirTemperatureCelsius from -120.0 to +180.0;
AirTemperatureCelsius yesterdaysHighTemp;
AirTemperatureCelsius todaysHighTemp;
if( todaysHighTemp > yesterdaysHighTemp ) { ... } // allowed
if( todaysHighTemp > yesterdaysHighTemp * 2.0 ) { ... } // not
Sample E
ratio TemperatureKelvin from 0.00 to 1000.00;
TemperatureKelvin previousReading;
TemperatureKelvin thisReading;
if( thisReading > previousReading * 2. ) { ... } // allowed
Sample F
double priceOfBook;
double highTemperature;
highTemperature = priceOfBook; // makes no sense but is allowed
Sample G
ratio Money from -10000.00 to +10000.00;
ratio TemperatureKelvin from 0.00 to 1000.00;
Money priceOfBook;
TemperatureKelvin highTemperature;
double highTemperature;
highTemperature = priceOfBook; // not allowed
Sample H
Figure 18.3. Code Samples for Measurement Theory

ENGINEERING FOUNDATIONS   18-15
method,   the   split-halves   method   and   the   
internal  consistency  method.  The  easiest  of  
these is the test-retest method. In this method, 
we  apply  the  measurement  method  twice  to  
the  same  subjects.  The  correlation  coefficient  
between  the  first  and  second  set  of  measure-
ment results gives us the reliability of the mea-
surement method.
7.6.  Goal-Question-Metric Paradigm:  
Why Measure?
The  final  concern  to  discuss  here  regarding  
measurement  is  the  importance  of  under-
standing why we measure in the first place. 
The  Goal-Question-Metric  paradigm  can  
be summarized with the simple observation 
that a measurement should be made to sup-
port  decision-making.  Some  measurements  
support  decisions  in  code.  Other  measure-
ments  support  decisions  made  by  people  
outside  of  code  (e.g.,  process  improvement  
measures).  The  critical  point  is  that  some  
decision  should  be  made  as  a  result  of  the  
measurement.   Many   real-world   software   
organizations  fall  victim  to  a  “measurement  
for  the  merely  curious”  syndrome,  where  
metrics are gathered simply because they are 
easy  to  measure  and  interesting  to  look  at  
when plotted in graphs. Those measurements 
are  not  used  to  support  any  decision  and  
are  a  waste  of  time  and  energy.  They  should  
be avoided. 
8. Standards [3*, c9s3.2]
Moore  states  that  a  standard  can  be  the  
following: 
a. An   object   or   measure   of   comparison   
that defines or represents the magnitude 
of a unit 
b. A characterization that establishes allow-
able tolerances for categories of items
c. A  degree  or  level  of  required  excellence  
or attainment 
Standards are definitional in nature, estab-
lished  either  to  further  understanding  and  
interaction  or  to  acknowledge  observed  (or  
desired) norms of exhibited characteristics or 
behavior [14, p8]. 
Standards   provide   requirements,   speci-
fications  or  guidelines  that  engineers  must  
observe so that products, processes and mate-
rials  are  of  acceptable  quality.  The  quali-
ties various standards dictate relate to safety, 
reliability  or  other  product  characteristics.  
Standards are considered critical to engineers, 
who  are  expected  to  be  familiar  with  and  
use  the  appropriate  standards  for  their  spe-
cific discipline.
Compliance   with   or   conformance   to   a   
standard allows an organization to assure the 
public  that  the  organization’s  products  meet  
the  requirements  contained  in  that  standard.  
Thus, standards divide organizations or their 
products into those that conform to the stan-
dard and those that do not. For a standard to 
be useful, conformance must add real or per-
ceived value to the product, process or effort.
Apart    from    supporting    organizational    
goals, standards also serve several other pur-
poses,  such  as  protecting  buyers,  protecting  
businesses,  and  better  defining  the  methods  
and procedures used in software engineering. 
Standards  also  provide  users  with  common  
terminology and expectations.
There  are  many  internationally  recognized  
standards-making    organizations,    including    
the  International  Telecommunication  Union  
(ITU),  the  International  Electrotechnical  
Commission     (IEC),     IEEE,     and     the     
International Organization for Standardization 
(ISO). In addition, regional and governmentally 
recognized  organizations  generate  standards  
for their region or country. For example, in the 
United  States,  more  than  300  organizations  
develop  standards.  These  include  organiza-
tions such as the American National Standards 
Institute  (ANSI),  ASTM  International  (for-
merly known as American Society for Testing 
and  Materials),  SAE  International  (formerly  
the  Society  of  Automotive  Engineers),  and  
Underwriters  Laboratories,  Inc.  (UL),  as  well  
as the US government. (For more information 
on standards used in software engineering, see 
Appendi x B.)

18-16   SWEBOK
®
 GUIDE V4.0
There is a set of commonly used principles 
behind  standards.  Standards  makers  attempt  
to  reach  consensus  for  their  decisions.  This  
approach fosters an openness within the com-
munity  of  interest  so  that  once  a  standard  is  
set, there is a good chance that it will be widely 
accepted.  Most  standards  organizations  have  
well-defined  processes  for  their  efforts  and  
adhere  to  them  carefully.  Engineers  must  
be  aware  of  the  existing  standards  and  keep  
abreast  of  any  changes  to  those  standards  
over time.
In  many  engineering  endeavors,  under-
standing the applicable standards is critical, 
and  the  law  may  even  require  that  spe-
cific  standards  be  followed.  In  these  cases,  
the  standards  often  represent  the  minimal  
requirements that must be met and thus are 
an  element  of  the  constraints  imposed  on  
the  design  effort.  Therefore,  the  engineer  
must  review  all  current  standards  related  
to  a  given  endeavor  and  determine  which  
must  be  met.  The  design  must  then  incor-
porate all constraints imposed by the appli-
cable standard.
9. Root Cause Analysis 
 [3*, c9s3-5] [13*, c5, c3s7, c9s8]
Root cause analysis (RCA) is a class of prob-
lem-solving  methods  for  identifying  under-
lying  causes  of  undesirable  outcomes.  RCA  
methods identify why and how an undesirable 
outcome  happened,  allowing  organizations  
to take effective action to prevent recurrence. 
Instead   of   merely   addressing   immediately   
obvious symptoms, the organization can solve 
problems  by  eliminating  root  causes.  RCA  
can  play  several  important  roles  in  software  
projects, including the following:
1. Identifying the real problem to be solved 
by an engineering effort
2. Exposing  the  underlying  drivers  of  risk,  
thus supporting project risk assessments
3. Revealing  opportunities  and  actions  for  
software process improvement
4. Discovering  sources  of  recurring  defects  
(defect causal analysis)
9.1.  Root Cause Analysis Techniques
Several  RCA  techniques  exist,  including  the  
following:
• Change    analysis    compares    situations    
resulting  in  undesirable  outcomes  with  
similar  situations  that  went  well.  The  
assumption is that the root cause will be 
found in the area of difference.
•    The  5-whys  technique  (see,  for  example,  
[2*,  c4])  starts  with  an  undesirable  out-
come  and  uses  repeated  “Why?”  ques-
tion-answer cycles to isolate the root cause.
• Cause-and-effect    diagrams,    sometimes    
called Ishikawa diagrams [15] or fishbone 
charts, break down, in successive levels of 
detail,  causes  that  potentially  contrib-
uted  to  an  undesirable  outcome.  Causes  
are  often  grouped  into  major  categories  
such  as  people,  processes,  tools,  mate-
rials,   measurements   and   environment.   
The  diagram  takes  the  form  of  a  tree  of  
potential causes that can all result in that 
undesirable outcome.
• Fault  tree  analysis  (FTA)  is  a  more  formal  
approach   to   cause-and-effect   diagram-
ming  that  focuses  on  and/or  relationships  
between causes and effects. In some cases, 
any  one  of  multiple  causes  can  drive  the  
effect (an “or” relationship); in other cases, a 
combination of multiple causes is required 
to  drive  the  effect  (an  “and”  relationship).  
Cause-and-effect  diagrams  do  not  distin-
guish  between  and  relationships  and  or 
relationships; fault tree analysis does.
• Failure modes and effects analysis (FMEA) 
forward-chains,  starting  with  elements  
that can fail and cascade into undesirable 
effects.  This  approach  contrasts  with  the  
backward-chaining    techniques    above,    
which start from an undesirable outcome 
and work backward toward causes.
•    A cause  map  [16]  is  a  structured  map  of  
cause-effect  relationships  that  includes  
an  undesirable  outcome  along  with  (1)  
chaining backward to driving causes and 
(2)  chaining  forward  to  effects  on  orga-
nizational   goals.   Cause   maps   require   

ENGINEERING FOUNDATIONS   18-17
evidence of the occurrence of causes and 
the causality of effects and are thus more 
rigorous than cause-and-effect diagrams, 
FTA, and FMEA.
•    A current  reality  tree  [17]  is  a  cause-ef-
fect  tree  bound  by  the  rules  of  logic  
(Categories of Legitimate Reservation).
• Human    performance    evaluation    posits    
that  human  performance  depends  on  (1)  
input detection, (2) input understanding, 
(3) action selection and (4) action execu-
tion. An undesirable outcome that results 
from  human  performance  can  be  identi-
fied  from  a  comprehensive  list  of  poten-
tial drivers, including cognitive overload, 
cognitive  underload  (boredom),  memory  
lapse,  tunnel  vision  or  lack  of  a  bigger  
picture, complacency, and fatigue.
Additional  techniques  can  be  found  in  
the   DOE-NE-STD-1004-92   Root   Cause   
Analysis Guidance Document. 
9.2.  Root Cause–Based Improvement
RCA  is  often  an  element  in  a  greater  pro-
cess  improvement  effort.  Why  just  identify  a  
root  cause  if  nothing  will  be  done  about  it?  
Why go through the effort of identifying the 
root  cause  of  low-importance  problems?  An  
example  of  a  systematic  process  for  a  larger  
improvement   effort   incorporating   RCA   is   
given below:
1. Select  the  problem  to  solve:  Techniques  
such   as   Pareto   analysis   (the   “80/20   
Rule”),  frequency-severity  prioritization  
(problems  that  happen  most  frequently  
and  consume  the  most  resources  to  rec-
tify  are  the  best  candidates),  and  statis-
tical  process  control  are  used  to  identify  
a  high-priority,  undesirable  outcome  to  
address. This step needs to clearly define 
the problem and its significance.
2. Gather   evidence   about   that   problem   
and  its  cause(s):  Consider  information  
surrounding   the   selected   undesirable   
outcome,  including  statements  or  testi-
mony,  relevant  processes  or  standards,  
specifications,  reports,  historical  trends,  
experiments, or tests.
3. Identify the root cause using one or more 
RCA  techniques  presented  in  9.1.  Root  
Cause Analysis Techniques.
4. Select corrective action(s) that (1) prevent 
recurrence,  (2)  are  within  the  organiza-
tion’s  ability  to  control,  (3)  meet  organi-
zational  goals  and  objectives,  and  (4)  do  
not cause other problems. More than one 
candidate corrective action should be con-
sidered,  and  the  potential  actions  should  
eliminate the cause, reduce the probability 
of  the  cause  occurring  or  disconnect  the  
cause  from  the  effect.  Selected  correc-
tive  actions  should  generate  the  greatest  
amount of control for the least cost.
5. Implement     the     selected     corrective     
action(s).
6. Observe  the  selected  corrective  action(s)  
to ensure efficiency and effectiveness.
10. Industry 4.0 and Software Engineering
The manufacturing industry has always been 
continuously  changing.  Industry  4.0  is  set  to  
change  the  manufacturing  segment  signifi-
cantly,  primarily  focusing  on  custom  manu-
facturing  supported  by  artificial  intelligence  
(AI).  This  offers  potential  benefits  for  cost,  
quality and efficiency.  Industry 4.0’s emphasis 
on  digitization  and  AI  calls  for  building  
bespoke  hardware  and  software  and  inte-
grating these with other standard systems. 
This is supported by Continuous Software 
Engineering     (CSE),     which     has     been     
addressing  continuous  manufacturing  prac-
tices such as continuous planning, continuous 
architecting/designing,    continuous    devel-
opment,  continuous  integration,  continuous  
deployments and continuous review/revision.
Software is a key component in the Industry 
4.0 revolution, and engineering the software is 
crucial to building robust and intelligent sys-
tems. The engineering for one product affects 
others,  as  more  devices  connect  with  other  
devices,  mostly  wirelessly,  to  provide  data  
and  receive  commands  and  data  for  further  
functioning. 

18-18   SWEBOK
®
 GUIDE V4.0
Many  technologies  are  used  in  Industry  
4.0,  including  the  Internet  of  Things  (IoT),  
Big data analytics, AI and machine learning, 
cybersecurity,  cloud  computing  and  Apps  for  
multiple  platforms  among  others.  Software  
plays  a  key  role  in  the  implementation  of  
all these.
Continuous      Systems      and      Software      
Engineering  for  Industry  4.0  (CSSE  I4.0)  
proposes   how   software   engineering   could   
be  applied  in  Industry  4.0.  Quantum  com-
puting  enables  complex  computations  to  be  
performed  faster  and  more  cost-effectively.  
The size and cost of devices that host the soft-
ware  are  decreasing  significantly,  easing  the  
adoption  of  Industry  4.0.  The  software  will  
be  increasingly  self-learning  and  proactive,  
developing the ability to predict users’ wants. 
MATRIX OF TOPICS VS. REFERENCE MATERIAL
To c k e y   2 0 0 4
 
[2*]
Voland 2003 [3*]McConnell 2004[6*]Montgomery and Runger 2018 [8*]Null and Lobur2018 [9 *]Cheney and Kincaid 2 0 0 7 [10 *]Sommerville 2018 [11*]Fairley 2009 [12*]Kan 2002 [13*]
1. The 
Engineering Process
c4
2.  Engineering Designc1s2-4
2.1. Engineering Design 
in Engineering Education
2.2. Design as a Problem-
Solving Activity
c1s4, 
c2s1, 
c3s3
c5s1
3. Abstraction and 
Encapsulation
c5s2-4
3.1. Levels of Abstraction
3.2. Encapsulation
3.3. Hierarchy
3.4. Alternate 
Abstractions
4. Empirical Methods 
and Experimental 
Te c h n i q u e s
c1
4.1. Designed 
Experiment
4.2. Observational Study
4.3. Retrospective Study
5. Statistical Analysis
c9s1, 
c2s1
c11s3

ENGINEERING FOUNDATIONS   18-19
5.1. Unit of Analysis 
(Sampling Units), 
Population and Sample
c3s5, 
c3s8, 
c4s5, 
c7s1, 
c7s3, 
c8s1, 
c9s1
5.2. Correlation and 
Regression
c11s2, 
c11s8
6. Modeling, 
Simulation and 
Prototyping
c6
c13s3c5
6.1. Modeling
6.2. Simulation
6.3. Prototypingc2s8
7. Measurement
pp 
442-
447
c4s4
c7s5c 3s1-2
7.1. Levels (Scales) of 
Measurement
p442-
447
c7s5c3s2
7.2. Implications of 
Measurement Theory for 
Programming Languages
7.3. Direct and 
Derived Measures
c7s5
7.4. Reliability 
and Validity
c3s4-5
7.5. Assessing Reliability
c3s5
7.6. Goal-Question-
Metric Paradigm: 
Why Measure?
8. Standardsc9s3.2
9. Root Cause Analysisc9s3-5
c 5, c 3s7,   
c9s8
9.1. Root Cause Analysis 
Techniques
c4
9.2. Root Cause-Based 
Improvement
10. Industry 4.0 and 
Software Engineering
FURTHER READINGS
A.   Abran,   Software   Metrics   and   Software   
Metrology. [18]
This book provides very good information on 
the proper use of the terms measure, measure-
ment method and measurement outcome. It pro-
vides  strong  support  material  for  the  entire  
section on measurement.

18-20   SWEBOK
®
 GUIDE V4.0
W.G.   Vi ncent i ,  What  Engineers  Know  and  
How They Know It. [19]
This book introduces engineering foundations 
through  case  studies  showing  many  foun-
dational  concepts  in  real-world  engineering  
applications. 
REFERENCES
[1] ISO/IEC/IEEE, “ISO/IEC/IEEE 
24765:2017 Systems and Software 
Engineering — Vocabulary,” 
2nd ed. 2017
[2*] S. Tockey, Return on Software: 
Maximizing the Return on Your 
Software Investment, 1st ed. Boston: 
Addison-Wesley, 2004.
[3*] G. Voland, Engineering by Design, 2nd 
ed. Upper Saddle River, NJ: Prentice 
Hall, 2003.
[4] “2021 Accreditation Criteria and 
Procedures,” Canadian Engineering 
Accreditation Board, Engineers 
Canada, 2021.
[5] E.A. Commission, “Criteria for 
Accrediting Engineering Programs, 
2022-2023,” ABET, 2021.
[6*] S. McConnell, Code Complete, 2nd ed. 
Redmond, WA: Microsoft Press, 2004.
[7]  Edsger W. Dijkstra, “The Humble 
Programmer,” Communications of the 
ACM, vol. 15, issue 10, October 1972.
[8*] D.C. Montgomery and G.C. Runger, 
Applied Statistics and Probability for 
Engineers, 7th ed. Hoboken, NJ: 
Wiley, 2018.
[9*] L. Null and J. Lobur, The Essentials 
of Computer Organization and 
Architecture, 5th ed. Sudbury, MA: 
Jones and Bartlett Publishers, 2018.
[10*] E.W. Cheney and D.R. Kincaid, 
Numerical Mathematics and 
Computing, 6th ed. Belmont, CA: 
Brooks/Cole, 2007.
[11*] I. Sommerville, Software Engineering, 
10th ed. New York: Addison-
Wesley, 2018.
[12*] R.E. Fairley, Managing and Leading 
Software Projects. Hoboken, NJ: Wiley-
IEEE Computer Society Press, 2009.
[13*] S.H. Kan, Metrics and Models in 
Software Quality Engineering, 2nd ed. 
Boston: Addison-Wesley, 2002.
[14] J.W. Moore, The Road Map to Software 
Engineering: A Standards-Based Guide, 
1st ed. Hoboken, NJ: Wiley-IEEE 
Computer Society Press, 2006.
[15]  K. Ishikawa, Introduction to Quality 
Control, Productivity Press, 1990.
[16]    D. Gano, Apollo Root Cause Analysis, 
3rd ed., Apollonian Publications, 2007.
[17]  E. Goldratt, It’s Not Luck, North 
River Press, 1994.
[18] A. Abran, Software Metrics and 
Software Metrology: Wiley-IEEE 
Computer Society Press, 2010.
[19] W.G. Vincenti, What Engineers 
Know and How They Know It. Johns 
Hopkins University Press, 1993.
[20]  Elisa Yumi Nakagawa, Pablo Oliveira 
Antonio, Frank Schnicke, Thomas 
Kuhn, Peter Liggesmeyer, Continuous 
Systems and Software Engineering for 
Industry 4.0: A disruptive view, Elsevier, 
Volume 135, July 2021, 106562 (https: 
//www.sciencedirect.com/science 
/article/abs/pii/S0950584921000458.)

A-1
KNOWLEDGE AREA DESCRIPTION SPECIFICATIONS
Appendix A 
INTRODUCTION
This appendix presents the specifications pro-
vided  to  the  knowledge  area  (KA)  editors  
regarding  the  KA  Descriptions  of  the  Guide 
to the Software Engineering Body of Knowledge, 
Version  4  (SWEBOK  Guide,  V4).  This  enables  
readers, reviewers and users to clearly under-
stand what specifications were used in devel-
oping this version of the SWEBOK Guide.
This   appendix   begins   by   situating   the   
SWEBOK Guide  as  a  foundational  document  
for the IEEE Computer Society’s suite of soft-
ware  engineering  products  and  more  widely  
within   the   software   engineering   commu-
nity. The appendix then describes the role of 
the baseline and change control. Criteria and 
requirements are defined for the breakdowns 
of  topics,  for  the  rationale  underlying  these  
breakdowns  and  the  succinct  description  of  
topics, and for reference materials. Important 
input documents are also identified, and their 
role  within  the  project  is  explained.  Finally,  
non-content issues such as submission format 
and style guidelines are discussed.
THE SWEBOK GUIDE IS A 
FOUNDATIONAL DOCUMENT 
FOR THE IEEE COMPUTER 
SOCIETY SUITE OF SOF TWARE 
ENGINEERING PRODUCTS
The SWEBOK  Guide  is  an  IEEE  Computer  
Society  flagship  and  structural  document  for  
the IEEE Computer Society’s suite of software 
engineering  products.  The  SWEBOK  Guide  is  
also  more  widely  recognized  as  a  foundational  
document throughout the software engineering 
community,    notably    through    the    official    
recognition  of  the  2004  and  2014  versions  
as   ISO/IEC   Technical   Report   19759:2005   
and  19759:2015,  respectively.  The  list  of  KAs  
and  the  breakdown  of  topics  within  each  are  
described and detailed in this SWEBOK Guide’s 
introduction.   Consequently,   the   SWEBOK 
Guide is foundational to other initiatives within 
the IEEE Computer Society, as follows:
•The   list   of   KAs   and   the   breakdown
of  topics  within  each  are  also  adopted
by  the  software  engineering  certifica-
tion  and  associated  professional  devel-
opment  products  offered  by  the  IEEE
Computer  Society.  (See  www.computer
.org/certification.)
•The  list  of  KAs  and  the  breakdown  of
topics  are  also  foundational  to  the  soft-
ware    engineering    curriculum    guide-
lines developed or endorsed by the IEEE
Computer  Society.  (See  www.computer.
org/portal/web/education/Curricula.)
•The   Consolidated   Reference   List   (see
Appendix  C)  —  meaning  the  list  of
Recommended  References  (to  the  level
of section number) that accompanies the
breakdown  of  topics  within  each  KA
—  is  also  adopted  by  the  software  engi-
neering  certification  and  associated  pro-
fessional  development  products  offered
by the IEEE Computer Society.
BASELINE AND CHANGE CONTROL
Due to the structural nature of the SWEBOK 
Guide  and  its  adoption  by  other  products,  a  
baseline  was  developed  at  the  outset  of  the  
project  by  a  SWEBOK  Steering  Group.  The  
baseline comprises the list of KAs, including 

A-2   SWEBOK
®
 GUIDE V4.0
new  ones,  and  the  breakdown  of  topics  for  
each KA from the previous version. 
Furthermore, a SWEBOK KA editors team 
has  been  put  in  place  for  the  development  
of  this  version  to  handle  all  major  change  
requests to this baseline coming from the KA 
editors,  arising  during  the  review  process  or  
otherwise. Change requests must be approved 
both  by  the  SWEBOK Guide  editors  and  by  
the   team   before   being   implemented.   The   
team  is  composed  of  members  of  the  initia-
tives listed above and acts under the authority 
of the Engineering Discipline Committee of 
the IEEE Computer Society Professional and 
Educational Activities Board (PEAB).
CRITERIA AND REQUIREMENTS 
FOR THE BREAKDOWN OF TOPICS 
WITHIN A KNOWLEDGE AREA
•    KA  editors  are  instructed  to  refine  the  
baseline  breakdown  of  topics  to  reflect  
the recent development in the target area 
for  KAs  that  continue  to  exist  from  the  
previous version. 
•    The breakdown of topics is expected to be 
“reasonable,” not “perfect.”
•    The  breakdown  of  topics  within  a  KA  
must   decompose   the   subset   of   the   
SWEBOK  that  is  “generally  recognized.”  
(See below for a more detailed discussion 
of this point.) 
•    The  breakdown  of  topics  within  a  KA  
must  not  presume  specific  application  
domains, business needs, sizes of organi-
zations,  organizational  structures,  man-
agement philosophies, software life cycle 
models,  software  technologies  or  soft-
ware development methods. 
•    The  breakdown  of  topics  must,  as  much  
as  possible,  be  compatible  with  the  var-
ious  schools  of  thought  within  software  
engineering. 
•    The  breakdown  of  topics  within  a  KA  
must  be  compatible  with  the  breakdown  
of  software  engineering  generally  found  
in  industry  and  in  the  software  engi-
neering literature and standards. 
•    The breakdown of topics is expected to be 
as inclusive as possible. 
•    The SWEBOK Guide adopts the position 
that even though the following “themes” 
are common across all KAs, they are also 
an  integral  part  of  all  KAs  and,  there-
fore,  must  be  incorporated  into  the  pro-
posed  breakdown  of  topics  of  each  KA.  
These common themes are measurement, 
quality (in general) and security. 
•    The breakdown of topics should be at most 
two  or  three  levels  deep.  Even  though  no  
upper  or  lower  limit  is  imposed  on  the  
number  of  topics  within  each  KA,  a  rea-
sonable  and  manageable  number  of  topics  
is  expected  to  be  included  in  each  KA.  
Emphasis should also be put on the selection 
of the topics themselves rather than on their 
organization in an appropriate hierarchy.
•    Topic  names  must  be  significant  enough  
to be meaningful even when cited outside 
the SWEBOK Guide. 
•    The  Description  of  a  KA  will  include  a  
chart (in tree form) describing the knowl-
edge breakdown. This chart will typically 
be the first figure in the respective KA.
CRITERIA AND REQUIREMENTS 
FOR DESCRIBING TOPICS
Topics  need  only  be  sufficiently  described  
so  readers  can  select  the  appropriate  refer-
ence material according to their needs. Topic 
descriptions must not be prescriptive.
CRITERIA AND REQUIREMENTS 
FOR REFERENCE MATERIAL
•    KA editors are instructed to use the ref-
erences  (to  the  level  of  section  number)  
allocated to their KA by the Consolidated 
Reference  List  as  their  Recommended  
References.
•    There   are   three   categories   of   refer-
ence material:
 »Recommended  References.  The  set  of  
Recommended References (to the level 

APPENDIX A    A-3
of section number) is collectively known 
as the Consolidated Reference List. 
 »Further Readings.
 »Additional  references  cited  in  the  KA  
Description  (e.g.,  the  source  of  a  quo-
tation  or  reference  material  in  sup-
port  of  a  rationale  behind  a  particular  
argument).
•    The SWEBOK Guide is intended by defi-
nition to be selective in its choice of topics 
and associated reference material. The list 
of  reference  material  should  be  clearly  
viewed  as  an  “informed  and  reasonable  
selection” rather than as a definitive list.
•    Reference  material  can  be  book  chap-
ters,   refereed   journal   papers,   refereed   
conference  papers,  refereed  technical  or  
industrial  reports,  or  any  other  type  of  
recognized artifact. References to another 
KA, subarea or topic are also permitted.
•    Reference   material   must   be   generally   
available  and  must  not  be  confidential  
in nature. 
•    Reference material must be in English. 
•    Criteria    and    requirements    for    rec-
ommended      reference      material      or      
Consolidated Reference List:
 »Collectively, the list of Recommended 
References should be:
i. Complete   —   covering   the   entire   
scope of the SWEBOK Guide
ii. Sufficient    —    providing    enough    
information  to  describe  “generally  
accepted” knowledge
iii. Consistent  —  not  providing  con-
tradictory     knowledge     or     con-
flicting practices
iv.   Credible — recognized as providing 
expert treatment
v.   Current  —  treating  the  subject  in  a  
manner  that  is  commensurate  with  
current, generally accepted knowledge
vi. Succinct — as short as possible (both 
in the number of reference items and 
in  total  page  count)  without  failing  
other objectives
 »Recommended     reference     material     
must   be   identified   for   each   topic.   
Each   recommended   reference   item   
may,  of  course,  cover  multiple  topics.  
Rarely, a topic may be self-descriptive 
and  not  cite  a  reference  material  item  
(e.g.,  a  topic  that  is  a  definition  or  a  
topic  for  which  the  description  itself  
without  any  cited  reference  material  
is  sufficient  for  the  objectives  of  the  
SWEBOK Guide). 
 »Each  reference  to  the  recommended  
reference material should be as precise 
as  possible,  identifying  what  specific  
chapter or section is relevant.
 »A  matrix  of  reference  material  (to  the  
level  of  section  number)  versus  topics  
must be provided.
 »The latest versions or editions should be 
used  as  the  Recommended  References  
if there are multiple versions or editions.
 »A reasonable amount of recommended 
reference  material  must  be  identified  
for each KA. The following guidelines 
should  be  used  in  determining  how  
much is reasonable: 
i. If    the    recommended    reference    
materials  are  written  in  a  coherent  
manner, follow the proposed break-
down of topics, and use a consistent 
style (e.g., list a new book based on 
the  proposed  KA  description),  an  
average  page  number  target  across  
all KAs would be 750. However, this 
target  may  not  be  attainable  when  
selecting  existing  reference  mate-
rial due to differences in style and to 
overlap  and  redundancy  among  the  
selected reference materials.
i. In  other  words,  the  target  for  the  
number  of  pages  for  the  entire  col-
lection of Recommended References 
in  the  SWEBOK  Guide  is  in  the  
range of 10,000 to 15,000 pages.
i. Another way of viewing this is that 
the  amount  of  recommended  refer-
ence material would be reasonable if 
it consisted of the study material for 
this  KA  for  a  software  engineering  
licensing   exam   that   a   graduate   
would  pass  after  completing  four  
years of work experience. 

A-4   SWEBOK
®
 GUIDE V4.0
•    Additional   reference   material   can   be   
included by the KA editor in a “Further 
Reading” list: 
 »These  materials  must  be  related  to  the  
topics  in  the  breakdown  rather  than,  
for example, to more advanced topics.
 »The  list  must  be  annotated  (one  para-
graph per reference) to explain why each 
reference was included. Further Reading 
could include alternative viewpoints on 
a KA or a seminal treatment of a KA.
 »A general guideline to be followed is 10 
or fewer further readings per KA.
 »There  is  no  matrix  of  the  reference  
materials listed in Further Reading and 
the breakdown of topics. 
•    Criteria    and    requirements    regarding    
additional  references  cited  in  the  KA  
Description:
 »The SWEBOK  Guide  is  not  a  research  
document,  and  its  readership  will  be  
varied.  Therefore,  a  delicate  balance  
must  be  maintained  between  ensuring  
a  high  level  of  readability  within  the  
document  and  maintaining  its  tech-
nical  excellence.  Additional  reference  
material  should,  therefore,  be  brought  
in  by  the  KA  editor  only  if  it  is  nec-
essary  to  the  discussion.  For  example,  
the   reference   material   might   iden-
tify  the  source  of  a  quotation  or  offer  
support  for  the  rationale  behind  an  
important argument.
COMMON STRUCTURE
KA  Descriptions  should  use  the  following  
structure: 
•    Acronyms
•    Introduction
•    Breakdown of Topics of the KA (including 
a figure describing the breakdown)
•    Matrix of Topics vs. Reference Material
•    List of Further Reading
•    References
WHAT DO WE MEAN BY 
“GENERALLY RECOGNIZED 
KNOWLEDGE”?
The Software Engineering Body of Knowledge 
is an all-inclusive term that describes the sum 
of knowledge within the profession of software 
engineering.  However,  the  SWEBOK  Guide 
seeks to identify and describe that subset of the 
body of knowledge that is generally recognized 
or, in other words, the core body of knowledge. 
To better illustrate what “generally recognized” 
knowledge is relative to other types of knowl-
edge,  Figure  A.1  proposes  a  three-category  
schema for classifying knowledge.
The   Project   Management   Institute,   in   
its Guide  to  the  Project  Management  Body  of  
Knowledge,   defines   “generally   recognized”   
knowledge for project management as:
that  subset  of  the  project  management  body  of  
knowledge  generally  recognized  as  good  prac-
tice. “Generally recognized ” means the knowl-
edge  and  practices  described  are  applicable  to  
most projects most of the time, and there is con-
sensus about their value and usefulness. “Good 
practice” means there is general agreement that 
the  application  of  these  skills,  tools,  and  tech-
niques  can  enhance  the  chances  of  success  over  
a  wide  range  of  projects.  “Good  practice”  does  
not mean that the knowledge described should 
always be applied uniformly to all projects; the 
organization and/or project management team 
is  responsible  for  determining  what  is  appro-
priate for any given project [1].
Specialized Practices Used Only 
for Certain Types of Software
Generally Recognized 
Established traditional practices 
recommended by many 
organizations
Advanced and Research
Innovative practices tested and used 
only by some organizations and 
concepts still being developed and 
tested in research organizations  
Figure A.1. Categories of Knowledge

APPENDIX A    A-5
“Generally accepted” knowledge could also 
be  viewed  as  knowledge  to  be  included  in  
the  study  material  of  a  software  engineering  
licensing  exam  (in  the  US)  that  a  graduate  
would  take  after  completing  four  years  of  
work experience. These two definitions should 
be seen as complementary.
KA  editors  are  also  expected  to  be  some-
what  forward-looking  in  their  interpretation  
by taking into consideration not only what is 
“generally  recognized”  today  but  also  what  
they expect will be “generally recognized” in 
a three- to five-year time frame.
LENGTH OF KA DESCRIPTION
KA  Descriptions  are  to  be  roughly  10  to  
20  pages  using  the  formatting  template  for  
papers  published  in  conference  proceedings  
of the IEEE Computer Society. This includes 
text, references, appendixes, tables, etc. This, 
of course, does not include the reference mate-
rials themselves. 
IMPORTANT RELATED 
DOCUMENTS
Graduate      Software      Engineering      2009      
(GSwE2009):     Curriculum     Guidelines     for     
Graduate     Degree     Programs     in     Software     
Engineering, 2009 [2].
This  document  “provides  guidelines  and  rec-
ommendations”  for  defining  the  curricula  of  
a professional master’s-level program in soft-
ware  engineering.  The  SWEBOK  Guide  is  
identified  as  a  “primary  reference”  in  devel-
oping the body of knowledge underlying these 
guidelines. This document has been officially 
endorsed by the IEEE Computer Society and 
sponsored by the Association for Computing 
Machiner y.
ISO/IEC/IEEE      12207-2017      Standard      
for  Systems  and  Software  Engineering  —  
Software  Life  Cycle  Processes,  ISO/IEC/
IEEE, 2017 [3].
This  standard  is  considered  the  key  standard  
regarding  the  definition  of  life  cycle  pro-
cesses and has been adopted by the two main 
standardization   bodies   in   software   engi-
neering: ISO/IEC JTC1/SC7 and the IEEE 
Computer   Society   Software   and   Systems   
Engineering  Standards  Committees.  It  also  
has been designated a pivotal standard by the 
Software and Systems Engineering Standards 
Committee (S2ESC) of the IEEE. 
Even though we do not intend the SWEBOK 
Guide to be fully 12207-conformant, this stan-
dard remains a key input to the SWEBOK Guide, 
and special care will be taken throughout the 
SWEBOK  Guide  regarding  the  compatibility  
of the Guide with the 12207 standard.
“Software   Engineering   2014:   Curriculum   
Guidelines     for     Undergraduate     Degree     
Programs  in  Software  Engineering,”  IEEE  
Computer    Society    and    Association    for    
Computing  Machinery,  2015;  https://www.
acm.org/binaries/content/assets/education/
se2014.pdf [4].
This document describes curriculum guidelines 
for  an  undergraduate  degree  in  software  engi-
neering.  The  SWEBOK  Guide  is  identified  as  
“one of the primary sources” in developing the 
body of knowledge underlying these guidelines.
“ISO/IEC/IEEE  24765:2017  Software  and  
Systems  Engineering  —  Vocabulary,”  ISO/
IEC/IEEE,    2017;    https://www.computer.
org/sevocab [5].
The hierarchy of references for terminology is 
Merriam-Webster’s  Collegiate  Dictionary  (11th  
ed.) [6], ISO/IEC/IEEE 24765 [5] and newly 
proposed definitions, if required.
“Software Professional Certification Program,” 
IEEE    Computer    Society;    https://www. 
computer.org/education/certifications [7].
Information on the certification and associated 
professional  development  products  developed  
and offered by the IEEE Computer Society for 
professionals in the field of software engineering 

A-6   SWEBOK
®
 GUIDE V4.0
can  be  found  on  this  website.  The  SWEBOK 
Guide is foundational to these products.
OTHER DETAILED GUIDELINES
When  referencing  the  Guide  to  the  Software  
Engineering  Body  of  Knowledge,  use  the  title  
SWEBOK Guide.
For  the  purpose  of  simplicity,  avoid  foot-
notes, and try to include their content in the 
main text.
Use  explicit  references  to  standards,  as  
opposed  to  simply  inserting  numbers  refer-
encing  items  in  the  bibliography.  We  believe  
this  approach  allows  the  reader  to  be  better  
exposed to the source and scope of a standard.
The  text  accompanying  figures  and  tables  
should  be  self-explanatory  or  have  enough  
related  text.  This  ensures  that  the  reader  
knows what the figures and tables mean.
To  make  sure  that  some  information  in  
the SWEBOK  Guide  does  not  become  rap-
idly obsolete and in order to reflect its generic 
nature, please avoid directly naming tools and 
products. Instead, try to name their functions.
EDITING 
Editors of the SWEBOK Guide, as well as profes-
sional copy editors, will edit KA Descriptions. 
Editing includes copy editing (grammar, punc-
tuation  and  capitalization),  style  editing  (con-
formance to the Computer Society style guide), 
and  content  editing  (flow,  meaning,  clarity,  
directness  and  organization).  The  final  editing  
will be a collaborative process in which the edi-
tors of the SWEBOK Guide and the KA editors 
will  work  together  to  achieve  a  concise,  well-
worded and useful KA Description.
RELEASE OF COPYRIGHT
All   intellectual   property   rights   associated   
with  the  SWEBOK  Guide  will  remain  with  
the IEEE. KA editors must sign a copyright 
release form.
It is also understood that the SWEBOK Guide 
will  continue  to  be  available  free  of  charge  in  
the  public  domain  in  at  least  one  format,  pro-
vided by the IEEE Computer Society through 
web technology or by other means.
(For more information, see www.computer.
org/copyright.htm.)
REFERENCES
[1] Project Management Institute, A 
Guide to the Project Management Body of 
Knowledge (PMBOK® Guide), 7th ed., 
Project Management Institute, 2021.
[2] Integrated Software and Systems 
Engineering Curriculum (iSSEc) Project, 
Graduate Software Engineering 2009 
(GSwE2009): Curriculum Guidelines 
for Graduate Degree Programs in 
Software Engineering, Stevens Institute 
of Technology, 2009; https://dl.acm.org/
doi/book/10.1145/2593248.
[3] ISO/IEC/IEEE 12207-2017 Systems 
and Software Engineering — Software 
Life Cycle Processes, 2017.
[4] Joint Task Force on Computing 
Curricula, IEEE Computer Society and 
Association for Computing Machinery, 
“Software Engineering 2014: Curriculum 
Guidelines for Undergraduate Degree 
Programs in Software Engineering, 
2015”; https://www.acm.org/binaries/
content/assets/education/se2014.pdf.
[5]  ISO/IEC/IEEE 24765:2017 Systems and 
Software Engineering — Vocabulary, 
2nd ed. 2017.
[6] Merriam-Webster’s Collegiate Dictionary, 
11th ed., 2003.
[7]   IEEE Computer Society, “Certification 
and Training for Software Professionals,” 
2013; https://www.computer.org/
education/certifications.

B-1 
IEEE AND ISO/IEC STANDARDS
Appendix B
ACRONYMS
EICInternational Electrotechnical 
Commission
ISO
International Organization for 
Standardization
JTC
Joint Technical Committee
MSS
Management System Standard
S2ESC
Systems and Software Engineering 
Standards Committee
SC
Subcommittee
SUPPORTING THE SOF TWARE 
ENGINEERING BODY OF 
KNOWLEDGE (SWEBOK)
1. Overview
The purpose of this appendix is to describe the 
relationship  between  IEEE  software  engi-
neering standards and the SWEBOK and to 
introduce  the  more  prominent  international  
software engineering standards most directly 
related  to  the  SWEBOK  knowledge  areas  
(KA).  A  summary  list  of  some  useful  stan-
dards  for  software  engineering,  including  all  
those referenced in this document, is in B.9.
1.1 The SWEBOK and standards
The  SWEBOK  and  other  bodies  of  knowl-
edge  are  closely  related  to  standards  for  soft-
ware  engineering,  and  standards  are  cited  
as  resources  in  knowledge  areas  (KA)  in  the  
SWEBOK.   Standards   for   software   engi-
neering extend and apply the generally accepted 
body  of  knowledge  that  is  collected  in  the  
SWEBOK. Conversely, standards also define 
and  organize  the  systematic  knowledge  that  
is then reflected in collected bodies of knowl-
edge. However, the SWEBOK has a different 
purpose from most software engineering stan-
dards.   The   SWEBOK   summarizes   gener-
ally  accepted  concepts  and  experience-based  
information  about  how  software  engineering  
is  practiced.  This  knowledge  summary  can  
be applied in various ways: to define a curric-
ulum for educating software engineers, or for 
employers or certification bodies determine if 
a  person  has  the  knowledge  and  accepts  the  
ethical  values  needed  to  practice  software  
engineering or to be certified.
In  contrast,  a  standard  is  a  “document,  
established  by  consensus  and  approved  by  a  
recognized  body,  that  provides,  for  common  
and repeated use, rules, guidelines or charac-
teristics  for  activities  or  their  results,  aimed  
at  the  achievement  of  the  optimum  degree  
of  order  in  a  given  context”  (ISO/IEC  TR  
29110-1:2016).   In   standards,   the   “Rules,   
guidelines,  or  characteristics”  are  expressed  
differently:
•    requirements   in   normative   standards,   
(stated using shall or the imperative),
•    recommended  practices  (stated  using   
should)
•    other  guidance  on  possible  approaches  
(stated using may)
Standards  allow  for  global  interoperability  
for  accepted  concepts,  processes,  people,  and  
products.  The  existence  of  standards  takes  a  
very large (possibly infinite) trade space of alter-
natives  and  normalizes  that  space,  supporting  
mutual  understanding  between  acquirers  and  
suppliers. In that respect, software engineering 
standards  counter  the  tendency  of  competing  

B-2   SWEBOK
®
 GUIDE V4.0
organizations  to  develop  unique,  proprietary  
products   that   do   not   interoperate   outside   
their own suite. When standards are open, so 
that  organizations  of  all  sizes  can  meet  their  
requirements,  demand  for  trustworthy  prod-
ucts  and  services  increases  to  the  benefit  of  
many suppliers and acquirers.
Standards  are  voluntary;  an  individual  or  
organization  can  choose  to  conform  to  their  
requirements  and  follow  their  recommenda-
tions.  When  the  standard  is  incorporated  in  
contracts or other agreements, laws, and reg-
ulations,  then  compliance  with  the  standard  
becomes mandatory.
1.2 Types of Standards
Standards  can  be  characterized  by  what  part  
of   software   engineering   they   standardize:   
concepts   and   terms,   processes,   products,   
people, or assessment of capabilities.
Some software engineering standards simply 
present  concepts  (characteristics)  and  define  
terms,  perhaps  even  establishing  a  schema  
of  knowledge  about  a  software  engineering  
topic.  An  example  of  this  type  of  standard  is  
ISO/IEC/IEEE  24765  Systems  and  software  
engineering:  Vocabulary,  which  is  freely  avail-
able   online   at   www.computer.org/sevocab.
1
 
However, most software engineering standards 
describe  one  or  more  of  the  software  engi-
neering  processes  and  give  requirements  and  
recommendations  about  how  to  perform  that  
process. The primary process standard in soft-
ware  engineering  is  ISO/IEC/IEEE  12207,  
Systems  and  software  engineering:  Software  life  
cycle processes. There is even a standard for how 
to describe a process: ISO/IEC/IEEE 24774, 
Systems  and  software  engineering  —Life  cycle  
management  —Specification  for  process  descrip-
tion. It describes the purpose, outcomes, activ-
ities,  tasks,  and  possibly  the  inputs,  outputs,  
and  other  features  of  a  process.  Process  stan-
dards should not be confused with procedures 
or instructions; they do not offer detailed rec-
ipes or step-by-step instructions for doing soft-
ware engineering.
1   http://pascal.computer.org/sev_display/index.action.
A few software engineering standards have 
standardized descriptions of products of soft-
ware engineering, such as models or informa-
tion products like a project management plan 
(ISO/IEC/IEEE   16326).   Another   notable   
standard  for  information  products  is  ISO/
IEC/IEEE 15289, Systems and software engi-
neering—Contents of life cycle information items 
(documentation). Initially, most software engi-
neering standards were standards for a prom-
inent   information   product,   a   plan.   These   
allowed  customers  (acquirers  of  software)  to  
understand and compare what their suppliers 
would  produce  (a  product).  A  standard  for  a  
plan describes what will be produced or deliv-
ered,  what  methods  and  techniques  will  be  
used,  and  what  activities  will  be  performed.  
In  recent  years,  most  of  the  standards  for  
plans have been revised to become standards 
for software engineering processes.
Besides  standards  for  concepts,  processes,  
and products, there are also standards for peo-
ple’s skills, knowledge, or abilities, and stan-
dards  for  certification  schemes  and  bodies  
of  knowledge  in  software  engineering.  An  
example  is  ISO/IEC  24773-1:2019,  Software 
and systems engineering — Certification of soft-
ware  and  systems  engineering  professionals  —  
Part   1:   General   requirements.   Reviews   and   
assessments  can  be  standardized  for  soft-
ware engineers, organizations, processes, and 
work products.
1.3 Sources of Software Engineering Standards
Although  there  are  thousands  of  pages  in  hun-
dreds   of   systems   and   software   engineering   
standards,  guides,  textbooks  and  handbooks,  
there  are  only  two  international  organizations  
accredited   to   produce   systems   and   software   
engineering  standards:  ISO/IEC  JTC  1/SC  7  
and  IEEE.  Both  have  produced  software  engi-
neering standards for over thirty-five years. Both 
are  committed  to  produce  standards  using  doc-
umented,  consensus-based  processes  with  open  
participation.  ISO/IEC  JTC  1  (International  
Organization for Standardization / International 

APPENDIX B   B-3
Electrotechnical  Commission  Joint  Technical  
Committee)  /  SC  7  (Subcommittee),  Software  
and  Systems  Engineering,  produces  standards  
through  its  membership  of  national  standards  
bodies.  JTC  1/SC  7  has  a  portfolio  of  over  
two hundred standards. The IEEE Computer 
Society   Systems   and   Software   Standards   
Committee  (S2ESC)  produces  standards  in  
working groups of individual experts. It main-
tains  about  fifty  standards,  of  which  about  
80%  have  been  approved  as  ISO/IEC/IEEE  
joint  standards.  These  are  IEEE  standards  
adopted  by  ISO/IEC  JTC  1/SC  7,  or  stan-
dards  that  are  jointly  developed  and  main-
tained  with  ISO/IEC  JTC  1  and  designated  
as  ISO/IEC/IEEE.  The  aim  of  these  jointly  
developed  standards  is  to  have  a  coordinated  
collection of consistent standards for interna-
tional use. For the ISO/IEC/IEEE standards 
described in this appendix, the IEEE version 
and  the  ISO/IEC  version  are  substantively  
identical.  The  respective  versions  may  have  
different front and back matter but the tech-
nical content is exactly the same.
Standards   can   be   purchased   from   the   
IEEE, ISO, and IEC websites, from national 
standards  organizations,  and  from  commer-
cial resellers. Academic institutions and soft-
ware engineering organizations can purchase 
or  subscribe  to  collections  of  standards  for  
use by their staffs. A few standards are freely 
available,  generally  those  that  provide  intro-
ductions to concepts or terminology.
In  both  IEEE  and  ISO/IEC  JTC  1,  stan-
dards  for  systems  engineering  are  maintained  
by  the  same  committee  as  those  for  software  
engineering.  Most  of  the  standards  apply  to  
both, especially when software is considered as 
a system or as the major component of a system 
of interest. So, instead of making fine distinc-
tions,  this  appendix  covers  both  as  applicable  
to  software  engineering.  It  does  not  mention  
older,  now  stabilized  standards  dealing  with  
the  foundations  of  computing  or  computing  
languages and basic programming, mathemat-
ical, or engineering concepts.
ISO and IEEE have their own numbering 
systems  for  their  standards.  When  an  IEEE  
standard  is  adopted  by  ISO/IEC  JTC  1,  it  
is  typically  renumbered  to  a  5-digit  number,  
e.g.,  IEEE  1062  becomes  ISO/IEC/IEEE  
41062.  ISO  standards  have  long,  taxonom-
ical titles with three and four levels of classi-
fication. The first level shows the general area 
(e.g.  systems  and  software  engineering);  the  
second level is the main title of the standard, 
and the third level provides even more detail, 
especially  for  multi-part  standards.  To  avoid  
cumbersome  repetition,  this  appendix  often  
uses a shortened title of the standard or simply 
cites it by number. The full title is given in the 
list in B.9. All of these software engineering 
standards are copyright protected, and IEEE 
standard numbers are trademarked.
2. The software engineering standards 
landscape
Figure  B.1  presents  an  overview  of  the  most  
prominent  software  engineering  standards,  
mainly  from  the  perspective  of  how  other  
standards  relate  to  the  major  software  engi-
neering life cycle process standard, ISO/IEC/
IEEE 12207, software engineering processes. 
It  is  closely  related  to  the  SWEBOK  in  that  
both  present  information  related  to  many  
of  the  same  software  life  cycle  processes.  
Also  in  the  upper  portion  of  Figure  B.1  are  
the  foundational  standards,  such  as  the  spe-
cialized   vocabulary   for   systems   and   soft-
ware  engineering  (SEVOCAB,  ISO/IEC/
IEEE  24765)  and  a  specification  for  how  to  
describe  processes  (ISO/IEC/IEEE  24774).  
There  are  standards  for  how  to  plan  for  and  
manage   software   engineering   (ISO/IEC/
IEEE 24748-5) and how to conduct rigorous 
reviews  and  audits,  appropriate  for  critical  
software  like  aerospace  and  defense  systems  
(ISO/IEC/IEEE 24748-8).
Using the life cycle process model of 12207 
as  described  in  the  following  section,  there  
are many more specialized standards covering 
individual processes and modern approaches to 
the processes, such as ISO/IEC/IEEE 32675, 
DevOps,  as  well  as  IEEE  1012,  Verification  
and  validation,  and  ISO/IEC/IEEE  29119,  
software  testing  (in  multiple  parts).  The  life  
cycle  processes  in  12207  generally  focus  on  a  

B-4   SWEBOK
®
 GUIDE V4.0
single system of interest (SOI) but more spe-
cialized series focus on processes and tools for 
product  line  engineering,  and  for  systems  of  
systems  (SoS).  The  System  of  Systems  stan-
dards,  ISO/IEC/IEEE  21839,  21840,  and  
21841, explain how to use systems engineering 
processes when the system of interest (SOI) is 
a constituent part of a system of systems.
The life cycle process standards are intended 
to be compatible with other well-known stan-
dards  for  management  systems.  According  
to ISO, “a management system is the way in 
which  an  organization  manages  the  interre-
lated parts of its business in order to achieve 
its objectives.” Management system standards 
(MSS) have a consistent structure and frame-
work  of  requirements,  but  each  MSS  covers  
a  specific  aspect  of  managing  and  delivering  
engineering   products   and   services.   MSS   
typically  come  in  multiple  parts  with  var-
ious  guides  for  different  aspects  of  their  sys-
tems.  Well-known  MSS  related  to  software  
engineering  include  ISO  9000  for  quality  
management,  ISO/IEC  20000  for  service  
management,  the  ISO/IEC  27000  series  for  
information  security  management,  the  ISO/
IEC 19770 series for managing IT assets like 
hardware  and  software,  and  the  ISO/IEC  
30105 series for business process outsourcing 
operations.
3. Life cycle process standards
ISO/IEC/IEEE  12207,  Software  life  cycle  
processes,    and    ISO/IEC/IEEE    15288,    
System  life  cycle  processes,  are  intentionally  
harmonized  for  use  together.  As  stated  in  
ISO/IEC/IEEE 15288:2023, “there is a con-
tinuum  of  human-made  systems  from  those  
that use little or no software to those in which 
software  is  the  primary  interest.  When  soft-
ware  is  the  predominant  system  or  element  
of  interest,  ISO/IEC/IEEE  12207  should  
be  used.”  Both  standards  have  identical  life  
cycle models (the same four process groups, as 
shown in Figure B.2) and the same processes, 
The processes have the same names, purposes, 
and  process  outcomes  (there  are  minor  vari-
ations  in  a  couple  of  process  names)  in  both  
standards.  Process  activities  and  tasks  differ  
between these two foundational standards, as 
some aspects of engineering for software sys-
tems  are  different  from  systems  in  general.  
Conformance  to  ISO/IEC/IEEE  12207  or  
IEEE Guide to 
SW Engineering 
Body of Knowledge 
(SWEBOK)
ISO/IEC/IEEE 24765 
Vocabulary 
(SEVOCAB)
Product 
Lines
Process Description
ISO/IEC/IEEE 24774
DevOps Process View
ISO/IEC/IEEE 32675
ISO/IEC/IEEE 24748-4 SE Plans
ISO/IEC/IEEE 24748-8 
Reviews and Audits
Management Systems
Information Mgmt: 
ISO/IEC/IEEE 
15289
Individual Processes
Verification/
Validation
IEEE 1012
Software Testing
ISO/IEC/IEEE 
29119
ISO 9001 Quality
ISO/IEC 20000 Service
ISO/IEC 27000 Security
ISO/IEC 19770 IT 
Asset Mgmt.
Systems of systems (SoS)
ISO/IEC/IEEE 
21839, 21840, 21841
Life Cycle Processes
ISO/IEC/IEEE 12207
Figure B.1. Software Engineering Standards Landscape

APPENDIX B   B-5
15288 can be shown either by demonstrating 
that all the outcomes of the process have been 
achieved,  or  that  all  the  required  activities  
and tasks of a process have been performed.
The  life  cycle  processes  are  presented  in  
the context of their use on projects, supported 
by  an  organization  that  provides  continuous  
services  applicable  across  multiple  projects.  
However,  the  processes  can  be  applied  in  
very small entities which are essentially orga-
nized as a single team, as well as on large pro-
grams and continuing efforts that do not have 
a defined end point like a project.
IEEE  Std  12207  establishes  a  common  
framework  for  software  life  cycle  processes,  
with well-defined terminology that can be ref-
erenced  by  the  software  industry.  ISO/IEC  
12207  applies  to  the  acquisition  of  systems  
and software products and services and to the 
supply,  development,  operation,  maintenance,  
and disposal of software systems and the soft-
ware  portion  of  a  system,  whether  performed  
internally  or  externally  to  an  organization.  
Those aspects of system definition and enabling 
systems (infrastructure) needed to provide the 
context for software products and services are 
included.  Selected  sets  of  these  processes  can  
be  applied  throughout  the  life  cycle  for  man-
aging  and  performing  the  stages  of  a  system’s  
life  cycle.  This  is  accomplished  through  the  
involvement  of  all  interested  parties,  with  the  
goal of achieving customer satisfaction.
Table  B.1  aligns  the  software  life  cycle  
processes  of  ISO/IEC/IEEE  12207  to  the  
SWEBOK  KA  and  identifies  related  stan-
dards  that  offer  more  detailed  requirements  
and  guidance  for  individual  processes.  The  
SWEBOK  KA  do  not  directly  cover  all  of  
the  process  groups  and  processes  in  ISO/
IEC/IEEE 12207. The Agreement processes 
(acquisition and supply) are not included, nor 
many  of  the  processes  in  the  Organizational  
Project-enabling  process  group,  and  not  all  
of  the  Technical  Management  or  Technical  
process  group  processes.  SWEBOK  KA  are  
selected   to   cover   the   essential   knowledge   
areas applied by individual software engineers 
working on projects or ongoing efforts, rather 
than those generally handled at higher levels 
in the organization or on a more general level.
This  version  of  the  SWEBOK  has  added  
the software security KA, which for historical 
reasons has been standardized separately from 
the  systems  and  software  engineering  stan-
dards committees. Security is not identified as 
a technical process in ISO/IEC/IEEE 12207. 
An extensive suite of security standards based 
on the ISO/IEC 27001 MSS are developed in 
ISO/IEC JTC 1 SC 27, Information security, 
cybersecurity, and privacy protection.
Table B.1 also identifies standards that are 
intended to identify process-related functions 
where  software  tools  and  methods  should  be  
applied,  or  to  apply  the  processes  to  product  
line engineering (see B.6).
4. Extensions and specialized applications 
of ISO/IEC/IEEE 12207
Numerous  useful  standards  supplement  the  
requirements  of  ISO/IEC/IEEE  12207  to  
handle  more  rigorous  or  specialized  situa-
tions,  or  to  provide  more  extended  guidance  
on its concepts and processes. Many of these 
standards  are  parts  of  the  ISO/IEC/IEEE  
24748 fa mi ly.
4.1, Explanations of concepts and several processes
ISO/IEC/IEEE   24748-1,   -2   and   -3   are   
overall  guides  to  the  life  cycle  processes  and  
invaluable  for  understanding  and  applying  
systems  and  software  engineering  concepts.  
single system of interest (SOI) but more spe-
cialized series focus on processes and tools for 
product  line  engineering,  and  for  systems  of  
systems  (SoS).  The  System  of  Systems  stan-
dards,  ISO/IEC/IEEE  21839,  21840,  and  
21841, explain how to use systems engineering 
processes when the system of interest (SOI) is 
a constituent part of a system of systems.
The life cycle process standards are intended 
to be compatible with other well-known stan-
dards  for  management  systems.  According  
to ISO, “a management system is the way in 
which  an  organization  manages  the  interre-
lated parts of its business in order to achieve 
its objectives.” Management system standards 
(MSS) have a consistent structure and frame-
work  of  requirements,  but  each  MSS  covers  
a  specific  aspect  of  managing  and  delivering  
engineering   products   and   services.   MSS   
typically  come  in  multiple  parts  with  var-
ious  guides  for  different  aspects  of  their  sys-
tems.  Well-known  MSS  related  to  software  
engineering  include  ISO  9000  for  quality  
management,  ISO/IEC  20000  for  service  
management,  the  ISO/IEC  27000  series  for  
information  security  management,  the  ISO/
IEC 19770 series for managing IT assets like 
Technical 
Management
Technical
Organizational 
Project-enabling
Agreement
Figure B.2. Process groups of ISO/IEC/
IEEE 12207

B-6   SWEBOK
®
 GUIDE V4.0
TABLE B.1. RELATED SOF TWARE ENGINEERING STANDARDS AND KA BY 
ISO/IEC/IEEE 12207 PROCESS GROUP AND PROCESS
12207 
Clause  
Number
Short titleSWEBOK K ARelated standard
(ISO/IEC/
IEEE unless 
otherwise shown)
Product line or 
tool standard  
(ISO/IEC)
Agreement
6.1.1Acquisition41062, 26512
6,1,2Supply41062
Organizational process enabling
6.2.1Life cycle model 
management
Ye s24748-1, 24748-2 , 
24748-3, 3302 0
6.2.2Infrastructure 
management
26550
6.2.3Portfolio management33001
26556
6.2.4Human Resources 
management
Yes, Professional  
practice
24773
6.2.5Quality managementYes, Quality  
Assurance
IEEE 730, 
25000, 90003
6.2.6Knowledge management
Technical management
6.3.1Project planningYe s16326, 
24748-4, 24748-5
26555
6.3.2Project 
assessment, control
Ye s16326, 24748-4, 
24748-5, 24748-7, 
26511, 20246
23396, 
23531, 26555, 
33001, 33002
6.3.3Decision management
6.3.4Risk Management16085, 15026 
(a l l par ts)
6.3.5Configuration 
Management
Ye sIEEE 
828, 16350,  
19770 (all parts)
26559, 
26560, 26561
6.3.6Information 
management
15289, 
26511, 26531, 
23026, 82079-1
6.3.7MeasurementYe s15939, 14143, 
32430, 19761, 
20926, 25020, 
25021, 25022, 
25023, 25024, 
29881, 33003
6.3.8Quality AssuranceYe sIEEE 730, 
IEEE 982.1, 
25010, 25012

APPENDIX B   B-7
ISO/IEC/IEEE   24748-1,   Guidelines   for   
life  cycle  management,  is  much  more  than  
a  guide  to  performing  the  life  cycle  man-
agement  process.  It  applies  to  both  software  
and systems engineering processes, with fur-
ther explanations of system and process con-
cepts.  Instead  of  describing  processes,  which  
are   usually   applied   repeatedly   throughout   
the  life  cycle,  it  includes  a  detailed  descrip-
tion  of  life  cycle  stages,  covering  their  pur-
pose and outcomes. There are several models 
of  life  cycle  stages,  and  in  ISO/IEC/IEEE  
24748-1  the  model  that  is  analyzed  in  detail  
includes the following stages: concept, devel-
opment, production, utilization, support, and 
retirement.  Since  software  engineers  rarely  
Te c h n i c a l
6.4.1Business or 
Mission Analysis
26561
6.4.2Stakeholder needs & 
requirements
Ye s25030
6.4.3Systems requirements 
definition
Ye s29148
26551
6.4.4Architecture definitionYe s42010, 42020
26442, 26552
6.4.5Design definitionYe s24748-
7000. 26514
26557, 26580
6.4.6System analysisYes, Models 
and Methods
ISO/IEC 24641
20246, 26558
6.4.7ImplementationYes, 
Construction
26553
6.4.8IntegrationYes, 
Construction
24748- 6
6.4.9VerificationYes, TestingIEEE 1012, 
25021,25040, 
25041, 25045, 
25062, 26513, 
29119-1, 29119-2,  
29119-3, 
33063, 42030
23643,26554,  
30130
6.4.10Transition
26562
6.4.11ValidationYes, TestingIEEE 1012
6.4.12OperationYe s32675
23531
6.4.13MaintenanceYe s14764
6.4.14Disposal
Software securityYe sISO/IEC 27000 
family, 15026 
(Parts 1 to 4) 
Software Engineering 
computing foundations
Ye sNumerous  
historic standards
Software Engineering 
Mathematical 
foundations
Ye sNumerous his-
toric standards
Software engineering 
Foundations
Ye sNumerous  
historic standards

B-8   SWEBOK
®
 GUIDE V4.0
focus on production as a stage of interest, an 
alternate  model  for  software  life  cycle  stages  
is  more  useful:  concept,  development,  opera-
tions  and  maintenance,  and  retirement.  Life  
cycle models are characterized by their devel-
opment approach: sequential, incremental, or 
evolutionary.  The  life  cycle  models  are  com-
pared in a risk-based approach.
ISO/IEC/IEEE   24748-2   is   the   overall   
guide to applying the systems engineering pro-
cesses  in  ISO/IEC/IEEE  15288.  However,  
it  does  not  offer  line-by-line  expansions  of  
each  process,  activity,  and  task,  but  presents  
an overall strategy for transitioning to use of 
standardized life cycle processes. There is yet 
more explanation of systems concepts, a pre-
sentation  of  organizational  concepts,  some  
discussion of conformance or adaptation (tai-
loring),  of  standard  processes,  and  an  intro-
duction to model-based systems and software 
engineering (MBSSE).
ISO/IEC/IEEE  24748-3,  guidelines  for  
the  application  of  software  life  cycle  pro-
cesses, also offers commentary on concepts of 
software systems, organizations and projects, 
processes, life cycle states, and life cycle pro-
cess  models  for  software  systems.  It  includes  
guidance  for  each  of  the  processes  in  ISO/
IEC/IEEE  12207,  including  further  anal-
ysis  of  process  purposes;  outcomes  and  out-
puts; activities, tasks, and approaches; closely 
related processes; and related standards.
ISO/IEC/IEEE  32675  DevOps,  (IEEE  
2675)    has    the    informative    subtitle    of    
“Building   Reliable   and   Secure   Systems,   
Including  Application  Build,  Package,  and  
Deployment”. It defines DevOps as a “set of 
principles  and  practices  which  enable  better  
communication  and  collaboration  between  
relevant stakeholders for the purpose of spec-
ifying,  developing,  and  operating  software  
and systems products and services, and con-
tinuous  improvements  in  all  aspects  of  the  
life  cycle.”  It  expounds  on  the  principles  of  
DevOps, including business or mission first, 
customer  focus,  left  shift  and  continuous  
everything,   and   systems   thinking.   (Left-
shift  is  defined  as  “  prioritizing  the  involve-
ment  of  relevant  stakeholders  in  applying  
quality  activities,  security,  privacy,  perfor-
mance, verification, and validation earlier in 
the  life  cycle.”)  IEEE  2675  emphasizes  the  
leadership commitment needed for successful 
application  of  DevOps.  It  reviews  many  of  
the  life  cycle  processes  in  ISO/IEC/IEEE  
12207  to  analyze  how  they  are  transformed  
by DevOps, and discusses the use of DevOps 
with agile methods.
In  earlier  versions,  both  ISO/IEC/IEEE  
24748-4 and 24748-5 covered what to include 
in a management plan (Systems Engineering 
Management  Plan  or  Software  Engineering  
Management  Plan),  respectively.  That  mate-
rial  is  still  there,  but  now  they  also  include  
guidance  for  systems  engineers  and  software  
engineers,  respectively,  on  the  management  
planning  and  control  processes,  with  brief  
presentations of related processes.
4.2 More specialized extensions
Although  standards  are  well  established  for  
specialized  areas  of  health  and  safety,  secu-
rity,  and  environmental  concerns,  standards  
relating  ethical  values  to  software  systems  
are relatively new. The potential for software 
systems  to  cause  harm  through  biased  deci-
sions,  violations  of  privacy,  or  lack  of  social  
responsibility led to the development of ISO/
IEC/IEEE 24748-7000 (IEEE 7000). IEEE 
7000  presents  a  model  process  for  incorpo-
rating  ethical  values  into  systems  design.  
Engineers, their managers, and other stake-
holders benefit from well-defined processes 
for  considering  ethical  issues  along  with  
the  usual  concerns  of  system  performance  
and  functionality  early  in  the  system  life  
cycle.  The  standard  requires  consideration  
of  values  relevant  to  the  culture  where  the  
system  is  to  be  deployed.  It  is  applicable  
with  any  life  cycle  model  or  development  
methodology.  The  processes  in  this  stan-
dard are intended to be performed concur-
rently with those in ISO/IEC/IEEE 12207 
(Table B.3)
Earlier versions of ISO/IEC/IEEE 12207 
were  considered  by  some  to  be  overly  pre-
scriptive in terms of required documentation, 

APPENDIX B   B-9
reviews, and task sequences. The current ver-
sion is intended to be used by any size or type 
of   organization,   having   a   more   strategic,   
agile, approach to the processes, with reduced 
documentation    and    review    requirements.    
However, for highly complex and critical sys-
tems,  a  more  rigorous  and  structured  set  of  
processes,  reviews,  and  audits  was  developed  
in  coordination  with  the  US  Department  
of  Defense  and  has  been  specified  in  ISO/
IEC/IEEE  24748-7:2019  Systems  and  soft-
ware  engineering  —  Life  cycle  management  —  
Part  7:  Application  of  systems  engineering  on  
defense programs and ISO/IEC/IEEE 24748-
8:2019 Systems and software engineering — Life 
cycle  management  —  Part  8:  Technical  reviews  
and audits on defense programs. For more gen-
eral  use,  ISO/IEC  20246  outlines  processes  
and  characteristics  for  work  product  reviews  
throughout the life cycle, covering both soft-
ware and information products.
ISO/IEC/IEEE 24748-9 is an application 
of  system  and  software  life  cycle  processes  
in  epidemic  prevention  and  control  systems.  
More  generally,  it  shows  ways  of  doing  sys-
tems  and  software  engineering  with  lim-
ited  infrastructure  and  staff  support,  such  as  
“insufficient  infrastructure  protection,  short  
delivery  cycles,  frequent  iterative  upgrades,  
and  special  requirements  such  as  accuracy,  
disaster   tolerance,   degradation   capability,   
safety,  user  capacity  and  stress  testing,  and  
rapid demand capture.”
4.3 SoS standards
Three standards explore how the systems and 
software  engineering  concepts  and  processes  
can  be  applied  to  systems  of  systems  (SoS).  
ISO/IEC/IEEE 21839 describes how systems 
that  are  constituents  of  SoS  are  affected  at  
each stage in their life cycle. ISO/IEC/IEEE 
21940 takes the opposite view, exploring con-
cepts  of  an  SoS  and  how  ISO/IEC/IEEE  
15288 can be applied to SoS. ISO/IEC/IEEE 
21841 is a brief taxonomy that identifies four 
types of SoS: directed, acknowledged, collab-
orative and virtual.
5. Single Process Standards
ISO/IEC/IEEE  12207  applies  to  all  types  
of  software  engineering  with  a  variety  of  
life  cycle  models,  techniques,  and  methods.  
Its process descriptions do not go into detail 
about  how  the  process  should  be  performed  
or   which   techniques   are   considered   best   
practice.  To  that  end,  there  are  numerous  
more  specialized  standards  with  additional  
requirements  and  guidelines  applicable  to  
most  of  the  software  engineering  processes.  
Table  B.1  correlates  each  process  in  ISO/
IEC/IEEE  12207  to  the  related  SWEBOK  
KAs,  more  specialized  standards  and  guid-
ance,  and  related  standards  for  applying  the  
process to product lines, tools, and methods. 
Table B.2 shows standards referenced in each 
knowledge area.
6. Standards for product line, methods, and 
tools
A  product  line  is  a  “  set  of  products  or  ser-
vices sharing explicitly defined and managed 
common  and  variable  features  and  relying  
on  the  same  domain  architecture  to  meet  
the  common  and  variable  needs  of  specific  
markets”   (ISO/IEC   26550:2015)   Product   
line   engineering   raises   different   consider-
ations,  especially  for  ongoing  configuration  
and  release  management,  maintenance,  and  
operations,  from  the  basic  approach  of  ISO/
IEC/IEEE  12207,  which  applies  software  
engineering from the perspective of a project 
within an organization.
Standards in the ISO/IEC 26550 to 26569 
series also cover capabilities of tools related to 
various  software  engineering  processes  and  
management  tasks.  Because  software  devel-
opment  and  operations  tool  capabilities  are  
continually being expanded and more tightly 
integrated  to  support  the  DevOps  pipeline,  
the  individual  standards  in  this  series  are  
not  closely  aligned  with  current  commer-
cial  product  suites  or  open-source  libraries.  
However, the tool standards do suggest useful 
features  to  seek  in  support  of  the  software  
lifecycle.

B-10   SWEBOK
®
 GUIDE V4.0
7. Process assessment standards
Process assessment is a long-standing method 
of    confirming    the    capabilities,    quality,    
and  maturity  of  software  engineering  pro-
cesses,   and   encouraging   process   improve-
ment.  Process  audits  look  for  evidence  of  
performance of activities and achievement of 
outcomes  (artifacts  like  work  products  and  
information  items).  The  assumption  is  that  a  
repeatable  process  with  organizational  sup-
port  performed  by  competent  practitioners  
is  more  likely  to  produce  acceptable  soft-
ware  products  and  services.  The  ISO/IEC  
TABLE B.2. STANDARDS CITED BY KNOWLEDGE AREA
K A 
Number
Knowledge Area Cited standards  
(ISO/IEC/IEEE unless otherwise designated)
Introduction 24765, 12207
1Software Requirements24765, 12207, ISO/IEC 25010, 29148
2Software Architecture24765, 12207, 42010
3Software Design12207, 24748-7000, 24765
4Software Construction
5Software TestingIEEE 1012, ISO/IEC 20246, 24765, ISO/IEC 25010, 
29119 (multiple parts), 32675 
6Software Operations12207, ISO/IEC 20000, 24765, 32675
7Software Maintenance12207, 14764, 15288, 32675
8Software Configuration 
Management
IEEE  828, 24765, 12207
9Software Engineering 
Management
1 2 2 0 7, 32 675
10Software 
Engineering Process
12207, 24748-1, 24748-3, 24765, 24774, ISO/IEC 
25000, 29110, 33001, 32675
11Software Engineering 
Models and Methods
12Software QualityIEEE 730, IEEE 982.1, IEEE 1012, IEEE 1228, IEEE 
1633, ISO 9001, 12207, 15026-1, 15288, 20000, 20246, 
24765, 25010, 27001, 33061, 90003,  IEC 60300
13Software SecurityISO/IEC 15408-1, ISO/IEC 18045, ISO/IEC 19770-1, 
ISO/IEC 21827, 25010, ISO/IEC 27000, ISO/IEC 
27001, ISO/IEC 27032
14Software Engineering 
Professional Practice 
ISO/IEC 24773-1, ISO/IEC 24773-4
15Software 
Engineering Economics
1 2 2 0 7, 152 8 8
16Computing Foundations1 2 2 0 7, 2 4765
17Mathematical 
Foundations
18Engineering Foundations24765

APPENDIX B   B-11
33000 family of standards currently includes 
over  twenty  active  standards  related  to  pro-
cess   assessment.   The   overall   architecture   
and  content  of  the  ISO/IEC  330xx  family  
is  described  in  ISO/IEC  33001.  A  process  
assessment  is  conducted  according  to  a  doc-
umented assessment process, which identifies 
the rating method for  process attributes and 
how  to  determine  process  ratings.  ISO/IEC  
33061  is  the  standard  for  process  assessment  
which is aligned with ISO/IEC/IEEE 12207 
software  engineering  processes,  treated  as  a  
process reference model. 
8. Professional Skills and Knowledge 
Standards
The ISO/IEC 24773 series contains require-
ments specifically related to certifications for 
software   and   systems   engineering   profes-
sionals.  It  is  useful  to  industry  organizations  
seeking  to  compare  various  certifications  for  
professionals in systems and/or software engi-
neering; to individual professionals seeking to 
obtain  certification;  and  to  employers  who  
may  choose  to  recognize  such  certifications.  
These standards are intended for international 
use,  and  do  not  replace  national  or  regional  
licensing   or   registration   requirements   for   
engineers.  ISO/IEC  24773-1  is  an  overview  
of certification concepts, and requirements for 
the  certification  processes  and  certification  
schemes  applicable  to  software  and  systems  
engineering. ISO/IEC 24773-4 provides spe-
cific  requirements  for  certification  bodies  in  
software  engineering.  It  specifies  this  IEEE  
SWEBOK  as  the  reference  body  of  knowl-
edge in software engineering.
9. Selected Software Engineering 
Standards
This  is  not  an  exhaustive  list  of  standards  
related   to   software   engineering   or   spon-
sored  by  the  IEEE  Systems  and  Software  
Engineering  Standards  Committee  (S2ESC)  
or  ISO/IEC  JTC  1/SC7,  Software  and  sys-
tems engineering. Those listed are considered 
more  authoritative,  relevant,  and  helpful  for  
SWEBOK users.
The  standards  described  in  this  appendix  
are  continually  being  revised  or  replaced  by  
newer  standards.  Users  of  standards  should  
look for the most recent version and for newer 
titles  relating  to  emerging  topics  in  software  
engineering,  such  as  digital  engineering  or  
standards related to artificial intelligence (AI).
•    IEEE   730-2014   IEEE   Standard   for   
Software Quality Assurance Processes
•    IEEE   828-2012   IEEE   Standard   for   
Configuration  Management  in  Systems  
TABLE B.3. ALIGNMENT OF ETHICAL VALUE PROCESSES IN ISO/IEC/IEEE 
24748-7000 (IEEE 7000) AND SOF TWARE ENGINEERING PROCESSES IN ISO/
IEC/IEEE 12207
IEEE Std 7000 process clause ISO/IEC/IEEE 12207:2017 and ISO/IEC/IEEE 
15288:2023 process clause 
7. Concept of Operations (ConOps) 
and Context Exploration
6.4.1 Business or mission analysis
8. Ethical Values Elicitation and 
Prioritization
6.4.1 Business or mission analysis,  
6.4.2 Stakeholder needs and requirements definition
9. Ethical Requirements Definition 6.4.2 Stakeholder needs and requirements definition,  
6.4.3 System requirements definition
10. Ethical Risk-Based Design 6.4.4 Architecture definition,  
6.4.5 Design definition
11. Transparency Management 6.3.6 Information management

B-12   SWEBOK
®
 GUIDE V4.0
and Software Engineering
•    IEEE     982.1-2005     IEEE     Standard     
Dictionary  of  Measures  of  the  Software  
Aspects of Dependability
•    IEEE     1012-2016     IEEE     Standard     
for   System,   Software,   and   Hardware   
Verification and Validation
•    IEEE     1228-1994     (R2002)     IEEE     
Standard for Software Safety Plans
•    IEEE  1633-2016  IEEE  Recommended  
Practice on Software Reliability
•    ISO   9000:2015   Quality   management   
systems — Fundamentals and vocabulary
•    ISO   9001:2015   Quality   management   
systems — Requirements
•    ISO/IEC/IEEE    12207:2017    Systems    
and    software    engineering:    Software    
engineering processes
•    ISO/IEC  14143  Information  technolo-
gy--Software   measurement--Functional   
size measurement (multiple parts)
•    ISO/ IEC/ IEEE   14764-2021   Sof t wa re   
Engineering    -    Software    Life    Cycle    
Processes - Maintenance
•    ISO/IEC/IEEE  15026-1-2019  Systems  
and Software Engineering—Systems and 
Software  Assurance—  Part  1:  Concepts  
a nd   Vo c a bu l a r y
•    ISO/IEC/IEEE 15026- 2:2021 Systems 
and    Software    Engineering—Systems    
and     Software     Assurance—Part     2:     
Assurance Case
•    ISO/IEC  15026-3:  2023  Systems  and  
Software    Engineering—Systems    and    
Software   Assurance—Part   3:   System   
Integrity Levels
•    ISO/IEC/IEEE  15026-4:2021,  Systems  
and Software Engineering—Systems and 
Software  Assurance—Part  4:  Assurance  
in the Life Cycle
•    ISO/IEC/IEEE   15288:2023   Standard   
for Systems and Software Engineering—
System Life Cycle Processes
•    ISO/IEC/IEEE    15289:2019    Systems    
and   Software   Engineering—   Content   
of    Life-Cycle    Information    Products    
(Documentation)
•    ISO/IEC    15408-1:2022    Information    
security,     cybersecurity     and     privacy     
protection   —   Evaluation   criteria   for   
IT  security  —  Part  1:  Introduction  and  
general model
•    ISO/IEC/IEEE    15939:2017    Systems    
and           Software           Engineering—
Measurement Process
•    ISO/IEC/IEEE    16085:2021    Systems    
and   Software   Engineering—Software   
Life Cycle Processes— Risk Management
•    ISO/IEC/IEEE    16326:2019    Systems    
and  Software  Engineering—Life  Cycle  
Processes—Project Management
•    ISO/IEC 16350:2015 Information tech-
nology  —  Systems  and  software  engi-
neering — Application management
•    ISO/IEC 18045:2022 Information secu-
rity, cybersecurity and privacy protection 
—  Evaluation  criteria  for  IT  security  —  
Methodology for IT security evaluation
•    ISO/IEC         19761:2011         Software         
Engineering—COSMIC:  A  Functional  
Size Measurement Method
•    ISO/IEC     19770-1:2017     Information     
technology  —  IT  asset  management  —  
Part  1:  IT  asset  management  systems  
— Requirements
•    ISO/IEC    19770-2:2015    Information    
technology  —  IT  asset  management  —  
Part 2: Software identification tag
•    ISO/IEC    19770-3:2016    Information    
technology  —  IT  asset  management  —  
Part 3: Entitlement schema
•    ISO/IEC    19770-4:2017    Information    
technology  —  IT  asset  management  —  
Part 4: Resource utilization measurement
•    ISO/IEC    19770-5:2015    Information    
technology  —  IT  asset  management  —  
Part 5: Overview and vocabulary
•    ISO/IEC    19770-8:2020    Information    
technology   —   IT   asset   management   
—  Part  8:  Guidelines  for  mapping  of  
industry  practices  to/from  the  ISO/IEC  
19770 family of standards
•    ISO/IEC   19770-11:2021   Information   
technology  —  IT  asset  management  —  
Part  11:  Requirements  for  bodies  pro-
viding audit and certification of IT asset 
management systems
•    ISO/IEC     20000-1:2018     Information     

APPENDIX B   B-13
Technology—Service        Management—
Part    1:    Service    management    system    
requirements
•    ISO/IEC 20246:2017 Software and sys-
tems engineering -- Work product reviews
•    ISO/IEC  20741:2017  Systems  and  soft-
ware  engineering  —  Guideline  for  the  
evaluation and selection of software engi-
neering tools
•    ISO/IEC    20926:2009    Software    and    
Systems               Engineering—Software               
Measurement—IFPUG  Functional  Size  
Measurement Method SW Requirements
•    ISO/IEC        20968:2002        Software        
Engineering—Mk   II   Function   Point   
Analysis—Counting   Practices   Manual   
SW Requirements
•    ISO/IEC 21827:2008 Information tech-
nology — Security techniques — systems 
security engineering — capability matu-
rity model® (SSE-CMM®)
•    ISO/IEC/IEEE    21839:2019    Systems    
and  software  engineering  —  system  of  
systems (SoS) considerations in life cycle 
stages of a system
•    ISO/IEC/IEEE    21840:2019    Systems    
and  software  engineering  —  Guidelines  
for  the  utilization  of  ISO/IEC/IEEE  
15288   in   the   context   of   system   of   
systems (SoS)
•    ISO/IEC/IEEE    21841:2019    Systems    
and  software  engineering  —  Taxonomy  
of systems of systems
•    ISO/IEC/IEEE    23026:2023    Systems    
and software engineering — Engineering 
and management of websites for systems, 
software, and services information
•    ISO/IEC  23396:2020  Systems  and  soft-
ware   engineering   —   Capabilities   of   
review tools
•    ISO/IEC  23531:2020  Systems  and  soft-
ware engineering — Capabilities of issue 
management tools
•    ISO/IEC   24570:2018   Software   engi-
neering   --   NESMA   functional   size   
measurement  method  --Definitions  and  
counting guidelines for the application of 
function point analysis
•    ISO/IEC/IEEE    24641:2023    Systems    
and  Software  engineering  —  Methods  
and  tools  for  model-based  systems  and  
software engineering
•    ISO/IEC/IEEE  24748-1:2024  Systems  
and  software  engineering  —  Life  cycle  
management  —  Part  1:  Guidelines  for  
life cycle management
•    ISO/IEC/IEEE  24748-2:2024  Systems  
and  software  engineering  —  Life  cycle  
management  —  Part  2:  Guidelines  for  
the application of ISO/IEC/IEEE 15288 
(system life cycle processes)
•    ISO/IEC/IEEE  24748-3:2020  Systems  
and  software  engineering  —  Life  cycle  
management  —  Part  3:  Guidelines  for  
the application of ISO/IEC/IEEE 12207 
(software life cycle processes)
•    ISO/IEC/IEEE  24748-4:2016  Systems  
and  software  engineering  —  Life  cycle  
management  —  Part  4:  Systems  engi-
neering planning
•    ISO/IEC/IEEE  24748-5:2017  Systems  
and  software  engineering  —  Life  cycle  
management  —  Part  5:  Software  devel-
opment planning
•    ISO/IEC/IEEE  24748-6:2023,  Systems  
and Software Engineering — Life Cycle 
Management  —  Part  6:  Systems  and  
Software Integration
•    ISO/IEC/IEEE  24748-7:2019  Systems  
and  software  engineering  —  Life  cycle  
management  —  Part  7:  Application   
of   systems   engineering   on   defense    
programs
•    ISO/IEC/IEEE  24748-8:2019  Systems  
and  software  engineering  —  Life  cycle  
management — Part 8: Technical reviews 
and audits on defense programs
•    ISO/IEC/IEEE  24748-9:2023  Systems  
and software engineering, prevention and 
control systems
•    ISO/IEC/IEEE           24748-7000:2022           
(IEEE  7000:2021)  Model  Process  for  
Addressing   Ethical   Concerns   during   
System Design
•    ISO/IEC/IEEE    24765:2017    Systems    
and Software Engineering — Vocabulary, 
available at www.computer.org/sevocab
•    ISO/IEC   24773-1:2019   Software   and   

B-14   SWEBOK
®
 GUIDE V4.0
systems  engineering  —  Certification  of  
software and systems engineering profes-
sionals — Part 1: General requirements
•    ISO/IEC  24773-4:2023  Software  and  
systems  engineering  —  Certification  of  
software and systems engineering profes-
sionals — Part 4: Software engineering
•    ISO/IEC/IEEE    24774:2021    Systems    
and  software  engineering  —  Life  cycle  
management — Specification for process 
description
•    ISO/IEC  25000:2014  Systems  and  soft-
ware engineering — Systems and software 
Quality   Requirements   and   Evaluation   
(SQuaRE) — Guide to SQuaRE
•    ISO/IEC  25001:2014  Systems  and  soft-
ware engineering — Systems and software 
Quality   Requirements   and   Evaluation   
(SQuaRE) — planning and management
•    ISO/IEC    25010:2023    Systems    and    
software   engineering   —   Systems   and   
software    Quality    Requirements    and    
Evaluation  (SQuaRE)  —  System  and  
software quality models
•    ISO/IEC   25012:2008   Software   engi-
neering   —   Software   product   Quality   
Requirements and Evaluation (SQuaRE) 
— Data quality model
•    ISO/IEC    25020:2019    Systems    and    
software   engineering   —   Systems   and   
software    Quality    Requirements    and    
Evaluation  (SQuaRE)  —  Quality  mea-
surement framework
•    ISO/IEC    25021:2012    Systems    and    
software   engineering   —   Systems   and   
software    Quality    Requirements    and    
Evaluation  (SQuaRE)  —  Quality  mea-
sure elements
•    ISO/IEC    25022:2016    Systems    and    
software   engineering   —   Systems   and   
software  quality  requirements  and  eval-
uation  (SQuaRE)  —  Measurement  of  
quality in use
•    ISO/IEC    25023:2016    Systems    and    
software   engineering   —   Systems   and   
software    Quality    Requirements    and    
Evaluation  (SQuaRE)  —  Measurement  
of system and software product quality
•    ISO/IEC    25024:2015    Systems    and    
software   engineering   —   Systems   and   
software    Quality    Requirements    and    
Evaluation  (SQuaRE)  —  Measurement  
of data quality
•    ISO/IEC    25030:2019    Systems    and    
software   engineering   —   Systems   and   
software  quality  requirements  and  eval-
uation  (SQuaRE)  —  Quality  require-
ments framework
•    ISO/IEC 25040:2011 Systems and soft-
ware engineering — Systems and software 
Quality   Requirements   and   Evaluation   
(SQuaRE) — Evaluation process
•    ISO/IEC    25041:2012    Systems    and    
software   engineering   —   Systems   and   
software    Quality    Requirements    and    
Evaluation   (SQuaRE)   —   Evaluation   
guide for developers, acquirers and inde-
pendent evaluators
•    ISO/IEC    25045:2010    Systems    and    
software   engineering   —   Systems   and   
software    Quality    Requirements    and    
Evaluation   (SQuaRE)   —   Evaluation   
module for recoverability
•    ISO/IEC   25051:2014   Software   engi-
neering — Systems and software Quality 
Requirements and Evaluation (SQuaRE) 
—  Requirements  for  quality  of  Ready  
to  Use  Software  Product  (RUSP)  and  
instructions for testing
•    ISO/IEC    25062    Software    Product    
Quality   Requirements   and   Evaluation   
(SQuaRE)—Common  Industry  Format  
(CIF) for Usability
•    ISO/IEC 26442:2019 Software and sys-
tems engineering--Tools and methods for 
product line architecture design
•    ISO/IEC/IEEE 26511:2018 Systems and 
software  engineering  —  Requirements  
for  managers  of  information  for  users  of  
systems, software, and services
•    ISO/IEC/IEEE 26512:2018 Systems and 
software  engineering  —  Requirements  
for  acquirers  and  suppliers  of  informa-
tion for users
•    ISO/IEC/IEEE 26513:2017 Systems and 
software  engineering  —  Requirements  
for   testers   and   reviewers   of   informa-
tion for users

APPENDIX B   B-15
•    ISO/IEC    26514:2021    Systems    and    
Software     Engineering--Design     and     
development of information for users
•    ISO/IEC/IEEE  26515:2018  Systems  and  
software engineering — Developing infor-
mation for users in an agile environment
•    ISO/IEC/IEEE   26531:2023   Systems   
and   software   engineering   —   Content   
management  for  product  life-cycle,  user  
and service management documentation
•    ISO/IEC  26550:2015  Software  and  sys-
tems  engineering  —  Reference  model  for  
product line engineering and management
•    ISO/IEC 26551:2016 Software and sys-
tems  engineering  —  Tools  and  methods  
for product line requirements engineering
•    ISO/IEC 26552:2019 Software and sys-
tems  engineering  —  Tools  and  methods  
for product line architecture design
•    ISO/IEC  26553:2018  Information  tech-
nology  —  Software  and  systems  engi-
neering — Tools and methods for product 
line realization
•    ISO/IEC 26554:2018 Information tech-
nology  —  Software  and  systems  engi-
neering — Tools and methods for product 
line testing
•    ISO/IEC 26555:2015 Software and sys-
tems  engineering  —  Tools  and  methods  
for product line technical management
•    ISO/IEC 26556:2018 Information tech-
nology  —  Software  and  systems  engi-
neering — Tools and methods for product 
line organizational management
•    ISO/IEC  26557:2016  Software  and  sys-
tems  engineering  —  Methods  and  tools  
for  variability  mechanisms  in  software  
and systems product line
•    ISO/IEC 26558:2017 Software and sys-
tems  engineering  —  Methods  and  tools  
for variability modelling in software and 
systems product line
•    ISO/IEC 26559:2017 Software and sys-
tems  engineering  —  Methods  and  tools  
for variability traceability in software and 
systems product line
•    ISO/IEC 26560:2019 Software and sys-
tems  engineering  —  Tools  and  methods  
for product line product management
•    ISO/IEC 26561:2019 Software and sys-
tems  engineering  —  Methods  and  tools  
for product line technical probe
•    ISO/IEC 26562:2019 Software and sys-
tems  engineering  —  Methods  and  tools  
for product line transition management
•    ISO/IEC 26580:2021 Software and sys-
tems  engineering  —  Methods  and  tools  
for the feature-based approach to software 
and systems product line engineering
•    ISO/IEC      27000:2018      Information      
technology  —  Security  techniques  —  
Information  security  management  sys-
tems — Overview and vocabulary
•    ISO/IEC 27001:2022 Information secu-
rity, cybersecurity and privacy protection 
—   Information   security   management   
systems — Requirements
•    ISO/IEC      27032:2012      Information      
technology  —  Security  techniques  —  
Guidelines for cybersecurity
•    ISO/IEC TR 29110-1:2016 Systems and 
software  engineering  —  Lifecycle  pro-
files  for  Very  Small  Entities  (VSEs)  —  
Part 1: Overview
•    ISO/IEC     29110-2-1:2015     Software     
engineering   —   Lifecycle   profiles   for   
Very  Small  Entities  (VSEs)  —  Part  2-1:  
Framework and taxonomy
•    ISO/IEC  TR  29110-5-3:2018  Systems  
and  software  engineering  —  Lifecycle  
profiles  for  Very  Small  Entities  (VSEs)  
— Part 5-3: Service delivery guidelines
•    ISO/IEC/IEEE 29119-1: 2022 Software 
and    systems    engineering    --Software    
testing --Part 1: Concepts and definitions
•    ISO/IEC/IEEE 29119-2: 2021 Software 
and    systems    engineering    --Software    
testing --Part 2: Test processes
•    ISO/IEC/IEEE 29119-3: 2021 Software 
and   systems   engineering   --   Software   
testing --Part 3: Test documentation
•    ISO/IEC/IEEE  29119-4  Software  and  
systems  engineering--Software  testing--
Part 4: Test techniques
•    ISO/IEC/IEEE 29119-5: 2016 Software 
and   systems   engineering   --   Software   
testing -- Part 5: Keyword-Driven Testing
•    ISO/IEC   TR   29119-6:2021   Software   

B-16   SWEBOK
®
 GUIDE V4.0
and   systems   engineering   —   Software   
testing — Part 6: Guidelines for the use 
of  ISO/IEC/IEEE  29119  (all  parts)  in  
agile projects
•    ISO/IEC  TR  29119-11:2020  Software  
and   systems   engineering   —   Software   
testing  —  Part  11:  Guidelines  on  the  
testing of AI-based systems
•    ISO/IEC/IEEE   29148:2018.   Systems   
and  Software  Engineering—Life  Cycle  
Processes—Requirements    Engineering    
SW Requirements
•    ISO/IEC   30130:2016   Software   engi-
neering   —   Capabilities   of   software   
testing tools
•    ISO/IEC      33001:2015      Information      
technology   —   Process   assessment   —   
Concepts and terminology
•    ISO/IEC      33002:2015      Information      
technology   —   Process   assessment   —   
Requirements   for   performing   process   
assessment
•    ISO/IEC      33003:2015      Information      
technology   —   Process   assessment   —   
Requirements  for  process  measurement  
frameworks
•    ISO/IEC      33004:2015      Information      
technology   —   Process   assessment   —   
Requirements for process reference, pro-
cess assessment and maturity models
•    ISO/IEC  TR  33014:2013  Information  
technology   —   Process   assessment   —   
Guide for process improvement
•    ISO/IEC 33020:2019 Information tech-
nology — Process assessment — Process 
measurement  framework  for  assessment  
of process capability
•    ISO/IEC  TS  33061:2021  Information  
technology   —   Process   assessment   —   
Process  assessment  model  for  software  
life cycle processes
•    ISO/IEC 33063:2015 Information tech-
nology — Process assessment — Process 
assessment model for software testing
•    ISO/IEC/IEEE  32430  Software  engi-
neering    —    Standard    for    software    
non-functional size measurements
•    ISO/IEC/IEEE     32675:2021     (IEEE     
2675:2021)  DevOps:  Building  Reliable  
and Secure Systems Including Application 
Build, Package, and Deployment
•    ISO/IEC  38500:2008  Corporate  gover-
nance of information technology
•    ISO/IEC/IEEE   41062:2023   Software   
engineering  —  Recommended  practice  
for software acquisition
•    ISO/IEC/IEEE  42010:2022  Software,  
systems  and  enterprise  —  Architecture  
description
•    ISO/IEC/IEEE  42020:2019:  Software,  
systems   and   enterprise   —   Architec-
ture processes
•    ISO/IEC/IEEE  42030:  2019  Software,  
systems,  and  enterprise  —  Architecture  
evaluation framework
•    IEC  60300-1:2014  Dependability  man-
agement - Part 1: Guidance for manage-
ment and application.
•    IEC/IEEE  82079-1  2019  Preparation0  
of  Information  for  Use  (Instructions  for  
Use) of Products - Part 1: Principles and 
General Requirements
•    ISO/IEC/IEEE   90003:2018   Software   
engineering    —    Guidelines    for    the    
application  of  ISO  9001:2015  to  com-
puter software

C-1 
CONSOLIDATED REFERENCE LIST
Appendix C
The   Consolidated   Reference   List   identi-
fies   all   recommended   reference   materials   
(to  the  level  of  section  number)  that  accom-
pany  the  breakdown  of  topics  within  each  
knowledge   area   (KA).   This   Consolidated   
Reference  List  is  adopted  by  the  software  
engineering certification and associated pro-
fessional  development  products  offered  by  
the  IEEE  Computer  Society.  KA  Editors  
used  the  references  allocated  to  their  KA  
by  the  Consolidated  Reference  List  as  their  
Recommended References.
Collectively  this  Consolidated  Reference   
List is
•    Complete:  Covering  the  entire  scope  of  
the SWEBOK Guide.
•    Sufficient:   Providing   enough   informa-
tion   to   describe   “generally   accepted”   
knowledge.
•    Consistent:  Not  providing  contradictory  
knowledge nor conflicting practices.
•    Credible: Recognized as providing expert 
treatment.
•    Current: Treating the subject in a manner 
that is commensurate with currently gen-
erally accepted knowledge.
•    Succinct:  As  short  as  possible  (both  in  
number of reference items and in total page 
count) without failing other objectives.
In   total,   there   are   37   reference   mate-
rials below. 
•    J.H.   Allen   et   al.,   Software   Security   
Engineering:    A    Guide    for    Project    
Managers, Addison-Wesley, 2008.
•    M.   Bishop,   Computer   Security:   Art   
and   Science,   2nd   Edition,   Addison-
Wesley, 2018.
•    B.   Boehm   and   R.   Turner,   Balancing   
Agility  and  Discipline:  A  Guide  for  the  
Perplexed, Addison-Wesley, 2003.
•    F.   Bott   et   al.,   Professional   Issues   in   
Software Engineering, 3rd ed., Taylor & 
Francis, 2000.
•    J.G.    Brookshear,    Computer    Science:    
An    Overview,    12th    ed.,    Addison-
Wesley, 2017.
•    D.  Budgen,  Software  Design,  3rd  ed.,  
CRC Press, 2021.
•    E.W.    Cheney    and    D.R.    Kincaid,    
Numerical Mathematics and Computing, 
6th ed., Brooks/Cole, 2007.
•    P. Clements et al., Documenting Software 
Architectures:  Views  and  Beyond,  2nd  
ed., Pearson Education, 2010.
•    R.E.   Fairley,   Managing   and   Leading   
Software Projects, Wiley-IEEE Computer 
Society Press, 2009.
•    C.Y Laporte, A.April, Software Quality 
Assurance,    IEEE    Computer    Society    
Press, 1st ed., 2018.
•    E.   Gamma   et   al.,   Design   Patterns:   
Elements  of  Reusable  Object-Oriented  
Software,    1st    ed.,    Addison-Wesley    
Professional, 1994.
•    P.  Grubb  and  A.A.  Takang,  Software  
Maintenance: Concepts and Practice, 2
nd
 
ed., World Scientific Publishing, 2003.
•    A.M.J. Hass, Configuration Management 
Principles and Practices, 1st ed., Addison- 
Wesley, 2003.
•    S.H.   Kan,   Metrics   and   Models   in   
Software  Quality  Engineering,  2nd  ed.,  
Addison-Wesley, 2002.
•    S. McConnell, Code Complete, 2nd ed., 
Microsoft Press, 2004.
•    J.   McGarry   et   al.,   Practical   Software   
Measurement:    Objective    Information    

C-2   SWEBOK
®
 GUIDE V4.0
for   Decision   Makers,   Addison-Wesley   
Professional, 2001.
•    S.J.  Mellor  and  M.J.  Balcer,  Executable  
UML:    A    Foundation    for    Model-
Driven  Architecture,  1st  ed.,  Addison-
Wesley, 2002.
•    S.   Naik   and   P.   Tripathy,   Software   
Testing  and  Quality  Assurance:  Theory  
and Practice, Wiley-Spektrum, 2008.
•    J. Nielsen, Usability Engineering, 1st ed., 
Morgan Kaufmann, 1993.
•    L.  Null  and  J.  Lobur,  The  Essentials  
of      Computer      Organization      and      
Architecture, 2nd ed., Jones and Bartlett 
Publishers, 2006.
•    M. Page-Jones, Fundamentals of Object-
Oriented   Design   in   UML,   1st   ed.,   
Addison-Wesley, 1999.
•    A.  Silberschatz,  P.B.  Galvin,  and  G.  
Gagne, Operating System Concepts, 8th 
ed., Wiley, 2008.
•    I.  Sommerville,  Software  Engineering,  
10th ed., Addison-Wesley, 2016.
•    S.     Tockey,     Return     on     Software:     
Maximizing    the    Return    on    Your    
Software  Investment,  1st  ed.,  Addison-
Wesley, 2004.
•    G.  Voland,  Engineering  by  Design,  2
nd
 
ed., Prentice Hall, 2003.
•    K.E.  Wiegers,  Software  Requirements,  
3rd ed., Microsoft Press, 2013.
•    J.M. Wing, “A Specifier’s Introduction to 
Formal Methods,” Computer, vol. 23, no. 
9, 1990, pp. 8, 10–23.
•    G. Kim, J. Humble, P. Debois, J. Willis 
and  J.  Allspaw,  The  DevOps  handbook:  
How  to  create  world-class  agility,  reli-
ability, & security in technology organi-
zations, 2nd ed., IT Revolution, 2021.
•    G. Booch, J. Rumbaugh and I. Jacobson, 
The     Unified     Modeling     Language     
User   Guide,   2nd   edition,   Addison-
Wesley, 2005. 
•    N.  Rozanski  and  E.  Woods,  Software  
Systems   Architecture:   Working   with   
Stakeholders    Using    Viewpoints    and    
Perspectives,    2nd    edition,    Addison-
Wesley, 2011. 
•    D. Farley, Modern Software Engineering: 
Doing   What   Works   to   Build   Better   
Software       Faster.       Addison-Wesley       
Professional, 2022.
•    J. Shore and S. Warden, The Art of Agile 
Development,      O’Reilly   Media,   2nd   
Edition, 2021.
•    Project Management Institute and Agile 
Alliance,  Agile  Practice  Guide,  Project  
Management Institute, 2017.
•    D.  C.  Montgomery  and  G.  C.  Runger,  
Applied     Statistics     and     Probability     
for  Engineers,  7th  ed.  Hoboken,  NJ:  
Wiley, 2018.
•    K.   Rosen,   Discrete   Mathematics   and   
its   Applications,   8th   ed.,   McGraw-
Hill, 2018.
•    E.W. Cheney and D.R. Kincaid, Numerical 
Mathematics  and  Computing,  7th  ed.,  
Addison Wesley, 2020.
•    L.  Null  and  J.  Lobur,  The  Essentials  of  
Computer Organization and Architecture, 
5th ed. Sudbury, MA: Jones and Bartlett 
Publishers, 2018.

The Guide to the Software Engineering Body of 
Knowledge (SWEBOK Guide), published by the IEEE 
Computer Society, represents the current state 
of generally accepted knowledge and promotes a 
consistent view of software engineering worldwide. 
Guide Version 4 reflects changes since the publication 
of Guide V3 in 2014, including modern development 
practices, new techniques, and the advancement of 
standards, such as areas and descriptions related to 
agile and DevOps, architecture, operations, security, 
and AI.
IEEE Computer Society is the largest computer 
science and technology community dedicated to 
engaging engineers, scientists, academia, and industry 
professionals from across the globe, driving continued 
advancements.